  [Restored contents truncated]
/Users/pleiades/Documents/work/tpheno/seqmaker/data/CKD/plot/model_evalation-ep200b16.tif

... ... metric loss: [0.40604804654675591, 0.40317532463454736, 0.34859689896966872, 0.42758441591955559, 0.5814931949749409, 0.43697597862155907, 0.40432522848212399, 0.70234414350611241, 0.51132039570635224, 0.39314552167426009] (n=60)
output> saving performance to:
/Users/pleiades/Documents/work/tpheno/seqmaker/data/CKD/plot/model_evalation-ep200b16.tif


model_selection> trying {'n_units': 100, 'dropout_rate': 0.6} ...

make_lstm> n_units=100, r_dropout=0.600000, n_layers=1, n_classes=6
  + lookup:
{'Others': 5, 'CKD Stage 5': 4, 'CKD Stage 4': 3, 'CKD Stage 3': 2, 'CKD Stage 2': 1, 'CKD Stage 1': 0}

... class weights:
{0: 6.344086021505376, 1: 0.74494949494949492, 2: 1.1238095238095238, 3: 7.0238095238095237, 4: 0.51890941072999119, 5: 0.64906490649064907}

====================================================================================================
... early stopping>
       + patience: 100, model='max'
... model training>
       + batch_size: 32, epochs: 60, shuffle? True, metric: auc_roc
====================================================================================================
Train on 1652 samples, validate on 708 samples
Epoch 1/60
1652/1652 [==============================] - 7s 4ms/step - loss: 1.7302 - acc: 0.2100 - auc_roc: 0.5446 - val_loss: 1.9408 - val_acc: 0.1285 - val_auc_roc: 0.5830
Epoch 2/60
1652/1652 [==============================] - 3s 2ms/step - loss: 1.5839 - acc: 0.4140 - auc_roc: 0.6213 - val_loss: 1.6425 - val_acc: 0.5847 - val_auc_roc: 0.6757
Epoch 3/60
1652/1652 [==============================] - 4s 2ms/step - loss: 1.4131 - acc: 0.4594 - auc_roc: 0.7061 - val_loss: 1.3995 - val_acc: 0.6384 - val_auc_roc: 0.7301
Epoch 4/60
1652/1652 [==============================] - 4s 2ms/step - loss: 1.2840 - acc: 0.4794 - auc_roc: 0.7483 - val_loss: 1.6417 - val_acc: 0.5466 - val_auc_roc: 0.7582
Epoch 5/60
1652/1652 [==============================] - 3s 2ms/step - loss: 1.1857 - acc: 0.4921 - auc_roc: 0.7661 - val_loss: 1.3188 - val_acc: 0.6794 - val_auc_roc: 0.7778
Epoch 6/60
1652/1652 [==============================] - 4s 2ms/step - loss: 1.1687 - acc: 0.4794 - auc_roc: 0.7858 - val_loss: 1.5740 - val_acc: 0.5777 - val_auc_roc: 0.7897
Epoch 7/60
1652/1652 [==============================] - 3s 2ms/step - loss: 1.0963 - acc: 0.5260 - auc_roc: 0.7956 - val_loss: 1.7996 - val_acc: 0.4068 - val_auc_roc: 0.7959
Epoch 8/60
1652/1652 [==============================] - 4s 2ms/step - loss: 1.0421 - acc: 0.5545 - auc_roc: 0.7969 - val_loss: 1.6841 - val_acc: 0.6963 - val_auc_roc: 0.8032
Epoch 9/60
1652/1652 [==============================] - 3s 2ms/step - loss: 0.9209 - acc: 0.5769 - auc_roc: 0.8095 - val_loss: 1.5130 - val_acc: 0.6963 - val_auc_roc: 0.8156
Epoch 10/60
1652/1652 [==============================] - 3s 2ms/step - loss: 0.8752 - acc: 0.5787 - auc_roc: 0.8202 - val_loss: 2.1275 - val_acc: 0.5636 - val_auc_roc: 0.8235
Epoch 11/60
1652/1652 [==============================] - 3s 2ms/step - loss: 0.9534 - acc: 0.5805 - auc_roc: 0.8254 - val_loss: 1.6322 - val_acc: 0.7274 - val_auc_roc: 0.8293
Epoch 12/60
1652/1652 [==============================] - 3s 2ms/step - loss: 0.8236 - acc: 0.6114 - auc_roc: 0.8333 - val_loss: 1.8551 - val_acc: 0.6850 - val_auc_roc: 0.8369
Epoch 13/60
1652/1652 [==============================] - 3s 2ms/step - loss: 0.8198 - acc: 0.6392 - auc_roc: 0.8397 - val_loss: 1.8168 - val_acc: 0.6695 - val_auc_roc: 0.8430
Epoch 14/60
1652/1652 [==============================] - 3s 2ms/step - loss: 0.7455 - acc: 0.6277 - auc_roc: 0.8457 - val_loss: 1.8461 - val_acc: 0.6935 - val_auc_roc: 0.8487
Epoch 15/60
1652/1652 [==============================] - 3s 2ms/step - loss: 0.6951 - acc: 0.6525 - auc_roc: 0.8513 - val_loss: 1.7866 - val_acc: 0.6766 - val_auc_roc: 0.8541
Epoch 16/60
1652/1652 [==============================] - 3s 2ms/step - loss: 0.7062 - acc: 0.6707 - auc_roc: 0.8562 - val_loss: 1.8782 - val_acc: 0.7119 - val_auc_roc: 0.8588
Epoch 17/60
1652/1652 [==============================] - 3s 2ms/step - loss: 0.6517 - acc: 0.6780 - auc_roc: 0.8611 - val_loss: 1.9625 - val_acc: 0.7161 - val_auc_roc: 0.8636
Epoch 18/60
1652/1652 [==============================] - 3s 2ms/step - loss: 0.6567 - acc: 0.6858 - auc_roc: 0.8658 - val_loss: 1.9364 - val_acc: 0.7246 - val_auc_roc: 0.8679
Epoch 19/60
1652/1652 [==============================] - 3s 2ms/step - loss: 0.6952 - acc: 0.6580 - auc_roc: 0.8695 - val_loss: 1.8687 - val_acc: 0.5989 - val_auc_roc: 0.8702
Epoch 20/60
1652/1652 [==============================] - 3s 2ms/step - loss: 0.6595 - acc: 0.6804 - auc_roc: 0.8712 - val_loss: 1.7533 - val_acc: 0.6935 - val_auc_roc: 0.8730
Epoch 21/60
1652/1652 [==============================] - 3s 2ms/step - loss: 0.5997 - acc: 0.7094 - auc_roc: 0.8745 - val_loss: 1.9879 - val_acc: 0.7189 - val_auc_roc: 0.8764
Epoch 22/60
1652/1652 [==============================] - 3s 2ms/step - loss: 0.5679 - acc: 0.7161 - auc_roc: 0.8779 - val_loss: 1.8621 - val_acc: 0.7020 - val_auc_roc: 0.8797
Epoch 23/60
1652/1652 [==============================] - 3s 2ms/step - loss: 0.5139 - acc: 0.7379 - auc_roc: 0.8812 - val_loss: 2.1833 - val_acc: 0.6751 - val_auc_roc: 0.8828
Epoch 24/60
1652/1652 [==============================] - 4s 2ms/step - loss: 0.4809 - acc: 0.7609 - auc_roc: 0.8841 - val_loss: 2.2101 - val_acc: 0.7260 - val_auc_roc: 0.8859
Epoch 25/60
1652/1652 [==============================] - 3s 2ms/step - loss: 0.4506 - acc: 0.7778 - auc_roc: 0.8874 - val_loss: 2.1506 - val_acc: 0.7218 - val_auc_roc: 0.8891
Epoch 26/60
1652/1652 [==============================] - 3s 2ms/step - loss: 0.4371 - acc: 0.7869 - auc_roc: 0.8906 - val_loss: 2.2026 - val_acc: 0.7373 - val_auc_roc: 0.8922
Epoch 27/60
1652/1652 [==============================] - 3s 2ms/step - loss: 0.3939 - acc: 0.8208 - auc_roc: 0.8937 - val_loss: 2.2382 - val_acc: 0.7232 - val_auc_roc: 0.8952
Epoch 28/60
1652/1652 [==============================] - 3s 2ms/step - loss: 0.3859 - acc: 0.8335 - auc_roc: 0.8966 - val_loss: 1.9957 - val_acc: 0.7218 - val_auc_roc: 0.8981
Epoch 29/60
1652/1652 [==============================] - 4s 2ms/step - loss: 0.4261 - acc: 0.7960 - auc_roc: 0.8991 - val_loss: 2.5530 - val_acc: 0.7090 - val_auc_roc: 0.9004
Epoch 30/60
1652/1652 [==============================] - 3s 2ms/step - loss: 0.3541 - acc: 0.8360 - auc_roc: 0.9015 - val_loss: 2.4155 - val_acc: 0.7161 - val_auc_roc: 0.9028
Epoch 31/60
1652/1652 [==============================] - 3s 2ms/step - loss: 0.3181 - acc: 0.8565 - auc_roc: 0.9039 - val_loss: 2.6701 - val_acc: 0.7316 - val_auc_roc: 0.9053
Epoch 32/60
1652/1652 [==============================] - 3s 2ms/step - loss: 0.3902 - acc: 0.8063 - auc_roc: 0.9062 - val_loss: 2.5955 - val_acc: 0.6412 - val_auc_roc: 0.9068
Epoch 33/60
1652/1652 [==============================] - 3s 2ms/step - loss: 0.3877 - acc: 0.8196 - auc_roc: 0.9074 - val_loss: 2.7866 - val_acc: 0.5607 - val_auc_roc: 0.9080
Epoch 34/60
1652/1652 [==============================] - 4s 2ms/step - loss: 0.3947 - acc: 0.8232 - auc_roc: 0.9085 - val_loss: 2.3515 - val_acc: 0.5734 - val_auc_roc: 0.9090
Epoch 35/60
1652/1652 [==============================] - 4s 2ms/step - loss: 0.3584 - acc: 0.8341 - auc_roc: 0.9096 - val_loss: 2.5036 - val_acc: 0.6554 - val_auc_roc: 0.9105
Epoch 36/60
1652/1652 [==============================] - 4s 2ms/step - loss: 0.2674 - acc: 0.8759 - auc_roc: 0.9112 - val_loss: 2.6107 - val_acc: 0.7331 - val_auc_roc: 0.9123
Epoch 37/60
1652/1652 [==============================] - 4s 2ms/step - loss: 0.2305 - acc: 0.8856 - auc_roc: 0.9132 - val_loss: 2.6654 - val_acc: 0.7246 - val_auc_roc: 0.9143
Epoch 38/60
1652/1652 [==============================] - 4s 2ms/step - loss: 0.2027 - acc: 0.9146 - auc_roc: 0.9152 - val_loss: 3.0095 - val_acc: 0.7274 - val_auc_roc: 0.9162
Epoch 39/60
1652/1652 [==============================] - 4s 2ms/step - loss: 0.2020 - acc: 0.9056 - auc_roc: 0.9170 - val_loss: 2.7908 - val_acc: 0.7076 - val_auc_roc: 0.9180
Epoch 40/60
1652/1652 [==============================] - 3s 2ms/step - loss: 0.1843 - acc: 0.9183 - auc_roc: 0.9188 - val_loss: 2.8138 - val_acc: 0.7203 - val_auc_roc: 0.9198
Epoch 41/60
1652/1652 [==============================] - 3s 2ms/step - loss: 0.2345 - acc: 0.9140 - auc_roc: 0.9205 - val_loss: 2.9072 - val_acc: 0.6935 - val_auc_roc: 0.9213
Epoch 42/60
1652/1652 [==============================] - 3s 2ms/step - loss: 0.4926 - acc: 0.8178 - auc_roc: 0.9216 - val_loss: 2.5958 - val_acc: 0.7175 - val_auc_roc: 0.9220
Epoch 43/60
1652/1652 [==============================] - 3s 2ms/step - loss: 0.3218 - acc: 0.8692 - auc_roc: 0.9225 - val_loss: 2.3785 - val_acc: 0.7175 - val_auc_roc: 0.9232
Epoch 44/60
1652/1652 [==============================] - 3s 2ms/step - loss: 0.2963 - acc: 0.8577 - auc_roc: 0.9237 - val_loss: 2.6166 - val_acc: 0.7288 - val_auc_roc: 0.9244
Epoch 45/60
1652/1652 [==============================] - 3s 2ms/step - loss: 0.1874 - acc: 0.9183 - auc_roc: 0.9250 - val_loss: 2.6970 - val_acc: 0.7189 - val_auc_roc: 0.9258
Epoch 46/60
1652/1652 [==============================] - 3s 2ms/step - loss: 0.1531 - acc: 0.9322 - auc_roc: 0.9264 - val_loss: 2.9751 - val_acc: 0.7302 - val_auc_roc: 0.9272
Epoch 47/60
1652/1652 [==============================] - 3s 2ms/step - loss: 0.1502 - acc: 0.9413 - auc_roc: 0.9278 - val_loss: 2.5458 - val_acc: 0.6427 - val_auc_roc: 0.9285
Epoch 48/60
1652/1652 [==============================] - 3s 2ms/step - loss: 0.2453 - acc: 0.8886 - auc_roc: 0.9289 - val_loss: 2.5296 - val_acc: 0.6737 - val_auc_roc: 0.9294
Epoch 49/60
1652/1652 [==============================] - 3s 2ms/step - loss: 0.1610 - acc: 0.9298 - auc_roc: 0.9298 - val_loss: 2.4872 - val_acc: 0.7189 - val_auc_roc: 0.9305
Epoch 50/60
1652/1652 [==============================] - 3s 2ms/step - loss: 0.1218 - acc: 0.9492 - auc_roc: 0.9310 - val_loss: 2.6174 - val_acc: 0.7246 - val_auc_roc: 0.9317
Epoch 51/60
1652/1652 [==============================] - 3s 2ms/step - loss: 0.1197 - acc: 0.9504 - auc_roc: 0.9322 - val_loss: 2.9719 - val_acc: 0.7302 - val_auc_roc: 0.9328
Epoch 52/60
1652/1652 [==============================] - 3s 2ms/step - loss: 0.2258 - acc: 0.9219 - auc_roc: 0.9332 - val_loss: 2.9774 - val_acc: 0.7034 - val_auc_roc: 0.9337
Epoch 53/60
1652/1652 [==============================] - 3s 2ms/step - loss: 0.1299 - acc: 0.9455 - auc_roc: 0.9341 - val_loss: 3.0787 - val_acc: 0.7076 - val_auc_roc: 0.9347
Epoch 54/60
1652/1652 [==============================] - 3s 2ms/step - loss: 0.1069 - acc: 0.9576 - auc_roc: 0.9351 - val_loss: 3.2861 - val_acc: 0.7274 - val_auc_roc: 0.9357
Epoch 55/60
1652/1652 [==============================] - 4s 2ms/step - loss: 0.0952 - acc: 0.9631 - auc_roc: 0.9361 - val_loss: 3.1428 - val_acc: 0.7415 - val_auc_roc: 0.9366
Epoch 56/60
1652/1652 [==============================] - 3s 2ms/step - loss: 0.0699 - acc: 0.9697 - auc_roc: 0.9371 - val_loss: 3.3584 - val_acc: 0.7260 - val_auc_roc: 0.9376
Epoch 57/60
1652/1652 [==============================] - 3s 2ms/step - loss: 0.0867 - acc: 0.9613 - auc_roc: 0.9380 - val_loss: 3.1604 - val_acc: 0.7274 - val_auc_roc: 0.9385
Epoch 58/60
1652/1652 [==============================] - 3s 2ms/step - loss: 0.0711 - acc: 0.9697 - auc_roc: 0.9388 - val_loss: 3.5440 - val_acc: 0.7006 - val_auc_roc: 0.9393
Epoch 59/60
1652/1652 [==============================] - 3s 2ms/step - loss: 0.0794 - acc: 0.9728 - auc_roc: 0.9396 - val_loss: 3.2923 - val_acc: 0.7274 - val_auc_roc: 0.9401
Epoch 60/60
1652/1652 [==============================] - 3s 2ms/step - loss: 0.0834 - acc: 0.9679 - auc_roc: 0.9404 - val_loss: 3.3691 - val_acc: 0.7288 - val_auc_roc: 0.9408
... history of metrics comprising: ['acc', 'loss', 'val_auc_roc', 'auc_roc', 'val_acc', 'val_loss']
... ... metric acc: [0.95036319598158681, 0.92191283278546088, 0.94552058096948033, 0.95762711849974658, 0.96307506053268765, 0.96973365588569183, 0.96125907961450541, 0.96973365603001294, 0.9727602904125795, 0.96791767554479424] (n=60)
output> saving performance to:
/Users/pleiades/Documents/work/tpheno/seqmaker/data/CKD/plot/model_evalation-ep200b16.tif

... ... metric loss: [0.11974062364701786, 0.22584861872343406, 0.1298910398351944, 0.10689565651208956, 0.095185320346320795, 0.069901378081150836, 0.086712400070402873, 0.071147900606904707, 0.079430555243757681, 0.083424702534772299] (n=60)
output> saving performance to:
/Users/pleiades/Documents/work/tpheno/seqmaker/data/CKD/plot/model_evalation-ep200b16.tif


model_selection> trying {'n_units': 200, 'dropout_rate': 0.6} ...

make_lstm> n_units=200, r_dropout=0.600000, n_layers=1, n_classes=6
  + lookup:
{'Others': 5, 'CKD Stage 5': 4, 'CKD Stage 4': 3, 'CKD Stage 3': 2, 'CKD Stage 2': 1, 'CKD Stage 1': 0}

... class weights:
{0: 6.344086021505376, 1: 0.74494949494949492, 2: 1.1238095238095238, 3: 7.0238095238095237, 4: 0.51890941072999119, 5: 0.64906490649064907}

====================================================================================================
... early stopping>
       + patience: 100, model='max'
... model training>
       + batch_size: 32, epochs: 60, shuffle? True, metric: auc_roc
====================================================================================================
Train on 1652 samples, validate on 708 samples
Epoch 1/60
1652/1652 [==============================] - 7s 5ms/step - loss: 1.7185 - acc: 0.2355 - auc_roc: 0.5914 - val_loss: 1.9089 - val_acc: 0.1243 - val_auc_roc: 0.5934
Epoch 2/60
1652/1652 [==============================] - 4s 3ms/step - loss: 1.4871 - acc: 0.4346 - auc_roc: 0.6249 - val_loss: 1.4483 - val_acc: 0.6215 - val_auc_roc: 0.6826
Epoch 3/60
1652/1652 [==============================] - 5s 3ms/step - loss: 1.3048 - acc: 0.4522 - auc_roc: 0.7179 - val_loss: 1.5712 - val_acc: 0.4421 - val_auc_roc: 0.7324
Epoch 4/60
1652/1652 [==============================] - 4s 3ms/step - loss: 1.2936 - acc: 0.4328 - auc_roc: 0.7412 - val_loss: 1.5314 - val_acc: 0.6299 - val_auc_roc: 0.7550
Epoch 5/60
1652/1652 [==============================] - 4s 3ms/step - loss: 1.2482 - acc: 0.4485 - auc_roc: 0.7647 - val_loss: 1.5817 - val_acc: 0.5480 - val_auc_roc: 0.7673
Epoch 6/60
1652/1652 [==============================] - 4s 2ms/step - loss: 1.1377 - acc: 0.4933 - auc_roc: 0.7745 - val_loss: 1.3572 - val_acc: 0.5198 - val_auc_roc: 0.7803
Epoch 7/60
1652/1652 [==============================] - 4s 2ms/step - loss: 1.0580 - acc: 0.5333 - auc_roc: 0.7849 - val_loss: 1.5370 - val_acc: 0.6455 - val_auc_roc: 0.7932
Epoch 8/60
1652/1652 [==============================] - 4s 2ms/step - loss: 1.0030 - acc: 0.5442 - auc_roc: 0.7989 - val_loss: 1.7920 - val_acc: 0.5339 - val_auc_roc: 0.8023
Epoch 9/60
1652/1652 [==============================] - 4s 2ms/step - loss: 0.9288 - acc: 0.5611 - auc_roc: 0.8066 - val_loss: 1.6177 - val_acc: 0.7020 - val_auc_roc: 0.8128
Epoch 10/60
1652/1652 [==============================] - 4s 3ms/step - loss: 0.9522 - acc: 0.5563 - auc_roc: 0.8168 - val_loss: 2.0248 - val_acc: 0.3884 - val_auc_roc: 0.8164
Epoch 11/60
1652/1652 [==============================] - 4s 3ms/step - loss: 0.9148 - acc: 0.5623 - auc_roc: 0.8168 - val_loss: 1.6708 - val_acc: 0.6751 - val_auc_roc: 0.8211
Epoch 12/60
1652/1652 [==============================] - 4s 2ms/step - loss: 0.8039 - acc: 0.6065 - auc_roc: 0.8251 - val_loss: 1.6624 - val_acc: 0.6751 - val_auc_roc: 0.8294
Epoch 13/60
1652/1652 [==============================] - 4s 3ms/step - loss: 0.7932 - acc: 0.6144 - auc_roc: 0.8325 - val_loss: 2.0378 - val_acc: 0.5904 - val_auc_roc: 0.8357
Epoch 14/60
1652/1652 [==============================] - 4s 2ms/step - loss: 0.7465 - acc: 0.6374 - auc_roc: 0.8381 - val_loss: 2.0467 - val_acc: 0.6709 - val_auc_roc: 0.8414
Epoch 15/60
1652/1652 [==============================] - 4s 3ms/step - loss: 0.6775 - acc: 0.6598 - auc_roc: 0.8442 - val_loss: 1.8582 - val_acc: 0.7034 - val_auc_roc: 0.8479
Epoch 16/60
1652/1652 [==============================] - 4s 2ms/step - loss: 0.6457 - acc: 0.6695 - auc_roc: 0.8508 - val_loss: 2.3695 - val_acc: 0.5155 - val_auc_roc: 0.8525
Epoch 17/60
1652/1652 [==============================] - 4s 2ms/step - loss: 0.6264 - acc: 0.6762 - auc_roc: 0.8540 - val_loss: 2.0370 - val_acc: 0.6850 - val_auc_roc: 0.8570
Epoch 18/60
1652/1652 [==============================] - 4s 2ms/step - loss: 0.5697 - acc: 0.7161 - auc_roc: 0.8596 - val_loss: 2.2765 - val_acc: 0.7218 - val_auc_roc: 0.8625
Epoch 19/60
1652/1652 [==============================] - 4s 3ms/step - loss: 0.5966 - acc: 0.7185 - auc_roc: 0.8648 - val_loss: 2.4677 - val_acc: 0.3983 - val_auc_roc: 0.8653
Epoch 20/60
1652/1652 [==============================] - 4s 2ms/step - loss: 0.6623 - acc: 0.6610 - auc_roc: 0.8653 - val_loss: 2.0643 - val_acc: 0.7076 - val_auc_roc: 0.8672
Epoch 21/60
1652/1652 [==============================] - 4s 3ms/step - loss: 0.5709 - acc: 0.7209 - auc_roc: 0.8692 - val_loss: 2.3297 - val_acc: 0.6201 - val_auc_roc: 0.8710
Epoch 22/60
1652/1652 [==============================] - 4s 2ms/step - loss: 0.4957 - acc: 0.7458 - auc_roc: 0.8727 - val_loss: 2.3858 - val_acc: 0.7147 - val_auc_roc: 0.8749
Epoch 23/60
1652/1652 [==============================] - 4s 3ms/step - loss: 0.5989 - acc: 0.7076 - auc_roc: 0.8764 - val_loss: 2.0162 - val_acc: 0.5862 - val_auc_roc: 0.8777
Epoch 24/60
1652/1652 [==============================] - 4s 2ms/step - loss: 0.5822 - acc: 0.7113 - auc_roc: 0.8784 - val_loss: 2.0296 - val_acc: 0.6709 - val_auc_roc: 0.8800
Epoch 25/60
1652/1652 [==============================] - 4s 3ms/step - loss: 0.5242 - acc: 0.7324 - auc_roc: 0.8813 - val_loss: 2.1316 - val_acc: 0.6737 - val_auc_roc: 0.8828
Epoch 26/60
1652/1652 [==============================] - 4s 3ms/step - loss: 0.4357 - acc: 0.7797 - auc_roc: 0.8842 - val_loss: 2.4052 - val_acc: 0.6879 - val_auc_roc: 0.8859
Epoch 27/60
1652/1652 [==============================] - 4s 3ms/step - loss: 0.4540 - acc: 0.7663 - auc_roc: 0.8872 - val_loss: 2.4710 - val_acc: 0.6314 - val_auc_roc: 0.8883
Epoch 28/60
1652/1652 [==============================] - 4s 3ms/step - loss: 0.5009 - acc: 0.7609 - auc_roc: 0.8892 - val_loss: 2.5120 - val_acc: 0.6596 - val_auc_roc: 0.8905
Epoch 29/60
1652/1652 [==============================] - 4s 3ms/step - loss: 0.3748 - acc: 0.8166 - auc_roc: 0.8918 - val_loss: 2.6227 - val_acc: 0.6822 - val_auc_roc: 0.8933
Epoch 30/60
1652/1652 [==============================] - 4s 3ms/step - loss: 0.3318 - acc: 0.8341 - auc_roc: 0.8946 - val_loss: 2.5638 - val_acc: 0.7218 - val_auc_roc: 0.8962
Epoch 31/60
1652/1652 [==============================] - 4s 2ms/step - loss: 0.2887 - acc: 0.8584 - auc_roc: 0.8976 - val_loss: 2.9369 - val_acc: 0.7006 - val_auc_roc: 0.8991
Epoch 32/60
1652/1652 [==============================] - 4s 2ms/step - loss: 0.2492 - acc: 0.8820 - auc_roc: 0.9004 - val_loss: 3.0746 - val_acc: 0.7076 - val_auc_roc: 0.9019
Epoch 33/60
1652/1652 [==============================] - 4s 3ms/step - loss: 0.2195 - acc: 0.8874 - auc_roc: 0.9032 - val_loss: 3.2191 - val_acc: 0.7246 - val_auc_roc: 0.9047
Epoch 34/60
1652/1652 [==============================] - 4s 3ms/step - loss: 0.1940 - acc: 0.9086 - auc_roc: 0.9059 - val_loss: 3.0368 - val_acc: 0.7076 - val_auc_roc: 0.9074
Epoch 35/60
1652/1652 [==============================] - 4s 3ms/step - loss: 0.2126 - acc: 0.9001 - auc_roc: 0.9085 - val_loss: 2.8965 - val_acc: 0.7105 - val_auc_roc: 0.9098
Epoch 36/60
1652/1652 [==============================] - 4s 2ms/step - loss: 0.1848 - acc: 0.9207 - auc_roc: 0.9110 - val_loss: 3.9223 - val_acc: 0.7133 - val_auc_roc: 0.9122
Epoch 37/60
1652/1652 [==============================] - 4s 3ms/step - loss: 0.1470 - acc: 0.9473 - auc_roc: 0.9133 - val_loss: 3.1939 - val_acc: 0.6935 - val_auc_roc: 0.9145
Epoch 38/60
1652/1652 [==============================] - 4s 2ms/step - loss: 0.1541 - acc: 0.9407 - auc_roc: 0.9154 - val_loss: 3.4446 - val_acc: 0.7076 - val_auc_roc: 0.9165
Epoch 39/60
1652/1652 [==============================] - 4s 3ms/step - loss: 0.1321 - acc: 0.9431 - auc_roc: 0.9174 - val_loss: 2.9535 - val_acc: 0.7076 - val_auc_roc: 0.9186
Epoch 40/60
1652/1652 [==============================] - 4s 3ms/step - loss: 0.2892 - acc: 0.8783 - auc_roc: 0.9193 - val_loss: 2.1637 - val_acc: 0.7260 - val_auc_roc: 0.9201
Epoch 41/60
1652/1652 [==============================] - 4s 3ms/step - loss: 0.2600 - acc: 0.8826 - auc_roc: 0.9208 - val_loss: 2.6497 - val_acc: 0.6949 - val_auc_roc: 0.9216
Epoch 42/60
1652/1652 [==============================] - 4s 3ms/step - loss: 0.1629 - acc: 0.9334 - auc_roc: 0.9224 - val_loss: 2.6185 - val_acc: 0.6949 - val_auc_roc: 0.9233
Epoch 43/60
1652/1652 [==============================] - 4s 2ms/step - loss: 0.1198 - acc: 0.9473 - auc_roc: 0.9240 - val_loss: 3.1358 - val_acc: 0.7133 - val_auc_roc: 0.9249
Epoch 44/60
1652/1652 [==============================] - 4s 3ms/step - loss: 0.1214 - acc: 0.9516 - auc_roc: 0.9256 - val_loss: 3.0478 - val_acc: 0.7133 - val_auc_roc: 0.9265
Epoch 45/60
1652/1652 [==============================] - 4s 3ms/step - loss: 0.1179 - acc: 0.9516 - auc_roc: 0.9272 - val_loss: 2.9875 - val_acc: 0.7331 - val_auc_roc: 0.9280
Epoch 46/60
1652/1652 [==============================] - 4s 2ms/step - loss: 0.1013 - acc: 0.9613 - auc_roc: 0.9287 - val_loss: 2.9741 - val_acc: 0.7175 - val_auc_roc: 0.9295
Epoch 47/60
1652/1652 [==============================] - 4s 3ms/step - loss: 0.0956 - acc: 0.9619 - auc_roc: 0.9301 - val_loss: 3.4064 - val_acc: 0.7274 - val_auc_roc: 0.9308
Epoch 48/60
1652/1652 [==============================] - 4s 3ms/step - loss: 0.2331 - acc: 0.9292 - auc_roc: 0.9314 - val_loss: 2.4699 - val_acc: 0.6582 - val_auc_roc: 0.9319
Epoch 49/60
1652/1652 [==============================] - 4s 3ms/step - loss: 0.2461 - acc: 0.9025 - auc_roc: 0.9322 - val_loss: 2.5284 - val_acc: 0.6808 - val_auc_roc: 0.9328
Epoch 50/60
1652/1652 [==============================] - 5s 3ms/step - loss: 0.1173 - acc: 0.9552 - auc_roc: 0.9333 - val_loss: 2.8853 - val_acc: 0.6850 - val_auc_roc: 0.9339
Epoch 51/60
1652/1652 [==============================] - 5s 3ms/step - loss: 0.0750 - acc: 0.9703 - auc_roc: 0.9345 - val_loss: 3.0253 - val_acc: 0.7288 - val_auc_roc: 0.9351
Epoch 52/60
1652/1652 [==============================] - 5s 3ms/step - loss: 0.0802 - acc: 0.9709 - auc_roc: 0.9356 - val_loss: 3.1397 - val_acc: 0.7175 - val_auc_roc: 0.9363
Epoch 53/60
1652/1652 [==============================] - 5s 3ms/step - loss: 0.0606 - acc: 0.9746 - auc_roc: 0.9367 - val_loss: 2.9436 - val_acc: 0.7218 - val_auc_roc: 0.9374
Epoch 54/60
1652/1652 [==============================] - 4s 3ms/step - loss: 0.0576 - acc: 0.9764 - auc_roc: 0.9379 - val_loss: 3.3778 - val_acc: 0.7175 - val_auc_roc: 0.9384
Epoch 55/60
1652/1652 [==============================] - 4s 3ms/step - loss: 0.0376 - acc: 0.9849 - auc_roc: 0.9389 - val_loss: 3.2928 - val_acc: 0.7020 - val_auc_roc: 0.9395
Epoch 56/60
1652/1652 [==============================] - 4s 3ms/step - loss: 0.0341 - acc: 0.9867 - auc_roc: 0.9399 - val_loss: 3.3903 - val_acc: 0.7133 - val_auc_roc: 0.9405
Epoch 57/60
1652/1652 [==============================] - 4s 3ms/step - loss: 0.0256 - acc: 0.9921 - auc_roc: 0.9409 - val_loss: 3.5688 - val_acc: 0.7147 - val_auc_roc: 0.9414
Epoch 58/60
1652/1652 [==============================] - 4s 3ms/step - loss: 0.0672 - acc: 0.9764 - auc_roc: 0.9418 - val_loss: 2.9922 - val_acc: 0.6879 - val_auc_roc: 0.9422
Epoch 59/60
1652/1652 [==============================] - 4s 2ms/step - loss: 0.0819 - acc: 0.9709 - auc_roc: 0.9425 - val_loss: 3.2546 - val_acc: 0.7260 - val_auc_roc: 0.9429
Epoch 60/60
1652/1652 [==============================] - 4s 3ms/step - loss: 0.0674 - acc: 0.9800 - auc_roc: 0.9432 - val_loss: 3.0878 - val_acc: 0.6780 - val_auc_roc: 0.9436
... history of metrics comprising: ['acc', 'loss', 'val_auc_roc', 'auc_roc', 'val_acc', 'val_loss']
... ... metric acc: [0.97033898290652632, 0.9709443099273608, 0.97457627118644063, 0.97639225152733833, 0.98486682808716708, 0.98668280871670699, 0.99213075060532685, 0.97639225152733833, 0.97094430978303958, 0.98002421307506049] (n=60)
output> saving performance to:
/Users/pleiades/Documents/work/tpheno/seqmaker/data/CKD/plot/model_evalation-ep200b16.tif

... ... metric loss: [0.075042981789706698, 0.080213172041042086, 0.060624623964326434, 0.057578421867572074, 0.037607340484893642, 0.034138056670583908, 0.02564677285237946, 0.067228647684069581, 0.081931267754506251, 0.067414033562666564] (n=60)
output> saving performance to:
/Users/pleiades/Documents/work/tpheno/seqmaker/data/CKD/plot/model_evalation-ep200b16.tif


model_selection> trying {'n_units': 300, 'dropout_rate': 0.6} ...

make_lstm> n_units=300, r_dropout=0.600000, n_layers=1, n_classes=6
  + lookup:
{'Others': 5, 'CKD Stage 5': 4, 'CKD Stage 4': 3, 'CKD Stage 3': 2, 'CKD Stage 2': 1, 'CKD Stage 1': 0}

... class weights:
{0: 6.344086021505376, 1: 0.74494949494949492, 2: 1.1238095238095238, 3: 7.0238095238095237, 4: 0.51890941072999119, 5: 0.64906490649064907}

====================================================================================================
... early stopping>
       + patience: 100, model='max'
... model training>
       + batch_size: 32, epochs: 60, shuffle? True, metric: auc_roc
====================================================================================================
Train on 1652 samples, validate on 708 samples
Epoch 1/60
1652/1652 [==============================] - 10s 6ms/step - loss: 1.6601 - acc: 0.3099 - auc_roc: 0.6152 - val_loss: 1.8196 - val_acc: 0.3616 - val_auc_roc: 0.6799
Epoch 2/60
1652/1652 [==============================] - 7s 4ms/step - loss: 1.4133 - acc: 0.4431 - auc_roc: 0.7078 - val_loss: 1.7699 - val_acc: 0.3686 - val_auc_roc: 0.7207
Epoch 3/60
1652/1652 [==============================] - 7s 4ms/step - loss: 1.3178 - acc: 0.4370 - auc_roc: 0.7306 - val_loss: 1.8458 - val_acc: 0.2684 - val_auc_roc: 0.7273
Epoch 4/60
1652/1652 [==============================] - 7s 4ms/step - loss: 1.2885 - acc: 0.4134 - auc_roc: 0.7277 - val_loss: 1.5861 - val_acc: 0.5198 - val_auc_roc: 0.7404
Epoch 5/60
1652/1652 [==============================] - 7s 4ms/step - loss: 1.2207 - acc: 0.4600 - auc_roc: 0.7479 - val_loss: 1.7071 - val_acc: 0.5692 - val_auc_roc: 0.7555
Epoch 6/60
1652/1652 [==============================] - 7s 4ms/step - loss: 1.1523 - acc: 0.5176 - auc_roc: 0.7643 - val_loss: 1.4808 - val_acc: 0.6215 - val_auc_roc: 0.7736
Epoch 7/60
1652/1652 [==============================] - 7s 4ms/step - loss: 1.0063 - acc: 0.5454 - auc_roc: 0.7823 - val_loss: 1.8908 - val_acc: 0.6638 - val_auc_roc: 0.7902
Epoch 8/60
1652/1652 [==============================] - 7s 4ms/step - loss: 1.0348 - acc: 0.5212 - auc_roc: 0.7964 - val_loss: 1.7449 - val_acc: 0.5085 - val_auc_roc: 0.7995
Epoch 9/60
1652/1652 [==============================] - 6s 4ms/step - loss: 0.9842 - acc: 0.5611 - auc_roc: 0.8031 - val_loss: 1.5802 - val_acc: 0.5494 - val_auc_roc: 0.8075
Epoch 10/60
1652/1652 [==============================] - 7s 4ms/step - loss: 0.8878 - acc: 0.6035 - auc_roc: 0.8116 - val_loss: 1.5934 - val_acc: 0.5946 - val_auc_roc: 0.8159
Epoch 11/60
1652/1652 [==============================] - 7s 4ms/step - loss: 0.8241 - acc: 0.6229 - auc_roc: 0.8197 - val_loss: 1.7728 - val_acc: 0.6455 - val_auc_roc: 0.8245
Epoch 12/60
1652/1652 [==============================] - 7s 4ms/step - loss: 0.7559 - acc: 0.6538 - auc_roc: 0.8287 - val_loss: 1.6586 - val_acc: 0.6186 - val_auc_roc: 0.8327
Epoch 13/60
1652/1652 [==============================] - 7s 4ms/step - loss: 0.7180 - acc: 0.6568 - auc_roc: 0.8360 - val_loss: 1.7669 - val_acc: 0.6596 - val_auc_roc: 0.8402
Epoch 14/60
1652/1652 [==============================] - 7s 4ms/step - loss: 0.6852 - acc: 0.6646 - auc_roc: 0.8435 - val_loss: 1.8108 - val_acc: 0.6525 - val_auc_roc: 0.8470
Epoch 15/60
1652/1652 [==============================] - 6s 4ms/step - loss: 0.7823 - acc: 0.6247 - auc_roc: 0.8492 - val_loss: 1.7824 - val_acc: 0.6624 - val_auc_roc: 0.8514
Epoch 16/60
1652/1652 [==============================] - 7s 4ms/step - loss: 0.6761 - acc: 0.6659 - auc_roc: 0.8540 - val_loss: 1.8828 - val_acc: 0.6751 - val_auc_roc: 0.8566
Epoch 17/60
1652/1652 [==============================] - 7s 4ms/step - loss: 0.6607 - acc: 0.6665 - auc_roc: 0.8587 - val_loss: 2.0205 - val_acc: 0.6949 - val_auc_roc: 0.8611
Epoch 18/60
1652/1652 [==============================] - 7s 4ms/step - loss: 0.6239 - acc: 0.6864 - auc_roc: 0.8632 - val_loss: 2.0716 - val_acc: 0.7062 - val_auc_roc: 0.8656
Epoch 19/60
1652/1652 [==============================] - 7s 4ms/step - loss: 0.5439 - acc: 0.7403 - auc_roc: 0.8679 - val_loss: 2.0219 - val_acc: 0.6483 - val_auc_roc: 0.8701
Epoch 20/60
1652/1652 [==============================] - 7s 4ms/step - loss: 0.5122 - acc: 0.7494 - auc_roc: 0.8721 - val_loss: 2.3661 - val_acc: 0.6850 - val_auc_roc: 0.8745
Epoch 21/60
1652/1652 [==============================] - 7s 4ms/step - loss: 0.5537 - acc: 0.7373 - auc_roc: 0.8761 - val_loss: 2.0501 - val_acc: 0.6907 - val_auc_roc: 0.8782
Epoch 22/60
1652/1652 [==============================] - 7s 4ms/step - loss: 0.4779 - acc: 0.7676 - auc_roc: 0.8801 - val_loss: 1.9757 - val_acc: 0.7175 - val_auc_roc: 0.8821
Epoch 23/60
1652/1652 [==============================] - 6s 4ms/step - loss: 0.4321 - acc: 0.8021 - auc_roc: 0.8840 - val_loss: 2.6423 - val_acc: 0.6229 - val_auc_roc: 0.8856
Epoch 24/60
1652/1652 [==============================] - 6s 4ms/step - loss: 0.4094 - acc: 0.7875 - auc_roc: 0.8870 - val_loss: 2.3795 - val_acc: 0.6949 - val_auc_roc: 0.8889
Epoch 25/60
1652/1652 [==============================] - 7s 4ms/step - loss: 0.3442 - acc: 0.8299 - auc_roc: 0.8907 - val_loss: 2.4947 - val_acc: 0.7006 - val_auc_roc: 0.8926
Epoch 26/60
1652/1652 [==============================] - 7s 4ms/step - loss: 0.3879 - acc: 0.8208 - auc_roc: 0.8942 - val_loss: 2.2947 - val_acc: 0.7218 - val_auc_roc: 0.8959
Epoch 27/60
1652/1652 [==============================] - 7s 4ms/step - loss: 0.6677 - acc: 0.7300 - auc_roc: 0.8966 - val_loss: 2.6787 - val_acc: 0.7274 - val_auc_roc: 0.8976
Epoch 28/60
1652/1652 [==============================] - 7s 4ms/step - loss: 0.4082 - acc: 0.8063 - auc_roc: 0.8988 - val_loss: 2.1076 - val_acc: 0.7062 - val_auc_roc: 0.9002
Epoch 29/60
1652/1652 [==============================] - 7s 4ms/step - loss: 0.3274 - acc: 0.8499 - auc_roc: 0.9015 - val_loss: 2.7454 - val_acc: 0.6879 - val_auc_roc: 0.9029
Epoch 30/60
1652/1652 [==============================] - 7s 4ms/step - loss: 0.2712 - acc: 0.8674 - auc_roc: 0.9041 - val_loss: 2.3897 - val_acc: 0.6723 - val_auc_roc: 0.9055
Epoch 31/60
1652/1652 [==============================] - 7s 4ms/step - loss: 0.2689 - acc: 0.8820 - auc_roc: 0.9067 - val_loss: 2.6377 - val_acc: 0.6977 - val_auc_roc: 0.9081
Epoch 32/60
1652/1652 [==============================] - 7s 4ms/step - loss: 0.2200 - acc: 0.8983 - auc_roc: 0.9093 - val_loss: 2.8695 - val_acc: 0.7189 - val_auc_roc: 0.9107
Epoch 33/60
1652/1652 [==============================] - 7s 4ms/step - loss: 0.2292 - acc: 0.9062 - auc_roc: 0.9119 - val_loss: 2.6660 - val_acc: 0.6723 - val_auc_roc: 0.9130
Epoch 34/60
1652/1652 [==============================] - 7s 5ms/step - loss: 0.6269 - acc: 0.7936 - auc_roc: 0.9134 - val_loss: 2.2325 - val_acc: 0.6977 - val_auc_roc: 0.9141
Epoch 35/60
1652/1652 [==============================] - 6s 4ms/step - loss: 0.2822 - acc: 0.8783 - auc_roc: 0.9150 - val_loss: 2.4775 - val_acc: 0.6850 - val_auc_roc: 0.9160
Epoch 36/60
1652/1652 [==============================] - 7s 4ms/step - loss: 0.2243 - acc: 0.9074 - auc_roc: 0.9168 - val_loss: 2.5266 - val_acc: 0.7062 - val_auc_roc: 0.9179
Epoch 37/60
1652/1652 [==============================] - 7s 4ms/step - loss: 0.1449 - acc: 0.9316 - auc_roc: 0.9189 - val_loss: 2.8745 - val_acc: 0.7062 - val_auc_roc: 0.9200
Epoch 38/60
1652/1652 [==============================] - 6s 4ms/step - loss: 0.1357 - acc: 0.9443 - auc_roc: 0.9208 - val_loss: 3.1750 - val_acc: 0.7147 - val_auc_roc: 0.9219
Epoch 39/60
1652/1652 [==============================] - 7s 4ms/step - loss: 0.1084 - acc: 0.9552 - auc_roc: 0.9228 - val_loss: 2.7429 - val_acc: 0.7119 - val_auc_roc: 0.9238
Epoch 40/60
1652/1652 [==============================] - 7s 4ms/step - loss: 0.2548 - acc: 0.9219 - auc_roc: 0.9246 - val_loss: 2.6060 - val_acc: 0.5621 - val_auc_roc: 0.9251
Epoch 41/60
1652/1652 [==============================] - 6s 4ms/step - loss: 0.5364 - acc: 0.7996 - auc_roc: 0.9249 - val_loss: 2.1709 - val_acc: 0.6822 - val_auc_roc: 0.9253
Epoch 42/60
1652/1652 [==============================] - 6s 4ms/step - loss: 0.2178 - acc: 0.8989 - auc_roc: 0.9258 - val_loss: 2.6039 - val_acc: 0.6751 - val_auc_roc: 0.9265
Epoch 43/60
1652/1652 [==============================] - 7s 4ms/step - loss: 0.1483 - acc: 0.9383 - auc_roc: 0.9271 - val_loss: 2.8017 - val_acc: 0.6624 - val_auc_roc: 0.9278
Epoch 44/60
1652/1652 [==============================] - 6s 4ms/step - loss: 0.1220 - acc: 0.9473 - auc_roc: 0.9284 - val_loss: 3.1931 - val_acc: 0.5763 - val_auc_roc: 0.9290
Epoch 45/60
1652/1652 [==============================] - 7s 4ms/step - loss: 0.1764 - acc: 0.9298 - auc_roc: 0.9293 - val_loss: 3.0013 - val_acc: 0.6935 - val_auc_roc: 0.9299
Epoch 46/60
1652/1652 [==============================] - 6s 4ms/step - loss: 0.0960 - acc: 0.9534 - auc_roc: 0.9305 - val_loss: 3.3721 - val_acc: 0.7189 - val_auc_roc: 0.9313
Epoch 47/60
1652/1652 [==============================] - 7s 4ms/step - loss: 0.0632 - acc: 0.9740 - auc_roc: 0.9319 - val_loss: 3.4768 - val_acc: 0.7175 - val_auc_roc: 0.9326
Epoch 48/60
1652/1652 [==============================] - 9s 5ms/step - loss: 0.0474 - acc: 0.9849 - auc_roc: 0.9332 - val_loss: 3.7155 - val_acc: 0.7090 - val_auc_roc: 0.9339
Epoch 49/60
1652/1652 [==============================] - 10s 6ms/step - loss: 0.0460 - acc: 0.9843 - auc_roc: 0.9344 - val_loss: 3.8229 - val_acc: 0.7175 - val_auc_roc: 0.9351
Epoch 50/60
1652/1652 [==============================] - 7s 4ms/step - loss: 0.0340 - acc: 0.9885 - auc_roc: 0.9356 - val_loss: 3.8893 - val_acc: 0.7232 - val_auc_roc: 0.9362
Epoch 51/60
1652/1652 [==============================] - 7s 4ms/step - loss: 0.0294 - acc: 0.9915 - auc_roc: 0.9367 - val_loss: 3.8743 - val_acc: 0.7147 - val_auc_roc: 0.9374
Epoch 52/60
1652/1652 [==============================] - 7s 4ms/step - loss: 0.0676 - acc: 0.9734 - auc_roc: 0.9378 - val_loss: 3.4587 - val_acc: 0.7090 - val_auc_roc: 0.9383
Epoch 53/60
1652/1652 [==============================] - 7s 4ms/step - loss: 0.0514 - acc: 0.9812 - auc_roc: 0.9388 - val_loss: 3.7178 - val_acc: 0.7076 - val_auc_roc: 0.9393
Epoch 54/60
1652/1652 [==============================] - 7s 4ms/step - loss: 0.0391 - acc: 0.9873 - auc_roc: 0.9397 - val_loss: 3.6006 - val_acc: 0.6511 - val_auc_roc: 0.9402
Epoch 55/60
1652/1652 [==============================] - 7s 4ms/step - loss: 0.0322 - acc: 0.9915 - auc_roc: 0.9405 - val_loss: 3.6664 - val_acc: 0.7274 - val_auc_roc: 0.9411
Epoch 56/60
1652/1652 [==============================] - 7s 4ms/step - loss: 0.0350 - acc: 0.9873 - auc_roc: 0.9415 - val_loss: 3.8560 - val_acc: 0.6893 - val_auc_roc: 0.9419
Epoch 57/60
1652/1652 [==============================] - 7s 4ms/step - loss: 0.0565 - acc: 0.9812 - auc_roc: 0.9422 - val_loss: 3.6234 - val_acc: 0.7274 - val_auc_roc: 0.9427
Epoch 58/60
1652/1652 [==============================] - 7s 4ms/step - loss: 0.0649 - acc: 0.9728 - auc_roc: 0.9430 - val_loss: 3.4236 - val_acc: 0.6808 - val_auc_roc: 0.9434
Epoch 59/60
1652/1652 [==============================] - 7s 4ms/step - loss: 0.0371 - acc: 0.9909 - auc_roc: 0.9437 - val_loss: 3.6630 - val_acc: 0.6992 - val_auc_roc: 0.9441
Epoch 60/60
1652/1652 [==============================] - 7s 4ms/step - loss: 0.0202 - acc: 0.9933 - auc_roc: 0.9444 - val_loss: 3.7844 - val_acc: 0.7133 - val_auc_roc: 0.9448
... history of metrics comprising: ['acc', 'loss', 'val_auc_roc', 'auc_roc', 'val_acc', 'val_loss']
... ... metric acc: [0.99152542344017125, 0.97336561728909288, 0.98123486668376603, 0.98728813559322037, 0.99152542358449236, 0.98728813530457804, 0.98123486682808714, 0.97276029026825839, 0.99092009670797909, 0.9933414043583535] (n=60)
output> saving performance to:
/Users/pleiades/Documents/work/tpheno/seqmaker/data/CKD/plot/model_evalation-ep200b16.tif

... ... metric loss: [0.029392954855074895, 0.067643516992396943, 0.05143542683369888, 0.039098520282899493, 0.032215918353409222, 0.035012305315051763, 0.056508051867418661, 0.06486966217401241, 0.037129574516206333, 0.020204851931506729] (n=60)
output> saving performance to:
/Users/pleiades/Documents/work/tpheno/seqmaker/data/CKD/plot/model_evalation-ep200b16.tif


model_selection> trying {'n_units': 500, 'dropout_rate': 0.6} ...

make_lstm> n_units=500, r_dropout=0.600000, n_layers=1, n_classes=6
  + lookup:
{'Others': 5, 'CKD Stage 5': 4, 'CKD Stage 4': 3, 'CKD Stage 3': 2, 'CKD Stage 2': 1, 'CKD Stage 1': 0}

... class weights:
{0: 6.344086021505376, 1: 0.74494949494949492, 2: 1.1238095238095238, 3: 7.0238095238095237, 4: 0.51890941072999119, 5: 0.64906490649064907}

====================================================================================================
... early stopping>
       + patience: 100, model='max'
... model training>
       + batch_size: 32, epochs: 60, shuffle? True, metric: auc_roc
====================================================================================================
Train on 1652 samples, validate on 708 samples
Epoch 1/60
1652/1652 [==============================] - 19s 12ms/step - loss: 1.6811 - acc: 0.2857 - auc_roc: 0.6340 - val_loss: 1.6332 - val_acc: 0.5212 - val_auc_roc: 0.6977
Epoch 2/60
1652/1652 [==============================] - 14s 9ms/step - loss: 1.4995 - acc: 0.4268 - auc_roc: 0.7225 - val_loss: 1.3829 - val_acc: 0.5989 - val_auc_roc: 0.7462
Epoch 3/60
1652/1652 [==============================] - 14s 9ms/step - loss: 1.4438 - acc: 0.3844 - auc_roc: 0.7509 - val_loss: 1.7799 - val_acc: 0.2387 - val_auc_roc: 0.7419
Epoch 4/60
1652/1652 [==============================] - 14s 8ms/step - loss: 1.3082 - acc: 0.4709 - auc_roc: 0.7436 - val_loss: 1.5123 - val_acc: 0.5565 - val_auc_roc: 0.7564
Epoch 5/60
1652/1652 [==============================] - 14s 8ms/step - loss: 1.2138 - acc: 0.4915 - auc_roc: 0.7656 - val_loss: 1.6842 - val_acc: 0.4887 - val_auc_roc: 0.7715
Epoch 6/60
1652/1652 [==============================] - 14s 8ms/step - loss: 1.1395 - acc: 0.5297 - auc_roc: 0.7771 - val_loss: 1.7985 - val_acc: 0.5664 - val_auc_roc: 0.7841
Epoch 7/60
1652/1652 [==============================] - 14s 8ms/step - loss: 1.1016 - acc: 0.5484 - auc_roc: 0.7902 - val_loss: 1.9680 - val_acc: 0.3234 - val_auc_roc: 0.7906
Epoch 8/60
1652/1652 [==============================] - 14s 8ms/step - loss: 1.0161 - acc: 0.5611 - auc_roc: 0.7916 - val_loss: 1.5964 - val_acc: 0.6992 - val_auc_roc: 0.7992
Epoch 9/60
1652/1652 [==============================] - 14s 8ms/step - loss: 0.9603 - acc: 0.5757 - auc_roc: 0.8057 - val_loss: 1.8663 - val_acc: 0.4534 - val_auc_roc: 0.8080
Epoch 10/60
1652/1652 [==============================] - 14s 8ms/step - loss: 0.8614 - acc: 0.6011 - auc_roc: 0.8110 - val_loss: 1.7879 - val_acc: 0.6596 - val_auc_roc: 0.8166
Epoch 11/60
1652/1652 [==============================] - 14s 8ms/step - loss: 0.8242 - acc: 0.6301 - auc_roc: 0.8213 - val_loss: 1.9270 - val_acc: 0.6525 - val_auc_roc: 0.8262
Epoch 12/60
1652/1652 [==============================] - 14s 9ms/step - loss: 0.8077 - acc: 0.6271 - auc_roc: 0.8303 - val_loss: 1.9167 - val_acc: 0.5367 - val_auc_roc: 0.8326
Epoch 13/60
1652/1652 [==============================] - 14s 8ms/step - loss: 0.7191 - acc: 0.6525 - auc_roc: 0.8355 - val_loss: 1.8535 - val_acc: 0.6935 - val_auc_roc: 0.8397
Epoch 14/60
1652/1652 [==============================] - 14s 8ms/step - loss: 0.7066 - acc: 0.6574 - auc_roc: 0.8434 - val_loss: 1.7195 - val_acc: 0.5353 - val_auc_roc: 0.8459
Epoch 15/60
1652/1652 [==============================] - 14s 8ms/step - loss: 0.6922 - acc: 0.6810 - auc_roc: 0.8476 - val_loss: 2.0122 - val_acc: 0.5254 - val_auc_roc: 0.8496
Epoch 16/60
1652/1652 [==============================] - 14s 8ms/step - loss: 0.5819 - acc: 0.7143 - auc_roc: 0.8517 - val_loss: 2.0660 - val_acc: 0.7020 - val_auc_roc: 0.8554
Epoch 17/60
1652/1652 [==============================] - 14s 8ms/step - loss: 0.5613 - acc: 0.7179 - auc_roc: 0.8583 - val_loss: 2.0384 - val_acc: 0.6525 - val_auc_roc: 0.8612
Epoch 18/60
1652/1652 [==============================] - 14s 8ms/step - loss: 0.5138 - acc: 0.7615 - auc_roc: 0.8638 - val_loss: 2.1155 - val_acc: 0.6977 - val_auc_roc: 0.8667
Epoch 19/60
1652/1652 [==============================] - 14s 8ms/step - loss: 0.6225 - acc: 0.7094 - auc_roc: 0.8689 - val_loss: 2.1011 - val_acc: 0.6582 - val_auc_roc: 0.8711
Epoch 20/60
1652/1652 [==============================] - 14s 8ms/step - loss: 0.4621 - acc: 0.7760 - auc_roc: 0.8732 - val_loss: 2.1583 - val_acc: 0.7189 - val_auc_roc: 0.8761
Epoch 21/60
1652/1652 [==============================] - 14s 8ms/step - loss: 0.3537 - acc: 0.8287 - auc_roc: 0.8786 - val_loss: 2.3931 - val_acc: 0.7048 - val_auc_roc: 0.8814
Epoch 22/60
1652/1652 [==============================] - 14s 8ms/step - loss: 0.3328 - acc: 0.8420 - auc_roc: 0.8838 - val_loss: 2.3217 - val_acc: 0.7429 - val_auc_roc: 0.8865
Epoch 23/60
1652/1652 [==============================] - 14s 8ms/step - loss: 0.2869 - acc: 0.8608 - auc_roc: 0.8888 - val_loss: 2.2822 - val_acc: 0.7260 - val_auc_roc: 0.8913
Epoch 24/60
1652/1652 [==============================] - 14s 8ms/step - loss: 0.2721 - acc: 0.8674 - auc_roc: 0.8935 - val_loss: 2.8115 - val_acc: 0.7246 - val_auc_roc: 0.8957
Epoch 25/60
1652/1652 [==============================] - 14s 8ms/step - loss: 0.2570 - acc: 0.8856 - auc_roc: 0.8975 - val_loss: 2.1534 - val_acc: 0.7105 - val_auc_roc: 0.8998
Epoch 26/60
1652/1652 [==============================] - 14s 8ms/step - loss: 0.2206 - acc: 0.8953 - auc_roc: 0.9016 - val_loss: 2.5419 - val_acc: 0.7006 - val_auc_roc: 0.9037
Epoch 27/60
1652/1652 [==============================] - 14s 8ms/step - loss: 0.1587 - acc: 0.9322 - auc_roc: 0.9055 - val_loss: 2.8819 - val_acc: 0.7133 - val_auc_roc: 0.9076
Epoch 28/60
1652/1652 [==============================] - 14s 8ms/step - loss: 0.1549 - acc: 0.9262 - auc_roc: 0.9092 - val_loss: 2.3871 - val_acc: 0.6949 - val_auc_roc: 0.9110
Epoch 29/60
1652/1652 [==============================] - 14s 8ms/step - loss: 0.1292 - acc: 0.9510 - auc_roc: 0.9125 - val_loss: 3.0100 - val_acc: 0.7189 - val_auc_roc: 0.9143
Epoch 30/60
1652/1652 [==============================] - 14s 8ms/step - loss: 0.1193 - acc: 0.9449 - auc_roc: 0.9157 - val_loss: 3.0104 - val_acc: 0.6723 - val_auc_roc: 0.9172
Epoch 31/60
1652/1652 [==============================] - 14s 8ms/step - loss: 0.2746 - acc: 0.8850 - auc_roc: 0.9179 - val_loss: 2.5179 - val_acc: 0.6921 - val_auc_roc: 0.9191
Epoch 32/60
1652/1652 [==============================] - 14s 8ms/step - loss: 0.1875 - acc: 0.9274 - auc_roc: 0.9201 - val_loss: 2.5272 - val_acc: 0.7133 - val_auc_roc: 0.9215
Epoch 33/60
1652/1652 [==============================] - 14s 8ms/step - loss: 0.1031 - acc: 0.9619 - auc_roc: 0.9226 - val_loss: 3.1765 - val_acc: 0.7020 - val_auc_roc: 0.9238
Epoch 34/60
1652/1652 [==============================] - 14s 9ms/step - loss: 0.0696 - acc: 0.9722 - auc_roc: 0.9248 - val_loss: 3.1810 - val_acc: 0.6992 - val_auc_roc: 0.9261
Epoch 35/60
1652/1652 [==============================] - 17s 10ms/step - loss: 0.0617 - acc: 0.9746 - auc_roc: 0.9270 - val_loss: 2.8135 - val_acc: 0.7062 - val_auc_roc: 0.9282
Epoch 36/60
1652/1652 [==============================] - 14s 9ms/step - loss: 0.1079 - acc: 0.9552 - auc_roc: 0.9290 - val_loss: 2.5838 - val_acc: 0.6780 - val_auc_roc: 0.9300
Epoch 37/60
1652/1652 [==============================] - 14s 8ms/step - loss: 0.0792 - acc: 0.9703 - auc_roc: 0.9308 - val_loss: 3.0908 - val_acc: 0.7006 - val_auc_roc: 0.9318
Epoch 38/60
1652/1652 [==============================] - 14s 8ms/step - loss: 0.0401 - acc: 0.9855 - auc_roc: 0.9325 - val_loss: 3.1373 - val_acc: 0.6992 - val_auc_roc: 0.9335
Epoch 39/60
1652/1652 [==============================] - 14s 8ms/step - loss: 0.0339 - acc: 0.9909 - auc_roc: 0.9341 - val_loss: 3.1727 - val_acc: 0.7500 - val_auc_roc: 0.9352
Epoch 40/60
1652/1652 [==============================] - 14s 8ms/step - loss: 0.1036 - acc: 0.9564 - auc_roc: 0.9358 - val_loss: 2.5556 - val_acc: 0.7387 - val_auc_roc: 0.9366
Epoch 41/60
1652/1652 [==============================] - 14s 8ms/step - loss: 0.1375 - acc: 0.9516 - auc_roc: 0.9371 - val_loss: 2.9410 - val_acc: 0.6766 - val_auc_roc: 0.9378
Epoch 42/60
1652/1652 [==============================] - 14s 8ms/step - loss: 0.1454 - acc: 0.9504 - auc_roc: 0.9382 - val_loss: 3.1638 - val_acc: 0.6864 - val_auc_roc: 0.9389
Epoch 43/60
1652/1652 [==============================] - 14s 8ms/step - loss: 0.0629 - acc: 0.9800 - auc_roc: 0.9393 - val_loss: 3.0747 - val_acc: 0.6822 - val_auc_roc: 0.9401
Epoch 44/60
1652/1652 [==============================] - 14s 8ms/step - loss: 0.0315 - acc: 0.9927 - auc_roc: 0.9405 - val_loss: 3.3648 - val_acc: 0.7105 - val_auc_roc: 0.9413
Epoch 45/60
1652/1652 [==============================] - 14s 8ms/step - loss: 0.0242 - acc: 0.9939 - auc_roc: 0.9417 - val_loss: 3.6511 - val_acc: 0.6949 - val_auc_roc: 0.9424
Epoch 46/60
1652/1652 [==============================] - 14s 8ms/step - loss: 0.0252 - acc: 0.9927 - auc_roc: 0.9428 - val_loss: 3.2153 - val_acc: 0.6949 - val_auc_roc: 0.9434
Epoch 47/60
1652/1652 [==============================] - 14s 8ms/step - loss: 0.0241 - acc: 0.9927 - auc_roc: 0.9438 - val_loss: 3.3658 - val_acc: 0.7090 - val_auc_roc: 0.9444
Epoch 48/60
1652/1652 [==============================] - 14s 8ms/step - loss: 0.0259 - acc: 0.9927 - auc_roc: 0.9448 - val_loss: 3.7780 - val_acc: 0.7189 - val_auc_roc: 0.9454
Epoch 49/60
1652/1652 [==============================] - 14s 8ms/step - loss: 0.0353 - acc: 0.9849 - auc_roc: 0.9457 - val_loss: 3.5386 - val_acc: 0.7175 - val_auc_roc: 0.9463
Epoch 50/60
1652/1652 [==============================] - 14s 9ms/step - loss: 0.0315 - acc: 0.9903 - auc_roc: 0.9466 - val_loss: 3.3501 - val_acc: 0.7246 - val_auc_roc: 0.9471
Epoch 51/60
1652/1652 [==============================] - 14s 8ms/step - loss: 0.0215 - acc: 0.9946 - auc_roc: 0.9475 - val_loss: 3.2381 - val_acc: 0.7147 - val_auc_roc: 0.9480
Epoch 52/60
1652/1652 [==============================] - 14s 8ms/step - loss: 0.0134 - acc: 0.9970 - auc_roc: 0.9484 - val_loss: 3.4534 - val_acc: 0.7175 - val_auc_roc: 0.9489
Epoch 53/60
1652/1652 [==============================] - 15s 9ms/step - loss: 0.0054 - acc: 1.0000 - auc_roc: 0.9492 - val_loss: 3.7921 - val_acc: 0.7090 - val_auc_roc: 0.9496
Epoch 54/60
1652/1652 [==============================] - 14s 8ms/step - loss: 0.0032 - acc: 1.0000 - auc_roc: 0.9499 - val_loss: 3.9583 - val_acc: 0.7288 - val_auc_roc: 0.9503
Epoch 55/60
1652/1652 [==============================] - 14s 8ms/step - loss: 0.0023 - acc: 1.0000 - auc_roc: 0.9505 - val_loss: 3.9505 - val_acc: 0.7203 - val_auc_roc: 0.9510
Epoch 56/60
1652/1652 [==============================] - 14s 8ms/step - loss: 0.0023 - acc: 1.0000 - auc_roc: 0.9512 - val_loss: 3.9762 - val_acc: 0.7274 - val_auc_roc: 0.9516
Epoch 57/60
1652/1652 [==============================] - 14s 8ms/step - loss: 0.0023 - acc: 0.9994 - auc_roc: 0.9518 - val_loss: 3.8952 - val_acc: 0.7232 - val_auc_roc: 0.9522
Epoch 58/60
1652/1652 [==============================] - 14s 8ms/step - loss: 0.0165 - acc: 0.9970 - auc_roc: 0.9524 - val_loss: 3.4310 - val_acc: 0.7302 - val_auc_roc: 0.9527
Epoch 59/60
1652/1652 [==============================] - 16s 10ms/step - loss: 0.1562 - acc: 0.9413 - auc_roc: 0.9528 - val_loss: 3.2386 - val_acc: 0.6653 - val_auc_roc: 0.9530
Epoch 60/60
1652/1652 [==============================] - 17s 10ms/step - loss: 0.1103 - acc: 0.9546 - auc_roc: 0.9531 - val_loss: 2.9572 - val_acc: 0.6709 - val_auc_roc: 0.9533
... history of metrics comprising: ['acc', 'loss', 'val_auc_roc', 'auc_roc', 'val_acc', 'val_loss']
... ... metric acc: [0.99455205811138014, 0.99697336561743344, 1.0, 1.0, 1.0, 1.0, 0.99939467312348673, 0.99697336561743344, 0.9412832926895659, 0.95460048426150124] (n=60)
output> saving performance to:
/Users/pleiades/Documents/work/tpheno/seqmaker/data/CKD/plot/model_evalation-ep200b16.tif

... ... metric loss: [0.021462274754767197, 0.01344824397877833, 0.0053581202901069967, 0.0031993504613356048, 0.0022510747725739354, 0.0022738626780389802, 0.0023261956421243473, 0.016459375687256979, 0.15617342765914327, 0.11026875945777784] (n=60)
output> saving performance to:
/Users/pleiades/Documents/work/tpheno/seqmaker/data/CKD/plot/model_evalation-ep200b16.tif


model_selection> trying {'n_units': 600, 'dropout_rate': 0.6} ...

make_lstm> n_units=600, r_dropout=0.600000, n_layers=1, n_classes=6
  + lookup:
{'Others': 5, 'CKD Stage 5': 4, 'CKD Stage 4': 3, 'CKD Stage 3': 2, 'CKD Stage 2': 1, 'CKD Stage 1': 0}

... class weights:
{0: 6.344086021505376, 1: 0.74494949494949492, 2: 1.1238095238095238, 3: 7.0238095238095237, 4: 0.51890941072999119, 5: 0.64906490649064907}

====================================================================================================
... early stopping>
       + patience: 100, model='max'
... model training>
       + batch_size: 32, epochs: 60, shuffle? True, metric: auc_roc
====================================================================================================
Train on 1652 samples, validate on 708 samples
Epoch 1/60
1652/1652 [==============================] - 24s 15ms/step - loss: 1.6678 - acc: 0.3130 - auc_roc: 0.6166 - val_loss: 2.2917 - val_acc: 0.1412 - val_auc_roc: 0.6325
Epoch 2/60
1652/1652 [==============================] - 19s 11ms/step - loss: 1.5236 - acc: 0.3372 - auc_roc: 0.6255 - val_loss: 1.9546 - val_acc: 0.2345 - val_auc_roc: 0.6432
Epoch 3/60
1652/1652 [==============================] - 19s 11ms/step - loss: 1.3361 - acc: 0.4576 - auc_roc: 0.6659 - val_loss: 1.6909 - val_acc: 0.4237 - val_auc_roc: 0.6909
Epoch 4/60
1652/1652 [==============================] - 19s 11ms/step - loss: 1.2404 - acc: 0.4534 - auc_roc: 0.7030 - val_loss: 1.7894 - val_acc: 0.5311 - val_auc_roc: 0.7211
Epoch 5/60
1652/1652 [==============================] - 19s 11ms/step - loss: 1.2522 - acc: 0.4455 - auc_roc: 0.7333 - val_loss: 1.8151 - val_acc: 0.2062 - val_auc_roc: 0.7316
Epoch 6/60
1652/1652 [==============================] - 18s 11ms/step - loss: 1.2380 - acc: 0.4334 - auc_roc: 0.7317 - val_loss: 1.5203 - val_acc: 0.6059 - val_auc_roc: 0.7419
Epoch 7/60
1652/1652 [==============================] - 18s 11ms/step - loss: 1.1912 - acc: 0.4588 - auc_roc: 0.7493 - val_loss: 1.8897 - val_acc: 0.2387 - val_auc_roc: 0.7497
Epoch 8/60
1652/1652 [==============================] - 20s 12ms/step - loss: 1.0747 - acc: 0.5260 - auc_roc: 0.7530 - val_loss: 2.1103 - val_acc: 0.2811 - val_auc_roc: 0.7556
Epoch 9/60
1652/1652 [==============================] - 19s 12ms/step - loss: 1.0501 - acc: 0.5176 - auc_roc: 0.7577 - val_loss: 1.7350 - val_acc: 0.5438 - val_auc_roc: 0.7636
Epoch 10/60
1652/1652 [==============================] - 19s 12ms/step - loss: 0.9623 - acc: 0.5636 - auc_roc: 0.7698 - val_loss: 1.7535 - val_acc: 0.5621 - val_auc_roc: 0.7759
Epoch 11/60
1652/1652 [==============================] - 20s 12ms/step - loss: 0.8930 - acc: 0.5866 - auc_roc: 0.7816 - val_loss: 1.8033 - val_acc: 0.5734 - val_auc_roc: 0.7864
Epoch 12/60
1652/1652 [==============================] - 20s 12ms/step - loss: 0.8412 - acc: 0.5914 - auc_roc: 0.7912 - val_loss: 2.1302 - val_acc: 0.5438 - val_auc_roc: 0.7960
Epoch 13/60
1652/1652 [==============================] - 20s 12ms/step - loss: 0.7855 - acc: 0.6229 - auc_roc: 0.8004 - val_loss: 2.0015 - val_acc: 0.6059 - val_auc_roc: 0.8054
Epoch 14/60
1652/1652 [==============================] - 20s 12ms/step - loss: 0.7489 - acc: 0.6598 - auc_roc: 0.8100 - val_loss: 2.0346 - val_acc: 0.6525 - val_auc_roc: 0.8150
Epoch 15/60
1652/1652 [==============================] - 21s 12ms/step - loss: 0.6642 - acc: 0.6707 - auc_roc: 0.8193 - val_loss: 2.0307 - val_acc: 0.6907 - val_auc_roc: 0.8243
Epoch 16/60
1652/1652 [==============================] - 21s 13ms/step - loss: 0.6100 - acc: 0.6937 - auc_roc: 0.8286 - val_loss: 2.0578 - val_acc: 0.6992 - val_auc_roc: 0.8331
Epoch 17/60
1652/1652 [==============================] - 18s 11ms/step - loss: 0.5699 - acc: 0.7179 - auc_roc: 0.8369 - val_loss: 1.8182 - val_acc: 0.6977 - val_auc_roc: 0.8410
Epoch 18/60
1652/1652 [==============================] - 17s 10ms/step - loss: 0.5571 - acc: 0.7561 - auc_roc: 0.8445 - val_loss: 2.0069 - val_acc: 0.6172 - val_auc_roc: 0.8478
Epoch 19/60
1652/1652 [==============================] - 17s 10ms/step - loss: 0.5572 - acc: 0.7282 - auc_roc: 0.8505 - val_loss: 2.2072 - val_acc: 0.6243 - val_auc_roc: 0.8532
Epoch 20/60
1652/1652 [==============================] - 17s 10ms/step - loss: 0.4633 - acc: 0.7706 - auc_roc: 0.8560 - val_loss: 2.4856 - val_acc: 0.6836 - val_auc_roc: 0.8592
Epoch 21/60
1652/1652 [==============================] - 17s 10ms/step - loss: 0.4046 - acc: 0.8039 - auc_roc: 0.8620 - val_loss: 2.4531 - val_acc: 0.6624 - val_auc_roc: 0.8651
Epoch 22/60
1652/1652 [==============================] - 17s 10ms/step - loss: 0.3324 - acc: 0.8408 - auc_roc: 0.8680 - val_loss: 2.5024 - val_acc: 0.7006 - val_auc_roc: 0.8711
Epoch 23/60
1652/1652 [==============================] - 17s 10ms/step - loss: 0.3488 - acc: 0.8232 - auc_roc: 0.8737 - val_loss: 2.3809 - val_acc: 0.6992 - val_auc_roc: 0.8762
Epoch 24/60
1652/1652 [==============================] - 17s 10ms/step - loss: 0.3744 - acc: 0.8208 - auc_roc: 0.8783 - val_loss: 2.4239 - val_acc: 0.6045 - val_auc_roc: 0.8803
Epoch 25/60
1652/1652 [==============================] - 17s 10ms/step - loss: 0.3402 - acc: 0.8450 - auc_roc: 0.8822 - val_loss: 2.5713 - val_acc: 0.6949 - val_auc_roc: 0.8845
Epoch 26/60
1652/1652 [==============================] - 17s 10ms/step - loss: 0.2357 - acc: 0.8923 - auc_roc: 0.8867 - val_loss: 2.6618 - val_acc: 0.6949 - val_auc_roc: 0.8892
Epoch 27/60
1652/1652 [==============================] - 17s 10ms/step - loss: 0.2291 - acc: 0.8923 - auc_roc: 0.8912 - val_loss: 2.5150 - val_acc: 0.6921 - val_auc_roc: 0.8934
Epoch 28/60
1652/1652 [==============================] - 17s 10ms/step - loss: 0.2841 - acc: 0.8656 - auc_roc: 0.8951 - val_loss: 2.7229 - val_acc: 0.6780 - val_auc_roc: 0.8966
Epoch 29/60
1652/1652 [==============================] - 17s 10ms/step - loss: 0.2092 - acc: 0.9056 - auc_roc: 0.8982 - val_loss: 2.3286 - val_acc: 0.6879 - val_auc_roc: 0.9001
Epoch 30/60
1652/1652 [==============================] - 17s 10ms/step - loss: 0.2533 - acc: 0.9098 - auc_roc: 0.9017 - val_loss: 3.0594 - val_acc: 0.6949 - val_auc_roc: 0.9034
Epoch 31/60
1652/1652 [==============================] - 23s 14ms/step - loss: 0.2002 - acc: 0.9201 - auc_roc: 0.9048 - val_loss: 2.6638 - val_acc: 0.6963 - val_auc_roc: 0.9065
Epoch 32/60
1652/1652 [==============================] - 19s 12ms/step - loss: 0.1634 - acc: 0.9310 - auc_roc: 0.9079 - val_loss: 2.5007 - val_acc: 0.7246 - val_auc_roc: 0.9096
Epoch 33/60
1652/1652 [==============================] - 20s 12ms/step - loss: 0.1375 - acc: 0.9401 - auc_roc: 0.9110 - val_loss: 2.7085 - val_acc: 0.7232 - val_auc_roc: 0.9126
Epoch 34/60
1652/1652 [==============================] - 19s 11ms/step - loss: 0.0975 - acc: 0.9631 - auc_roc: 0.9139 - val_loss: 2.9641 - val_acc: 0.7260 - val_auc_roc: 0.9155
Epoch 35/60
1652/1652 [==============================] - 18s 11ms/step - loss: 0.0737 - acc: 0.9728 - auc_roc: 0.9168 - val_loss: 2.9875 - val_acc: 0.7203 - val_auc_roc: 0.9183
Epoch 36/60
1652/1652 [==============================] - 19s 11ms/step - loss: 0.0671 - acc: 0.9758 - auc_roc: 0.9194 - val_loss: 3.2928 - val_acc: 0.7161 - val_auc_roc: 0.9208
Epoch 37/60
1652/1652 [==============================] - 19s 11ms/step - loss: 0.0875 - acc: 0.9752 - auc_roc: 0.9219 - val_loss: 2.7431 - val_acc: 0.7288 - val_auc_roc: 0.9232
Epoch 38/60
1652/1652 [==============================] - 19s 12ms/step - loss: 0.0554 - acc: 0.9818 - auc_roc: 0.9242 - val_loss: 2.8451 - val_acc: 0.7034 - val_auc_roc: 0.9254
Epoch 39/60
1652/1652 [==============================] - 20s 12ms/step - loss: 0.0562 - acc: 0.9818 - auc_roc: 0.9263 - val_loss: 3.2070 - val_acc: 0.7316 - val_auc_roc: 0.9275
Epoch 40/60
1652/1652 [==============================] - 21s 13ms/step - loss: 0.0454 - acc: 0.9879 - auc_roc: 0.9284 - val_loss: 3.1156 - val_acc: 0.7274 - val_auc_roc: 0.9295
Epoch 41/60
1652/1652 [==============================] - 20s 12ms/step - loss: 0.0544 - acc: 0.9800 - auc_roc: 0.9303 - val_loss: 3.2908 - val_acc: 0.7331 - val_auc_roc: 0.9313
Epoch 42/60
1652/1652 [==============================] - 20s 12ms/step - loss: 0.1367 - acc: 0.9576 - auc_roc: 0.9320 - val_loss: 2.5349 - val_acc: 0.6554 - val_auc_roc: 0.9328
Epoch 43/60
1652/1652 [==============================] - 21s 12ms/step - loss: 0.1566 - acc: 0.9485 - auc_roc: 0.9333 - val_loss: 2.6799 - val_acc: 0.7316 - val_auc_roc: 0.9341
Epoch 44/60
1652/1652 [==============================] - 20s 12ms/step - loss: 0.0551 - acc: 0.9831 - auc_roc: 0.9348 - val_loss: 2.7631 - val_acc: 0.7260 - val_auc_roc: 0.9357
Epoch 45/60
1652/1652 [==============================] - 20s 12ms/step - loss: 0.0283 - acc: 0.9939 - auc_roc: 0.9364 - val_loss: 3.4474 - val_acc: 0.7119 - val_auc_roc: 0.9372
Epoch 46/60
1652/1652 [==============================] - 20s 12ms/step - loss: 0.1565 - acc: 0.9510 - auc_roc: 0.9377 - val_loss: 2.6486 - val_acc: 0.7006 - val_auc_roc: 0.9383
Epoch 47/60
1652/1652 [==============================] - 28s 17ms/step - loss: 0.1680 - acc: 0.9280 - auc_roc: 0.9387 - val_loss: 2.5606 - val_acc: 0.6836 - val_auc_roc: 0.9391
Epoch 48/60
1652/1652 [==============================] - 23s 14ms/step - loss: 0.1522 - acc: 0.9479 - auc_roc: 0.9396 - val_loss: 2.9187 - val_acc: 0.6596 - val_auc_roc: 0.9400
Epoch 49/60
1652/1652 [==============================] - 21s 13ms/step - loss: 0.0792 - acc: 0.9715 - auc_roc: 0.9405 - val_loss: 3.0816 - val_acc: 0.7274 - val_auc_roc: 0.9411
Epoch 50/60
1652/1652 [==============================] - 21s 13ms/step - loss: 0.0362 - acc: 0.9879 - auc_roc: 0.9416 - val_loss: 3.3268 - val_acc: 0.7232 - val_auc_roc: 0.9422
Epoch 51/60
1652/1652 [==============================] - 20s 12ms/step - loss: 0.0347 - acc: 0.9891 - auc_roc: 0.9427 - val_loss: 3.2607 - val_acc: 0.7189 - val_auc_roc: 0.9433
Epoch 52/60
1652/1652 [==============================] - 21s 12ms/step - loss: 0.0192 - acc: 0.9952 - auc_roc: 0.9437 - val_loss: 3.6533 - val_acc: 0.7189 - val_auc_roc: 0.9443
Epoch 53/60
1652/1652 [==============================] - 21s 12ms/step - loss: 0.0100 - acc: 0.9970 - auc_roc: 0.9447 - val_loss: 3.8001 - val_acc: 0.7274 - val_auc_roc: 0.9453
Epoch 54/60
1652/1652 [==============================] - 21s 13ms/step - loss: 0.0063 - acc: 0.9988 - auc_roc: 0.9457 - val_loss: 3.8979 - val_acc: 0.7345 - val_auc_roc: 0.9462
Epoch 55/60
1652/1652 [==============================] - 20s 12ms/step - loss: 0.0054 - acc: 0.9988 - auc_roc: 0.9466 - val_loss: 3.8726 - val_acc: 0.7345 - val_auc_roc: 0.9471
Epoch 56/60
1652/1652 [==============================] - 21s 13ms/step - loss: 0.0042 - acc: 0.9988 - auc_roc: 0.9475 - val_loss: 4.0484 - val_acc: 0.7345 - val_auc_roc: 0.9480
Epoch 57/60
1652/1652 [==============================] - 22s 13ms/step - loss: 0.0034 - acc: 1.0000 - auc_roc: 0.9483 - val_loss: 4.0746 - val_acc: 0.7387 - val_auc_roc: 0.9487
Epoch 58/60
1652/1652 [==============================] - 20s 12ms/step - loss: 0.0136 - acc: 0.9939 - auc_roc: 0.9490 - val_loss: 3.8586 - val_acc: 0.6907 - val_auc_roc: 0.9494
Epoch 59/60
1652/1652 [==============================] - 19s 12ms/step - loss: 0.0177 - acc: 0.9952 - auc_roc: 0.9496 - val_loss: 3.5665 - val_acc: 0.7105 - val_auc_roc: 0.9500
Epoch 60/60
1652/1652 [==============================] - 19s 12ms/step - loss: 0.0506 - acc: 0.9824 - auc_roc: 0.9502 - val_loss: 3.1104 - val_acc: 0.7316 - val_auc_roc: 0.9506
... history of metrics comprising: ['acc', 'loss', 'val_auc_roc', 'auc_roc', 'val_acc', 'val_loss']
... ... metric acc: [0.98910411622276029, 0.99515738498789341, 0.99697336561743344, 0.99878934624697335, 0.99878934624697335, 0.99878934624697335, 1.0, 0.99394673123486688, 0.99515738498789341, 0.98244552058111378] (n=60)
output> saving performance to:
/Users/pleiades/Documents/work/tpheno/seqmaker/data/CKD/plot/model_evalation-ep200b16.tif

... ... metric loss: [0.034660809840240288, 0.019220126638319748, 0.0099614841421529401, 0.0063476588193115214, 0.0054381129641388037, 0.0042266473619461276, 0.0034312855274152669, 0.013558242208725766, 0.01769242373004231, 0.050570456468957962] (n=60)
output> saving performance to:
/Users/pleiades/Documents/work/tpheno/seqmaker/data/CKD/plot/model_evalation-ep200b16.tif


model_selection> trying {'n_units': 1000, 'dropout_rate': 0.6} ...

make_lstm> n_units=1000, r_dropout=0.600000, n_layers=1, n_classes=6
  + lookup:
{'Others': 5, 'CKD Stage 5': 4, 'CKD Stage 4': 3, 'CKD Stage 3': 2, 'CKD Stage 2': 1, 'CKD Stage 1': 0}

... class weights:
{0: 6.344086021505376, 1: 0.74494949494949492, 2: 1.1238095238095238, 3: 7.0238095238095237, 4: 0.51890941072999119, 5: 0.64906490649064907}

====================================================================================================
... early stopping>
       + patience: 100, model='max'
... model training>
       + batch_size: 32, epochs: 60, shuffle? True, metric: auc_roc
====================================================================================================
Train on 1652 samples, validate on 708 samples
Epoch 1/60
1652/1652 [==============================] - 63s 38ms/step - loss: 1.6828 - acc: 0.3287 - auc_roc: 0.6749 - val_loss: 1.5541 - val_acc: 0.4873 - val_auc_roc: 0.7285
Epoch 2/60
1652/1652 [==============================] - 52s 32ms/step - loss: 1.5358 - acc: 0.3705 - auc_roc: 0.7359 - val_loss: 1.8328 - val_acc: 0.3489 - val_auc_roc: 0.7289
Epoch 3/60
1652/1652 [==============================] - 51s 31ms/step - loss: 1.3608 - acc: 0.4346 - auc_roc: 0.7370 - val_loss: 1.5678 - val_acc: 0.4477 - val_auc_roc: 0.7501
Epoch 4/60
1652/1652 [==============================] - 55s 33ms/step - loss: 1.3286 - acc: 0.4540 - auc_roc: 0.7579 - val_loss: 1.9204 - val_acc: 0.1596 - val_auc_roc: 0.7508
Epoch 5/60
1652/1652 [==============================] - 53s 32ms/step - loss: 1.2459 - acc: 0.4631 - auc_roc: 0.7486 - val_loss: 2.0022 - val_acc: 0.6299 - val_auc_roc: 0.7591
Epoch 6/60
1652/1652 [==============================] - 53s 32ms/step - loss: 1.2078 - acc: 0.5073 - auc_roc: 0.7677 - val_loss: 1.8217 - val_acc: 0.4873 - val_auc_roc: 0.7721
Epoch 7/60
1652/1652 [==============================] - 54s 33ms/step - loss: 1.1540 - acc: 0.4818 - auc_roc: 0.7758 - val_loss: 1.8265 - val_acc: 0.4223 - val_auc_roc: 0.7774
Epoch 8/60
1652/1652 [==============================] - 58s 35ms/step - loss: 1.0592 - acc: 0.5472 - auc_roc: 0.7806 - val_loss: 2.0372 - val_acc: 0.3644 - val_auc_roc: 0.7829
Epoch 9/60
1652/1652 [==============================] - 54s 32ms/step - loss: 1.0352 - acc: 0.5502 - auc_roc: 0.7854 - val_loss: 1.8257 - val_acc: 0.3291 - val_auc_roc: 0.7867
Epoch 10/60
1652/1652 [==============================] - 54s 33ms/step - loss: 0.9428 - acc: 0.5775 - auc_roc: 0.7890 - val_loss: 2.0155 - val_acc: 0.4492 - val_auc_roc: 0.7929
Epoch 11/60
1652/1652 [==============================] - 53s 32ms/step - loss: 0.8293 - acc: 0.6017 - auc_roc: 0.7971 - val_loss: 1.8972 - val_acc: 0.6554 - val_auc_roc: 0.8022
Epoch 12/60
1652/1652 [==============================] - 62s 38ms/step - loss: 0.7904 - acc: 0.6192 - auc_roc: 0.8070 - val_loss: 2.1520 - val_acc: 0.6144 - val_auc_roc: 0.8117
Epoch 13/60
1652/1652 [==============================] - 57s 34ms/step - loss: 0.7410 - acc: 0.6556 - auc_roc: 0.8162 - val_loss: 1.7133 - val_acc: 0.6469 - val_auc_roc: 0.8208
Epoch 14/60
1652/1652 [==============================] - 54s 32ms/step - loss: 0.6861 - acc: 0.6646 - auc_roc: 0.8250 - val_loss: 1.9141 - val_acc: 0.6977 - val_auc_roc: 0.8296
Epoch 15/60
1652/1652 [==============================] - 3794s 2s/step - loss: 0.8324 - acc: 0.6295 - auc_roc: 0.8327 - val_loss: 1.7738 - val_acc: 0.7020 - val_auc_roc: 0.8360
Epoch 16/60
1652/1652 [==============================] - 50s 30ms/step - loss: 0.6661 - acc: 0.6707 - auc_roc: 0.8392 - val_loss: 1.9137 - val_acc: 0.7006 - val_auc_roc: 0.8427
Epoch 17/60
1652/1652 [==============================] - 42s 25ms/step - loss: 0.5507 - acc: 0.7034 - auc_roc: 0.8462 - val_loss: 1.8774 - val_acc: 0.6653 - val_auc_roc: 0.8497
Epoch 18/60
1652/1652 [==============================] - 40s 24ms/step - loss: 0.5052 - acc: 0.7482 - auc_roc: 0.8529 - val_loss: 2.1695 - val_acc: 0.6540 - val_auc_roc: 0.8561
Epoch 19/60
1652/1652 [==============================] - 40s 24ms/step - loss: 0.4809 - acc: 0.7494 - auc_roc: 0.8589 - val_loss: 2.0787 - val_acc: 0.7218 - val_auc_roc: 0.8623
Epoch 20/60
1652/1652 [==============================] - 40s 24ms/step - loss: 0.4165 - acc: 0.7851 - auc_roc: 0.8654 - val_loss: 2.1585 - val_acc: 0.7147 - val_auc_roc: 0.8686
Epoch 21/60
1652/1652 [==============================] - 41s 25ms/step - loss: 0.3782 - acc: 0.8027 - auc_roc: 0.8716 - val_loss: 2.3010 - val_acc: 0.7218 - val_auc_roc: 0.8745
Epoch 22/60
1652/1652 [==============================] - 41s 25ms/step - loss: 0.3860 - acc: 0.8190 - auc_roc: 0.8769 - val_loss: 2.1017 - val_acc: 0.7415 - val_auc_roc: 0.8797
Epoch 23/60
1652/1652 [==============================] - 42s 25ms/step - loss: 0.3190 - acc: 0.8438 - auc_roc: 0.8823 - val_loss: 2.3780 - val_acc: 0.7260 - val_auc_roc: 0.8850
Epoch 24/60
1652/1652 [==============================] - 43s 26ms/step - loss: 0.2951 - acc: 0.8590 - auc_roc: 0.8873 - val_loss: 2.3737 - val_acc: 0.7062 - val_auc_roc: 0.8898
Epoch 25/60
1652/1652 [==============================] - 43s 26ms/step - loss: 0.2478 - acc: 0.8808 - auc_roc: 0.8920 - val_loss: 2.3952 - val_acc: 0.7302 - val_auc_roc: 0.8944
Epoch 26/60
1652/1652 [==============================] - 43s 26ms/step - loss: 0.1988 - acc: 0.9038 - auc_roc: 0.8965 - val_loss: 2.5060 - val_acc: 0.7076 - val_auc_roc: 0.8987
Epoch 27/60
1652/1652 [==============================] - 46s 28ms/step - loss: 0.1832 - acc: 0.9153 - auc_roc: 0.9006 - val_loss: 2.4457 - val_acc: 0.7401 - val_auc_roc: 0.9028
Epoch 28/60
1652/1652 [==============================] - 41s 25ms/step - loss: 0.1848 - acc: 0.9171 - auc_roc: 0.9046 - val_loss: 2.9692 - val_acc: 0.7218 - val_auc_roc: 0.9065
Epoch 29/60
1652/1652 [==============================] - 45s 27ms/step - loss: 0.1264 - acc: 0.9431 - auc_roc: 0.9082 - val_loss: 2.7819 - val_acc: 0.7514 - val_auc_roc: 0.9102
Epoch 30/60
1652/1652 [==============================] - 44s 27ms/step - loss: 0.1018 - acc: 0.9558 - auc_roc: 0.9119 - val_loss: 3.0319 - val_acc: 0.7147 - val_auc_roc: 0.9136
Epoch 31/60
1652/1652 [==============================] - 56s 34ms/step - loss: 0.0748 - acc: 0.9691 - auc_roc: 0.9151 - val_loss: 3.2274 - val_acc: 0.6850 - val_auc_roc: 0.9167
Epoch 32/60
1652/1652 [==============================] - 48s 29ms/step - loss: 0.0547 - acc: 0.9824 - auc_roc: 0.9179 - val_loss: 3.3539 - val_acc: 0.7274 - val_auc_roc: 0.9196
Epoch 33/60
1652/1652 [==============================] - 46s 28ms/step - loss: 0.0780 - acc: 0.9667 - auc_roc: 0.9208 - val_loss: 2.7397 - val_acc: 0.7260 - val_auc_roc: 0.9222
Epoch 34/60
1652/1652 [==============================] - 41s 25ms/step - loss: 0.3148 - acc: 0.8711 - auc_roc: 0.9231 - val_loss: 3.0527 - val_acc: 0.4958 - val_auc_roc: 0.9235
Epoch 35/60
1652/1652 [==============================] - 41s 25ms/step - loss: 0.3745 - acc: 0.8632 - auc_roc: 0.9237 - val_loss: 2.6443 - val_acc: 0.7175 - val_auc_roc: 0.9246
Epoch 36/60
1652/1652 [==============================] - 41s 25ms/step - loss: 0.1749 - acc: 0.9340 - auc_roc: 0.9255 - val_loss: 2.4341 - val_acc: 0.7316 - val_auc_roc: 0.9266
Epoch 37/60
1652/1652 [==============================] - 42s 25ms/step - loss: 0.1136 - acc: 0.9619 - auc_roc: 0.9275 - val_loss: 2.5142 - val_acc: 0.7246 - val_auc_roc: 0.9286
Epoch 38/60
1652/1652 [==============================] - 40s 24ms/step - loss: 0.0980 - acc: 0.9673 - auc_roc: 0.9295 - val_loss: 2.5742 - val_acc: 0.7175 - val_auc_roc: 0.9306
Epoch 39/60
1652/1652 [==============================] - 43s 26ms/step - loss: 0.0586 - acc: 0.9806 - auc_roc: 0.9314 - val_loss: 3.2600 - val_acc: 0.7246 - val_auc_roc: 0.9325
Epoch 40/60
1652/1652 [==============================] - 45s 27ms/step - loss: 0.0229 - acc: 0.9958 - auc_roc: 0.9333 - val_loss: 3.3599 - val_acc: 0.7288 - val_auc_roc: 0.9343
Epoch 41/60
1652/1652 [==============================] - 41s 25ms/step - loss: 0.0197 - acc: 0.9939 - auc_roc: 0.9350 - val_loss: 3.5790 - val_acc: 0.7288 - val_auc_roc: 0.9360
Epoch 42/60
1652/1652 [==============================] - 40s 24ms/step - loss: 0.0261 - acc: 0.9933 - auc_roc: 0.9366 - val_loss: 3.4956 - val_acc: 0.7105 - val_auc_roc: 0.9375
Epoch 43/60
1652/1652 [==============================] - 41s 25ms/step - loss: 0.0209 - acc: 0.9958 - auc_roc: 0.9381 - val_loss: 3.2613 - val_acc: 0.7387 - val_auc_roc: 0.9390
Epoch 44/60
1652/1652 [==============================] - 40s 24ms/step - loss: 0.0132 - acc: 0.9976 - auc_roc: 0.9396 - val_loss: 3.5567 - val_acc: 0.7133 - val_auc_roc: 0.9403
Epoch 45/60
1652/1652 [==============================] - 40s 24ms/step - loss: 0.0091 - acc: 0.9994 - auc_roc: 0.9408 - val_loss: 3.6655 - val_acc: 0.7161 - val_auc_roc: 0.9416
Epoch 46/60
1652/1652 [==============================] - 40s 24ms/step - loss: 0.0069 - acc: 0.9982 - auc_roc: 0.9421 - val_loss: 3.7097 - val_acc: 0.7232 - val_auc_roc: 0.9427
Epoch 47/60
1652/1652 [==============================] - 42s 25ms/step - loss: 0.0031 - acc: 1.0000 - auc_roc: 0.9432 - val_loss: 3.7538 - val_acc: 0.7147 - val_auc_roc: 0.9438
Epoch 48/60
1652/1652 [==============================] - 39s 23ms/step - loss: 0.0041 - acc: 0.9994 - auc_roc: 0.9443 - val_loss: 3.8284 - val_acc: 0.7218 - val_auc_roc: 0.9449
Epoch 49/60
1652/1652 [==============================] - 41s 25ms/step - loss: 0.0025 - acc: 1.0000 - auc_roc: 0.9453 - val_loss: 3.9713 - val_acc: 0.7105 - val_auc_roc: 0.9458
Epoch 50/60
1652/1652 [==============================] - 41s 25ms/step - loss: 0.0024 - acc: 0.9994 - auc_roc: 0.9462 - val_loss: 4.1249 - val_acc: 0.7218 - val_auc_roc: 0.9467
Epoch 51/60
1652/1652 [==============================] - 41s 25ms/step - loss: 0.0011 - acc: 1.0000 - auc_roc: 0.9470 - val_loss: 4.1821 - val_acc: 0.7161 - val_auc_roc: 0.9475
Epoch 52/60
1652/1652 [==============================] - 46s 28ms/step - loss: 0.0011 - acc: 1.0000 - auc_roc: 0.9478 - val_loss: 4.2205 - val_acc: 0.7218 - val_auc_roc: 0.9483
Epoch 53/60
1652/1652 [==============================] - 41s 25ms/step - loss: 7.0531e-04 - acc: 1.0000 - auc_roc: 0.9486 - val_loss: 4.3736 - val_acc: 0.7133 - val_auc_roc: 0.9490
Epoch 54/60
1652/1652 [==============================] - 40s 24ms/step - loss: 8.9464e-04 - acc: 1.0000 - auc_roc: 0.9493 - val_loss: 4.4923 - val_acc: 0.7161 - val_auc_roc: 0.9497
Epoch 55/60
1652/1652 [==============================] - 41s 25ms/step - loss: 5.5604e-04 - acc: 1.0000 - auc_roc: 0.9499 - val_loss: 4.4550 - val_acc: 0.7218 - val_auc_roc: 0.9503
Epoch 56/60
1652/1652 [==============================] - 45s 27ms/step - loss: 4.1548e-04 - acc: 1.0000 - auc_roc: 0.9505 - val_loss: 4.5383 - val_acc: 0.7175 - val_auc_roc: 0.9509
Epoch 57/60
1652/1652 [==============================] - 42s 26ms/step - loss: 5.2705e-04 - acc: 1.0000 - auc_roc: 0.9511 - val_loss: 4.5262 - val_acc: 0.7175 - val_auc_roc: 0.9515
Epoch 58/60
1652/1652 [==============================] - 40s 24ms/step - loss: 7.3020e-04 - acc: 1.0000 - auc_roc: 0.9516 - val_loss: 4.5282 - val_acc: 0.7203 - val_auc_roc: 0.9520
Epoch 59/60
1652/1652 [==============================] - 40s 24ms/step - loss: 7.3453e-04 - acc: 1.0000 - auc_roc: 0.9522 - val_loss: 4.4094 - val_acc: 0.7260 - val_auc_roc: 0.9525
Epoch 60/60
1652/1652 [==============================] - 41s 25ms/step - loss: 5.2312e-04 - acc: 1.0000 - auc_roc: 0.9527 - val_loss: 4.4152 - val_acc: 0.7218 - val_auc_roc: 0.9530
... history of metrics comprising: ['acc', 'loss', 'val_auc_roc', 'auc_roc', 'val_acc', 'val_loss']
... ... metric acc: [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0] (n=60)
output> saving performance to:
/Users/pleiades/Documents/work/tpheno/seqmaker/data/CKD/plot/model_evalation-ep200b16.tif

... ... metric loss: [0.0010924683328487935, 0.0010947185972582584, 0.00070530827426110317, 0.00089463948481603467, 0.00055604000191359845, 0.0004154801996489344, 0.00052705012655368218, 0.00073020413521334489, 0.00073453205562654437, 0.00052311769386439988] (n=60)
output> saving performance to:
/Users/pleiades/Documents/work/tpheno/seqmaker/data/CKD/plot/model_evalation-ep200b16.tif

result> performance scores ...

Traceback (most recent call last):
  File "dnn_utils.py", line 2521, in <module>
    test2()
  File "dnn_utils.py", line 2508, in test2
    last_n_visits=tset['last_n_visits'])
  File "dnn_utils.py", line 2251, in t_deep_classify
    opt = rank_model(target_metric=targetMetric)  # rank hyperparams and their scores
  File "dnn_utils.py", line 2093, in rank_model
    popularModels.update(((k, v) for k, v in setting.items()))
AttributeError: 'numpy.float64' object has no attribute 'items'
pleiades@~/Documents/work/tpheno/seqmaker\:) python dnn_utils.py 
  File "dnn_utils.py", line 2304
    param_grid = {'n_units': [150, 200, 300, 400], 'dropout_rate': [0.2, 0.3, 0.4 0.5, 0.6, ]}
                                                                                    ^
SyntaxError: invalid syntax
pleiades@~/Documents/work/tpheno/seqmaker\:) python dnn_utils.py 
Using TensorFlow backend.
config> d2v: pv-dm2, user descriptor (model, tset, mcs): smallCKD
        cohort: CKD, ctype: regular
            + augmented? False, simplified? False dir_type=combined
check> sysConfig complete ... meta? smallCKD
load_data> inputs:
['/Users/pleiades/Documents/work/tpheno/seqmaker/data/CKD/condition_drug_labeled_seq-CKD.csv']

================================================================================
1. Read temporal doc files ...
================================================================================
loadDocuments> input files: ['/Users/pleiades/Documents/work/tpheno/seqmaker/data/CKD/condition_drug_labeled_seq-CKD.csv']
readDocFromCSV> input files: ['/Users/pleiades/Documents/work/tpheno/seqmaker/data/CKD/condition_drug_labeled_seq-CKD.csv']
read> reading from 1 source files:
['/Users/pleiades/Documents/work/tpheno/seqmaker/data/CKD/condition_drug_labeled_seq-CKD.csv']

read> processing header sequence ...
read> processing header timestamp ...
read> processing header label ...
    + labels (converted to single-label format, n=11): ['CKD G1-control' 'CKD G1A1-control' 'CKD Stage 1' 'CKD Stage 2'
 'CKD Stage 3a' 'CKD Stage 3b' 'CKD Stage 4' 'CKD Stage 5'
 'ESRD after transplant' 'ESRD on dialysis' 'Unknown']
seqReaderApp.load> nD: 2833, nT: 2833, nL: 2833
  + Stats: n_docs: 2833, n_classes:11 | cohort: CKD
processDocuments> Begin document transformation operations (e.g. simplify, diag-only, etc)
filterDocuments> Policy: Remove empty documents ...
transformDocuments> nD: 2833 (<- 2833), nT: 2833, nL: 2833
  + Stats: n_docs: 2833, n_classes:11
transformDocuments2> nD: 2360, nT: 2360, nL: 2360
  + Stats: n_docs: 2360, n_classes:11 | cohort: ?
    + (after transform) nDoc: 2833 -> 2360, size(D0): 16 -> 16
    + (after transform) nD: 2360, nT: 2360, nL: 2360
  + nD: 2360 | cohort=CKD, ctype=regular, labeled? True, simplified? False
  + doc(last 150 chars):
['V82.9', '716.59', '725', '725', '786.51', '272.0', 'V16.0', '530.11', '535.10', '578.9', '531.90', '578.1', '531.00', 'V16.0', '535.00', '530.81', '285.9', 'V76.51', 'V16.0', '211.3', '562.10', '455.0', '280.9', '531.40', '564.00', '280.9', '530.11', '211.3', '786.51', '272.0', 'V15.82', '244.9', '600.00', '401.9', '413.9', '272.0', '584.5', '414.01', 'MED:60439', 'MED:63302', 'MED:62934', 'MED:61889', 'MED:75069', 'MED:61211', 'MED:60887', 'MED:61892', 'MED:62147', 'MED:63114', 'MED:61319', 'MED:62094', '414.10', '530.11', '211.3', '286.0', '585.9', 'V15.82', '786.50', '244.9', '996.72', '600.00', '428.0', '413.9', 'E878.1', '414.01', 'MED:61543', 'MED:67465', 'MED:63302', 'MED:62934', 'MED:61319', 'MED:75069', 'MED:61211', 'MED:60445', 'MED:61078', 'MED:60723', 'MED:61892', 'MED:61889', 'MED:62028', 'MED:63114', 'MED:62439', 'MED:62094', '786.51', '414.01']

  + vdoc
    + ['530.11', '211.3']
    + ['786.51', '272.0']
    + ['V15.82', '244.9', '600.00', '401.9', '413.9', '272.0', '584.5', '414.01', 'MED:60439', 'MED:63302', 'MED:62934', 'MED:61889', 'MED:75069', 'MED:61211', 'MED:60887', 'MED:61892', 'MED:62147', 'MED:63114']
    + ['MED:61319', 'MED:62094']
    + ['414.10']
    + ['530.11', '211.3', '286.0']
    + ['585.9', 'V15.82', '786.50', '244.9', '996.72', '600.00', '428.0', '413.9', 'E878.1', '414.01', 'MED:61543', 'MED:67465', 'MED:63302', 'MED:62934', 'MED:61319', 'MED:75069', 'MED:61211', 'MED:60445', 'MED:61078', 'MED:60723', 'MED:61892', 'MED:61889', 'MED:62028', 'MED:63114']
    + ['MED:62439', 'MED:62094']
    + ['786.51']
    + ['414.01']
  + doc(last 150 chars):
['MED:61759', 'MED:61331', 'MED:63590', 'MED:61895', 'MED:63413', 'MED:63518', 'MED:63182', 'MED:60553', 'MED:61894', 'MED:69248', 'MED:62094', 'MED:69248', 'MED:63413', 'MED:97274', 'MED:75034', 'MED:61331', 'MED:61894', 'MED:61759', 'MED:61754', 'MED:62940', 'MED:62940', 'MED:61765', 'MED:61759', 'MED:69248', 'MED:68349', '599.0', '250.00', '416.8', '428.0', '401.9', '294.8', '255.4', '276.51', 'E879.6', '780.97', '799.02', '996.64', '041.04', 'MED:67463', 'MED:63494', 'MED:72900', 'MED:81159', 'MED:69488', 'MED:61522', 'MED:61124', 'MED:61309', 'MED:62940', 'MED:61895', 'MED:61892', 'MED:61836', 'MED:61836', 'MED:63573', 'MED:63573', 'MED:69248', 'MED:68338', 'MED:71905', 'MED:62899', 'MED:63182', 'MED:62853', 'MED:60592', 'MED:61836', 'MED:69248', 'MED:62439', 'MED:61759', 'MED:62940', 'MED:69248', 'MED:60490', 'MED:69488', 'MED:62940', 'MED:62940', 'MED:69248', 'MED:60490', 'MED:62940', 'MED:69155', 'MED:75037', 'MED:72900', 'MED:62934', 'MED:72702', 'MED:61003', 'MED:62899', 'MED:62664', 'MED:62899', 'MED:60490', 'MED:62800', 'MED:72900', 'MED:60592', 'MED:61956', 'MED:69248', 'MED:69155', 'MED:61171', 'MED:62058', 'MED:62940', 'MED:72702', 'MED:62876', 'MED:72702', 'MED:62610', 'MED:62439', 'MED:61112', 'MED:61348', 'MED:69248', 'MED:60592', 'V58.67', '599.0', 'unknown', '995.92', '785.52', '584.9', '250.00', '401.9', '294.8', '287.5', '276.7', '276.0', '453.8', '410.71', '416.0', 'MED:62439', 'MED:63518', 'MED:72900', 'MED:99338', 'MED:61112', 'MED:61003', 'MED:60465', 'MED:61825', 'MED:61744', 'MED:61522', 'MED:61895', 'MED:100183', 'MED:61836', 'MED:61974', 'MED:69147', 'MED:68338', 'MED:100187', 'MED:62899', 'MED:72900', 'MED:97465', 'MED:62934', 'MED:60429', 'MED:61003', 'MED:61825', 'MED:61744', 'MED:61013', 'MED:61002', 'MED:61889', 'MED:61895', 'MED:61881', 'MED:62876', 'MED:61957', 'MED:61972', 'MED:61002']

  + vdoc
    + ['MED:62899', 'MED:60490', 'MED:62800', 'MED:72900', 'MED:60592']
    + ['MED:61956', 'MED:69248']
    + ['MED:69155', 'MED:61171', 'MED:62058', 'MED:62940', 'MED:72702']
    + ['MED:62876']
    + ['MED:72702', 'MED:62610']
    + ['MED:62439', 'MED:61112', 'MED:61348']
    + ['MED:69248', 'MED:60592']
    + ['V58.67', '599.0', 'unknown', '995.92', '785.52', '584.9', '250.00', '401.9', '294.8', '287.5', '276.7', '276.0', '453.8', '410.71', '416.0', 'MED:62439', 'MED:63518', 'MED:72900', 'MED:99338', 'MED:61112', 'MED:61003', 'MED:60465', 'MED:61825', 'MED:61744', 'MED:61522', 'MED:61895', 'MED:100183', 'MED:61836']
    + ['MED:61974', 'MED:69147', 'MED:68338', 'MED:100187', 'MED:62899', 'MED:72900', 'MED:97465', 'MED:62934', 'MED:60429', 'MED:61003', 'MED:61825', 'MED:61744', 'MED:61013', 'MED:61002', 'MED:61889', 'MED:61895', 'MED:61881', 'MED:62876']
    + ['MED:61957', 'MED:61972', 'MED:61002']
  + doc(last 150 chars):
['873.40', 'V82.9', '367.1', '365.22', '378.9', '365.23', '365.23', '365.23', '366.10', '367.4', '367.9', '366.10', '367.4', '366.10', '365.23', '379.91', '366.16', '998.6', '379.91', '366.10', '366.9', '366.16', '998.6', '373.2', '998.6', '367.1', 'V67.00', '998.6', '998.6']

  + vdoc
    + ['998.6']
    + ['379.91']
    + ['366.10']
    + ['366.9', '366.16']
    + ['998.6']
    + ['373.2', '998.6']
    + ['367.1']
    + ['V67.00']
    + ['998.6']
    + ['998.6']
  + doc(last 150 chars):
['465.9', '473.9', '493.91', '473.9', 'unknown', '472.0', '473.0', '461.0', '461.0', '465.9', '472.0', '472.0', '472.0', '472.0', '401.9', '217', '477.9', '217', '611.71', '472.0', '724.5', '816.00', '727.03', 'V72.3', '727.03', '616.10', 'V72.3', '727.03', '627.1', 'V67.0', '401.9', '627.8', '346.9', '401.9', '784.0', '558.9', '784.0', '999999', '477.9', '729.81', '477.9', '389.02', '786.0', '401.9', '999999', '784.0', '558.9', '535.0', '616.10', '569.9', '564.0', '455.6', '569.49', '455.0', '569.49', '401.9', '401.9', '272.0', '729.9', '682.9', '782.3', 'V70.0', '401.9', '625.9', '443.9', '459.9', '272.0', '715.90', '401.9', '401.9', '366.10', '789.00', '401.9', '789.00', '401.9', '574.20', '692.9', '789.00', '401.9', '272.0', '401.9', '724.3', '272.0', 'MED:45794', '787.01', '401.9', '558.9']

  + vdoc
    + ['459.9', '272.0']
    + ['715.90', '401.9']
    + ['401.9']
    + ['366.10']
    + ['789.00', '401.9']
    + ['789.00', '401.9']
    + ['574.20']
    + ['692.9', '789.00', '401.9', '272.0']
    + ['401.9', '724.3', '272.0', 'MED:45794']
    + ['787.01', '401.9', '558.9']
  + doc(last 150 chars):
['V72.6', 'V72.6', 'V72.6', 'V82.9', '599.0', '786.4', '486', '333.1', '276.7', '333.1', '333.1', '285.9', '783.0', '783.9', 'V70.0', '725', '428.0', '725', '333.1', '725', '333.1', '725', '725', '331.1', '725', '725', 'V12.6', '725', '366.10', '780.2', '725', '276.5', 'MED:62439', 'MED:62936', '333.1', '725', '401.9', '285.29', '783.21', '787.99', '786.2', '466.0', '333.1', 'V58.69', '725', '401.9', '424.0', 'V58.69', '725', '401.1', '401.9', '331.0', '780.2', '333.1', '401.1', '401.9', 'V58.69', '401.9', '268.9', '333.1', 'V58.69', '401.9', '268.9', '401.9', '781.0', '268.9', '285.29', '401.1', '366.16', 'V58.69', '401.9', '268.9', '786.2', '486', '401.9', '276.51', '799.02', 'MED:60671', 'MED:62934', 'MED:62679', 'MED:100198', 'MED:122364', 'MED:60671', 'MED:63590', 'MED:62439', 'MED:61939', 'MED:60884', 'MED:62679', 'MED:100198', 'MULTUM:5070', 'NDC:00093714656', 'NDC:00247033920', '486', '401.9', '311', 'Per_Pt_Rxed_Anti_Htn_Meds_By_Pmd_But_Is_Not_Taking', 'N89.8']

  + vdoc
    + ['333.1', 'V58.69', '401.9', '268.9']
    + ['401.9', '781.0', '268.9', '285.29']
    + ['401.1']
    + ['366.16']
    + ['V58.69', '401.9', '268.9']
    + ['786.2', '486', '401.9', '276.51', '799.02', 'MED:60671', 'MED:62934', 'MED:62679', 'MED:100198']
    + ['MED:122364', 'MED:60671', 'MED:63590', 'MED:62439', 'MED:61939', 'MED:60884', 'MED:62679', 'MED:100198']
    + ['MULTUM:5070', 'NDC:00093714656', 'NDC:00247033920']
    + ['486', '401.9', '311', 'Per_Pt_Rxed_Anti_Htn_Meds_By_Pmd_But_Is_Not_Taking']
    + ['N89.8']
  + doc(last 150 chars):
['372.00', '372.00', '372.10', '372.10', '372.10', 'V72.5', 'V76.1', 'V76.1', 'V76.1', '846.0', '574.21', '611.79', '784.0', 'V76.12', '787.02', '536.8', '401.9', '276.51', '272.0', 'MED:33606']

  + vdoc
    + ['V76.1']
    + ['V76.1']
    + ['V76.1']
    + ['846.0']
    + ['574.21']
    + ['611.79']
    + ['784.0']
    + ['V76.12']
    + ['787.02', '536.8', '401.9', '276.51', '272.0']
    + ['MED:33606']
  + doc(last 150 chars):
['E849.0', 'E920.3', 'V58.67', '879.2', '250.00', '401.9', 'MED:28499', 'V58.3', '780.4', '787.01', '729.5', '724.2', '250.00', '401.9', '698.9', '250.00', '401.9', '272.0', '719.41', '250.00', '401.9', '719.40']

  + vdoc
    + ['E849.0', 'E920.3', 'V58.67', '879.2', '250.00', '401.9', 'MED:28499']
    + ['V58.3']
    + ['780.4', '787.01', '729.5', '724.2', '250.00', '401.9']
    + ['698.9', '250.00', '401.9', '272.0']
    + ['719.41', '250.00', '401.9']
    + ['719.40']
  + doc(last 150 chars):
['780.4', '780.4', '780.4', '999999', '789.00', '592.0', '574.00', '789.06', '535.00', '789.00', '574.10', 'MED:63523', 'MED:62439', 'MED:67859', 'MED:61293', 'MED:61112', 'MED:68338', 'MED:67790', 'MED:61889', 'MED:61692', 'MED:61543', 'MED:67866', 'MED:63439', 'MED:62810', 'MED:60783', '575.9', '592.1', 'E884.3', 'E888.9', '802.0', '873.63', 'V76.12']

  + vdoc
    + ['780.4']
    + ['999999']
    + ['789.00', '592.0']
    + ['574.00', '789.06', '535.00', '789.00', '574.10', 'MED:63523', 'MED:62439', 'MED:67859', 'MED:61293', 'MED:61112']
    + ['MED:68338', 'MED:67790', 'MED:61889', 'MED:61692']
    + ['MED:61543', 'MED:67866', 'MED:63439', 'MED:62810', 'MED:60783']
    + ['575.9']
    + ['592.1']
    + ['E884.3', 'E888.9', '802.0', '873.63']
    + ['V76.12']
  + doc(last 150 chars):
['MED:63156', 'MED:126143', 'MED:61460', 'MED:62679', 'MED:63156', 'MED:61319', 'NDC:58864088230', 'NDC:00065026625', 'NDC:00574202116', 'MED:105560', 'MED:63441', 'MED:63089', 'MED:103229', 'MED:89117', 'MED:70402', 'MED:81151', 'MED:61269', 'MED:60920', 'MED:61968', 'MED:61785', 'MED:73041', 'MED:61124', 'MED:60798', 'MED:61460', 'MED:62679', 'Glucose_Meter_Strips', 'NDC:51672203701', 'NDC:55289097330', 'NDC:00093050793', 'NDC:68084008090', 'NDC:00456140201', 'NDC:00006027728', 'NDC:66267059210', 'MULTUM:7235', 'NDC:68462021210', 'NDC:00536106708', 'NDC:63874017230', 'NDC:58864088730', 'MULTUM:5908', 'NDC:58980010817', 'NDC:49999058730', 'MED:69248', 'MED:103229', 'MED:122364', 'MED:102858', 'MED:61269', 'MED:61331', 'MED:60920', 'MED:61513', 'MED:61939', 'MED:62371', 'MED:60669', 'MED:60612', 'MED:62543', 'MULTUM:608', 'NDC:00597005801', 'NDC:00456342133', 'MED:122364', 'MED:63089', 'MED:61269', 'MED:60920', 'MED:61331', 'MED:61513', 'MED:62371', 'MED:63356', 'MED:136371', 'MED:60920', 'MED:60669', 'MED:69248', 'MED:62363', 'MED:122364', 'MED:61513', 'MED:61118', 'MED:63448', 'NDC:00093731405', 'MULTUM:2882', 'NDC:00007414220', 'NDC:00182055489', 'NDC:00135011701', 'NDC:00039006605', 'NDC:00085137401', 'NDC:00071015823', 'NDC:00008060701', 'NDC:00006022128', '585.9', '575.10', '600.00', '250.00', '496', '389.9', '379.91', '403.90', 'MED:101068', 'MED:167651', 'NDC:00247027681', '585.3', 'MED:72900', 'MED:62899', 'MED:60481', 'MED:67866', 'MED:61319', 'MED:73041', 'MED:162541', 'MED:63089', 'MED:103229', 'MED:70402', 'MED:81152', 'MED:62934', 'MED:72702', 'MED:167651', 'MED:61939', 'MED:60798', 'MED:60465', 'MED:61068', 'MED:69248', 'MED:62363', 'NDC:00006027702', 'MED:105560', 'MED:93886', 'MED:61513', 'NDC:68084008090', 'NDC:00093050793', 'NDC:00456342133', 'NDC:00378522205', 'MED:60926', 'MED:61319', 'MED:69248', 'MED:93886', 'MED:102417', 'MED:94350', 'MED:69248', 'MED:73041', 'MED:122364', 'MED:62564', 'MED:100198', 'MED:60887', 'MED:61513', 'MED:61253', 'MED:61124', 'MED:102417', 'MED:102417', 'MULTUM:13383', 'MULTUM:608', 'NDC:00536106708', 'MULTUM:13364', 'MULTUM:3559', 'NDC:00093050793', 'MULTUM:7727', 'MULTUM:14192', 'MULTUM:3819']

  + vdoc
    + ['MED:67866', 'MED:61319', 'MED:73041', 'MED:162541', 'MED:63089', 'MED:103229', 'MED:70402', 'MED:81152', 'MED:62934', 'MED:72702', 'MED:167651', 'MED:61939', 'MED:60798', 'MED:60465', 'MED:61068']
    + ['MED:69248', 'MED:62363', 'NDC:00006027702', 'MED:105560', 'MED:93886', 'MED:61513', 'NDC:68084008090', 'NDC:00093050793', 'NDC:00456342133', 'NDC:00378522205']
    + ['MED:60926', 'MED:61319', 'MED:69248', 'MED:93886', 'MED:102417']
    + ['MED:94350']
    + ['MED:69248', 'MED:73041']
    + ['MED:122364', 'MED:62564', 'MED:100198']
    + ['MED:60887', 'MED:61513']
    + ['MED:61253', 'MED:61124']
    + ['MED:102417']
    + ['MED:102417', 'MULTUM:13383', 'MULTUM:608', 'NDC:00536106708', 'MULTUM:13364', 'MULTUM:3559', 'NDC:00093050793', 'MULTUM:7727', 'MULTUM:14192', 'MULTUM:3819']
  + doc(last 150 chars):
['401.9', '285.8', '300.00', '300.01', '478.19', 'V12.54', '300.29', '428.33', 'MED:61335', '600.00', 'V45.81', '427.31', '414.00', '428.0', '401.9', '285.8', '300.00', '300.01', '478.19', 'V12.54', '300.29', '428.33', 'MED:62746', 'MED:62586', 'MED:61939', 'MED:61335', 'MED:63376', 'MED:61522', 'MED:60592', 'MED:167651', 'MED:62934', 'MED:61895', 'MED:63408', 'MED:69860', 'MED:61955', 'MED:61815', 'MED:60592', 'MED:62453', 'MED:61335', 'MED:81159', 'MED:61955', 'MED:61331', 'MED:61335', 'MED:61335', 'MED:63089', 'MULTUM:5432', 'NDC:00037502001', 'MULTUM:6449', 'MED:62070', 'MED:61335', 'MED:61331', 'MED:162541', 'MED:68349', 'MED:61785', 'MED:61939', 'MED:61522', 'MED:61815', 'MED:122364', 'MED:106626', 'MED:167651', 'MED:63089', 'MED:61895', 'MED:60926', 'MED:69860', 'NDC:00603613721', 'NDC:00093482001', 'NDC:00054007725', 'MULTUM:3503', 'NDC:00228280311', 'MED:62990', 'MED:61335', 'MED:61815', 'MED:60926', 'MED:62746', 'MED:100198', 'MED:94350', 'MED:101583', 'MULTUM:6958', 'MED:60972', 'MED:167651', 'MED:72702', 'MED:62899', 'MED:61955', 'MED:62611', 'MED:60920', 'MED:69860', 'MED:63148', 'MED:61558', 'MED:69488', 'MED:72702', 'MED:69488', 'MED:86673', 'MED:62899', 'MED:62739', 'MED:167651', 'MED:61335', 'MED:63178', 'MED:61432', 'MED:60577', 'MED:101583', 'MED:95599', 'MULTUM:5968', 'MULTUM:1794', 'MULTUM:1793', 'MULTUM:2982', 'MULTUM:4004', 'MULTUM:14922', 'MULTUM:15645', 'MED:61939', 'MED:61335', 'MED:61432', 'MED:61895', 'MED:61815', 'MED:61112', 'MED:60669', 'MED:122364', 'MED:167651', 'MED:133119', 'MED:95599', 'MED:99018', 'MED:162541', 'MED:69860', 'MED:61335', 'MED:60669', 'MED:81159', 'MED:62564', 'MED:61331', 'MED:86673', 'MED:62899', 'MED:61177', 'MED:61955', 'MED:60998', 'MED:61692', 'MED:61055', 'MED:60592', 'MED:61955', 'MED:61055', 'MED:60592', 'NDC:00378459610', 'MULTUM:1733', 'MED:62586', 'MED:61055', 'MED:86673', 'MED:61055', 'MED:61955', 'MED:102218', 'MULTUM:4153', 'MED:77728', 'MULTUM:1733', 'NDC:00039006710']

  + vdoc
    + ['MED:61939', 'MED:61335', 'MED:61432', 'MED:61895', 'MED:61815', 'MED:61112', 'MED:60669', 'MED:122364', 'MED:167651', 'MED:133119', 'MED:95599', 'MED:99018', 'MED:162541', 'MED:69860']
    + ['MED:61335', 'MED:60669', 'MED:81159', 'MED:62564']
    + ['MED:61331', 'MED:86673', 'MED:62899']
    + ['MED:61177', 'MED:61955']
    + ['MED:60998', 'MED:61692', 'MED:61055', 'MED:60592', 'MED:61955']
    + ['MED:61055', 'MED:60592', 'NDC:00378459610', 'MULTUM:1733']
    + ['MED:62586', 'MED:61055', 'MED:86673']
    + ['MED:61055', 'MED:61955']
    + ['MED:102218']
    + ['MULTUM:4153', 'MED:77728', 'MULTUM:1733', 'NDC:00039006710']
  + doc(last 150 chars):
['MED:124621', 'MED:77476', 'MED:63093', 'MED:106480', 'MED:126767', 'MED:63518', 'MED:106478', 'MED:72705', 'MED:62974', 'MED:62595', 'MED:60481', 'MED:61269', 'MED:94350', 'MED:106476', 'MED:126767', 'MED:62871', 'MED:60481', 'MED:60967', 'MED:106476', 'MED:126767', 'MED:60481', 'MED:60998', 'MED:62838', 'MED:63518', 'MED:126767', 'MED:60481', 'MED:69239', 'MED:72160', 'MED:62564', 'MED:126767', 'MED:69853', 'MED:132302', 'MED:61471', 'MED:60998', 'MED:60481', 'MED:66387', 'MED:133116', 'MED:132302', 'MED:62564', 'MED:126767', 'MED:72705', 'MED:63518', 'MED:73141', 'MED:63055', 'MED:63264', 'MED:61471', 'MED:62035', 'MED:60481', 'MED:60998', 'MED:61331', 'MED:60645', 'MED:94350', 'MED:106476', 'MED:62934', 'MED:106480', 'MED:62659', 'MED:126767', 'MED:63518', 'MED:62402', 'MED:62838', 'MED:60481', 'MED:72705', 'MED:63518', 'MED:63055', 'MED:69239', 'MED:106476', 'MED:63540', 'MED:106480', 'MED:102424', 'MED:72705', 'MED:63518', 'MED:157468', 'MED:63096', 'MED:61492', 'MED:61604', 'MED:61471', 'MED:66023', 'MED:61269', 'MED:60481', 'MED:62934', 'MED:132302', 'MED:63518', 'MED:106480', 'MED:106476', 'MED:63055', 'MED:62035', 'MED:60481', 'MED:60460', 'MED:63518', 'MED:61471', 'MED:61269', 'MED:60481', 'MED:62829', 'MED:133116', 'MED:124621', 'MED:62564', 'MED:62838', 'MED:63518', 'MED:72705', 'MED:73141', 'MED:63055', 'MED:62439', 'MED:60645', 'MED:60481', 'MED:94350', 'MED:63518', 'MED:63055', 'MED:60481', 'MED:60645', 'MED:101532', 'MED:63518', 'MED:89117', 'MED:69840', 'MED:62871', 'MED:60826', 'MED:60481', 'MED:62934', 'MED:63540', 'MED:62838', 'MED:62987', 'MED:63518', 'MED:62062', 'MED:106480', 'MED:106476', 'MED:62871', 'MED:61427', 'MED:60826', 'MED:62286', 'MED:61816', 'MED:61471', 'MED:62829', 'MED:60481', 'MED:78210', 'MED:62987', 'MED:63518', 'MED:61253', 'MED:62195', 'MED:61269', 'MED:69863', 'MED:60481', 'MED:62543', 'MED:133116', 'MED:62062', 'MED:62099', 'MED:61471', 'MED:69863', 'MED:60481', 'MED:62829', 'MED:69863', 'MED:61237']

  + vdoc
    + ['MED:69239', 'MED:106476', 'MED:63540', 'MED:106480', 'MED:102424', 'MED:72705', 'MED:63518', 'MED:157468', 'MED:63096', 'MED:61492', 'MED:61604', 'MED:61471', 'MED:66023', 'MED:61269', 'MED:60481']
    + ['MED:62934', 'MED:132302', 'MED:63518', 'MED:106480', 'MED:106476', 'MED:63055', 'MED:62035', 'MED:60481', 'MED:60460']
    + ['MED:63518', 'MED:61471', 'MED:61269', 'MED:60481', 'MED:62829']
    + ['MED:133116', 'MED:124621', 'MED:62564', 'MED:62838', 'MED:63518', 'MED:72705', 'MED:73141', 'MED:63055', 'MED:62439', 'MED:60645', 'MED:60481', 'MED:94350']
    + ['MED:63518', 'MED:63055', 'MED:60481', 'MED:60645']
    + ['MED:101532', 'MED:63518', 'MED:89117', 'MED:69840', 'MED:62871', 'MED:60826', 'MED:60481']
    + ['MED:62934', 'MED:63540', 'MED:62838', 'MED:62987', 'MED:63518', 'MED:62062', 'MED:106480', 'MED:106476', 'MED:62871', 'MED:61427', 'MED:60826', 'MED:62286', 'MED:61816', 'MED:61471', 'MED:62829', 'MED:60481']
    + ['MED:78210', 'MED:62987', 'MED:63518', 'MED:61253', 'MED:62195', 'MED:61269', 'MED:69863', 'MED:60481', 'MED:62543']
    + ['MED:133116', 'MED:62062', 'MED:62099', 'MED:61471', 'MED:69863', 'MED:60481', 'MED:62829']
    + ['MED:69863', 'MED:61237']
  + doc(last 150 chars):
['NDC:00093715310', '719.7', '729.5', '110.1', '709.9', '250.02', '784.1', 'NDC:00054350049', 'MULTUM:113', 'NDC:00085000805', 'NDC:00072571208', 'MULTUM:22151', '465.9', 'NDC:00031223419', 'NDC:00113040378', '294.20', 'NDC:00904501735', 'NDC:00093715310', 'NDC:00247206030', 'NDC:00143126201', 'NDC:00087606005', '784.0', 'NDC:00093715310', 'NDC:00143126201', 'NDC:00247206030', 'NDC:00113040378', '367.4', 'V04.81', '719.40', 'NDC:00085000805', '719.40', 'NDC:21695079100', '401.9', 'NDC:00054010022', 'NDC:00113022771', '250.00', '401.9', '368.16', '308.9', 'MED:63220', 'MED:62527', 'MED:89118', 'MED:61951', 'MED:60582', '296.90', '296.90', '296.90', 'NDC:00054010022', 'NDC:00093715310', 'NDC:00087606005', 'NDC:00247206030', 'NDC:00143126201', 'NDC:00113040378', 'NDC:00143126201', 'NDC:00093715310', 'NDC:00247206030', 'NDC:00087606005', 'NDC:00113022771', 'NDC:00054010022', '294.20', 'NDC:52959087703', '294.20', 'NDC:00904501735', 'Free_Style_Lyte_Glucose_Test_Strips', 'NDC:00143126201', 'NDC:00087606005', 'NDC:00093715310', 'NDC:00054010022', 'NDC:00247206030', 'NDC:00247206030', 'NDC:00093715310', 'NDC:00113022771', 'NDC:00143126201', 'NDC:00054010022', 'NDC:21695079100', 'NDC:00087606005', 'NDC:00143126201', 'NDC:00247206030', 'NDC:00113022771', 'NDC:00054010022', 'NDC:00093715310', '401.9', 'Referral_For_Dermatology', 'NDC:00247028100', 'NDC:00904501735', 'NDC:00247206030', 'NDC:00087606005', 'NDC:00143126201', 'NDC:00093715310', 'NDC:00113022771', 'NDC:00054010022', 'NDC:00245006804', 'NDC:00143126201', 'NDC:00247206030', 'NDC:00087606005', 'NDC:00247028100', 'NDC:00054010022', 'NDC:00072571208', 'NDC:00245006804', 'NDC:00247206030', 'NDC:00113022771', '294.20', 'NDC:37000056512', 'NDC:00065027225', 'NDC:00054010122', 'NDC:00247206030', 'NDC:00173075300', 'Adult_Diapers', 'wheelchair', 'NDC:00904501735', 'NDC:00087606005', 'NDC:00113022771', '719.40', 'MULTUM:4218', 'NDC:00054010222', '719.40', 'NDC:00113022771', 'NDC:00904501735', '782.1', '401.9', 'NDC:00247028100', 'NDC:00247206030', 'NDC:00054010222', 'NDC:00247014415', 'Podiatry_Referral', 'NDC:00065027225', 'NDC:00113022771', 'NDC:00087606005', 'NDC:00173075300', '380.4', '389.9', '380.10', 'NDC:21695088105', '380.4', '380.10', '389.18', 'NDC:00085128801', '110.1', '709.00', 'NDC:00168040730', 'NDC:00066800802', 'NDC:00168000615', 'V04.81', 'Z23', 'R60.9', '782.3', 'NDC:00247206030', 'NDC:00087606005', 'NDC:00113022771', 'NDC:00054010222']

  + vdoc
    + ['NDC:00143126201', 'NDC:00247206030', 'NDC:00087606005', 'NDC:00247028100', 'NDC:00054010022']
    + ['NDC:00072571208', 'NDC:00245006804', 'NDC:00247206030', 'NDC:00113022771']
    + ['294.20', 'NDC:37000056512', 'NDC:00065027225', 'NDC:00054010122', 'NDC:00247206030', 'NDC:00173075300', 'Adult_Diapers', 'wheelchair', 'NDC:00904501735', 'NDC:00087606005', 'NDC:00113022771']
    + ['719.40', 'MULTUM:4218', 'NDC:00054010222']
    + ['719.40', 'NDC:00113022771', 'NDC:00904501735']
    + ['782.1', '401.9', 'NDC:00247028100', 'NDC:00247206030', 'NDC:00054010222', 'NDC:00247014415', 'Podiatry_Referral', 'NDC:00065027225', 'NDC:00113022771', 'NDC:00087606005', 'NDC:00173075300']
    + ['380.4', '389.9', '380.10', 'NDC:21695088105']
    + ['380.4', '380.10', '389.18', 'NDC:00085128801']
    + ['110.1', '709.00', 'NDC:00168040730', 'NDC:00066800802', 'NDC:00168000615']
    + ['V04.81', 'Z23', 'R60.9', '782.3', 'NDC:00247206030', 'NDC:00087606005', 'NDC:00113022771', 'NDC:00054010222']
  + doc(last 150 chars):
['565.1', 'V75.8', '129', '401.9', '401.9', '272.4', '288.3', '401.9', '719.45', '401.9', '272.4', '288.3', '401.9', '272.4', '288.3', '401.9', '272.4', '790.21', '455.6', '401.9', '272.4', 'MED:77862', '565.1', 'V67.09', '565.1', '401.9', '272.4', '788.61', '785.6', '288.3', '783.21', '401.9', '272.4', '288.3', '797', '414.00', '401.9', '272.4', '785.6', '414.00', '401.9', '272.4', '288.3', '414.00', '401.9', '272.4', '437.3', '786.59', '413.9', '787.03', '414.00', '401.9', '272.4', '288.3', '437.3', 'V12.72', '211.3', '455.0', 'E849.8', 'E888.9', 'V06.5', '959.7', 'E849.8', 'E885.9', '719.46', '959.7', 'MED:60926', '844.9', '845.00', 'MULTUM:2071', 'E849.8', 'E888.9', '719.16', '924.11', '437.3', 'V45.82', '682.4', '600.00', '401.9', '272.4', '414.01', 'MED:61939', 'MED:62148', 'MED:62453', 'MED:62008', 'MED:62696', 'MED:62439', 'MED:61319', 'MED:63089', 'NDC:00029608612', 'V12.72', 'V76.51', 'E849.8', '936', 'E915', '780.4', 'V12.59', '787.91', '401.9', 'MED:62934', '716.90', '733.00', '788.20', 'V45.82', '682.4', '244.9', '600.00', '401.9', '272.4', '414.01', 'MED:60588', 'MED:61078', 'MED:62008', 'MED:60946', 'MED:61124', 'MED:60582', 'MED:62453', 'MED:62072', 'MED:61939', 'MED:63114', 'MED:62624', 'MED:63518', 'MED:63089', 'MED:158045', 'NDC:00093735501', 'NDC:00093078701', 'MULTUM:1101', 'NDC:00378209601', 'NDC:62107002726', 'NDC:00074455211', 'NDC:65597011430', 'NDC:00071015523', 'MED:60926', 'MED:63089', 'NDC:00093227534', '787.91', '789.00', '401.9', '272.4', 'MED:62934', 'NDC:52083026260']

  + vdoc
    + ['V45.82', '682.4', '600.00', '401.9', '272.4', '414.01', 'MED:61939', 'MED:62148', 'MED:62453']
    + ['MED:62008', 'MED:62696', 'MED:62439', 'MED:61319', 'MED:63089', 'NDC:00029608612']
    + ['V12.72', 'V76.51', 'E849.8', '936', 'E915']
    + ['780.4', 'V12.59', '787.91', '401.9', 'MED:62934']
    + ['716.90', '733.00']
    + ['788.20']
    + ['V45.82', '682.4', '244.9', '600.00', '401.9', '272.4', '414.01', 'MED:60588', 'MED:61078', 'MED:62008', 'MED:60946', 'MED:61124', 'MED:60582', 'MED:62453', 'MED:62072', 'MED:61939', 'MED:63114', 'MED:62624', 'MED:63518', 'MED:63089', 'MED:158045', 'NDC:00093735501', 'NDC:00093078701', 'MULTUM:1101', 'NDC:00378209601', 'NDC:62107002726', 'NDC:00074455211', 'NDC:65597011430', 'NDC:00071015523']
    + ['MED:60926', 'MED:63089']
    + ['NDC:00093227534']
    + ['787.91', '789.00', '401.9', '272.4', 'MED:62934', 'NDC:52083026260']
  + doc(last 150 chars):
['780.6', '426.13', '424.0', '745.4', '745.5', '745.12', '426.0', '427.1', '426.0', 'MED:66046', 'MED:69155', 'MED:63377', 'MED:63122', 'MED:61915', 'MED:61511', '426.0', '426.0', '780.50', 'V45.01', '474.10', '426.0', '381.3', '389.00', '426.0', '745.12', '476.0', '426.0', '426.0', '426.10', '426.0', 'V53.31', '426.0', '425.4', '745.4', '745.12', 'NDC:00054465025', '426.10', '426.0', 'V45.01', '426.10']

  + vdoc
    + ['426.0']
    + ['745.12']
    + ['476.0']
    + ['426.0']
    + ['426.0']
    + ['426.10', '426.0']
    + ['V53.31', '426.0', '425.4', '745.4', '745.12', 'NDC:00054465025']
    + ['426.10']
    + ['426.0']
    + ['V45.01', '426.10']
  + doc(last 150 chars):
['581.3', '581.9', '581.9', '581.3', '581.3', '581.9', '272.4', '403.90', '581.9', '272.4', '403.90', '581.9', '581.9', '272.4', '403.90', '593.9', '791.0', '581.3', '791.0', '585.1', '581.3', '581.9', '581.3', '782.3', '453.41', '453.40', 'MED:60921', 'MED:61902', 'MED:62439', 'MED:62013', 'MED:69490', 'NDC:00832121689', 'NDC:00781312168', '791.0', '581.2', '581.3', '997.91', '272.4', '581.3', '401.9', '782.3', '453.41', '415.19', '273.8', 'MED:61648', 'MED:61112', 'MED:60921', 'MED:62355', 'MED:61648', 'MED:61522', 'MED:61951', 'MED:62439', 'MED:61895', 'MED:106708', 'MED:158045', 'MED:69490', 'MED:61648', 'NDC:00075291501', 'NDC:00075062300', 'MULTUM:8487', 'NDC:00006010654', 'V87.46', '581.3', '272.4', 'MED:62936', 'MED:62871', 'MED:60481', '581.3', 'MED:60481', 'MED:62871', 'MED:167651']

  + vdoc
    + ['581.3']
    + ['782.3', '453.41', '453.40']
    + ['MED:60921', 'MED:61902', 'MED:62439', 'MED:62013', 'MED:69490', 'NDC:00832121689', 'NDC:00781312168']
    + ['791.0', '581.2']
    + ['581.3', '997.91', '272.4']
    + ['581.3', '401.9', '782.3', '453.41', '415.19', '273.8', 'MED:61648']
    + ['MED:61112', 'MED:60921', 'MED:62355', 'MED:61648', 'MED:61522', 'MED:61951', 'MED:62439', 'MED:61895', 'MED:106708', 'MED:158045', 'MED:69490']
    + ['MED:61648', 'NDC:00075291501', 'NDC:00075062300', 'MULTUM:8487', 'NDC:00006010654']
    + ['V87.46', '581.3', '272.4', 'MED:62936', 'MED:62871', 'MED:60481']
    + ['581.3', 'MED:60481', 'MED:62871', 'MED:167651']
  + doc(last 150 chars):
['584.9', '593.4', '996.81', '591', '285.21', 'MED:101652', 'MED:61471', 'MED:61939', 'MED:60553', 'MED:61895', 'MED:62439', 'MED:63306', 'MED:63617', 'MED:60918', 'MED:89117', 'MULTUM:4004', 'NDC:54569201502', 'NDC:00078038666', 'MULTUM:3270', 'NDC:66553000801', 'MED:69242', 'MULTUM:8313', 'NDC:63874052330', 'NDC:00004003822', 'NDC:68387058015', 'NDC:54629006201', 'V42.0', 'V58.69', 'E878.0', '585.6', '996.81', 'MED:63617', 'V42.0', 'V58.69', 'V42.0', 'V58.69', 'V58.82', 'V42.0', 'V58.69', 'V42.0', 'V58.69', 'V58.69', 'V42.0', 'V58.69', 'V42.0', 'V58.69', 'V42.0', 'V58.69', 'V42.0', 'V58.69', 'V42.0', 'V58.69', 'E878.0', '599.0', '585.6', '593.3', '996.81', '710.0', '285.9', 'unknown', 'MED:101652', 'MED:62511', 'MED:60553', 'MED:60918', 'MED:61471', 'MED:89117', 'MED:60826', 'MED:61939', 'MED:61895', 'MED:122364', 'MED:63523', 'MED:61471', 'MED:71675', 'MED:60826', 'MED:61471', 'MED:81159', 'MED:62829', 'MED:61338', 'MED:60926', 'MED:69488', 'MED:87666', 'MED:60972', 'MED:62375', 'MED:107393', 'NDC:55111052501', 'MED:69148', 'NDC:00024156210', 'MED:60728', 'MED:61471', 'NDC:00469061773', 'MULTUM:8469', 'imipenem', 'V42.0', 'V58.69', 'V42.0', 'V58.69', '585.3', '285.21', 'MED:87666', 'V42.0', 'V58.69', 'V42.0', 'V58.69', 'E878.0', '996.81', 'V42.0', 'V58.69', 'V42.0', 'V42.0', 'V58.69', 'V42.0', 'V58.69', 'V42.0', 'V58.69', 'V42.0', '585.6', 'V42.0', '585.6', '710.0', '401.9', '996.1', 'E878.2', 'MULTUM:17066', 'V42.0', 'V58.69', 'V42.0', 'V58.69', 'V42.0', 'V58.69', '996.81', 'V42.0', 'V58.69', '996.81', 'V42.0', 'V58.69', '996.81', 'V42.0', 'V58.69', '996.81', 'V42.0', 'V58.69', '996.81', 'V42.0', '996.81', 'V42.0', 'V58.69', '996.81', 'V42.0', 'V58.69', '996.81']

  + vdoc
    + ['V42.0', 'V58.69']
    + ['V42.0', 'V58.69']
    + ['V42.0', 'V58.69', '996.81']
    + ['V42.0', 'V58.69', '996.81']
    + ['V42.0', 'V58.69', '996.81']
    + ['V42.0', 'V58.69', '996.81']
    + ['V42.0', 'V58.69', '996.81']
    + ['V42.0', '996.81']
    + ['V42.0', 'V58.69', '996.81']
    + ['V42.0', 'V58.69', '996.81']
  + doc(last 150 chars):
['NDC:00054429925', 'MULTUM:2395', 'NDC:00054430125', 'MED:60926', 'NDC:00093081901', 'MED:62624', 'V42.0', 'V58.69', '996.81', 'V42.0', 'V58.69', '996.81', 'V42.0', 'V58.69', '996.81', '996.80', 'V58.69', 'V42.0', '996.81', 'V42.0', '585.6', 'V42.0', 'V58.69', '996.81', 'V42.0', 'V58.69', '996.81', 'V42.0', 'V58.69', '996.81', 'V42.0', 'V58.69', '996.81', 'V42.0', 'V58.69', '996.81', 'V42.0', 'V58.69', '996.81', 'V42.0', 'V58.69', '996.81', 'V42.0', '996.81', 'MED:62852', 'V42.0', '996.81', 'MED:62852', 'V42.0', '996.81', 'MED:62852', 'V42.0', '996.81', 'MED:63518', 'V04.81', '585.9', 'V42.0', 'V58.69', '996.81', '268.9', 'MED:133079', 'V42.0', '996.81', 'V42.0', '996.81', 'V42.0', 'V58.69', '996.81', '996.81', 'MED:63518', 'V42.0', '996.81', 'MED:63518', 'V42.0', 'V58.69', '996.81', 'MED:63518', '585.9', 'V42.0', 'V58.69', '996.81', '268.9', 'V42.0', '996.81', 'MED:63518', 'V42.0', '996.81', 'MED:63518', 'V42.0', '996.81', 'MED:63518', 'V42.0', '996.81', 'MED:63518', 'V42.0', 'V58.69', '996.81', 'V42.0', '996.81', 'MED:63518', 'V42.0', '996.81', 'MED:63518', 'V42.0', '996.81', 'MED:63518', 'V42.0', '996.81', 'MED:63518', 'V42.0', '996.81', 'MED:63518', 'V42.0', '996.81', 'MED:62846', 'MED:63518', 'V42.0', '996.81', 'MED:63518', 'V42.0', '996.81', 'MED:63518', 'V42.0', 'V58.69', '996.81', 'V42.0', 'V58.69', '996.81', 'V42.0', '996.81', 'MED:63518', 'V42.0', '996.81', 'MED:63518', 'V42.0', 'V58.69', 'V04.81', 'MED:158045', 'V42.0', '996.81', 'V42.0', '996.81', 'V42.0', 'V70.0', 'V58.69', 'Z94.0', 'Z79.899', 'F04', 'Z94.0', 'Z79.899']

  + vdoc
    + ['V42.0', '996.81', 'MED:63518']
    + ['V42.0', '996.81', 'MED:63518']
    + ['V42.0', 'V58.69', 'V04.81', 'MED:158045']
    + ['V42.0', '996.81']
    + ['V42.0', '996.81']
    + ['V42.0']
    + ['V70.0', 'V58.69']
    + ['Z94.0', 'Z79.899']
    + ['F04']
    + ['Z94.0', 'Z79.899']
  + doc(last 150 chars):
['V28.0', 'V22.0', '655.81', 'V02.51', 'V27.0', '664.11', '659.71', '664.81', '648.91', 'MULTUM:13271', 'MED:63022', 'MED:66090', 'MED:89274', 'MED:106261', 'MED:62994', 'MED:61382', 'MED:63517', 'MED:60926', 'MED:61895', 'MED:62683', 'MED:62439', 'MED:61829', 'MED:61736', 'MED:61120', 'MED:99142', 'MED:62296', 'MED:62624', 'MED:107078', 'MULTUM:2072', 'NDC:63481062370', 'NDC:49999058730', 'NDC:00009738702']

  + vdoc
    + ['V28.0']
    + ['V22.0', '655.81', 'V02.51', 'V27.0', '664.11', '659.71', '664.81', '648.91', 'MULTUM:13271']
    + ['MED:63022', 'MED:66090', 'MED:89274', 'MED:106261']
    + ['MED:62994', 'MED:61382', 'MED:63517', 'MED:60926', 'MED:61895', 'MED:62683', 'MED:62439', 'MED:61829', 'MED:61736', 'MED:61120', 'MED:99142', 'MED:62296', 'MED:62624', 'MED:107078']
    + ['MULTUM:2072', 'NDC:63481062370', 'NDC:49999058730', 'NDC:00009738702']
  + doc(last 150 chars):
['NDC:00378420278', 'NDC:00054472825', 'NDC:00004196401', 'MED:60635', 'MED:101652', 'MED:61460', 'MED:62936', 'MED:129949', 'MED:62439', 'MED:81258', 'MED:63306', 'MULTUM:3240', 'MULTUM:318', 'MULTUM:1807', 'NDC:00078038666', 'NDC:00054472825', 'MULTUM:5326', 'NDC:00378204701', 'MED:61361', 'NDC:00004003822', 'NDC:00186504031', 'V42.0', 'V58.69', '996.81', 'V42.0', '285.9', '585.3', '285.21', 'MED:87663', 'V04.81', '585.6', '585.3', '285.21', 'MED:87663', 'MED:158045', 'V42.0', '585.4', 'V42.0', 'V58.69', 'V42.0', '996.81', 'MED:63518', 'V42.0', '996.81', 'MED:63540', 'V42.0', '996.81', 'MED:63540', '585.9', 'V42.0', 'V58.69', '788.41', 'V42.0', '996.81', 'MED:63540', 'V42.0', '996.81', 'MED:63540', 'V42.0', '585.6', '996.81', 'MED:63540', '585.4', '780.60', '783.21', 'E878.0', 'V65.3', 'V85.1', '787.20', '790.8', '588.81', '583.9', '590.10', '996.81', '530.81', '345.90', '041.85', '276.51', '268.9', '300.00', '285.21', '262', 'MED:122364', 'MED:60635', 'MED:61895', 'MED:60762', 'MED:60723', 'MED:62170', 'MED:60926', 'MED:61338', 'MED:107078', 'MED:66048', 'MED:62934', 'MED:89117', 'MED:62659', 'MED:62564', 'MED:71505', 'MED:63306', 'MED:60972', 'MED:129541', 'MED:94350', 'MED:60553', 'MED:63376', 'MED:62936', 'MED:62062', 'MED:60972', 'MED:62035', 'MED:61471', 'MED:66125', 'MED:99323', 'MED:62301', 'MED:62564', 'V42.0', '996.81', 'NDC:00006384371', 'MED:60972', 'MED:60614', 'MED:62035', 'MED:63376', 'MED:63122', 'MED:62564', 'MED:63518', 'MED:62871', 'MED:62899', 'MULTUM:4527', 'MULTUM:5116', 'MULTUM:6740', 'MULTUM:2709', 'MULTUM:420', 'MULTUM:3270', 'MED:62035', 'MED:62564', 'V42.0', 'V58.69', '996.81', 'MED:62852', 'V42.0', '996.81', 'MED:63540', 'V42.0', '585.6', '996.81', 'MED:63540', 'V42.0', '996.81', 'V42.0', 'V58.69', '996.81', 'Z94.0', 'Z79.899']

  + vdoc
    + ['MED:60972', 'MED:62035', 'MED:61471', 'MED:66125', 'MED:99323', 'MED:62301', 'MED:62564']
    + ['V42.0', '996.81', 'NDC:00006384371', 'MED:60972', 'MED:60614', 'MED:62035', 'MED:63376', 'MED:63122', 'MED:62564', 'MED:63518', 'MED:62871', 'MED:62899']
    + ['MULTUM:4527', 'MULTUM:5116', 'MULTUM:6740', 'MULTUM:2709', 'MULTUM:420', 'MULTUM:3270', 'MED:62035', 'MED:62564']
    + ['V42.0', 'V58.69', '996.81']
    + ['MED:62852']
    + ['V42.0', '996.81', 'MED:63540']
    + ['V42.0', '585.6', '996.81', 'MED:63540']
    + ['V42.0', '996.81']
    + ['V42.0', 'V58.69', '996.81']
    + ['Z94.0', 'Z79.899']
  + doc(last 150 chars):
['V30.01', '770.83', '747.0', '745.10', '745.5', 'MED:104248', 'MED:75961', 'MED:63543', 'MED:61093', 'MED:94350', 'MED:61972', 'MED:60486', 'MED:80988', 'MED:104245', 'MED:61972', 'MED:94350', 'MED:62838', 'MED:62062', 'MED:98284', 'MED:104245', 'MED:63060', 'MED:81379', 'MED:94350', 'MED:60486', 'MED:89129', 'MED:63060', 'MED:69247', 'MED:61253', 'MED:86686', 'MED:81379', 'MED:63543', 'MED:62595', 'MED:61972', 'MED:61511', 'MED:60486', 'MED:80988', 'MED:95751', 'MED:63185', 'MED:61253', 'MED:63060', 'MED:63543', 'MED:62595', 'MED:86686', 'MED:61972', 'MED:60486', 'MED:80988', 'MED:62595', 'MED:60486', 'MED:80988', 'MED:72141', 'MED:62595', 'MED:60486', 'MED:61511', 'MED:61972', 'MED:80988', 'MED:62564', 'MED:72141', 'MED:69155', 'MED:69247', 'MED:62062', 'MED:104245', 'MED:62595', 'MED:61502', 'MED:86686', 'MED:94350', 'MED:61511', 'MED:80988', 'MED:63185', 'MED:104245', 'MED:86686', 'MED:61035', 'MED:60486', 'MED:70466', 'MED:104245', 'MED:61972', 'MED:60472', 'MED:66091', 'MED:61253', 'MED:66091']

  + vdoc
    + ['MED:89129', 'MED:63060', 'MED:69247', 'MED:61253', 'MED:86686', 'MED:81379', 'MED:63543', 'MED:62595', 'MED:61972', 'MED:61511', 'MED:60486']
    + ['MED:80988', 'MED:95751', 'MED:63185', 'MED:61253', 'MED:63060', 'MED:63543', 'MED:62595', 'MED:86686', 'MED:61972', 'MED:60486']
    + ['MED:80988', 'MED:62595', 'MED:60486']
    + ['MED:80988', 'MED:72141', 'MED:62595', 'MED:60486', 'MED:61511', 'MED:61972']
    + ['MED:80988', 'MED:62564', 'MED:72141', 'MED:69155', 'MED:69247', 'MED:62062', 'MED:104245', 'MED:62595', 'MED:61502', 'MED:86686', 'MED:94350', 'MED:61511']
    + ['MED:80988', 'MED:63185', 'MED:104245', 'MED:86686', 'MED:61035', 'MED:60486']
    + ['MED:70466', 'MED:104245', 'MED:61972']
    + ['MED:60472']
    + ['MED:66091', 'MED:61253']
    + ['MED:66091']
  + avgL: 3.401748, max n_tokens_in_visit: 71, min: 1, std: 4.775765
  + avgV: 90.685169, max n_visits_in_doc:   1082, min: 1, std: 114.666660
visitToDocment> size(V):2360 -> size(Dv):214017 (E[nVperDoc]=90.685169)
> D:
[['813.42', '813.42', '813.42', '813.42', '813.42', '813.42', '813.42', '813.42', '813.42', '813.42', '813.42', '813.42', '813.42', '813.42', '813.42', '813.42', '813.42', '813.42', '813.42', '813.42', '813.42', '813.42', '813.42', '813.42', '813.42', '813.42', '813.42', '813.42', '813.42', '813.42', '813.42', '813.42', '813.42', '813.42', '813.42', '813.42', '813.42', '813.42', '813.42', '813.42', '813.42', '813.42', '813.42', '813.42', '813.42', '813.42', '813.42', '813.42', '813.42', '813.42', '813.42', '813.42', '813.42', '813.42', '813.42', '813.42', '813.42', '813.42', '813.42', '813.42', '813.42', '813.42', '813.42', '813.42', '813.42', '813.42', '813.42', '813.42', '813.42', '813.42', '813.42'], ['813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41'], ['813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41'], ['813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41'], ['813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41'], ['813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41'], ['813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41'], ['813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41'], ['813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41'], ['813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41']]

    + computing document vectors nD:2360 => nDEff: 214017 ...
makeTSetVisit> model dir: /Users/pleiades/Documents/work/tpheno/seqmaker/data/CKD/model
getDocVec> method: pv-dm2, model ID: smallCKD, segment_by_visit? True, load precomputed? True
getDocVecPV> prior to labelDocuments, already labeled? False, example: ['813.42', '813.42', '813.42', '813.42', '813.42', '813.42', '813.42', '813.42', '813.42', '813.42', '813.42', '813.42', '813.42', '813.42', '813.42', '813.42', '813.42', '813.42', '813.42', '813.42', '813.42', '813.42', '813.42', '813.42', '813.42', '813.42', '813.42', '813.42', '813.42', '813.42', '813.42', '813.42', '813.42', '813.42', '813.42', '813.42', '813.42', '813.42', '813.42', '813.42', '813.42', '813.42', '813.42', '813.42', '813.42', '813.42', '813.42', '813.42', '813.42', '813.42', '813.42', '813.42', '813.42', '813.42', '813.42', '813.42', '813.42', '813.42', '813.42', '813.42', '813.42', '813.42', '813.42', '813.42', '813.42', '813.42', '813.42', '813.42', '813.42', '813.42', '813.42'], type: <type 'list'>
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
Doc2Vec Parameters
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
  + current d2v method: pv-dm2
  + number of features: 50
  + window size: 10
  + ignore tokens with total freq less than 2
  + number of epochs: 20
  + training method: negative sampling  + number of negative samples: 15  + use concatenation of context vectors? False

getDocVecPV> total: 214017
getDocVecPV> Params summary of d2v models (n_workers: 18, n_iter: 20) ...
  + n_features: 50, window: 10
  + negative sample? 15
  + min count: 2

D2V.load> Info: model path:
/Users/pleiades/Documents/work/tpheno/seqmaker/data/CKD/model/Pf50w10i20-smallCKD.dm

D2V.load> Info: model path:
/Users/pleiades/Documents/work/tpheno/seqmaker/data/CKD/model/Pf50w10i20-smallCKD.dbow

check> input prior to consolidateVisits dim(X): (214017, 100), len(visitDocIDs): 214017
(check) contatenated vector dim: 5000 | lastN=50, indv fDim=100
(check) visit idx:
[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2]
(check) scope idx:
[0, 14, 97, 110, 112, 338, 429, 459, 503, 529, 606, 645, 712, 741, 951, 1075, 1198, 1212, 1372, 1508, 1715, 1794, 1844, 2002, 2011, 2389, 2561, 2958, 2986, 3087, 3103, 3162, 3459, 3530, 3619, 3625, 3778, 3841, 3990, 4012, 4070, 4123, 4223, 4226, 4665, 4813, 4932, 5178, 5549, 5676, 5688, 5716, 5805, 5921, 6438, 6445, 6463, 6562, 6641, 6751, 6825, 7009, 7053, 7074, 7079, 7175, 7245, 7326, 7590, 8072, 8132, 8135, 8147, 8186, 8241, 8587, 8595, 8709, 8737, 8831, 8847, 8968, 9000, 9059, 9167, 10166, 10315, 10501, 10553, 10577, 11085, 11192, 11221, 11887, 11969, 12067, 12116, 12120, 12461, 12569]

verify> mean dim: 9068.516949, median: 4900.000000, std: 11466.665963
(check) flatterned X, dim(Xp): (2360,)
tsHandler> save document vectors (cv=0), sparse? False ...
  + params: dim(X):(2360, 5000), index:0, n(docIDs):2360, d2v:pv-dm2, cohort:CKD, ctype:regular, shuffle? False, meta: smallCKD
tsHandler> training set dir: /Users/pleiades/Documents/work/tpheno/seqmaker/data/CKD/combined
prepareTrainingSet> n_classes: 11
TSet> Params: cohort: CKD, file id: regular-pv-dm2-smallCKD
TSet.saveDataFrame> tset params (cohort:CKD d2v:pv-dm2, ctype:regular, suffix=smallCKD)
TSet.saveDataFrame> Saving (cohort=CKD, d2v=pv-dm2, suffix=smallCKD) dataset to:
/Users/pleiades/Documents/work/tpheno/seqmaker/data/CKD/combined/tset-n0-IDregular-pv-dm2-smallCKD-GCKD.csv

status> Model computation complete (@nTrial=0)
info> each doc is repr by the last 50 visits
TSet> Params: cohort: CKD, file id: regular-pv-dm2-smallCKD
TSet.load> loading training set (cohort=CKD, suffix=smallCKD) from:
/Users/pleiades/Documents/work/tpheno/seqmaker/data/CKD/combined/tset-n0-IDregular-pv-dm2-smallCKD-GCKD.csv

tsHandler.profile> Found 11 unique labels ...
  + label=CKD Stage 3a => N=215
  + label=Unknown => N=411
  + label=CKD Stage 3b => N=135
  + label=ESRD on dialysis => N=41
  + label=CKD G1-control => N=87
  + label=CKD G1A1-control => N=108
  + label=CKD Stage 5 => N=31
  + label=CKD Stage 4 => N=56
  + label=ESRD after transplant => N=686
  + label=CKD Stage 2 => N=528
  + label=CKD Stage 1 => N=62
loadTSetCombined> Modifying training data ...
> Prior to re-labeling ...
tsHandler.profile> Found 11 unique labels ...
  + label=CKD Stage 3a => N=215
  + label=Unknown => N=411
  + label=CKD Stage 3b => N=135
  + label=ESRD on dialysis => N=41
  + label=CKD G1-control => N=87
  + label=CKD G1A1-control => N=108
  + label=CKD Stage 5 => N=31
  + label=CKD Stage 4 => N=56
  + label=ESRD after transplant => N=686
  + label=CKD Stage 2 => N=528
  + label=CKD Stage 1 => N=62
  + (before) unique labels:
['CKD Stage 3a' 'CKD Stage 2' 'Unknown' 'CKD Stage 3b' 'CKD Stage 4'
 'ESRD after transplant' 'ESRD on dialysis' 'CKD G1A1-control'
 'CKD Stage 1' 'CKD G1-control' 'CKD Stage 5']

  + CKD Stage 5 <- ['ESRD after transplant', 'ESRD on dialysis']
  + CKD Stage 3 <- ['CKD Stage 3a', 'CKD Stage 3b']
  + Others <- ['CKD G1-control', 'CKD G1A1-control', 'Unknown']
merge> n_labels: 11 -> 6
  + (after) unique labels:
['CKD Stage 3' 'CKD Stage 2' 'Others' 'CKD Stage 4' 'CKD Stage 5'
 'CKD Stage 1']

> After re-labeling ...
tsHandler.profile> Found 6 unique labels ...
  + label=Others => N=606
  + label=CKD Stage 5 => N=758
  + label=CKD Stage 4 => N=56
  + label=CKD Stage 3 => N=350
  + label=CKD Stage 2 => N=528
  + label=CKD Stage 1 => N=62
loadTSet> number of classes: 6
... cohort=CKD, ctype=regular, d2v=pv-dm2, meta=smallCKD
  + is_simplified? False, ... 
  + classification mode: multiclass
  + classifiers:
[]
  + training set type:dense
  + training set dim:2360
  + n classes:6

d_classify> dim(ts): (2360, 5002) > n_timesteps: 50, n_features: 100
  + dim(X <- ts): (2360, 5000)
d_classify> reshaped X: (2360, 50, 100) | n_classes=6

<<< Experimental Settings >>>

   + tset type dense, maxNPerClass: None, drop control? False
  + cohort: CKD, ctype: regular

  + D2V: pv-dm2, params> window: 10, n_features: 50
       + n_iter: 20, min_count: 2

  + userFileID: smallCKD

... data: 

... params (model selection): 

model_selection> trying {'n_units': 150, 'dropout_rate': 0.2} ...

make_lstm> n_units=150, r_dropout=0.200000, n_layers=1, n_classes=6
WARNING:tensorflow:From dnn_utils.py:154: streaming_auc (from tensorflow.contrib.metrics.python.ops.metric_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Please switch to tf.metrics.auc. Note that the order of the labels and predictions arguments has been switched.
  + lookup:
{'Others': 5, 'CKD Stage 5': 4, 'CKD Stage 4': 3, 'CKD Stage 3': 2, 'CKD Stage 2': 1, 'CKD Stage 1': 0}

... class weights:
{0: 6.344086021505376, 1: 0.74494949494949492, 2: 1.1238095238095238, 3: 7.0238095238095237, 4: 0.51890941072999119, 5: 0.64906490649064907}

====================================================================================================
... early stopping>
       + patience: 20, model='max'
... model training>
       + batch_size: 32, epochs: 60, shuffle? True, metric: auc_roc
====================================================================================================
Train on 1652 samples, validate on 708 samples
Epoch 1/60
2018-07-01 11:05:13.491993: I tensorflow/core/platform/cpu_feature_guard.cc:140] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA
1652/1652 [==============================] - 12s 7ms/step - loss: 1.6539 - acc: 0.2942 - auc_roc: 0.6082 - val_loss: 1.5034 - val_acc: 0.6172 - val_auc_roc: 0.7243
Epoch 2/60
1652/1652 [==============================] - 9s 6ms/step - loss: 1.4070 - acc: 0.4419 - auc_roc: 0.7567 - val_loss: 1.6935 - val_acc: 0.4887 - val_auc_roc: 0.7720
Epoch 3/60
1652/1652 [==============================] - 13s 8ms/step - loss: 1.3330 - acc: 0.4322 - auc_roc: 0.7792 - val_loss: 1.7401 - val_acc: 0.3686 - val_auc_roc: 0.7727
Epoch 4/60
1652/1652 [==============================] - 11s 7ms/step - loss: 1.2155 - acc: 0.4855 - auc_roc: 0.7728 - val_loss: 1.3462 - val_acc: 0.6624 - val_auc_roc: 0.7864
Epoch 5/60
1652/1652 [==============================] - 11s 7ms/step - loss: 1.0774 - acc: 0.5260 - auc_roc: 0.7964 - val_loss: 1.4766 - val_acc: 0.6822 - val_auc_roc: 0.8058
Epoch 6/60
1652/1652 [==============================] - 11s 7ms/step - loss: 1.1147 - acc: 0.4740 - auc_roc: 0.8087 - val_loss: 1.6177 - val_acc: 0.5268 - val_auc_roc: 0.8097
Epoch 7/60
1652/1652 [==============================] - 11s 7ms/step - loss: 0.9777 - acc: 0.5847 - auc_roc: 0.8140 - val_loss: 1.4904 - val_acc: 0.6045 - val_auc_roc: 0.8189
Epoch 8/60
1652/1652 [==============================] - 11s 7ms/step - loss: 0.8730 - acc: 0.6065 - auc_roc: 0.8236 - val_loss: 1.8000 - val_acc: 0.6116 - val_auc_roc: 0.8285
Epoch 9/60
1652/1652 [==============================] - 11s 6ms/step - loss: 0.7969 - acc: 0.6277 - auc_roc: 0.8333 - val_loss: 1.7486 - val_acc: 0.6921 - val_auc_roc: 0.8388
Epoch 10/60
1652/1652 [==============================] - 11s 7ms/step - loss: 0.7653 - acc: 0.6513 - auc_roc: 0.8434 - val_loss: 1.6687 - val_acc: 0.6285 - val_auc_roc: 0.8474
Epoch 11/60
1652/1652 [==============================] - 10s 6ms/step - loss: 0.7089 - acc: 0.6531 - auc_roc: 0.8509 - val_loss: 2.0333 - val_acc: 0.6328 - val_auc_roc: 0.8544
Epoch 12/60
1652/1652 [==============================] - 12s 8ms/step - loss: 0.6709 - acc: 0.6816 - auc_roc: 0.8574 - val_loss: 2.0261 - val_acc: 0.6186 - val_auc_roc: 0.8606
Epoch 13/60
1652/1652 [==============================] - 10s 6ms/step - loss: 0.6308 - acc: 0.7173 - auc_roc: 0.8633 - val_loss: 1.9671 - val_acc: 0.7048 - val_auc_roc: 0.8668
Epoch 14/60
1652/1652 [==============================] - 11s 6ms/step - loss: 0.6963 - acc: 0.6840 - auc_roc: 0.8691 - val_loss: 1.8474 - val_acc: 0.6455 - val_auc_roc: 0.8713
Epoch 15/60
1652/1652 [==============================] - 11s 6ms/step - loss: 0.6125 - acc: 0.7016 - auc_roc: 0.8734 - val_loss: 2.2866 - val_acc: 0.2924 - val_auc_roc: 0.8733
Epoch 16/60
1652/1652 [==============================] - 10s 6ms/step - loss: 0.5745 - acc: 0.7167 - auc_roc: 0.8734 - val_loss: 2.0623 - val_acc: 0.6582 - val_auc_roc: 0.8760
Epoch 17/60
1652/1652 [==============================] - 8s 5ms/step - loss: 0.4719 - acc: 0.7742 - auc_roc: 0.8783 - val_loss: 2.2776 - val_acc: 0.6879 - val_auc_roc: 0.8810
Epoch 18/60
1652/1652 [==============================] - 10s 6ms/step - loss: 0.5037 - acc: 0.7458 - auc_roc: 0.8829 - val_loss: 2.2799 - val_acc: 0.6328 - val_auc_roc: 0.8848
Epoch 19/60
1652/1652 [==============================] - 9s 6ms/step - loss: 0.4523 - acc: 0.7821 - auc_roc: 0.8865 - val_loss: 2.2971 - val_acc: 0.6384 - val_auc_roc: 0.8884
Epoch 20/60
1652/1652 [==============================] - 10s 6ms/step - loss: 0.3687 - acc: 0.8293 - auc_roc: 0.8903 - val_loss: 2.3303 - val_acc: 0.6766 - val_auc_roc: 0.8926
Epoch 21/60
1652/1652 [==============================] - 7s 4ms/step - loss: 0.3227 - acc: 0.8438 - auc_roc: 0.8946 - val_loss: 2.4711 - val_acc: 0.6808 - val_auc_roc: 0.8968
Epoch 22/60
1652/1652 [==============================] - 6s 4ms/step - loss: 0.3206 - acc: 0.8511 - auc_roc: 0.8986 - val_loss: 2.3646 - val_acc: 0.6907 - val_auc_roc: 0.9006
Epoch 23/60
1652/1652 [==============================] - 7s 4ms/step - loss: 0.3536 - acc: 0.8281 - auc_roc: 0.9021 - val_loss: 2.5200 - val_acc: 0.5890 - val_auc_roc: 0.9033
Epoch 24/60
1652/1652 [==============================] - 8s 5ms/step - loss: 0.3418 - acc: 0.8438 - auc_roc: 0.9043 - val_loss: 2.7569 - val_acc: 0.6215 - val_auc_roc: 0.9057
Epoch 00024: early stopping
... history of metrics comprising: ['acc', 'loss', 'val_auc_roc', 'auc_roc', 'val_acc', 'val_loss']
... ... metric (acc): [0.70157385016757701, 0.71670702193608871, 0.77421307534917505, 0.74576271186440679, 0.78208232445520576, 0.82929782111188688, 0.84382566614820653, 0.8510895886663663, 0.82808716678157557, 0.84382566557092187] (n=24)
output> saving performance to:
/Users/pleiades/Documents/work/tpheno/seqmaker/data/CKD/plot/model_evalation-ep200b16.tif

... ... metric (loss): [0.61248184015329465, 0.57454221185125387, 0.47190951146456001, 0.50374924718034753, 0.45230465319197055, 0.36865786360193398, 0.32270481424816583, 0.32057689415340562, 0.35359510902053798, 0.34175972304967644] (n=24)
output> saving performance to:
/Users/pleiades/Documents/work/tpheno/seqmaker/data/CKD/plot/model_evalation-ep200b16.tif


model_selection> trying {'n_units': 200, 'dropout_rate': 0.2} ...

make_lstm> n_units=200, r_dropout=0.200000, n_layers=1, n_classes=6
  + lookup:
{'Others': 5, 'CKD Stage 5': 4, 'CKD Stage 4': 3, 'CKD Stage 3': 2, 'CKD Stage 2': 1, 'CKD Stage 1': 0}

... class weights:
{0: 6.344086021505376, 1: 0.74494949494949492, 2: 1.1238095238095238, 3: 7.0238095238095237, 4: 0.51890941072999119, 5: 0.64906490649064907}

====================================================================================================
... early stopping>
       + patience: 20, model='max'
... model training>
       + batch_size: 32, epochs: 60, shuffle? True, metric: auc_roc
====================================================================================================
Train on 1652 samples, validate on 708 samples
Epoch 1/60
1652/1652 [==============================] - 10s 6ms/step - loss: 1.6351 - acc: 0.3190 - auc_roc: 0.6321 - val_loss: 1.7728 - val_acc: 0.2966 - val_auc_roc: 0.6822
Epoch 2/60
1652/1652 [==============================] - 9s 5ms/step - loss: 1.3685 - acc: 0.4558 - auc_roc: 0.7038 - val_loss: 1.9588 - val_acc: 0.3983 - val_auc_roc: 0.7266
Epoch 3/60
1652/1652 [==============================] - 9s 5ms/step - loss: 1.2595 - acc: 0.5236 - auc_roc: 0.7403 - val_loss: 1.5865 - val_acc: 0.5028 - val_auc_roc: 0.7558
Epoch 4/60
1652/1652 [==============================] - 9s 5ms/step - loss: 1.1697 - acc: 0.5218 - auc_roc: 0.7671 - val_loss: 1.3572 - val_acc: 0.6751 - val_auc_roc: 0.7833
Epoch 5/60
1652/1652 [==============================] - 9s 5ms/step - loss: 1.0658 - acc: 0.5254 - auc_roc: 0.7941 - val_loss: 1.4527 - val_acc: 0.6921 - val_auc_roc: 0.8046
Epoch 6/60
1652/1652 [==============================] - 8s 5ms/step - loss: 0.9985 - acc: 0.5484 - auc_roc: 0.8123 - val_loss: 1.6680 - val_acc: 0.6271 - val_auc_roc: 0.8189
Epoch 7/60
1652/1652 [==============================] - 9s 5ms/step - loss: 0.8882 - acc: 0.6108 - auc_roc: 0.8251 - val_loss: 1.7101 - val_acc: 0.6977 - val_auc_roc: 0.8319
Epoch 8/60
1652/1652 [==============================] - 9s 5ms/step - loss: 0.8235 - acc: 0.6084 - auc_roc: 0.8373 - val_loss: 1.6384 - val_acc: 0.6681 - val_auc_roc: 0.8427
Epoch 9/60
1652/1652 [==============================] - 9s 5ms/step - loss: 0.7517 - acc: 0.6423 - auc_roc: 0.8472 - val_loss: 1.8080 - val_acc: 0.7006 - val_auc_roc: 0.8524
Epoch 10/60
1652/1652 [==============================] - 9s 5ms/step - loss: 0.7611 - acc: 0.6471 - auc_roc: 0.8561 - val_loss: 1.8284 - val_acc: 0.6949 - val_auc_roc: 0.8599
Epoch 11/60
1652/1652 [==============================] - 8s 5ms/step - loss: 0.7054 - acc: 0.6671 - auc_roc: 0.8630 - val_loss: 1.6758 - val_acc: 0.6780 - val_auc_roc: 0.8665
Epoch 12/60
1652/1652 [==============================] - 8s 5ms/step - loss: 0.6463 - acc: 0.6979 - auc_roc: 0.8692 - val_loss: 1.9190 - val_acc: 0.6610 - val_auc_roc: 0.8721
Epoch 13/60
1652/1652 [==============================] - 8s 5ms/step - loss: 0.5810 - acc: 0.7179 - auc_roc: 0.8745 - val_loss: 2.1600 - val_acc: 0.6751 - val_auc_roc: 0.8774
Epoch 14/60
1652/1652 [==============================] - 9s 5ms/step - loss: 0.5350 - acc: 0.7403 - auc_roc: 0.8798 - val_loss: 2.1327 - val_acc: 0.6427 - val_auc_roc: 0.8823
Epoch 15/60
1652/1652 [==============================] - 8s 5ms/step - loss: 0.5077 - acc: 0.7585 - auc_roc: 0.8844 - val_loss: 2.0036 - val_acc: 0.6285 - val_auc_roc: 0.8865
Epoch 16/60
1652/1652 [==============================] - 7s 4ms/step - loss: 0.5390 - acc: 0.7458 - auc_roc: 0.8883 - val_loss: 2.2792 - val_acc: 0.6328 - val_auc_roc: 0.8900
Epoch 17/60
1652/1652 [==============================] - 7s 5ms/step - loss: 0.5601 - acc: 0.7252 - auc_roc: 0.8909 - val_loss: 2.2699 - val_acc: 0.7203 - val_auc_roc: 0.8929
Epoch 18/60
1652/1652 [==============================] - 8s 5ms/step - loss: 0.4656 - acc: 0.7809 - auc_roc: 0.8947 - val_loss: 2.2031 - val_acc: 0.6455 - val_auc_roc: 0.8965
Epoch 19/60
1652/1652 [==============================] - 8s 5ms/step - loss: 0.4009 - acc: 0.8021 - auc_roc: 0.8979 - val_loss: 2.4828 - val_acc: 0.7260 - val_auc_roc: 0.9001
Epoch 20/60
1652/1652 [==============================] - 8s 5ms/step - loss: 0.3199 - acc: 0.8414 - auc_roc: 0.9020 - val_loss: 2.6025 - val_acc: 0.6624 - val_auc_roc: 0.9038
Epoch 21/60
1652/1652 [==============================] - 9s 5ms/step - loss: 0.2773 - acc: 0.8705 - auc_roc: 0.9053 - val_loss: 2.7017 - val_acc: 0.7203 - val_auc_roc: 0.9075
Epoch 22/60
1652/1652 [==============================] - 8s 5ms/step - loss: 0.2638 - acc: 0.8783 - auc_roc: 0.9091 - val_loss: 2.6626 - val_acc: 0.6695 - val_auc_roc: 0.9109
Epoch 23/60
1652/1652 [==============================] - 8s 5ms/step - loss: 0.2343 - acc: 0.9068 - auc_roc: 0.9123 - val_loss: 2.6144 - val_acc: 0.7203 - val_auc_roc: 0.9142
Epoch 24/60
1652/1652 [==============================] - 8s 5ms/step - loss: 0.1649 - acc: 0.9255 - auc_roc: 0.9157 - val_loss: 2.8943 - val_acc: 0.7090 - val_auc_roc: 0.9176
Epoch 00024: early stopping
... history of metrics comprising: ['acc', 'loss', 'val_auc_roc', 'auc_roc', 'val_acc', 'val_loss']
... ... metric (acc): [0.75847457612686531, 0.74576271215304912, 0.72518159791863279, 0.78087167099082155, 0.8020581116687876, 0.84140435806486857, 0.87046004828182899, 0.87832929782082325, 0.90677966072830685, 0.92554479418886193] (n=24)
output> saving performance to:
/Users/pleiades/Documents/work/tpheno/seqmaker/data/CKD/plot/model_evalation-ep200b16.tif

... ... metric (loss): [0.50767781601691075, 0.53900389824306127, 0.56008200841723577, 0.46558169764410207, 0.40091328413088156, 0.3198650437463571, 0.27730943713580725, 0.2638344835787651, 0.23425600459442877, 0.16489175833382849] (n=24)
output> saving performance to:
/Users/pleiades/Documents/work/tpheno/seqmaker/data/CKD/plot/model_evalation-ep200b16.tif


model_selection> trying {'n_units': 300, 'dropout_rate': 0.2} ...

make_lstm> n_units=300, r_dropout=0.200000, n_layers=1, n_classes=6
  + lookup:
{'Others': 5, 'CKD Stage 5': 4, 'CKD Stage 4': 3, 'CKD Stage 3': 2, 'CKD Stage 2': 1, 'CKD Stage 1': 0}

... class weights:
{0: 6.344086021505376, 1: 0.74494949494949492, 2: 1.1238095238095238, 3: 7.0238095238095237, 4: 0.51890941072999119, 5: 0.64906490649064907}

====================================================================================================
... early stopping>
       + patience: 20, model='max'
... model training>
       + batch_size: 32, epochs: 60, shuffle? True, metric: auc_roc
====================================================================================================
Train on 1652 samples, validate on 708 samples
Epoch 1/60
1652/1652 [==============================] - 20s 12ms/step - loss: 1.6729 - acc: 0.2833 - auc_roc: 0.6211 - val_loss: 1.8886 - val_acc: 0.1751 - val_auc_roc: 0.6358
Epoch 2/60
1652/1652 [==============================] - 17s 10ms/step - loss: 1.4497 - acc: 0.4255 - auc_roc: 0.6678 - val_loss: 1.7176 - val_acc: 0.4619 - val_auc_roc: 0.6970
Epoch 3/60
1652/1652 [==============================] - 17s 10ms/step - loss: 1.2965 - acc: 0.4800 - auc_roc: 0.7194 - val_loss: 1.7064 - val_acc: 0.4661 - val_auc_roc: 0.7395
Epoch 4/60
1652/1652 [==============================] - 13s 8ms/step - loss: 1.1756 - acc: 0.5260 - auc_roc: 0.7542 - val_loss: 1.5262 - val_acc: 0.6681 - val_auc_roc: 0.7714
Epoch 5/60
1652/1652 [==============================] - 13s 8ms/step - loss: 1.0565 - acc: 0.5412 - auc_roc: 0.7849 - val_loss: 1.5348 - val_acc: 0.6201 - val_auc_roc: 0.7946
Epoch 6/60
1652/1652 [==============================] - 16s 10ms/step - loss: 0.9991 - acc: 0.5642 - auc_roc: 0.8031 - val_loss: 1.6543 - val_acc: 0.6822 - val_auc_roc: 0.8118
Epoch 7/60
1652/1652 [==============================] - 20s 12ms/step - loss: 0.9135 - acc: 0.5866 - auc_roc: 0.8188 - val_loss: 1.9698 - val_acc: 0.5268 - val_auc_roc: 0.8231
Epoch 8/60
1652/1652 [==============================] - 11s 6ms/step - loss: 0.7937 - acc: 0.6326 - auc_roc: 0.8270 - val_loss: 1.7450 - val_acc: 0.6893 - val_auc_roc: 0.8344
Epoch 9/60
1652/1652 [==============================] - 10s 6ms/step - loss: 0.8081 - acc: 0.6265 - auc_roc: 0.8392 - val_loss: 1.8719 - val_acc: 0.5862 - val_auc_roc: 0.8433
Epoch 10/60
1652/1652 [==============================] - 8s 5ms/step - loss: 0.7841 - acc: 0.6144 - auc_roc: 0.8459 - val_loss: 2.1384 - val_acc: 0.6850 - val_auc_roc: 0.8501
Epoch 11/60
1652/1652 [==============================] - 7s 4ms/step - loss: 0.7074 - acc: 0.6683 - auc_roc: 0.8537 - val_loss: 1.9738 - val_acc: 0.5085 - val_auc_roc: 0.8556
Epoch 12/60
1652/1652 [==============================] - 7s 4ms/step - loss: 0.6730 - acc: 0.6659 - auc_roc: 0.8575 - val_loss: 1.7835 - val_acc: 0.6681 - val_auc_roc: 0.8611
Epoch 13/60
1652/1652 [==============================] - 7s 4ms/step - loss: 0.5987 - acc: 0.7149 - auc_roc: 0.8643 - val_loss: 1.8295 - val_acc: 0.7203 - val_auc_roc: 0.8682
Epoch 14/60
1652/1652 [==============================] - 7s 4ms/step - loss: 0.6369 - acc: 0.6979 - auc_roc: 0.8710 - val_loss: 1.8120 - val_acc: 0.7006 - val_auc_roc: 0.8739
Epoch 15/60
1652/1652 [==============================] - 7s 4ms/step - loss: 0.5414 - acc: 0.7312 - auc_roc: 0.8766 - val_loss: 1.9419 - val_acc: 0.7020 - val_auc_roc: 0.8795
Epoch 16/60
1652/1652 [==============================] - 7s 4ms/step - loss: 0.4450 - acc: 0.7772 - auc_roc: 0.8822 - val_loss: 1.9894 - val_acc: 0.6963 - val_auc_roc: 0.8852
Epoch 17/60
1652/1652 [==============================] - 7s 4ms/step - loss: 0.3764 - acc: 0.8087 - auc_roc: 0.8879 - val_loss: 2.1073 - val_acc: 0.7105 - val_auc_roc: 0.8908
Epoch 18/60
1652/1652 [==============================] - 7s 4ms/step - loss: 0.3250 - acc: 0.8366 - auc_roc: 0.8933 - val_loss: 2.2300 - val_acc: 0.6907 - val_auc_roc: 0.8959
Epoch 19/60
1652/1652 [==============================] - 7s 4ms/step - loss: 0.3239 - acc: 0.8438 - auc_roc: 0.8979 - val_loss: 2.4754 - val_acc: 0.7161 - val_auc_roc: 0.9003
Epoch 20/60
1652/1652 [==============================] - 7s 4ms/step - loss: 0.2478 - acc: 0.8777 - auc_roc: 0.9025 - val_loss: 2.3749 - val_acc: 0.6568 - val_auc_roc: 0.9046
Epoch 21/60
1652/1652 [==============================] - 7s 4ms/step - loss: 0.2126 - acc: 0.9007 - auc_roc: 0.9065 - val_loss: 2.6124 - val_acc: 0.7472 - val_auc_roc: 0.9089
Epoch 22/60
1652/1652 [==============================] - 7s 4ms/step - loss: 0.1848 - acc: 0.9189 - auc_roc: 0.9109 - val_loss: 2.6764 - val_acc: 0.6963 - val_auc_roc: 0.9130
Epoch 23/60
1652/1652 [==============================] - 7s 4ms/step - loss: 0.1641 - acc: 0.9334 - auc_roc: 0.9147 - val_loss: 2.9051 - val_acc: 0.7034 - val_auc_roc: 0.9166
Epoch 24/60
1652/1652 [==============================] - 7s 4ms/step - loss: 0.1376 - acc: 0.9443 - auc_roc: 0.9182 - val_loss: 2.7285 - val_acc: 0.7288 - val_auc_roc: 0.9201
Epoch 00024: early stopping
... history of metrics comprising: ['acc', 'loss', 'val_auc_roc', 'auc_roc', 'val_acc', 'val_loss']
... ... metric (acc): [0.73123486668376603, 0.7772397095874205, 0.80871670702179177, 0.83656174363004676, 0.84382566600388531, 0.87772397123295232, 0.90072639196317361, 0.91888619825857309, 0.93341404358353508, 0.94430992721645368] (n=24)
output> saving performance to:
/Users/pleiades/Documents/work/tpheno/seqmaker/data/CKD/plot/model_evalation-ep200b16.tif

... ... metric (loss): [0.54139975427715314, 0.44495623928582695, 0.37638688130759729, 0.32503937606950073, 0.32391000847550916, 0.24783218307443161, 0.21260860042768298, 0.18477108612764834, 0.16410873083456376, 0.13758512970610334] (n=24)
output> saving performance to:
/Users/pleiades/Documents/work/tpheno/seqmaker/data/CKD/plot/model_evalation-ep200b16.tif


model_selection> trying {'n_units': 400, 'dropout_rate': 0.2} ...

make_lstm> n_units=400, r_dropout=0.200000, n_layers=1, n_classes=6
  + lookup:
{'Others': 5, 'CKD Stage 5': 4, 'CKD Stage 4': 3, 'CKD Stage 3': 2, 'CKD Stage 2': 1, 'CKD Stage 1': 0}

... class weights:
{0: 6.344086021505376, 1: 0.74494949494949492, 2: 1.1238095238095238, 3: 7.0238095238095237, 4: 0.51890941072999119, 5: 0.64906490649064907}

====================================================================================================
... early stopping>
       + patience: 20, model='max'
... model training>
       + batch_size: 32, epochs: 60, shuffle? True, metric: auc_roc
====================================================================================================
Train on 1652 samples, validate on 708 samples
Epoch 1/60
1652/1652 [==============================] - 10s 6ms/step - loss: 1.6218 - acc: 0.3517 - auc_roc: 0.6720 - val_loss: 1.4416 - val_acc: 0.5989 - val_auc_roc: 0.7614
Epoch 2/60
1652/1652 [==============================] - 11s 6ms/step - loss: 1.4898 - acc: 0.3977 - auc_roc: 0.7687 - val_loss: 1.7189 - val_acc: 0.5777 - val_auc_roc: 0.7719
Epoch 3/60
1652/1652 [==============================] - 10s 6ms/step - loss: 1.2833 - acc: 0.4867 - auc_roc: 0.7851 - val_loss: 1.6739 - val_acc: 0.3220 - val_auc_roc: 0.7791
Epoch 4/60
1652/1652 [==============================] - 11s 6ms/step - loss: 1.1734 - acc: 0.5091 - auc_roc: 0.7808 - val_loss: 1.4436 - val_acc: 0.6540 - val_auc_roc: 0.7919
Epoch 5/60
1652/1652 [==============================] - 10s 6ms/step - loss: 1.1378 - acc: 0.5266 - auc_roc: 0.8009 - val_loss: 1.9371 - val_acc: 0.2825 - val_auc_roc: 0.7992
Epoch 6/60
1652/1652 [==============================] - 10s 6ms/step - loss: 1.0575 - acc: 0.5442 - auc_roc: 0.7991 - val_loss: 1.6873 - val_acc: 0.5508 - val_auc_roc: 0.8040
Epoch 7/60
1652/1652 [==============================] - 10s 6ms/step - loss: 0.9076 - acc: 0.5866 - auc_roc: 0.8094 - val_loss: 1.7034 - val_acc: 0.6017 - val_auc_roc: 0.8160
Epoch 8/60
1652/1652 [==============================] - 10s 6ms/step - loss: 0.8545 - acc: 0.6271 - auc_roc: 0.8215 - val_loss: 1.9621 - val_acc: 0.6681 - val_auc_roc: 0.8282
Epoch 9/60
1652/1652 [==============================] - 10s 6ms/step - loss: 0.7987 - acc: 0.6519 - auc_roc: 0.8338 - val_loss: 1.5245 - val_acc: 0.6596 - val_auc_roc: 0.8395
Epoch 10/60
1652/1652 [==============================] - 10s 6ms/step - loss: 0.7436 - acc: 0.6665 - auc_roc: 0.8438 - val_loss: 1.9285 - val_acc: 0.6638 - val_auc_roc: 0.8485
Epoch 11/60
1652/1652 [==============================] - 10s 6ms/step - loss: 0.6729 - acc: 0.6768 - auc_roc: 0.8527 - val_loss: 1.8293 - val_acc: 0.6554 - val_auc_roc: 0.8568
Epoch 12/60
1652/1652 [==============================] - 10s 6ms/step - loss: 0.6184 - acc: 0.7040 - auc_roc: 0.8605 - val_loss: 2.0277 - val_acc: 0.6172 - val_auc_roc: 0.8640
Epoch 13/60
1652/1652 [==============================] - 11s 7ms/step - loss: 0.5777 - acc: 0.7215 - auc_roc: 0.8667 - val_loss: 1.9151 - val_acc: 0.6314 - val_auc_roc: 0.8699
Epoch 14/60
1652/1652 [==============================] - 10s 6ms/step - loss: 0.5008 - acc: 0.7476 - auc_roc: 0.8727 - val_loss: 2.1205 - val_acc: 0.7345 - val_auc_roc: 0.8765
Epoch 15/60
1652/1652 [==============================] - 10s 6ms/step - loss: 0.4023 - acc: 0.7978 - auc_roc: 0.8800 - val_loss: 2.5166 - val_acc: 0.6186 - val_auc_roc: 0.8831
Epoch 16/60
1652/1652 [==============================] - 10s 6ms/step - loss: 0.3474 - acc: 0.8329 - auc_roc: 0.8857 - val_loss: 2.2375 - val_acc: 0.7006 - val_auc_roc: 0.8890
Epoch 17/60
1652/1652 [==============================] - 11s 6ms/step - loss: 0.3303 - acc: 0.8347 - auc_roc: 0.8917 - val_loss: 2.3120 - val_acc: 0.6808 - val_auc_roc: 0.8945
Epoch 18/60
1652/1652 [==============================] - 10s 6ms/step - loss: 0.3424 - acc: 0.8432 - auc_roc: 0.8968 - val_loss: 2.1722 - val_acc: 0.6949 - val_auc_roc: 0.8994
Epoch 19/60
1652/1652 [==============================] - 11s 6ms/step - loss: 0.3611 - acc: 0.8553 - auc_roc: 0.9015 - val_loss: 2.0203 - val_acc: 0.7076 - val_auc_roc: 0.9038
Epoch 20/60
1652/1652 [==============================] - 10s 6ms/step - loss: 0.2817 - acc: 0.8729 - auc_roc: 0.9057 - val_loss: 2.4610 - val_acc: 0.6907 - val_auc_roc: 0.9079
Epoch 21/60
1652/1652 [==============================] - 10s 6ms/step - loss: 0.2824 - acc: 0.8904 - auc_roc: 0.9096 - val_loss: 2.4761 - val_acc: 0.7062 - val_auc_roc: 0.9116
Epoch 00021: early stopping
... history of metrics comprising: ['acc', 'loss', 'val_auc_roc', 'auc_roc', 'val_acc', 'val_loss']
... ... metric (acc): [0.70399515752930908, 0.72154963665955296, 0.74757869220530437, 0.79782082310023084, 0.83292978179368216, 0.83474576242322207, 0.84322033883872971, 0.85532687636899607, 0.87288135622084573, 0.89043583520676839] (n=21)
output> saving performance to:
/Users/pleiades/Documents/work/tpheno/seqmaker/data/CKD/plot/model_evalation-ep200b16.tif

... ... metric (loss): [0.61838849202772606, 0.57773506771276995, 0.5008396542029, 0.4023285557225022, 0.34741132895825272, 0.3303152339726903, 0.34237665710091303, 0.36110872102418767, 0.28168682317468213, 0.28239775219927687] (n=21)
output> saving performance to:
/Users/pleiades/Documents/work/tpheno/seqmaker/data/CKD/plot/model_evalation-ep200b16.tif


model_selection> trying {'n_units': 150, 'dropout_rate': 0.3} ...

make_lstm> n_units=150, r_dropout=0.300000, n_layers=1, n_classes=6
  + lookup:
{'Others': 5, 'CKD Stage 5': 4, 'CKD Stage 4': 3, 'CKD Stage 3': 2, 'CKD Stage 2': 1, 'CKD Stage 1': 0}

... class weights:
{0: 6.344086021505376, 1: 0.74494949494949492, 2: 1.1238095238095238, 3: 7.0238095238095237, 4: 0.51890941072999119, 5: 0.64906490649064907}

====================================================================================================
... early stopping>
       + patience: 20, model='max'
... model training>
       + batch_size: 32, epochs: 60, shuffle? True, metric: auc_roc
====================================================================================================
Train on 1652 samples, validate on 708 samples
Epoch 1/60
1652/1652 [==============================] - 4s 3ms/step - loss: 1.6352 - acc: 0.3323 - auc_roc: 0.6212 - val_loss: 1.6709 - val_acc: 0.5198 - val_auc_roc: 0.7226
Epoch 2/60
1652/1652 [==============================] - 4s 2ms/step - loss: 1.4208 - acc: 0.4128 - auc_roc: 0.7391 - val_loss: 1.4052 - val_acc: 0.6299 - val_auc_roc: 0.7655
Epoch 3/60
1652/1652 [==============================] - 4s 2ms/step - loss: 1.2600 - acc: 0.4933 - auc_roc: 0.7832 - val_loss: 1.9780 - val_acc: 0.2528 - val_auc_roc: 0.7710
Epoch 4/60
1652/1652 [==============================] - 4s 2ms/step - loss: 1.2088 - acc: 0.4740 - auc_roc: 0.7640 - val_loss: 1.3938 - val_acc: 0.6412 - val_auc_roc: 0.7768
Epoch 5/60
1652/1652 [==============================] - 4s 2ms/step - loss: 1.1434 - acc: 0.5085 - auc_roc: 0.7851 - val_loss: 1.7397 - val_acc: 0.5932 - val_auc_roc: 0.7927
Epoch 6/60
1652/1652 [==============================] - 4s 2ms/step - loss: 1.0232 - acc: 0.5575 - auc_roc: 0.8004 - val_loss: 1.5826 - val_acc: 0.5523 - val_auc_roc: 0.8067
Epoch 7/60
1652/1652 [==============================] - 4s 2ms/step - loss: 0.9146 - acc: 0.6096 - auc_roc: 0.8125 - val_loss: 1.6306 - val_acc: 0.6624 - val_auc_roc: 0.8200
Epoch 8/60
1652/1652 [==============================] - 4s 2ms/step - loss: 0.9282 - acc: 0.5660 - auc_roc: 0.8241 - val_loss: 1.7707 - val_acc: 0.6059 - val_auc_roc: 0.8274
Epoch 9/60
1652/1652 [==============================] - 4s 2ms/step - loss: 0.8394 - acc: 0.6168 - auc_roc: 0.8317 - val_loss: 1.6088 - val_acc: 0.6469 - val_auc_roc: 0.8365
Epoch 10/60
1652/1652 [==============================] - 4s 2ms/step - loss: 0.7474 - acc: 0.6338 - auc_roc: 0.8413 - val_loss: 2.0951 - val_acc: 0.4831 - val_auc_roc: 0.8434
Epoch 11/60
1652/1652 [==============================] - 4s 2ms/step - loss: 0.7254 - acc: 0.6525 - auc_roc: 0.8453 - val_loss: 1.7179 - val_acc: 0.6992 - val_auc_roc: 0.8497
Epoch 12/60
1652/1652 [==============================] - 4s 2ms/step - loss: 0.6608 - acc: 0.6889 - auc_roc: 0.8535 - val_loss: 1.8568 - val_acc: 0.6808 - val_auc_roc: 0.8572
Epoch 13/60
1652/1652 [==============================] - 4s 2ms/step - loss: 0.5938 - acc: 0.7040 - auc_roc: 0.8607 - val_loss: 1.8451 - val_acc: 0.6441 - val_auc_roc: 0.8641
Epoch 14/60
1652/1652 [==============================] - 4s 2ms/step - loss: 0.5963 - acc: 0.7185 - auc_roc: 0.8671 - val_loss: 2.0979 - val_acc: 0.6469 - val_auc_roc: 0.8697
Epoch 15/60
1652/1652 [==============================] - 4s 2ms/step - loss: 0.5568 - acc: 0.7349 - auc_roc: 0.8719 - val_loss: 1.8868 - val_acc: 0.7175 - val_auc_roc: 0.8751
Epoch 16/60
1652/1652 [==============================] - 4s 2ms/step - loss: 0.5180 - acc: 0.7530 - auc_roc: 0.8778 - val_loss: 1.9414 - val_acc: 0.7161 - val_auc_roc: 0.8806
Epoch 17/60
1652/1652 [==============================] - 4s 2ms/step - loss: 0.4990 - acc: 0.7554 - auc_roc: 0.8829 - val_loss: 2.2154 - val_acc: 0.7048 - val_auc_roc: 0.8854
Epoch 18/60
1652/1652 [==============================] - 4s 2ms/step - loss: 0.3990 - acc: 0.8033 - auc_roc: 0.8878 - val_loss: 2.3827 - val_acc: 0.7062 - val_auc_roc: 0.8904
Epoch 19/60
1652/1652 [==============================] - 4s 2ms/step - loss: 0.3961 - acc: 0.8142 - auc_roc: 0.8925 - val_loss: 1.8130 - val_acc: 0.6554 - val_auc_roc: 0.8947
Epoch 20/60
1652/1652 [==============================] - 4s 2ms/step - loss: 0.4828 - acc: 0.7639 - auc_roc: 0.8959 - val_loss: 2.1089 - val_acc: 0.7062 - val_auc_roc: 0.8978
Epoch 21/60
1652/1652 [==============================] - 4s 2ms/step - loss: 0.4273 - acc: 0.8087 - auc_roc: 0.8993 - val_loss: 2.2588 - val_acc: 0.6977 - val_auc_roc: 0.9010
Epoch 22/60
1652/1652 [==============================] - 4s 2ms/step - loss: 0.3084 - acc: 0.8590 - auc_roc: 0.9027 - val_loss: 2.2758 - val_acc: 0.7020 - val_auc_roc: 0.9047
Epoch 23/60
1652/1652 [==============================] - 4s 2ms/step - loss: 0.3007 - acc: 0.8656 - auc_roc: 0.9063 - val_loss: 2.1673 - val_acc: 0.7076 - val_auc_roc: 0.9082
Epoch 24/60
1652/1652 [==============================] - 4s 2ms/step - loss: 0.2126 - acc: 0.9086 - auc_roc: 0.9098 - val_loss: 2.4993 - val_acc: 0.7090 - val_auc_roc: 0.9117
Epoch 00024: early stopping
... history of metrics comprising: ['acc', 'loss', 'val_auc_roc', 'auc_roc', 'val_acc', 'val_loss']
... ... metric (acc): [0.73486682837580941, 0.75302663423824545, 0.75544794203294108, 0.80326876498885069, 0.8141646487660904, 0.76392251801548516, 0.80871670702179177, 0.85895883806103945, 0.86561743312540118, 0.90859564150216798] (n=24)
output> saving performance to:
/Users/pleiades/Documents/work/tpheno/seqmaker/data/CKD/plot/model_evalation-ep200b16.tif

... ... metric (loss): [0.55679251206700509, 0.51801170578303113, 0.49904117933485759, 0.39902961860268804, 0.39608129346630477, 0.48276268945190576, 0.42726724134807725, 0.3083750226018504, 0.30072693920020044, 0.2126358702381933] (n=24)
output> saving performance to:
/Users/pleiades/Documents/work/tpheno/seqmaker/data/CKD/plot/model_evalation-ep200b16.tif


model_selection> trying {'n_units': 200, 'dropout_rate': 0.3} ...

make_lstm> n_units=200, r_dropout=0.300000, n_layers=1, n_classes=6
  + lookup:
{'Others': 5, 'CKD Stage 5': 4, 'CKD Stage 4': 3, 'CKD Stage 3': 2, 'CKD Stage 2': 1, 'CKD Stage 1': 0}

... class weights:
{0: 6.344086021505376, 1: 0.74494949494949492, 2: 1.1238095238095238, 3: 7.0238095238095237, 4: 0.51890941072999119, 5: 0.64906490649064907}

====================================================================================================
... early stopping>
       + patience: 20, model='max'
... model training>
       + batch_size: 32, epochs: 60, shuffle? True, metric: auc_roc
====================================================================================================
Train on 1652 samples, validate on 708 samples
Epoch 1/60
1652/1652 [==============================] - 6s 3ms/step - loss: 1.6620 - acc: 0.3081 - auc_roc: 0.6613 - val_loss: 1.7925 - val_acc: 0.4435 - val_auc_roc: 0.6997
Epoch 2/60
1652/1652 [==============================] - 4s 3ms/step - loss: 1.3418 - acc: 0.4498 - auc_roc: 0.7209 - val_loss: 1.5819 - val_acc: 0.5113 - val_auc_roc: 0.7538
Epoch 3/60
1652/1652 [==============================] - 4s 3ms/step - loss: 1.2153 - acc: 0.4752 - auc_roc: 0.7675 - val_loss: 1.7355 - val_acc: 0.6130 - val_auc_roc: 0.7832
Epoch 4/60
1652/1652 [==============================] - 5s 3ms/step - loss: 1.1326 - acc: 0.5357 - auc_roc: 0.7956 - val_loss: 1.4956 - val_acc: 0.6596 - val_auc_roc: 0.8060
Epoch 5/60
1652/1652 [==============================] - 10s 6ms/step - loss: 1.0798 - acc: 0.5188 - auc_roc: 0.8122 - val_loss: 1.8341 - val_acc: 0.6469 - val_auc_roc: 0.8188
Epoch 6/60
1652/1652 [==============================] - 13s 8ms/step - loss: 0.9917 - acc: 0.5593 - auc_roc: 0.8242 - val_loss: 1.8488 - val_acc: 0.6653 - val_auc_roc: 0.8299
Epoch 7/60
1652/1652 [==============================] - 12s 7ms/step - loss: 0.9248 - acc: 0.5835 - auc_roc: 0.8352 - val_loss: 1.5431 - val_acc: 0.6709 - val_auc_roc: 0.8402
Epoch 8/60
1652/1652 [==============================] - 12s 7ms/step - loss: 0.8183 - acc: 0.6096 - auc_roc: 0.8447 - val_loss: 2.1850 - val_acc: 0.4788 - val_auc_roc: 0.8461
Epoch 9/60
1652/1652 [==============================] - 10s 6ms/step - loss: 0.8172 - acc: 0.5975 - auc_roc: 0.8472 - val_loss: 1.8410 - val_acc: 0.7076 - val_auc_roc: 0.8513
Epoch 10/60
1652/1652 [==============================] - 9s 6ms/step - loss: 0.7929 - acc: 0.6174 - auc_roc: 0.8551 - val_loss: 1.7433 - val_acc: 0.6907 - val_auc_roc: 0.8582
Epoch 11/60
1652/1652 [==============================] - 8s 5ms/step - loss: 0.6906 - acc: 0.6628 - auc_roc: 0.8615 - val_loss: 1.9340 - val_acc: 0.7090 - val_auc_roc: 0.8652
Epoch 12/60
1652/1652 [==============================] - 8s 5ms/step - loss: 0.6332 - acc: 0.6883 - auc_roc: 0.8681 - val_loss: 1.9256 - val_acc: 0.7232 - val_auc_roc: 0.8717
Epoch 13/60
1652/1652 [==============================] - 10s 6ms/step - loss: 0.5461 - acc: 0.7228 - auc_roc: 0.8747 - val_loss: 2.4654 - val_acc: 0.7048 - val_auc_roc: 0.8780
Epoch 14/60
1652/1652 [==============================] - 10s 6ms/step - loss: 0.5232 - acc: 0.7349 - auc_roc: 0.8808 - val_loss: 2.1997 - val_acc: 0.7133 - val_auc_roc: 0.8838
Epoch 15/60
1652/1652 [==============================] - 9s 6ms/step - loss: 0.6686 - acc: 0.6925 - auc_roc: 0.8853 - val_loss: 1.9263 - val_acc: 0.6483 - val_auc_roc: 0.8870
Epoch 16/60
1652/1652 [==============================] - 9s 6ms/step - loss: 0.6054 - acc: 0.7131 - auc_roc: 0.8885 - val_loss: 2.0078 - val_acc: 0.6992 - val_auc_roc: 0.8905
Epoch 17/60
1652/1652 [==============================] - 10s 6ms/step - loss: 0.5019 - acc: 0.7567 - auc_roc: 0.8924 - val_loss: 2.1968 - val_acc: 0.7218 - val_auc_roc: 0.8945
Epoch 18/60
1652/1652 [==============================] - 9s 6ms/step - loss: 0.3956 - acc: 0.8008 - auc_roc: 0.8967 - val_loss: 2.2232 - val_acc: 0.7260 - val_auc_roc: 0.8990
Epoch 19/60
1652/1652 [==============================] - 9s 5ms/step - loss: 0.3848 - acc: 0.8214 - auc_roc: 0.9009 - val_loss: 2.2894 - val_acc: 0.6751 - val_auc_roc: 0.9027
Epoch 20/60
1652/1652 [==============================] - 9s 6ms/step - loss: 0.3238 - acc: 0.8402 - auc_roc: 0.9043 - val_loss: 2.2367 - val_acc: 0.7175 - val_auc_roc: 0.9064
Epoch 21/60
1652/1652 [==============================] - 9s 6ms/step - loss: 0.2684 - acc: 0.8771 - auc_roc: 0.9082 - val_loss: 2.5383 - val_acc: 0.7260 - val_auc_roc: 0.9103
Epoch 22/60
1652/1652 [==============================] - 9s 5ms/step - loss: 0.2582 - acc: 0.8862 - auc_roc: 0.9120 - val_loss: 2.3624 - val_acc: 0.6737 - val_auc_roc: 0.9137
Epoch 23/60
1652/1652 [==============================] - 9s 5ms/step - loss: 0.2158 - acc: 0.9001 - auc_roc: 0.9152 - val_loss: 2.7688 - val_acc: 0.7203 - val_auc_roc: 0.9170
Epoch 24/60
1652/1652 [==============================] - 10s 6ms/step - loss: 0.1966 - acc: 0.9116 - auc_roc: 0.9184 - val_loss: 2.5157 - val_acc: 0.6709 - val_auc_roc: 0.9201
Epoch 00024: early stopping
... history of metrics comprising: ['acc', 'loss', 'val_auc_roc', 'auc_roc', 'val_acc', 'val_loss']
... ... metric (acc): [0.69249394687555599, 0.71307506038836643, 0.75665859535300417, 0.80084745748279751, 0.82142857128425029, 0.84019370488912659, 0.8771186440677966, 0.88619854707117518, 0.90012106508666034, 0.91162227574041332] (n=24)
output> saving performance to:
/Users/pleiades/Documents/work/tpheno/seqmaker/data/CKD/plot/model_evalation-ep200b16.tif

... ... metric (loss): [0.6686385985436798, 0.60538545402429866, 0.50186435246871686, 0.39558378266075911, 0.3848480128347152, 0.32375037482517971, 0.26842935249822769, 0.25817813509601656, 0.21575124605083004, 0.19657484894803304] (n=24)
output> saving performance to:
/Users/pleiades/Documents/work/tpheno/seqmaker/data/CKD/plot/model_evalation-ep200b16.tif


model_selection> trying {'n_units': 300, 'dropout_rate': 0.3} ...

make_lstm> n_units=300, r_dropout=0.300000, n_layers=1, n_classes=6
  + lookup:
{'Others': 5, 'CKD Stage 5': 4, 'CKD Stage 4': 3, 'CKD Stage 3': 2, 'CKD Stage 2': 1, 'CKD Stage 1': 0}

... class weights:
{0: 6.344086021505376, 1: 0.74494949494949492, 2: 1.1238095238095238, 3: 7.0238095238095237, 4: 0.51890941072999119, 5: 0.64906490649064907}

====================================================================================================
... early stopping>
       + patience: 20, model='max'
... model training>
       + batch_size: 32, epochs: 60, shuffle? True, metric: auc_roc
====================================================================================================
Train on 1652 samples, validate on 708 samples
Epoch 1/60
1652/1652 [==============================] - 20s 12ms/step - loss: 1.6505 - acc: 0.3499 - auc_roc: 0.6375 - val_loss: 1.7915 - val_acc: 0.3249 - val_auc_roc: 0.7076
Epoch 2/60
1652/1652 [==============================] - 16s 10ms/step - loss: 1.4486 - acc: 0.4213 - auc_roc: 0.7241 - val_loss: 1.7265 - val_acc: 0.2895 - val_auc_roc: 0.7253
Epoch 3/60
1652/1652 [==============================] - 11s 7ms/step - loss: 1.2706 - acc: 0.4794 - auc_roc: 0.7302 - val_loss: 1.8660 - val_acc: 0.3814 - val_auc_roc: 0.7402
Epoch 4/60
1652/1652 [==============================] - 8s 5ms/step - loss: 1.1561 - acc: 0.4921 - auc_roc: 0.7483 - val_loss: 1.4966 - val_acc: 0.6455 - val_auc_roc: 0.7669
Epoch 5/60
1652/1652 [==============================] - 7s 4ms/step - loss: 1.0712 - acc: 0.5484 - auc_roc: 0.7814 - val_loss: 1.8353 - val_acc: 0.3785 - val_auc_roc: 0.7846
Epoch 6/60
1652/1652 [==============================] - 7s 4ms/step - loss: 0.9955 - acc: 0.5714 - auc_roc: 0.7887 - val_loss: 1.5970 - val_acc: 0.6483 - val_auc_roc: 0.7983
Epoch 7/60
1652/1652 [==============================] - 7s 5ms/step - loss: 0.9016 - acc: 0.5914 - auc_roc: 0.8062 - val_loss: 1.9417 - val_acc: 0.6737 - val_auc_roc: 0.8143
Epoch 8/60
1652/1652 [==============================] - 7s 4ms/step - loss: 0.8968 - acc: 0.5726 - auc_roc: 0.8200 - val_loss: 1.5915 - val_acc: 0.5749 - val_auc_roc: 0.8249
Epoch 9/60
1652/1652 [==============================] - 7s 4ms/step - loss: 0.9386 - acc: 0.5569 - auc_roc: 0.8283 - val_loss: 1.6819 - val_acc: 0.5862 - val_auc_roc: 0.8314
Epoch 10/60
1652/1652 [==============================] - 7s 4ms/step - loss: 0.8169 - acc: 0.6096 - auc_roc: 0.8347 - val_loss: 1.7525 - val_acc: 0.6511 - val_auc_roc: 0.8387
Epoch 11/60
1652/1652 [==============================] - 7s 4ms/step - loss: 0.7614 - acc: 0.6217 - auc_roc: 0.8423 - val_loss: 1.8099 - val_acc: 0.6780 - val_auc_roc: 0.8463
Epoch 12/60
1652/1652 [==============================] - 8s 5ms/step - loss: 0.6939 - acc: 0.6598 - auc_roc: 0.8503 - val_loss: 2.1554 - val_acc: 0.4703 - val_auc_roc: 0.8520
Epoch 13/60
1652/1652 [==============================] - 9s 6ms/step - loss: 0.6508 - acc: 0.6883 - auc_roc: 0.8535 - val_loss: 2.2103 - val_acc: 0.6540 - val_auc_roc: 0.8573
Epoch 14/60
1652/1652 [==============================] - 10s 6ms/step - loss: 0.5760 - acc: 0.7113 - auc_roc: 0.8603 - val_loss: 1.9088 - val_acc: 0.6158 - val_auc_roc: 0.8635
Epoch 15/60
1652/1652 [==============================] - 11s 7ms/step - loss: 0.5407 - acc: 0.7282 - auc_roc: 0.8663 - val_loss: 2.1661 - val_acc: 0.5268 - val_auc_roc: 0.8684
Epoch 16/60
1652/1652 [==============================] - 11s 7ms/step - loss: 0.5465 - acc: 0.7349 - auc_roc: 0.8699 - val_loss: 2.2343 - val_acc: 0.6836 - val_auc_roc: 0.8728
Epoch 17/60
1652/1652 [==============================] - 10s 6ms/step - loss: 0.4362 - acc: 0.7760 - auc_roc: 0.8755 - val_loss: 2.3412 - val_acc: 0.7034 - val_auc_roc: 0.8786
Epoch 18/60
1652/1652 [==============================] - 9s 6ms/step - loss: 0.4179 - acc: 0.8021 - auc_roc: 0.8811 - val_loss: 2.5925 - val_acc: 0.7218 - val_auc_roc: 0.8840
Epoch 19/60
1652/1652 [==============================] - 9s 5ms/step - loss: 0.3616 - acc: 0.8251 - auc_roc: 0.8866 - val_loss: 2.5381 - val_acc: 0.7119 - val_auc_roc: 0.8893
Epoch 20/60
1652/1652 [==============================] - 10s 6ms/step - loss: 0.3607 - acc: 0.8232 - auc_roc: 0.8914 - val_loss: 2.4273 - val_acc: 0.6822 - val_auc_roc: 0.8938
Epoch 21/60
1652/1652 [==============================] - 9s 6ms/step - loss: 0.4177 - acc: 0.8154 - auc_roc: 0.8955 - val_loss: 2.2203 - val_acc: 0.6864 - val_auc_roc: 0.8975
Epoch 22/60
1652/1652 [==============================] - 9s 5ms/step - loss: 0.3038 - acc: 0.8481 - auc_roc: 0.8993 - val_loss: 2.6826 - val_acc: 0.6949 - val_auc_roc: 0.9014
Epoch 23/60
1652/1652 [==============================] - 9s 6ms/step - loss: 0.2478 - acc: 0.8923 - auc_roc: 0.9031 - val_loss: 2.7370 - val_acc: 0.6850 - val_auc_roc: 0.9051
Epoch 24/60
1652/1652 [==============================] - 9s 6ms/step - loss: 0.1823 - acc: 0.9201 - auc_roc: 0.9070 - val_loss: 2.6944 - val_acc: 0.7020 - val_auc_roc: 0.9090
Epoch 00024: early stopping
... history of metrics comprising: ['acc', 'loss', 'val_auc_roc', 'auc_roc', 'val_acc', 'val_loss']
... ... metric (acc): [0.7282082325898418, 0.73486682837580941, 0.77602905569007263, 0.8020581116687876, 0.82506053268765134, 0.82324455220243253, 0.81537530237479594, 0.84806295428379974, 0.89225181569198719, 0.92009685215592096] (n=24)
output> saving performance to:
/Users/pleiades/Documents/work/tpheno/seqmaker/data/CKD/plot/model_evalation-ep200b16.tif

... ... metric (loss): [0.54069116220924529, 0.54653712450447733, 0.43624871319777742, 0.41793490199430805, 0.36156423689378087, 0.36065323409098976, 0.41767998671127576, 0.30382392113491641, 0.2477784070206612, 0.1822908538738694] (n=24)
output> saving performance to:
/Users/pleiades/Documents/work/tpheno/seqmaker/data/CKD/plot/model_evalation-ep200b16.tif


model_selection> trying {'n_units': 400, 'dropout_rate': 0.3} ...

make_lstm> n_units=400, r_dropout=0.300000, n_layers=1, n_classes=6
  + lookup:
{'Others': 5, 'CKD Stage 5': 4, 'CKD Stage 4': 3, 'CKD Stage 3': 2, 'CKD Stage 2': 1, 'CKD Stage 1': 0}

... class weights:
{0: 6.344086021505376, 1: 0.74494949494949492, 2: 1.1238095238095238, 3: 7.0238095238095237, 4: 0.51890941072999119, 5: 0.64906490649064907}

====================================================================================================
... early stopping>
       + patience: 20, model='max'
... model training>
       + batch_size: 32, epochs: 60, shuffle? True, metric: auc_roc
====================================================================================================
Train on 1652 samples, validate on 708 samples
Epoch 1/60
1652/1652 [==============================] - 15s 9ms/step - loss: 1.6502 - acc: 0.3311 - auc_roc: 0.6774 - val_loss: 1.6348 - val_acc: 0.6243 - val_auc_roc: 0.7333
Epoch 2/60
1652/1652 [==============================] - 14s 9ms/step - loss: 1.3870 - acc: 0.4522 - auc_roc: 0.7590 - val_loss: 1.6317 - val_acc: 0.4407 - val_auc_roc: 0.7633
Epoch 3/60
1652/1652 [==============================] - 14s 9ms/step - loss: 1.3554 - acc: 0.4328 - auc_roc: 0.7617 - val_loss: 1.4969 - val_acc: 0.5523 - val_auc_roc: 0.7666
Epoch 4/60
1652/1652 [==============================] - 14s 9ms/step - loss: 1.2425 - acc: 0.4431 - auc_roc: 0.7742 - val_loss: 1.5065 - val_acc: 0.6328 - val_auc_roc: 0.7842
Epoch 5/60
1652/1652 [==============================] - 14s 9ms/step - loss: 1.1259 - acc: 0.5224 - auc_roc: 0.7937 - val_loss: 1.5974 - val_acc: 0.4520 - val_auc_roc: 0.7979
Epoch 6/60
1652/1652 [==============================] - 16s 10ms/step - loss: 1.0728 - acc: 0.5333 - auc_roc: 0.7990 - val_loss: 1.9107 - val_acc: 0.3757 - val_auc_roc: 0.7987
Epoch 7/60
1652/1652 [==============================] - 15s 9ms/step - loss: 0.9761 - acc: 0.5484 - auc_roc: 0.8002 - val_loss: 1.5988 - val_acc: 0.6907 - val_auc_roc: 0.8078
Epoch 8/60
1652/1652 [==============================] - 16s 9ms/step - loss: 0.9092 - acc: 0.5956 - auc_roc: 0.8140 - val_loss: 1.7719 - val_acc: 0.6879 - val_auc_roc: 0.8207
Epoch 9/60
1652/1652 [==============================] - 16s 10ms/step - loss: 0.8964 - acc: 0.6108 - auc_roc: 0.8264 - val_loss: 1.8615 - val_acc: 0.5734 - val_auc_roc: 0.8296
Epoch 10/60
1652/1652 [==============================] - 16s 10ms/step - loss: 0.8843 - acc: 0.5944 - auc_roc: 0.8322 - val_loss: 1.8249 - val_acc: 0.6568 - val_auc_roc: 0.8364
Epoch 11/60
1652/1652 [==============================] - 17s 10ms/step - loss: 0.7837 - acc: 0.6326 - auc_roc: 0.8402 - val_loss: 1.7650 - val_acc: 0.5819 - val_auc_roc: 0.8432
Epoch 12/60
1652/1652 [==============================] - 15s 9ms/step - loss: 0.6858 - acc: 0.6683 - auc_roc: 0.8462 - val_loss: 1.8591 - val_acc: 0.7133 - val_auc_roc: 0.8507
Epoch 13/60
1652/1652 [==============================] - 14s 8ms/step - loss: 0.6254 - acc: 0.6949 - auc_roc: 0.8545 - val_loss: 2.0075 - val_acc: 0.6893 - val_auc_roc: 0.8583
Epoch 14/60
1652/1652 [==============================] - 14s 8ms/step - loss: 0.5941 - acc: 0.7070 - auc_roc: 0.8616 - val_loss: 2.1669 - val_acc: 0.6836 - val_auc_roc: 0.8646
Epoch 15/60
1652/1652 [==============================] - 14s 8ms/step - loss: 0.5872 - acc: 0.7197 - auc_roc: 0.8674 - val_loss: 2.3376 - val_acc: 0.6780 - val_auc_roc: 0.8701
Epoch 16/60
1652/1652 [==============================] - 14s 9ms/step - loss: 0.5479 - acc: 0.7464 - auc_roc: 0.8723 - val_loss: 2.0227 - val_acc: 0.7020 - val_auc_roc: 0.8751
Epoch 17/60
1652/1652 [==============================] - 14s 8ms/step - loss: 0.4560 - acc: 0.7676 - auc_roc: 0.8780 - val_loss: 2.2287 - val_acc: 0.6963 - val_auc_roc: 0.8806
Epoch 18/60
1652/1652 [==============================] - 15s 9ms/step - loss: 0.5090 - acc: 0.7706 - auc_roc: 0.8827 - val_loss: 2.3179 - val_acc: 0.6469 - val_auc_roc: 0.8849
Epoch 19/60
1652/1652 [==============================] - 14s 9ms/step - loss: 0.4407 - acc: 0.7972 - auc_roc: 0.8867 - val_loss: 2.1098 - val_acc: 0.6384 - val_auc_roc: 0.8888
Epoch 20/60
1652/1652 [==============================] - 14s 9ms/step - loss: 0.4055 - acc: 0.8002 - auc_roc: 0.8907 - val_loss: 2.1059 - val_acc: 0.6822 - val_auc_roc: 0.8927
Epoch 21/60
1652/1652 [==============================] - 14s 8ms/step - loss: 0.3116 - acc: 0.8541 - auc_roc: 0.8948 - val_loss: 2.2145 - val_acc: 0.6610 - val_auc_roc: 0.8971
Epoch 22/60
1652/1652 [==============================] - 14s 9ms/step - loss: 0.2735 - acc: 0.8668 - auc_roc: 0.8989 - val_loss: 2.1414 - val_acc: 0.6653 - val_auc_roc: 0.9010
Epoch 23/60
1652/1652 [==============================] - 14s 9ms/step - loss: 0.3121 - acc: 0.8632 - auc_roc: 0.9028 - val_loss: 1.9339 - val_acc: 0.6596 - val_auc_roc: 0.9046
Epoch 00023: early stopping
... history of metrics comprising: ['acc', 'loss', 'val_auc_roc', 'auc_roc', 'val_acc', 'val_loss']
... ... metric (acc): [0.70702179205619686, 0.71973365624649477, 0.74636803888524128, 0.76755447913024388, 0.770581113945774, 0.7972154965123599, 0.80024213075060535, 0.8541162224716482, 0.86682808731139138, 0.863196125619348] (n=23)
output> saving performance to:
/Users/pleiades/Documents/work/tpheno/seqmaker/data/CKD/plot/model_evalation-ep200b16.tif

... ... metric (loss): [0.59414761897726731, 0.58720452026362568, 0.54793342551076674, 0.45601610193529662, 0.5090127634944408, 0.44067699655204939, 0.4054687546327097, 0.3115697415053989, 0.27353927687928981, 0.31208808528886289] (n=23)
output> saving performance to:
/Users/pleiades/Documents/work/tpheno/seqmaker/data/CKD/plot/model_evalation-ep200b16.tif


model_selection> trying {'n_units': 150, 'dropout_rate': 0.5} ...

make_lstm> n_units=150, r_dropout=0.500000, n_layers=1, n_classes=6
  + lookup:
{'Others': 5, 'CKD Stage 5': 4, 'CKD Stage 4': 3, 'CKD Stage 3': 2, 'CKD Stage 2': 1, 'CKD Stage 1': 0}

... class weights:
{0: 6.344086021505376, 1: 0.74494949494949492, 2: 1.1238095238095238, 3: 7.0238095238095237, 4: 0.51890941072999119, 5: 0.64906490649064907}

====================================================================================================
... early stopping>
       + patience: 20, model='max'
... model training>
       + batch_size: 32, epochs: 60, shuffle? True, metric: auc_roc
====================================================================================================
Train on 1652 samples, validate on 708 samples
Epoch 1/60
1652/1652 [==============================] - 6s 4ms/step - loss: 1.6869 - acc: 0.2676 - auc_roc: 0.6099 - val_loss: 1.9801 - val_acc: 0.2684 - val_auc_roc: 0.6624
Epoch 2/60
1652/1652 [==============================] - 5s 3ms/step - loss: 1.4565 - acc: 0.4310 - auc_roc: 0.6896 - val_loss: 1.4345 - val_acc: 0.5395 - val_auc_roc: 0.7237
Epoch 3/60
1652/1652 [==============================] - 5s 3ms/step - loss: 1.2810 - acc: 0.4927 - auc_roc: 0.7450 - val_loss: 1.5282 - val_acc: 0.6201 - val_auc_roc: 0.7636
Epoch 4/60
1652/1652 [==============================] - 5s 3ms/step - loss: 1.1566 - acc: 0.5315 - auc_roc: 0.7803 - val_loss: 1.6499 - val_acc: 0.5876 - val_auc_roc: 0.7885
Epoch 5/60
1652/1652 [==============================] - 5s 3ms/step - loss: 1.0889 - acc: 0.5381 - auc_roc: 0.7956 - val_loss: 1.7053 - val_acc: 0.5184 - val_auc_roc: 0.8007
Epoch 6/60
1652/1652 [==============================] - 5s 3ms/step - loss: 1.0662 - acc: 0.5381 - auc_roc: 0.8048 - val_loss: 1.6770 - val_acc: 0.6356 - val_auc_roc: 0.8107
Epoch 7/60
1652/1652 [==============================] - 5s 3ms/step - loss: 0.9851 - acc: 0.5684 - auc_roc: 0.8155 - val_loss: 1.5184 - val_acc: 0.7020 - val_auc_roc: 0.8226
Epoch 8/60
1652/1652 [==============================] - 5s 3ms/step - loss: 0.9274 - acc: 0.5823 - auc_roc: 0.8276 - val_loss: 1.5149 - val_acc: 0.6949 - val_auc_roc: 0.8330
Epoch 9/60
1652/1652 [==============================] - 5s 3ms/step - loss: 0.8838 - acc: 0.5817 - auc_roc: 0.8375 - val_loss: 2.3454 - val_acc: 0.2641 - val_auc_roc: 0.8330
Epoch 10/60
1652/1652 [==============================] - 5s 3ms/step - loss: 0.9680 - acc: 0.4891 - auc_roc: 0.8277 - val_loss: 1.7748 - val_acc: 0.4958 - val_auc_roc: 0.8281
Epoch 11/60
1652/1652 [==============================] - 5s 3ms/step - loss: 0.8358 - acc: 0.5993 - auc_roc: 0.8300 - val_loss: 2.2266 - val_acc: 0.3150 - val_auc_roc: 0.8298
Epoch 12/60
1652/1652 [==============================] - 5s 3ms/step - loss: 0.7785 - acc: 0.6229 - auc_roc: 0.8296 - val_loss: 1.7859 - val_acc: 0.6949 - val_auc_roc: 0.8340
Epoch 13/60
1652/1652 [==============================] - 5s 3ms/step - loss: 0.7127 - acc: 0.6634 - auc_roc: 0.8378 - val_loss: 1.9789 - val_acc: 0.7147 - val_auc_roc: 0.8419
Epoch 14/60
1652/1652 [==============================] - 5s 3ms/step - loss: 0.6916 - acc: 0.6628 - auc_roc: 0.8453 - val_loss: 1.9351 - val_acc: 0.7175 - val_auc_roc: 0.8490
Epoch 15/60
1652/1652 [==============================] - 5s 3ms/step - loss: 0.6441 - acc: 0.6943 - auc_roc: 0.8525 - val_loss: 1.9042 - val_acc: 0.7105 - val_auc_roc: 0.8558
Epoch 16/60
1652/1652 [==============================] - 5s 3ms/step - loss: 0.6204 - acc: 0.7179 - auc_roc: 0.8587 - val_loss: 1.9802 - val_acc: 0.7203 - val_auc_roc: 0.8618
Epoch 17/60
1652/1652 [==============================] - 5s 3ms/step - loss: 0.5740 - acc: 0.7137 - auc_roc: 0.8647 - val_loss: 2.0738 - val_acc: 0.6879 - val_auc_roc: 0.8673
Epoch 18/60
1652/1652 [==============================] - 5s 3ms/step - loss: 0.5984 - acc: 0.7088 - auc_roc: 0.8694 - val_loss: 1.9383 - val_acc: 0.6582 - val_auc_roc: 0.8714
Epoch 19/60
1652/1652 [==============================] - 5s 3ms/step - loss: 0.5289 - acc: 0.7349 - auc_roc: 0.8734 - val_loss: 2.2342 - val_acc: 0.7260 - val_auc_roc: 0.8758
Epoch 20/60
1652/1652 [==============================] - 5s 3ms/step - loss: 0.5267 - acc: 0.7518 - auc_roc: 0.8778 - val_loss: 1.9277 - val_acc: 0.7048 - val_auc_roc: 0.8799
Epoch 21/60
1652/1652 [==============================] - 5s 3ms/step - loss: 0.5337 - acc: 0.7518 - auc_roc: 0.8815 - val_loss: 2.1561 - val_acc: 0.7260 - val_auc_roc: 0.8836
Epoch 22/60
1652/1652 [==============================] - 5s 3ms/step - loss: 0.4454 - acc: 0.7645 - auc_roc: 0.8855 - val_loss: 2.2370 - val_acc: 0.7246 - val_auc_roc: 0.8876
Epoch 00022: early stopping
... history of metrics comprising: ['acc', 'loss', 'val_auc_roc', 'auc_roc', 'val_acc', 'val_loss']
... ... metric (acc): [0.66343825680291679, 0.66283293007072464, 0.69430992764941712, 0.71791767540047302, 0.71368038755352214, 0.70883777225277322, 0.73486682837580941, 0.7518159804852188, 0.7518159804852188, 0.76452784532496199] (n=22)
output> saving performance to:
/Users/pleiades/Documents/work/tpheno/seqmaker/data/CKD/plot/model_evalation-ep200b16.tif

... ... metric (loss): [0.71272487278134711, 0.69159260875664963, 0.64408233249447244, 0.62037381739073749, 0.57404655867569676, 0.59836718981260251, 0.52888373788852094, 0.52670378156782061, 0.53368678898268695, 0.44538895428613656] (n=22)
output> saving performance to:
/Users/pleiades/Documents/work/tpheno/seqmaker/data/CKD/plot/model_evalation-ep200b16.tif


model_selection> trying {'n_units': 200, 'dropout_rate': 0.5} ...

make_lstm> n_units=200, r_dropout=0.500000, n_layers=1, n_classes=6
  + lookup:
{'Others': 5, 'CKD Stage 5': 4, 'CKD Stage 4': 3, 'CKD Stage 3': 2, 'CKD Stage 2': 1, 'CKD Stage 1': 0}

... class weights:
{0: 6.344086021505376, 1: 0.74494949494949492, 2: 1.1238095238095238, 3: 7.0238095238095237, 4: 0.51890941072999119, 5: 0.64906490649064907}

====================================================================================================
... early stopping>
       + patience: 20, model='max'
... model training>
       + batch_size: 32, epochs: 60, shuffle? True, metric: auc_roc
====================================================================================================
Train on 1652 samples, validate on 708 samples
Epoch 1/60
1652/1652 [==============================] - 6s 4ms/step - loss: 1.6669 - acc: 0.2815 - auc_roc: 0.5861 - val_loss: 1.5797 - val_acc: 0.6201 - val_auc_roc: 0.7045
Epoch 2/60
1652/1652 [==============================] - 5s 3ms/step - loss: 1.4653 - acc: 0.3868 - auc_roc: 0.7429 - val_loss: 1.6109 - val_acc: 0.4901 - val_auc_roc: 0.7427
Epoch 3/60
1652/1652 [==============================] - 5s 3ms/step - loss: 1.3274 - acc: 0.4588 - auc_roc: 0.7549 - val_loss: 1.7977 - val_acc: 0.4124 - val_auc_roc: 0.7565
Epoch 4/60
1652/1652 [==============================] - 6s 3ms/step - loss: 1.2070 - acc: 0.4885 - auc_roc: 0.7630 - val_loss: 1.4059 - val_acc: 0.6356 - val_auc_roc: 0.7760
Epoch 5/60
1652/1652 [==============================] - 5s 3ms/step - loss: 1.0887 - acc: 0.5297 - auc_roc: 0.7870 - val_loss: 1.7848 - val_acc: 0.6073 - val_auc_roc: 0.7950
Epoch 6/60
1652/1652 [==============================] - 6s 3ms/step - loss: 1.0663 - acc: 0.5176 - auc_roc: 0.8007 - val_loss: 1.6130 - val_acc: 0.5960 - val_auc_roc: 0.8069
Epoch 7/60
1652/1652 [==============================] - 6s 3ms/step - loss: 1.0399 - acc: 0.5303 - auc_roc: 0.8110 - val_loss: 2.1021 - val_acc: 0.2444 - val_auc_roc: 0.8072
Epoch 8/60
1652/1652 [==============================] - 6s 3ms/step - loss: 0.9602 - acc: 0.5357 - auc_roc: 0.8045 - val_loss: 1.6627 - val_acc: 0.6186 - val_auc_roc: 0.8096
Epoch 9/60
1652/1652 [==============================] - 5s 3ms/step - loss: 0.8797 - acc: 0.5860 - auc_roc: 0.8147 - val_loss: 1.7781 - val_acc: 0.5989 - val_auc_roc: 0.8202
Epoch 10/60
1652/1652 [==============================] - 5s 3ms/step - loss: 0.8727 - acc: 0.6005 - auc_roc: 0.8247 - val_loss: 1.8948 - val_acc: 0.6681 - val_auc_roc: 0.8291
Epoch 11/60
1652/1652 [==============================] - 6s 3ms/step - loss: 0.7924 - acc: 0.6368 - auc_roc: 0.8334 - val_loss: 1.8438 - val_acc: 0.6638 - val_auc_roc: 0.8378
Epoch 12/60
1652/1652 [==============================] - 5s 3ms/step - loss: 0.7098 - acc: 0.6501 - auc_roc: 0.8416 - val_loss: 1.7890 - val_acc: 0.6907 - val_auc_roc: 0.8459
Epoch 13/60
1652/1652 [==============================] - 5s 3ms/step - loss: 0.6869 - acc: 0.6786 - auc_roc: 0.8497 - val_loss: 2.1887 - val_acc: 0.7034 - val_auc_roc: 0.8533
Epoch 14/60
1652/1652 [==============================] - 6s 4ms/step - loss: 0.6579 - acc: 0.6913 - auc_roc: 0.8561 - val_loss: 2.1305 - val_acc: 0.6695 - val_auc_roc: 0.8595
Epoch 15/60
1652/1652 [==============================] - 6s 4ms/step - loss: 0.5921 - acc: 0.6943 - auc_roc: 0.8622 - val_loss: 2.0903 - val_acc: 0.6638 - val_auc_roc: 0.8653
Epoch 16/60
1652/1652 [==============================] - 5s 3ms/step - loss: 0.5777 - acc: 0.6998 - auc_roc: 0.8678 - val_loss: 2.4103 - val_acc: 0.5904 - val_auc_roc: 0.8699
Epoch 17/60
1652/1652 [==============================] - 5s 3ms/step - loss: 0.6764 - acc: 0.6816 - auc_roc: 0.8711 - val_loss: 2.0425 - val_acc: 0.6201 - val_auc_roc: 0.8726
Epoch 18/60
1652/1652 [==============================] - 6s 3ms/step - loss: 0.6095 - acc: 0.7288 - auc_roc: 0.8741 - val_loss: 2.0522 - val_acc: 0.6511 - val_auc_roc: 0.8761
Epoch 19/60
1652/1652 [==============================] - 5s 3ms/step - loss: 0.5020 - acc: 0.7470 - auc_roc: 0.8781 - val_loss: 2.2358 - val_acc: 0.7119 - val_auc_roc: 0.8804
Epoch 20/60
1652/1652 [==============================] - 6s 4ms/step - loss: 0.4372 - acc: 0.7803 - auc_roc: 0.8824 - val_loss: 2.4374 - val_acc: 0.7062 - val_auc_roc: 0.8847
Epoch 21/60
1652/1652 [==============================] - 6s 3ms/step - loss: 0.3900 - acc: 0.8117 - auc_roc: 0.8868 - val_loss: 2.6825 - val_acc: 0.6469 - val_auc_roc: 0.8887
Epoch 22/60
1652/1652 [==============================] - 5s 3ms/step - loss: 0.3471 - acc: 0.8402 - auc_roc: 0.8903 - val_loss: 2.5191 - val_acc: 0.7076 - val_auc_roc: 0.8926
Epoch 23/60
1652/1652 [==============================] - 5s 3ms/step - loss: 0.4300 - acc: 0.8087 - auc_roc: 0.8943 - val_loss: 2.2363 - val_acc: 0.6582 - val_auc_roc: 0.8959
Epoch 24/60
1652/1652 [==============================] - 5s 3ms/step - loss: 0.3809 - acc: 0.8360 - auc_roc: 0.8973 - val_loss: 2.4187 - val_acc: 0.6667 - val_auc_roc: 0.8989
Epoch 00024: early stopping
... history of metrics comprising: ['acc', 'loss', 'val_auc_roc', 'auc_roc', 'val_acc', 'val_loss']
... ... metric (acc): [0.69430992707213246, 0.69975786953803698, 0.68159806295399517, 0.72881355946635507, 0.74697336590607577, 0.78026634382566584, 0.81174334140435833, 0.84019370431184193, 0.8087167073104341, 0.83595641660921216] (n=24)
output> saving performance to:
/Users/pleiades/Documents/work/tpheno/seqmaker/data/CKD/plot/model_evalation-ep200b16.tif

... ... metric (loss): [0.59213189308060288, 0.57772653977461064, 0.67637888138288449, 0.60946638835255806, 0.50198278653708261, 0.43724124158843086, 0.39001911864153699, 0.34712108009952608, 0.43001606447067448, 0.38088411027813651] (n=24)
output> saving performance to:
/Users/pleiades/Documents/work/tpheno/seqmaker/data/CKD/plot/model_evalation-ep200b16.tif


model_selection> trying {'n_units': 300, 'dropout_rate': 0.5} ...

make_lstm> n_units=300, r_dropout=0.500000, n_layers=1, n_classes=6
  + lookup:
{'Others': 5, 'CKD Stage 5': 4, 'CKD Stage 4': 3, 'CKD Stage 3': 2, 'CKD Stage 2': 1, 'CKD Stage 1': 0}

... class weights:
{0: 6.344086021505376, 1: 0.74494949494949492, 2: 1.1238095238095238, 3: 7.0238095238095237, 4: 0.51890941072999119, 5: 0.64906490649064907}

====================================================================================================
... early stopping>
       + patience: 20, model='max'
... model training>
       + batch_size: 32, epochs: 60, shuffle? True, metric: auc_roc
====================================================================================================
Train on 1652 samples, validate on 708 samples
Epoch 1/60
1652/1652 [==============================] - 10s 6ms/step - loss: 1.6724 - acc: 0.2821 - auc_roc: 0.6349 - val_loss: 1.9651 - val_acc: 0.3799 - val_auc_roc: 0.6577
Epoch 2/60
1652/1652 [==============================] - 8s 5ms/step - loss: 1.3990 - acc: 0.4631 - auc_roc: 0.6943 - val_loss: 2.0408 - val_acc: 0.1610 - val_auc_roc: 0.6891
Epoch 3/60
1652/1652 [==============================] - 9s 5ms/step - loss: 1.2886 - acc: 0.4806 - auc_roc: 0.6924 - val_loss: 1.5885 - val_acc: 0.6172 - val_auc_roc: 0.7262
Epoch 4/60
1652/1652 [==============================] - 9s 5ms/step - loss: 1.2574 - acc: 0.4582 - auc_roc: 0.7408 - val_loss: 1.6788 - val_acc: 0.5904 - val_auc_roc: 0.7521
Epoch 5/60
1652/1652 [==============================] - 9s 5ms/step - loss: 1.1216 - acc: 0.5176 - auc_roc: 0.7654 - val_loss: 1.3965 - val_acc: 0.5763 - val_auc_roc: 0.7746
Epoch 6/60
1652/1652 [==============================] - 8s 5ms/step - loss: 1.0757 - acc: 0.5151 - auc_roc: 0.7831 - val_loss: 1.8696 - val_acc: 0.2669 - val_auc_roc: 0.7830
Epoch 7/60
1652/1652 [==============================] - 9s 5ms/step - loss: 1.0753 - acc: 0.5073 - auc_roc: 0.7812 - val_loss: 1.8111 - val_acc: 0.5932 - val_auc_roc: 0.7873
Epoch 8/60
1652/1652 [==============================] - 9s 5ms/step - loss: 0.9261 - acc: 0.5781 - auc_roc: 0.7940 - val_loss: 1.7323 - val_acc: 0.6455 - val_auc_roc: 0.8015
Epoch 9/60
1652/1652 [==============================] - 9s 6ms/step - loss: 0.8470 - acc: 0.6065 - auc_roc: 0.8079 - val_loss: 1.7984 - val_acc: 0.6610 - val_auc_roc: 0.8145
Epoch 10/60
1652/1652 [==============================] - 8s 5ms/step - loss: 0.9366 - acc: 0.5448 - auc_roc: 0.8185 - val_loss: 2.1783 - val_acc: 0.5720 - val_auc_roc: 0.8210
Epoch 11/60
1652/1652 [==============================] - 9s 5ms/step - loss: 0.8289 - acc: 0.6053 - auc_roc: 0.8242 - val_loss: 1.7913 - val_acc: 0.6624 - val_auc_roc: 0.8287
Epoch 12/60
1652/1652 [==============================] - 8s 5ms/step - loss: 0.7259 - acc: 0.6416 - auc_roc: 0.8327 - val_loss: 2.1239 - val_acc: 0.6257 - val_auc_roc: 0.8371
Epoch 13/60
1652/1652 [==============================] - 8s 5ms/step - loss: 0.7173 - acc: 0.6544 - auc_roc: 0.8404 - val_loss: 1.8125 - val_acc: 0.5975 - val_auc_roc: 0.8437
Epoch 14/60
1652/1652 [==============================] - 9s 5ms/step - loss: 0.7697 - acc: 0.6519 - auc_roc: 0.8460 - val_loss: 1.7393 - val_acc: 0.6483 - val_auc_roc: 0.8489
Epoch 15/60
1652/1652 [==============================] - 8s 5ms/step - loss: 0.6388 - acc: 0.6822 - auc_roc: 0.8518 - val_loss: 1.9932 - val_acc: 0.6031 - val_auc_roc: 0.8547
Epoch 16/60
1652/1652 [==============================] - 9s 5ms/step - loss: 0.5930 - acc: 0.7094 - auc_roc: 0.8570 - val_loss: 2.0807 - val_acc: 0.7034 - val_auc_roc: 0.8602
Epoch 17/60
1652/1652 [==============================] - 9s 5ms/step - loss: 0.5331 - acc: 0.7324 - auc_roc: 0.8630 - val_loss: 2.0610 - val_acc: 0.6893 - val_auc_roc: 0.8661
Epoch 18/60
1652/1652 [==============================] - 8s 5ms/step - loss: 0.5155 - acc: 0.7288 - auc_roc: 0.8686 - val_loss: 2.1467 - val_acc: 0.7161 - val_auc_roc: 0.8713
Epoch 19/60
1652/1652 [==============================] - 8s 5ms/step - loss: 0.4342 - acc: 0.7833 - auc_roc: 0.8738 - val_loss: 2.3632 - val_acc: 0.7302 - val_auc_roc: 0.8769
Epoch 20/60
1652/1652 [==============================] - 9s 5ms/step - loss: 0.4048 - acc: 0.7960 - auc_roc: 0.8793 - val_loss: 2.3499 - val_acc: 0.6836 - val_auc_roc: 0.8818
Epoch 21/60
1652/1652 [==============================] - 10s 6ms/step - loss: 0.3811 - acc: 0.8172 - auc_roc: 0.8839 - val_loss: 2.3619 - val_acc: 0.7175 - val_auc_roc: 0.8864
Epoch 22/60
1652/1652 [==============================] - 9s 6ms/step - loss: 0.3230 - acc: 0.8493 - auc_roc: 0.8887 - val_loss: 2.5993 - val_acc: 0.6907 - val_auc_roc: 0.8910
Epoch 23/60
1652/1652 [==============================] - 8s 5ms/step - loss: 0.2925 - acc: 0.8680 - auc_roc: 0.8931 - val_loss: 2.5188 - val_acc: 0.6992 - val_auc_roc: 0.8954
Epoch 24/60
1652/1652 [==============================] - 8s 5ms/step - loss: 0.3942 - acc: 0.8117 - auc_roc: 0.8968 - val_loss: 2.3092 - val_acc: 0.6935 - val_auc_roc: 0.8986
Epoch 25/60
1652/1652 [==============================] - 8s 5ms/step - loss: 0.2924 - acc: 0.8620 - auc_roc: 0.9002 - val_loss: 2.3450 - val_acc: 0.7246 - val_auc_roc: 0.9022
Epoch 00025: early stopping
... history of metrics comprising: ['acc', 'loss', 'val_auc_roc', 'auc_roc', 'val_acc', 'val_loss']
... ... metric (acc): [0.70944309956225005, 0.73244552058111378, 0.72881355917771273, 0.78329297791959007, 0.79600484232636981, 0.81719128314865708, 0.84927360789250517, 0.86803874092009681, 0.81174334169300066, 0.86198547244360602] (n=25)
output> saving performance to:
/Users/pleiades/Documents/work/tpheno/seqmaker/data/CKD/plot/model_evalation-ep200b16.tif

... ... metric (loss): [0.59301865187453295, 0.5330838146856276, 0.51554463006393669, 0.43423817492570482, 0.40476818516237106, 0.38112254213478608, 0.32304366225191816, 0.29254900759703889, 0.39424744392711369, 0.29242382492626551] (n=25)
output> saving performance to:
/Users/pleiades/Documents/work/tpheno/seqmaker/data/CKD/plot/model_evalation-ep200b16.tif


model_selection> trying {'n_units': 400, 'dropout_rate': 0.5} ...

make_lstm> n_units=400, r_dropout=0.500000, n_layers=1, n_classes=6
  + lookup:
{'Others': 5, 'CKD Stage 5': 4, 'CKD Stage 4': 3, 'CKD Stage 3': 2, 'CKD Stage 2': 1, 'CKD Stage 1': 0}

... class weights:
{0: 6.344086021505376, 1: 0.74494949494949492, 2: 1.1238095238095238, 3: 7.0238095238095237, 4: 0.51890941072999119, 5: 0.64906490649064907}

====================================================================================================
... early stopping>
       + patience: 20, model='max'
... model training>
       + batch_size: 32, epochs: 60, shuffle? True, metric: auc_roc
====================================================================================================
Train on 1652 samples, validate on 708 samples
Epoch 1/60
1652/1652 [==============================] - 14s 9ms/step - loss: 1.6869 - acc: 0.2930 - auc_roc: 0.6445 - val_loss: 1.8430 - val_acc: 0.2105 - val_auc_roc: 0.6625
Epoch 2/60
1652/1652 [==============================] - 13s 8ms/step - loss: 1.4813 - acc: 0.4025 - auc_roc: 0.6756 - val_loss: 1.7037 - val_acc: 0.4308 - val_auc_roc: 0.6944
Epoch 3/60
1652/1652 [==============================] - 12s 8ms/step - loss: 1.3837 - acc: 0.4358 - auc_roc: 0.7141 - val_loss: 1.5969 - val_acc: 0.3150 - val_auc_roc: 0.7182
Epoch 4/60
1652/1652 [==============================] - 13s 8ms/step - loss: 1.2871 - acc: 0.4631 - auc_roc: 0.7261 - val_loss: 2.0062 - val_acc: 0.2260 - val_auc_roc: 0.7257
Epoch 5/60
1652/1652 [==============================] - 13s 8ms/step - loss: 1.2310 - acc: 0.4915 - auc_roc: 0.7290 - val_loss: 1.7775 - val_acc: 0.2684 - val_auc_roc: 0.7308
Epoch 6/60
1652/1652 [==============================] - 14s 8ms/step - loss: 1.1326 - acc: 0.4824 - auc_roc: 0.7326 - val_loss: 1.5993 - val_acc: 0.6709 - val_auc_roc: 0.7454
Epoch 7/60
1652/1652 [==============================] - 17s 10ms/step - loss: 1.0447 - acc: 0.5581 - auc_roc: 0.7580 - val_loss: 1.6519 - val_acc: 0.4746 - val_auc_roc: 0.7657
Epoch 8/60
1652/1652 [==============================] - 13s 8ms/step - loss: 0.9331 - acc: 0.5726 - auc_roc: 0.7722 - val_loss: 1.6186 - val_acc: 0.6158 - val_auc_roc: 0.7801
Epoch 9/60
1652/1652 [==============================] - 13s 8ms/step - loss: 0.8858 - acc: 0.6029 - auc_roc: 0.7867 - val_loss: 1.5622 - val_acc: 0.6737 - val_auc_roc: 0.7953
Epoch 10/60
1652/1652 [==============================] - 12s 7ms/step - loss: 0.8069 - acc: 0.6265 - auc_roc: 0.8019 - val_loss: 1.8836 - val_acc: 0.6864 - val_auc_roc: 0.8089
Epoch 11/60
1652/1652 [==============================] - 12s 7ms/step - loss: 0.7665 - acc: 0.6374 - auc_roc: 0.8149 - val_loss: 1.6538 - val_acc: 0.7048 - val_auc_roc: 0.8205
Epoch 12/60
1652/1652 [==============================] - 12s 8ms/step - loss: 0.7504 - acc: 0.6362 - auc_roc: 0.8251 - val_loss: 1.8310 - val_acc: 0.5452 - val_auc_roc: 0.8285
Epoch 13/60
1652/1652 [==============================] - 12s 7ms/step - loss: 0.7321 - acc: 0.6471 - auc_roc: 0.8316 - val_loss: 1.8675 - val_acc: 0.6992 - val_auc_roc: 0.8358
Epoch 14/60
1652/1652 [==============================] - 12s 7ms/step - loss: 0.7303 - acc: 0.6550 - auc_roc: 0.8394 - val_loss: 2.0648 - val_acc: 0.6850 - val_auc_roc: 0.8428
Epoch 15/60
1652/1652 [==============================] - 12s 7ms/step - loss: 0.6380 - acc: 0.6822 - auc_roc: 0.8461 - val_loss: 2.1499 - val_acc: 0.4266 - val_auc_roc: 0.8477
Epoch 16/60
1652/1652 [==============================] - 13s 8ms/step - loss: 0.6171 - acc: 0.6913 - auc_roc: 0.8492 - val_loss: 2.5011 - val_acc: 0.4887 - val_auc_roc: 0.8513
Epoch 17/60
1652/1652 [==============================] - 12s 7ms/step - loss: 0.6552 - acc: 0.7125 - auc_roc: 0.8528 - val_loss: 1.8364 - val_acc: 0.6540 - val_auc_roc: 0.8559
Epoch 18/60
1652/1652 [==============================] - 12s 7ms/step - loss: 0.5160 - acc: 0.7603 - auc_roc: 0.8586 - val_loss: 2.0994 - val_acc: 0.6921 - val_auc_roc: 0.8617
Epoch 19/60
1652/1652 [==============================] - 12s 7ms/step - loss: 0.4404 - acc: 0.7803 - auc_roc: 0.8646 - val_loss: 2.1786 - val_acc: 0.7218 - val_auc_roc: 0.8678
Epoch 20/60
1652/1652 [==============================] - 12s 7ms/step - loss: 0.3757 - acc: 0.8220 - auc_roc: 0.8708 - val_loss: 2.3268 - val_acc: 0.6963 - val_auc_roc: 0.8739
Epoch 21/60
1652/1652 [==============================] - 12s 7ms/step - loss: 0.5542 - acc: 0.7633 - auc_roc: 0.8759 - val_loss: 2.0764 - val_acc: 0.6921 - val_auc_roc: 0.8779
Epoch 22/60
1652/1652 [==============================] - 12s 7ms/step - loss: 0.4705 - acc: 0.8008 - auc_roc: 0.8800 - val_loss: 2.2315 - val_acc: 0.7147 - val_auc_roc: 0.8822
Epoch 23/60
1652/1652 [==============================] - 12s 7ms/step - loss: 0.3441 - acc: 0.8408 - auc_roc: 0.8844 - val_loss: 2.2884 - val_acc: 0.7048 - val_auc_roc: 0.8867
Epoch 24/60
1652/1652 [==============================] - 12s 7ms/step - loss: 0.2939 - acc: 0.8644 - auc_roc: 0.8888 - val_loss: 2.2501 - val_acc: 0.7373 - val_auc_roc: 0.8912
Epoch 25/60
1652/1652 [==============================] - 12s 7ms/step - loss: 0.3039 - acc: 0.8668 - auc_roc: 0.8932 - val_loss: 2.4330 - val_acc: 0.6992 - val_auc_roc: 0.8954
Epoch 26/60
1652/1652 [==============================] - 12s 7ms/step - loss: 0.2279 - acc: 0.8953 - auc_roc: 0.8973 - val_loss: 2.4529 - val_acc: 0.6215 - val_auc_roc: 0.8990
Epoch 27/60
1652/1652 [==============================] - 11s 7ms/step - loss: 0.1937 - acc: 0.9098 - auc_roc: 0.9006 - val_loss: 2.6762 - val_acc: 0.6469 - val_auc_roc: 0.9025
Epoch 28/60
1652/1652 [==============================] - 12s 7ms/step - loss: 0.1524 - acc: 0.9346 - auc_roc: 0.9041 - val_loss: 2.6966 - val_acc: 0.6992 - val_auc_roc: 0.9061
Epoch 29/60
1652/1652 [==============================] - 12s 7ms/step - loss: 0.1190 - acc: 0.9510 - auc_roc: 0.9077 - val_loss: 2.9999 - val_acc: 0.6554 - val_auc_roc: 0.9094
Epoch 00029: early stopping
... history of metrics comprising: ['acc', 'loss', 'val_auc_roc', 'auc_roc', 'val_acc', 'val_loss']
... ... metric (acc): [0.82203389844940589, 0.76331719157193534, 0.80084745733847629, 0.84079903118835519, 0.86440677951669576, 0.86682808702274905, 0.89527845036319609, 0.90980629525519452, 0.93462469704791939, 0.9509685230024213] (n=29)
output> saving performance to:
/Users/pleiades/Documents/work/tpheno/seqmaker/data/CKD/plot/model_evalation-ep200b16.tif

... ... metric (loss): [0.37573833774423482, 0.55423471187275197, 0.4704755829696794, 0.34408488400623238, 0.29392966801260056, 0.303905041613244, 0.2278903818736642, 0.19373431228119295, 0.15235930789469518, 0.11897621130611359] (n=29)
output> saving performance to:
/Users/pleiades/Documents/work/tpheno/seqmaker/data/CKD/plot/model_evalation-ep200b16.tif


model_selection> trying {'n_units': 150, 'dropout_rate': 0.6} ...

make_lstm> n_units=150, r_dropout=0.600000, n_layers=1, n_classes=6
  + lookup:
{'Others': 5, 'CKD Stage 5': 4, 'CKD Stage 4': 3, 'CKD Stage 3': 2, 'CKD Stage 2': 1, 'CKD Stage 1': 0}

... class weights:
{0: 6.344086021505376, 1: 0.74494949494949492, 2: 1.1238095238095238, 3: 7.0238095238095237, 4: 0.51890941072999119, 5: 0.64906490649064907}

====================================================================================================
... early stopping>
       + patience: 20, model='max'
... model training>
       + batch_size: 32, epochs: 60, shuffle? True, metric: auc_roc
====================================================================================================
Train on 1652 samples, validate on 708 samples
Epoch 1/60
1652/1652 [==============================] - 6s 4ms/step - loss: 1.7189 - acc: 0.2657 - auc_roc: 0.5850 - val_loss: 1.8174 - val_acc: 0.4209 - val_auc_roc: 0.6565
Epoch 2/60
1652/1652 [==============================] - 4s 3ms/step - loss: 1.5095 - acc: 0.4086 - auc_roc: 0.6876 - val_loss: 1.5171 - val_acc: 0.5466 - val_auc_roc: 0.7124
Epoch 3/60
1652/1652 [==============================] - 4s 3ms/step - loss: 1.4753 - acc: 0.3777 - auc_roc: 0.7252 - val_loss: 1.6102 - val_acc: 0.3376 - val_auc_roc: 0.7168
Epoch 4/60
1652/1652 [==============================] - 4s 3ms/step - loss: 1.3202 - acc: 0.4407 - auc_roc: 0.7221 - val_loss: 1.6628 - val_acc: 0.5395 - val_auc_roc: 0.7361
Epoch 5/60
1652/1652 [==============================] - 4s 3ms/step - loss: 1.1856 - acc: 0.4958 - auc_roc: 0.7472 - val_loss: 2.1245 - val_acc: 0.3376 - val_auc_roc: 0.7494
Epoch 6/60
1652/1652 [==============================] - 4s 3ms/step - loss: 1.1331 - acc: 0.5285 - auc_roc: 0.7532 - val_loss: 1.6234 - val_acc: 0.5268 - val_auc_roc: 0.7619
Epoch 7/60
1652/1652 [==============================] - 4s 3ms/step - loss: 1.0126 - acc: 0.5333 - auc_roc: 0.7695 - val_loss: 1.6463 - val_acc: 0.6314 - val_auc_roc: 0.7797
Epoch 8/60
1652/1652 [==============================] - 4s 3ms/step - loss: 0.9629 - acc: 0.5714 - auc_roc: 0.7874 - val_loss: 1.7380 - val_acc: 0.5932 - val_auc_roc: 0.7945
Epoch 9/60
1652/1652 [==============================] - 4s 3ms/step - loss: 0.9279 - acc: 0.5866 - auc_roc: 0.8008 - val_loss: 1.4057 - val_acc: 0.6766 - val_auc_roc: 0.8077
Epoch 10/60
1652/1652 [==============================] - 4s 3ms/step - loss: 0.9054 - acc: 0.5835 - auc_roc: 0.8131 - val_loss: 1.7631 - val_acc: 0.6017 - val_auc_roc: 0.8166
Epoch 11/60
1652/1652 [==============================] - 4s 3ms/step - loss: 0.8741 - acc: 0.6084 - auc_roc: 0.8203 - val_loss: 1.9947 - val_acc: 0.5763 - val_auc_roc: 0.8238
Epoch 12/60
1652/1652 [==============================] - 4s 3ms/step - loss: 0.8544 - acc: 0.5920 - auc_roc: 0.8263 - val_loss: 1.4563 - val_acc: 0.6455 - val_auc_roc: 0.8299
Epoch 13/60
1652/1652 [==============================] - 4s 3ms/step - loss: 0.7607 - acc: 0.6314 - auc_roc: 0.8335 - val_loss: 1.8303 - val_acc: 0.6638 - val_auc_roc: 0.8371
Epoch 14/60
1652/1652 [==============================] - 4s 3ms/step - loss: 0.7426 - acc: 0.6283 - auc_roc: 0.8403 - val_loss: 1.8458 - val_acc: 0.6497 - val_auc_roc: 0.8433
Epoch 15/60
1652/1652 [==============================] - 4s 2ms/step - loss: 0.6796 - acc: 0.6568 - auc_roc: 0.8460 - val_loss: 2.0572 - val_acc: 0.6596 - val_auc_roc: 0.8491
Epoch 16/60
1652/1652 [==============================] - 4s 3ms/step - loss: 0.6801 - acc: 0.6689 - auc_roc: 0.8514 - val_loss: 2.0171 - val_acc: 0.6469 - val_auc_roc: 0.8539
Epoch 17/60
1652/1652 [==============================] - 4s 3ms/step - loss: 0.7631 - acc: 0.6368 - auc_roc: 0.8557 - val_loss: 1.8524 - val_acc: 0.4477 - val_auc_roc: 0.8564
Epoch 18/60
1652/1652 [==============================] - 4s 3ms/step - loss: 0.7332 - acc: 0.6550 - auc_roc: 0.8569 - val_loss: 1.9716 - val_acc: 0.6257 - val_auc_roc: 0.8588
Epoch 19/60
1652/1652 [==============================] - 4s 3ms/step - loss: 0.6346 - acc: 0.6961 - auc_roc: 0.8607 - val_loss: 1.8616 - val_acc: 0.6935 - val_auc_roc: 0.8629
Epoch 20/60
1652/1652 [==============================] - 4s 3ms/step - loss: 0.5661 - acc: 0.7149 - auc_roc: 0.8648 - val_loss: 2.2131 - val_acc: 0.7147 - val_auc_roc: 0.8673
Epoch 21/60
1652/1652 [==============================] - 4s 3ms/step - loss: 0.5247 - acc: 0.7355 - auc_roc: 0.8693 - val_loss: 2.1624 - val_acc: 0.6864 - val_auc_roc: 0.8716
Epoch 22/60
1652/1652 [==============================] - 4s 2ms/step - loss: 0.5342 - acc: 0.7318 - auc_roc: 0.8733 - val_loss: 2.2120 - val_acc: 0.6836 - val_auc_roc: 0.8752
Epoch 23/60
1652/1652 [==============================] - 4s 3ms/step - loss: 0.4621 - acc: 0.7645 - auc_roc: 0.8769 - val_loss: 2.3909 - val_acc: 0.7034 - val_auc_roc: 0.8791
Epoch 24/60
1652/1652 [==============================] - 4s 3ms/step - loss: 0.4500 - acc: 0.7875 - auc_roc: 0.8807 - val_loss: 2.3009 - val_acc: 0.6963 - val_auc_roc: 0.8826
Epoch 25/60
1652/1652 [==============================] - 4s 3ms/step - loss: 0.5227 - acc: 0.7609 - auc_roc: 0.8839 - val_loss: 2.1893 - val_acc: 0.6935 - val_auc_roc: 0.8855
Epoch 26/60
1652/1652 [==============================] - 4s 3ms/step - loss: 0.4689 - acc: 0.7827 - auc_roc: 0.8869 - val_loss: 2.2515 - val_acc: 0.6935 - val_auc_roc: 0.8885
Epoch 27/60
1652/1652 [==============================] - 4s 2ms/step - loss: 0.4279 - acc: 0.7863 - auc_roc: 0.8898 - val_loss: 2.2622 - val_acc: 0.6935 - val_auc_roc: 0.8913
Epoch 28/60
1652/1652 [==============================] - 4s 3ms/step - loss: 0.3674 - acc: 0.8263 - auc_roc: 0.8926 - val_loss: 2.5716 - val_acc: 0.7105 - val_auc_roc: 0.8943
Epoch 29/60
1652/1652 [==============================] - 4s 2ms/step - loss: 0.3204 - acc: 0.8487 - auc_roc: 0.8957 - val_loss: 2.4711 - val_acc: 0.7133 - val_auc_roc: 0.8973
Epoch 00029: early stopping
... history of metrics comprising: ['acc', 'loss', 'val_auc_roc', 'auc_roc', 'val_acc', 'val_loss']
... ... metric (acc): [0.71489104116222757, 0.73547215481935924, 0.73184019341595818, 0.76452784532496199, 0.78753026634382561, 0.76089588406588204, 0.7826876510430768, 0.78631961273512019, 0.82627118615203565, 0.84866828087167068] (n=29)
output> saving performance to:
/Users/pleiades/Documents/work/tpheno/seqmaker/data/CKD/plot/model_evalation-ep200b16.tif

... ... metric (loss): [0.56611451340645336, 0.52474937939759314, 0.53417988377679637, 0.4620722934928414, 0.44997505053480946, 0.52267439807731364, 0.46887725432906252, 0.42786489495642249, 0.36744263140398997, 0.32038253920996163] (n=29)
output> saving performance to:
/Users/pleiades/Documents/work/tpheno/seqmaker/data/CKD/plot/model_evalation-ep200b16.tif


model_selection> trying {'n_units': 200, 'dropout_rate': 0.6} ...

make_lstm> n_units=200, r_dropout=0.600000, n_layers=1, n_classes=6
  + lookup:
{'Others': 5, 'CKD Stage 5': 4, 'CKD Stage 4': 3, 'CKD Stage 3': 2, 'CKD Stage 2': 1, 'CKD Stage 1': 0}

... class weights:
{0: 6.344086021505376, 1: 0.74494949494949492, 2: 1.1238095238095238, 3: 7.0238095238095237, 4: 0.51890941072999119, 5: 0.64906490649064907}

====================================================================================================
... early stopping>
       + patience: 20, model='max'
... model training>
       + batch_size: 32, epochs: 60, shuffle? True, metric: auc_roc
====================================================================================================
Train on 1652 samples, validate on 708 samples
Epoch 1/60
1652/1652 [==============================] - 6s 4ms/step - loss: 1.6975 - acc: 0.2633 - auc_roc: 0.5673 - val_loss: 1.8734 - val_acc: 0.3870 - val_auc_roc: 0.6593
Epoch 2/60
1652/1652 [==============================] - 5s 3ms/step - loss: 1.4598 - acc: 0.4092 - auc_roc: 0.6932 - val_loss: 1.4009 - val_acc: 0.6257 - val_auc_roc: 0.7259
Epoch 3/60
1652/1652 [==============================] - 5s 3ms/step - loss: 1.3007 - acc: 0.4709 - auc_roc: 0.7489 - val_loss: 1.5972 - val_acc: 0.5734 - val_auc_roc: 0.7642
Epoch 4/60
1652/1652 [==============================] - 5s 3ms/step - loss: 1.2555 - acc: 0.4728 - auc_roc: 0.7735 - val_loss: 1.5310 - val_acc: 0.5593 - val_auc_roc: 0.7793
Epoch 5/60
1652/1652 [==============================] - 6s 3ms/step - loss: 1.1667 - acc: 0.5036 - auc_roc: 0.7852 - val_loss: 1.8236 - val_acc: 0.5621 - val_auc_roc: 0.7911
Epoch 6/60
1652/1652 [==============================] - 5s 3ms/step - loss: 1.0768 - acc: 0.5030 - auc_roc: 0.7967 - val_loss: 1.4800 - val_acc: 0.6116 - val_auc_roc: 0.8033
Epoch 7/60
1652/1652 [==============================] - 5s 3ms/step - loss: 1.0705 - acc: 0.5266 - auc_roc: 0.8081 - val_loss: 1.7669 - val_acc: 0.6271 - val_auc_roc: 0.8125
Epoch 8/60
1652/1652 [==============================] - 5s 3ms/step - loss: 0.9761 - acc: 0.5684 - auc_roc: 0.8167 - val_loss: 1.5437 - val_acc: 0.6681 - val_auc_roc: 0.8221
Epoch 9/60
1652/1652 [==============================] - 5s 3ms/step - loss: 0.8780 - acc: 0.5926 - auc_roc: 0.8268 - val_loss: 1.7349 - val_acc: 0.6935 - val_auc_roc: 0.8320
Epoch 10/60
1652/1652 [==============================] - 5s 3ms/step - loss: 0.8534 - acc: 0.5993 - auc_roc: 0.8363 - val_loss: 1.6356 - val_acc: 0.6554 - val_auc_roc: 0.8398
Epoch 11/60
1652/1652 [==============================] - 5s 3ms/step - loss: 0.8381 - acc: 0.6047 - auc_roc: 0.8427 - val_loss: 1.5854 - val_acc: 0.6850 - val_auc_roc: 0.8463
Epoch 12/60
1652/1652 [==============================] - 5s 3ms/step - loss: 0.7866 - acc: 0.6271 - auc_roc: 0.8494 - val_loss: 1.7803 - val_acc: 0.6949 - val_auc_roc: 0.8524
Epoch 13/60
1652/1652 [==============================] - 5s 3ms/step - loss: 0.7747 - acc: 0.6283 - auc_roc: 0.8549 - val_loss: 1.9468 - val_acc: 0.6780 - val_auc_roc: 0.8577
Epoch 14/60
1652/1652 [==============================] - 5s 3ms/step - loss: 0.7736 - acc: 0.6308 - auc_roc: 0.8594 - val_loss: 1.6330 - val_acc: 0.6836 - val_auc_roc: 0.8617
Epoch 15/60
1652/1652 [==============================] - 5s 3ms/step - loss: 0.7655 - acc: 0.6477 - auc_roc: 0.8636 - val_loss: 1.5843 - val_acc: 0.7246 - val_auc_roc: 0.8660
Epoch 16/60
1652/1652 [==============================] - 5s 3ms/step - loss: 0.6536 - acc: 0.6834 - auc_roc: 0.8684 - val_loss: 1.9332 - val_acc: 0.5042 - val_auc_roc: 0.8690
Epoch 17/60
1652/1652 [==============================] - 5s 3ms/step - loss: 0.6393 - acc: 0.6822 - auc_roc: 0.8700 - val_loss: 1.9310 - val_acc: 0.7076 - val_auc_roc: 0.8723
Epoch 18/60
1652/1652 [==============================] - 5s 3ms/step - loss: 0.5851 - acc: 0.7076 - auc_roc: 0.8741 - val_loss: 2.2049 - val_acc: 0.6285 - val_auc_roc: 0.8758
Epoch 19/60
1652/1652 [==============================] - 5s 3ms/step - loss: 0.5408 - acc: 0.7070 - auc_roc: 0.8773 - val_loss: 1.9161 - val_acc: 0.7175 - val_auc_roc: 0.8794
Epoch 20/60
1652/1652 [==============================] - 5s 3ms/step - loss: 0.4989 - acc: 0.7542 - auc_roc: 0.8814 - val_loss: 2.0998 - val_acc: 0.6808 - val_auc_roc: 0.8834
Epoch 21/60
1652/1652 [==============================] - 5s 3ms/step - loss: 0.5097 - acc: 0.7633 - auc_roc: 0.8850 - val_loss: 2.2194 - val_acc: 0.7218 - val_auc_roc: 0.8870
Epoch 22/60
1652/1652 [==============================] - 5s 3ms/step - loss: 0.4820 - acc: 0.7615 - auc_roc: 0.8886 - val_loss: 2.2909 - val_acc: 0.6977 - val_auc_roc: 0.8902
Epoch 00022: early stopping
... history of metrics comprising: ['acc', 'loss', 'val_auc_roc', 'auc_roc', 'val_acc', 'val_loss']
... ... metric (acc): [0.62832929767650203, 0.63075060547119766, 0.64769975758060705, 0.68341404343921397, 0.68220339011915088, 0.70762711835542547, 0.70702179191187564, 0.7542372879912721, 0.76331719157193534, 0.76150121065375298] (n=22)
output> saving performance to:
/Users/pleiades/Documents/work/tpheno/seqmaker/data/CKD/plot/model_evalation-ep200b16.tif

... ... metric (loss): [0.77468584784583949, 0.77359534522234386, 0.7655184456568942, 0.65357760872159687, 0.63934440257762881, 0.58513915481059375, 0.54075403010008116, 0.49892958342018773, 0.50969419583281361, 0.48201133884471498] (n=22)
output> saving performance to:
/Users/pleiades/Documents/work/tpheno/seqmaker/data/CKD/plot/model_evalation-ep200b16.tif


model_selection> trying {'n_units': 300, 'dropout_rate': 0.6} ...

make_lstm> n_units=300, r_dropout=0.600000, n_layers=1, n_classes=6
  + lookup:
{'Others': 5, 'CKD Stage 5': 4, 'CKD Stage 4': 3, 'CKD Stage 3': 2, 'CKD Stage 2': 1, 'CKD Stage 1': 0}

... class weights:
{0: 6.344086021505376, 1: 0.74494949494949492, 2: 1.1238095238095238, 3: 7.0238095238095237, 4: 0.51890941072999119, 5: 0.64906490649064907}

====================================================================================================
... early stopping>
       + patience: 20, model='max'
... model training>
       + batch_size: 32, epochs: 60, shuffle? True, metric: auc_roc
====================================================================================================
Train on 1652 samples, validate on 708 samples
Epoch 1/60
1652/1652 [==============================] - 9s 5ms/step - loss: 1.6895 - acc: 0.2863 - auc_roc: 0.6094 - val_loss: 1.6402 - val_acc: 0.5353 - val_auc_roc: 0.7013
Epoch 2/60
1652/1652 [==============================] - 7s 4ms/step - loss: 1.4305 - acc: 0.4570 - auc_roc: 0.7352 - val_loss: 1.8754 - val_acc: 0.5198 - val_auc_roc: 0.7554
Epoch 3/60
1652/1652 [==============================] - 8s 5ms/step - loss: 1.2971 - acc: 0.4588 - auc_roc: 0.7659 - val_loss: 1.4489 - val_acc: 0.5805 - val_auc_roc: 0.7794
Epoch 4/60
1652/1652 [==============================] - 8s 5ms/step - loss: 1.1675 - acc: 0.4988 - auc_roc: 0.7895 - val_loss: 1.5548 - val_acc: 0.5918 - val_auc_roc: 0.7958
Epoch 5/60
1652/1652 [==============================] - 8s 5ms/step - loss: 1.1441 - acc: 0.5042 - auc_roc: 0.8022 - val_loss: 1.6933 - val_acc: 0.5749 - val_auc_roc: 0.8088
Epoch 6/60
1652/1652 [==============================] - 7s 4ms/step - loss: 1.0792 - acc: 0.5218 - auc_roc: 0.8139 - val_loss: 1.8463 - val_acc: 0.4718 - val_auc_roc: 0.8161
Epoch 7/60
1652/1652 [==============================] - 8s 5ms/step - loss: 1.1863 - acc: 0.4613 - auc_roc: 0.8158 - val_loss: 1.8354 - val_acc: 0.2302 - val_auc_roc: 0.8097
Epoch 8/60
1652/1652 [==============================] - 8s 5ms/step - loss: 1.0409 - acc: 0.4994 - auc_roc: 0.8077 - val_loss: 1.8388 - val_acc: 0.5240 - val_auc_roc: 0.8095
Epoch 9/60
1652/1652 [==============================] - 8s 5ms/step - loss: 0.9037 - acc: 0.5969 - auc_roc: 0.8132 - val_loss: 1.8039 - val_acc: 0.5720 - val_auc_roc: 0.8171
Epoch 10/60
1652/1652 [==============================] - 8s 5ms/step - loss: 0.8680 - acc: 0.5648 - auc_roc: 0.8202 - val_loss: 1.7842 - val_acc: 0.6201 - val_auc_roc: 0.8238
Epoch 11/60
1652/1652 [==============================] - 8s 5ms/step - loss: 0.8094 - acc: 0.6205 - auc_roc: 0.8275 - val_loss: 1.8098 - val_acc: 0.6921 - val_auc_roc: 0.8320
Epoch 12/60
1652/1652 [==============================] - 8s 5ms/step - loss: 0.7733 - acc: 0.6362 - auc_roc: 0.8363 - val_loss: 1.5621 - val_acc: 0.6935 - val_auc_roc: 0.8403
Epoch 13/60
1652/1652 [==============================] - 9s 6ms/step - loss: 0.7641 - acc: 0.6320 - auc_roc: 0.8434 - val_loss: 2.0676 - val_acc: 0.6215 - val_auc_roc: 0.8463
Epoch 14/60
1652/1652 [==============================] - 8s 5ms/step - loss: 0.6960 - acc: 0.6646 - auc_roc: 0.8490 - val_loss: 1.8219 - val_acc: 0.6949 - val_auc_roc: 0.8523
Epoch 15/60
1652/1652 [==============================] - 8s 5ms/step - loss: 0.6345 - acc: 0.6786 - auc_roc: 0.8552 - val_loss: 1.9508 - val_acc: 0.7218 - val_auc_roc: 0.8586
Epoch 16/60
1652/1652 [==============================] - 8s 5ms/step - loss: 0.6467 - acc: 0.6743 - auc_roc: 0.8609 - val_loss: 1.9989 - val_acc: 0.6483 - val_auc_roc: 0.8633
Epoch 17/60
1652/1652 [==============================] - 8s 5ms/step - loss: 0.5832 - acc: 0.7161 - auc_roc: 0.8653 - val_loss: 2.1186 - val_acc: 0.6963 - val_auc_roc: 0.8680
Epoch 18/60
1652/1652 [==============================] - 8s 5ms/step - loss: 0.6654 - acc: 0.6913 - auc_roc: 0.8699 - val_loss: 1.8701 - val_acc: 0.6766 - val_auc_roc: 0.8718
Epoch 19/60
1652/1652 [==============================] - 7s 4ms/step - loss: 0.6013 - acc: 0.6943 - auc_roc: 0.8735 - val_loss: 2.1575 - val_acc: 0.6907 - val_auc_roc: 0.8755
Epoch 20/60
1652/1652 [==============================] - 8s 5ms/step - loss: 0.5274 - acc: 0.7264 - auc_roc: 0.8774 - val_loss: 2.1234 - val_acc: 0.7105 - val_auc_roc: 0.8795
Epoch 21/60
1652/1652 [==============================] - 7s 4ms/step - loss: 0.4519 - acc: 0.7724 - auc_roc: 0.8813 - val_loss: 2.4250 - val_acc: 0.7161 - val_auc_roc: 0.8836
Epoch 22/60
1652/1652 [==============================] - 8s 5ms/step - loss: 0.4518 - acc: 0.7760 - auc_roc: 0.8854 - val_loss: 2.4829 - val_acc: 0.6737 - val_auc_roc: 0.8872
Epoch 23/60
1652/1652 [==============================] - 7s 4ms/step - loss: 0.5271 - acc: 0.7579 - auc_roc: 0.8887 - val_loss: 1.8106 - val_acc: 0.6921 - val_auc_roc: 0.8900
Epoch 00023: early stopping
... history of metrics comprising: ['acc', 'loss', 'val_auc_roc', 'auc_roc', 'val_acc', 'val_loss']
... ... metric (acc): [0.66464891012297989, 0.6785714285714286, 0.67433414043583539, 0.71610169505957544, 0.6912832926895659, 0.69430992736077479, 0.72639225152733833, 0.77239709428667158, 0.77602905597871497, 0.75786924910603082] (n=23)
output> saving performance to:
/Users/pleiades/Documents/work/tpheno/seqmaker/data/CKD/plot/model_evalation-ep200b16.tif

... ... metric (loss): [0.69598694531738614, 0.63446722769564057, 0.64671673793480988, 0.58324501849259935, 0.66536127813791823, 0.60128006028782655, 0.52740013657124218, 0.45193622432667174, 0.45175328482727162, 0.52710663579566719] (n=23)
output> saving performance to:
/Users/pleiades/Documents/work/tpheno/seqmaker/data/CKD/plot/model_evalation-ep200b16.tif


model_selection> trying {'n_units': 400, 'dropout_rate': 0.6} ...

make_lstm> n_units=400, r_dropout=0.600000, n_layers=1, n_classes=6
  + lookup:
{'Others': 5, 'CKD Stage 5': 4, 'CKD Stage 4': 3, 'CKD Stage 3': 2, 'CKD Stage 2': 1, 'CKD Stage 1': 0}

... class weights:
{0: 6.344086021505376, 1: 0.74494949494949492, 2: 1.1238095238095238, 3: 7.0238095238095237, 4: 0.51890941072999119, 5: 0.64906490649064907}

====================================================================================================
... early stopping>
       + patience: 20, model='max'
... model training>
       + batch_size: 32, epochs: 60, shuffle? True, metric: auc_roc
====================================================================================================
Train on 1652 samples, validate on 708 samples
Epoch 1/60
1652/1652 [==============================] - 13s 8ms/step - loss: 1.6662 - acc: 0.3027 - auc_roc: 0.6409 - val_loss: 1.5866 - val_acc: 0.5734 - val_auc_roc: 0.7145
Epoch 2/60
1652/1652 [==============================] - 11s 7ms/step - loss: 1.4178 - acc: 0.4038 - auc_roc: 0.7385 - val_loss: 2.0472 - val_acc: 0.5000 - val_auc_roc: 0.7477
Epoch 3/60
1652/1652 [==============================] - 11s 7ms/step - loss: 1.3284 - acc: 0.4655 - auc_roc: 0.7597 - val_loss: 1.3665 - val_acc: 0.6681 - val_auc_roc: 0.7734
Epoch 4/60
1652/1652 [==============================] - 13s 8ms/step - loss: 1.2042 - acc: 0.4703 - auc_roc: 0.7832 - val_loss: 1.6865 - val_acc: 0.6116 - val_auc_roc: 0.7943
Epoch 5/60
1652/1652 [==============================] - 13s 8ms/step - loss: 1.1539 - acc: 0.5097 - auc_roc: 0.8015 - val_loss: 1.9670 - val_acc: 0.2331 - val_auc_roc: 0.7987
Epoch 6/60
1652/1652 [==============================] - 13s 8ms/step - loss: 1.0943 - acc: 0.5254 - auc_roc: 0.7981 - val_loss: 2.2746 - val_acc: 0.2246 - val_auc_roc: 0.7946
Epoch 7/60
1652/1652 [==============================] - 12s 7ms/step - loss: 1.0756 - acc: 0.5079 - auc_roc: 0.7907 - val_loss: 1.7612 - val_acc: 0.5960 - val_auc_roc: 0.7960
Epoch 8/60
1652/1652 [==============================] - 13s 8ms/step - loss: 0.9616 - acc: 0.5745 - auc_roc: 0.8025 - val_loss: 1.6712 - val_acc: 0.6568 - val_auc_roc: 0.8094
Epoch 9/60
1652/1652 [==============================] - 12s 7ms/step - loss: 0.9902 - acc: 0.5714 - auc_roc: 0.8141 - val_loss: 1.7560 - val_acc: 0.6285 - val_auc_roc: 0.8185
Epoch 10/60
1652/1652 [==============================] - 11s 7ms/step - loss: 0.8464 - acc: 0.6144 - auc_roc: 0.8226 - val_loss: 1.8309 - val_acc: 0.6836 - val_auc_roc: 0.8277
Epoch 11/60
1652/1652 [==============================] - 11s 7ms/step - loss: 0.8075 - acc: 0.6235 - auc_roc: 0.8321 - val_loss: 1.8137 - val_acc: 0.6596 - val_auc_roc: 0.8364
Epoch 12/60
1652/1652 [==============================] - 11s 7ms/step - loss: 0.7679 - acc: 0.6435 - auc_roc: 0.8401 - val_loss: 2.0906 - val_acc: 0.6229 - val_auc_roc: 0.8431
Epoch 13/60
1652/1652 [==============================] - 11s 7ms/step - loss: 0.7318 - acc: 0.6483 - auc_roc: 0.8461 - val_loss: 1.9287 - val_acc: 0.7274 - val_auc_roc: 0.8498
Epoch 14/60
1652/1652 [==============================] - 11s 7ms/step - loss: 0.7268 - acc: 0.6374 - auc_roc: 0.8525 - val_loss: 2.1111 - val_acc: 0.6483 - val_auc_roc: 0.8550
Epoch 15/60
1652/1652 [==============================] - 12s 7ms/step - loss: 0.7299 - acc: 0.6622 - auc_roc: 0.8573 - val_loss: 2.2077 - val_acc: 0.6102 - val_auc_roc: 0.8592
Epoch 16/60
1652/1652 [==============================] - 12s 7ms/step - loss: 0.6287 - acc: 0.7034 - auc_roc: 0.8614 - val_loss: 2.3389 - val_acc: 0.6427 - val_auc_roc: 0.8639
Epoch 17/60
1652/1652 [==============================] - 13s 8ms/step - loss: 0.5585 - acc: 0.7234 - auc_roc: 0.8663 - val_loss: 2.0060 - val_acc: 0.7175 - val_auc_roc: 0.8693
Epoch 18/60
1652/1652 [==============================] - 11s 7ms/step - loss: 0.5024 - acc: 0.7524 - auc_roc: 0.8719 - val_loss: 2.2065 - val_acc: 0.6893 - val_auc_roc: 0.8746
Epoch 19/60
1652/1652 [==============================] - 12s 7ms/step - loss: 0.5127 - acc: 0.7446 - auc_roc: 0.8769 - val_loss: 2.2566 - val_acc: 0.7189 - val_auc_roc: 0.8793
Epoch 20/60
1652/1652 [==============================] - 11s 7ms/step - loss: 0.4560 - acc: 0.7839 - auc_roc: 0.8817 - val_loss: 1.9955 - val_acc: 0.6681 - val_auc_roc: 0.8839
Epoch 21/60
1652/1652 [==============================] - 11s 7ms/step - loss: 0.4692 - acc: 0.7797 - auc_roc: 0.8859 - val_loss: 2.4299 - val_acc: 0.7161 - val_auc_roc: 0.8878
Epoch 22/60
1652/1652 [==============================] - 11s 7ms/step - loss: 0.4502 - acc: 0.7996 - auc_roc: 0.8896 - val_loss: 2.2785 - val_acc: 0.7006 - val_auc_roc: 0.8916
Epoch 23/60
1652/1652 [==============================] - 11s 7ms/step - loss: 0.3402 - acc: 0.8293 - auc_roc: 0.8936 - val_loss: 2.5620 - val_acc: 0.7189 - val_auc_roc: 0.8956
Epoch 00023: early stopping
... history of metrics comprising: ['acc', 'loss', 'val_auc_roc', 'auc_roc', 'val_acc', 'val_loss']
... ... metric (acc): [0.63740920082420183, 0.66222760276124781, 0.70338983036415337, 0.72336561714477166, 0.75242130779469563, 0.74455205796705892, 0.78389830508474578, 0.77966101709347368, 0.7996368041627343, 0.82929782096756577] (n=23)
output> saving performance to:
/Users/pleiades/Documents/work/tpheno/seqmaker/data/CKD/plot/model_evalation-ep200b16.tif

... ... metric (loss): [0.72683080489641239, 0.72992653203068292, 0.62868888124138045, 0.55851330090377294, 0.50235003435005576, 0.51268526038592432, 0.45595665748702413, 0.46920592718493853, 0.45017205333882904, 0.34022963956250984] (n=23)
output> saving performance to:
/Users/pleiades/Documents/work/tpheno/seqmaker/data/CKD/plot/model_evalation-ep200b16.tif

result> performance scores ...

Traceback (most recent call last):
  File "dnn_utils.py", line 2618, in <module>
    test2()
  File "dnn_utils.py", line 2605, in test2
    last_n_visits=tset['last_n_visits'])
  File "dnn_utils.py", line 2343, in t_deep_classify
    opt = rank_model(target_metric=targetMetric)  # rank hyperparams and their scores
  File "dnn_utils.py", line 2183, in rank_model
    best_scores = grid_scores[metric][0]
IndexError: list index out of range
pleiades@~/Documents/work/tpheno/seqmaker\:) python dnn_utils.py 
Using TensorFlow backend.
config> d2v: pv-dm2, user descriptor (model, tset, mcs): smallCKD
        cohort: CKD, ctype: regular
            + augmented? False, simplified? False dir_type=combined
check> sysConfig complete ... meta? smallCKD
load_data> inputs:
['/Users/pleiades/Documents/work/tpheno/seqmaker/data/CKD/condition_drug_labeled_seq-CKD.csv']

================================================================================
1. Read temporal doc files ...
================================================================================
loadDocuments> input files: ['/Users/pleiades/Documents/work/tpheno/seqmaker/data/CKD/condition_drug_labeled_seq-CKD.csv']
readDocFromCSV> input files: ['/Users/pleiades/Documents/work/tpheno/seqmaker/data/CKD/condition_drug_labeled_seq-CKD.csv']
read> reading from 1 source files:
['/Users/pleiades/Documents/work/tpheno/seqmaker/data/CKD/condition_drug_labeled_seq-CKD.csv']

read> processing header sequence ...
read> processing header timestamp ...
read> processing header label ...
    + labels (converted to single-label format, n=11): ['CKD G1-control' 'CKD G1A1-control' 'CKD Stage 1' 'CKD Stage 2'
 'CKD Stage 3a' 'CKD Stage 3b' 'CKD Stage 4' 'CKD Stage 5'
 'ESRD after transplant' 'ESRD on dialysis' 'Unknown']
seqReaderApp.load> nD: 2833, nT: 2833, nL: 2833
  + Stats: n_docs: 2833, n_classes:11 | cohort: CKD
processDocuments> Begin document transformation operations (e.g. simplify, diag-only, etc)
filterDocuments> Policy: Remove empty documents ...
transformDocuments> nD: 2833 (<- 2833), nT: 2833, nL: 2833
  + Stats: n_docs: 2833, n_classes:11
transformDocuments2> nD: 2360, nT: 2360, nL: 2360
  + Stats: n_docs: 2360, n_classes:11 | cohort: ?
    + (after transform) nDoc: 2833 -> 2360, size(D0): 16 -> 16
    + (after transform) nD: 2360, nT: 2360, nL: 2360
  + nD: 2360 | cohort=CKD, ctype=regular, labeled? True, simplified? False
  + doc(last 150 chars):
['V82.9', 'V15.89', '185', '185', '185', '185', '185', 'V72.9', 'V72.9', '185', '185', '185', '185', '185', '185', '599.0', '185', '599.0', '185', 'V76.51', 'E879.2', 'V10.46', '569.49', '562.10', 'V10.46', '719.44', 'V10.46', '727.03', 'V10.46', 'V10.46', '401.9', '366.16', '599.0', '185', '185', '185', 'E958.0', '873.49', '246.8', '600.00', '305.01', '365.9', '311', '296.23', '788.41', 'MED:61025', 'MED:60946', '185', 'V10.46', '185']

  + vdoc
    + ['V10.46']
    + ['V10.46', '401.9', '366.16']
    + ['599.0']
    + ['185']
    + ['185']
    + ['185']
    + ['E958.0', '873.49', '246.8', '600.00', '305.01', '365.9', '311', '296.23', '788.41']
    + ['MED:61025', 'MED:60946']
    + ['185']
    + ['V10.46', '185']
  + doc(last 150 chars):
['296.7', '311', '290.0', 'MED:56357', '715.90', '599.0', '331.0', '296.7', '272.0', '311', 'MED:28592', '599.0', '290.0', '788.43', '599.0', '507.0', '799.0', '294.10', '780.39', '331.0', '295.20', 'MED:61895', 'MED:61522', 'MED:60950', 'MED:60924', 'MED:60573', 'MED:66042', 'MED:61525', 'MED:62513', 'MED:63456', 'MED:62973', 'MED:60439', 'MED:66160', 'MED:63413', '331.0', '599.0', '780.39', '331.0', '796.4', 'MED:59127', '290.0', 'V68.1', 'MED:33963', '780.52', '294.10', '780.39', '331.0', 'MED:33963', '780.39', '331.0', '784.0', '564.00', 'MED:30027', '564.01', '780.6', '790.6', '715.98', '787.91', '487.1', '294.10', '780.39', '331.0', '272.4', '276.51', 'MED:62527', 'MED:61836', 'MED:61892', 'MED:60998', 'MED:60924', 'MED:63385', 'MED:86675', 'MED:62191', 'MED:71905', 'MED:33963', 'V49.84', '294.10', '780.39', '331.0', '331.0', '790.6', '716.90', '564.09', '599.0', '507.0', '294.10', '780.39', '331.0', '276.51', '780.02', 'MED:62527', 'MED:62028', 'MED:61895', 'MED:62934', 'MED:61522', 'MED:62439', 'MED:61666', 'MED:60924', 'MED:63249', 'MED:72900', 'MED:71905', 'MED:28362', '331.0', '331.0', '331.0', '564.00', '780.39', '331.0', 'MED:33147', '443.9', '443.9', '780.39', '331.0', 'MED:77862', '707.9', '892.1', '892.1', '892.1', '707.14', '707.14', '294.10', '331.0', '345.90', '272.4', '296.80', '444.22', '440.23', 'MED:61836', 'MED:61283', 'MED:62527', 'MED:62439', 'MED:61736', 'MED:60429', 'MED:60575', 'MED:62739', 'MED:61836', 'MED:61283', 'MED:60429', 'MED:62739', 'MED:60926', 'MED:62439', 'MED:61266', 'MED:62527', 'MED:61319', 'MED:60926', 'MED:62439', 'MED:62876', 'MED:56606', 'MED:28787', 'MED:77862', 'MED:28787']

  + vdoc
    + ['707.9']
    + ['892.1']
    + ['892.1']
    + ['892.1']
    + ['707.14']
    + ['707.14', '294.10', '331.0', '345.90', '272.4', '296.80', '444.22', '440.23', 'MED:61836', 'MED:61283', 'MED:62527', 'MED:62439', 'MED:61736', 'MED:60429', 'MED:60575', 'MED:62739']
    + ['MED:61836', 'MED:61283', 'MED:60429', 'MED:62739', 'MED:60926', 'MED:62439']
    + ['MED:61266', 'MED:62527', 'MED:61319', 'MED:60926', 'MED:62439']
    + ['MED:62876', 'MED:56606', 'MED:28787', 'MED:77862']
    + ['MED:28787']
  + doc(last 150 chars):
['MED:61237', 'MED:62624', 'NDC:00045051380', 'V10.05', 'V12.55', 'V15.88', 'V45.82', '715.90', '250.00', '722.4', '401.9', '389.10', '294.10', '294.11', '331.0', '280.9', '781.2', '311', 'V45.72', '414.01', 'NDC:00054429925', 'MULTUM:1819', 'MED:122364', 'MED:62439', 'MED:106708', 'MED:61939', 'MED:60926', 'MED:61895', 'MED:61112', 'MULTUM:6865', 'MULTUM:6701', 'NDC:00071101268', 'NDC:00093078701', 'MULTUM:6026', 'NDC:00143126601', 'NDC:00067067410', 'MULTUM:1255', 'MULTUM:471', 'MED:62936', 'NDC:00005557619', 'E849.9', 'E887', '729.5', '813.42', 'MED:60972', 'MED:63416', 'MED:60669', 'V54.89', '729.5', '401.9', '719.43', '294.21', 'MED:62439', '813.41', '813.41', '729.5', '412', '451.84', '401.9', '414.01', '733.82', 'Removable_Wrist_Splint', '780.60', 'V04.81', 'V10.05', 'V12.51', 'V15.88', 'V49.86', '715.90', '553.3', '511.9', '486', '465.9', '530.81', '401.9', 'unknown', '280.9', '311', '389.18', '294.20', '414.01', 'MULTUM:1509', 'NDC:00182101701', 'MED:62934', 'MED:60669', 'NDC:00378522205', 'MULTUM:8359', 'MULTUM:7049', 'MULTUM:1255', '780.60', 'V04.81', 'V10.05', 'V12.51', 'V15.88', 'V49.86', '715.90', '553.3', '511.9', '486', '465.9', '530.81', '401.9', 'unknown', '280.9', '311', '389.18', '294.20', '414.01', 'MED:60671', 'MED:63255', 'MED:122364', 'MED:158045', 'MED:71161', 'MED:61228', 'MED:62439', 'MED:62899', 'MED:63089', 'MED:89117', 'MED:61895', 'MED:61522', 'MED:61361', 'MED:100198', 'MULTUM:1509', 'MULTUM:11701', 'NDC:00067057804', 'MULTUM:7049', 'V10.05', 'V12.55', 'V45.82', 'V49.86', '486', '786.05', '414.00', '401.9', '389.18', 'MED:60998', 'MED:100198', 'MED:63159', 'MED:71161', 'MED:61228', 'MED:63089', 'MED:89117', 'MED:60671', 'MED:63590', 'MED:60645', 'MED:61223', 'MED:100198', 'MED:62679', 'NDC:00093729253', 'NDC:00121074404']

  + vdoc
    + ['V54.89', '729.5', '401.9', '719.43', '294.21', 'MED:62439']
    + ['813.41']
    + ['813.41']
    + ['729.5', '412', '451.84', '401.9', '414.01']
    + ['733.82', 'Removable_Wrist_Splint']
    + ['780.60', 'V04.81', 'V10.05', 'V12.51', 'V15.88', 'V49.86', '715.90', '553.3', '511.9', '486', '465.9', '530.81', '401.9', 'unknown', '280.9', '311', '389.18', '294.20', '414.01', 'MULTUM:1509', 'NDC:00182101701', 'MED:62934', 'MED:60669', 'NDC:00378522205', 'MULTUM:8359', 'MULTUM:7049', 'MULTUM:1255']
    + ['780.60', 'V04.81', 'V10.05', 'V12.51', 'V15.88', 'V49.86', '715.90', '553.3', '511.9', '486', '465.9', '530.81', '401.9', 'unknown', '280.9', '311', '389.18', '294.20', '414.01', 'MED:60671', 'MED:63255', 'MED:122364', 'MED:158045', 'MED:71161', 'MED:61228', 'MED:62439', 'MED:62899', 'MED:63089', 'MED:89117', 'MED:61895', 'MED:61522', 'MED:61361', 'MED:100198']
    + ['MULTUM:1509', 'MULTUM:11701', 'NDC:00067057804', 'MULTUM:7049']
    + ['V10.05', 'V12.55', 'V45.82', 'V49.86', '486', '786.05', '414.00', '401.9', '389.18', 'MED:60998', 'MED:100198']
    + ['MED:63159', 'MED:71161', 'MED:61228', 'MED:63089', 'MED:89117', 'MED:60671', 'MED:63590', 'MED:60645', 'MED:61223', 'MED:100198', 'MED:62679', 'NDC:00093729253', 'NDC:00121074404']
  + doc(last 150 chars):
['NDC:00054001720', 'NDC:00093521201', 'NDC:49692094225', '296.30', 'NDC:00093550201', 'NDC:16590032330', 'V45.51', '583.81', '623.8', '710.0', 'MED:62439', 'NDC:00054472825', '583.81', '626.2', '710.0', '280.0', '281.9', '280.9', '305.1', 'NDC:00186504031', 'NDC:00093023333', 'NDC:00054472825', 'NDC:00024156210', 'NDC:00173073601', 'NDC:00143126601', 'NDC:00182414126', 'NDC:00182120140', 'NDC:00004026001', 'MED:61112', 'MED:61338', 'MED:61939', 'MED:61412', 'MED:89117', 'MED:62934', 'MED:72666', 'MED:133079', 'MED:62439', 'MED:62170', 'NDC:00024156210', 'NDC:00004026001', '626.2', 'NDC:50419042101', 'V25.42', 'V67.59', 'NDC:55111068301', '710.0', 'NDC:00024156210', 'NDC:00378522205', 'NDC:00054474225', 'NDC:00182120140', 'NDC:00004026001', '780.60', '583.9', '486', '710.0', '280.9', 'MED:60965', 'MED:62439', 'MED:60826', 'MED:62934', 'MED:62742', 'NDC:00093716956', '710.0', 'NDC:00004026001', 'NDC:00182120140', 'NDC:00378522205', 'NDC:00054474225', 'NDC:00024156210', '296.30', 'NDC:00115681102', '296.30', 'NDC:00182125989', 'NDC:00143126601', '710.0', 'NDC:00143126501', '296.30', 'NDC:00115681102', '710.0', 'NDC:21695079100', 'NDC:24987056210', 'NDC:00004026001', '367.1', '1525_025_X_180_Od_1575_000_X_00_Os', '535.50', '789.09', '305.1', '285.9', '788.41', 'NDC:00093314701', '296.30', 'NDC:00115681102', 'NDC:00456200501', '710.0', 'NDC:55111068301', 'NDC:00143126601', 'NDC:00143126501', 'NDC:24987056210', 'NDC:00004026001', '296.32', 'NDC:00024542131', 'NDC:00173073101', '296.32', 'NDC:00024542131', '296.32', '710.0', 'NDC:24987056210', 'NDC:00004026001', 'NDC:00143126501', 'NDC:00143126601', '296.32', '296.31', '296.32', '296.31', 'NDC:00024542131', 'NDC:00173073101', '296.32', '296.31', '583.9', '710.0', '599.0', '724.2', '710.0', '401.9', '272.4', 'MED:60826', 'MED:132318', 'MED:62879', 'MED:62934', 'NDC:00093224001', 'NDC:00093023333', 'NDC:00067610004', '740.0', '710.0', '710.0', '585.4', '780.64', '490', '710.0', '079.99', 'MED:60926', 'MED:167651', 'MED:62934', 'MED:60671', 'MED:62742', 'NDC:00093714656', 'NDC:00247225500', 'MED:60826', 'F39', 'unknown', 'F39']

  + vdoc
    + ['NDC:00093224001', 'NDC:00093023333']
    + ['NDC:00067610004']
    + ['740.0']
    + ['710.0']
    + ['710.0']
    + ['585.4']
    + ['780.64', '490', '710.0', '079.99', 'MED:60926', 'MED:167651', 'MED:62934', 'MED:60671', 'MED:62742', 'NDC:00093714656', 'NDC:00247225500']
    + ['MED:60826']
    + ['F39']
    + ['unknown', 'F39']
  + doc(last 150 chars):
['401.9', '196.2', '575.6', '153.9', '574.10', '153.1', '199.1', '789.0', '239.9', '153.9', '153.9', '153.9', '153.9', '162.9', '153.9', '153.9', '153.9', '153.9', 'V72.6', '153.9', '173.9', 'V72.6', '153.9', '153.9', '153.9', '153.9', '153.9', '153.9', '153.9', '153.9', '162.9', '153.9', '162.9', '153.9', '162.9', '153.9', '153.9', '202.80', '153.9', '153.9', '153.9', '558.9', '199.1', '153.9', '153.9', '153.9', '162.9', '153.9', '789.0', 'E878.8', '997.3', '276.2', '153.6', '153.9', '153.9', '153.9', '153.9', '153.9', '153.9', '799.9', 'V67.9', 'V82.9', 'V82.9', 'V10.05', '197.7', '401.9', '285.1', '285.9', 'V82.9', '799.9', '799.9', '789.9', 'V72.6', '789.0', '842.00', '153.9', '719.40', 'V72.6', '153.9', '789.0', '198.89', '153.9', 'V72.6', '786.50', 'V82.9', '153.9', '162.9', 'V10.05', 'V10.07', '197.0', '518.5', '276.2', '276.3', 'V10.05', '197.7', '511.9', '427.31', '786.5', 'V72.6', '786.50', '786.50', '553.21', '553.21', '789.0', '427.31', '401.9', '537.2', '558.9', '401.9', '789.0', 'V10.05', 'V10.52', '560.89', '789.00', '401.9', 'V10.04', '152.8', '427.31', '560.81', 'V72.6', '153.9', '401.9', '162.9']

  + vdoc
    + ['789.0']
    + ['427.31', '401.9']
    + ['537.2', '558.9']
    + ['401.9']
    + ['789.0']
    + ['V10.05', 'V10.52', '560.89', '789.00', '401.9']
    + ['V10.04', '152.8', '427.31', '560.81']
    + ['V72.6']
    + ['153.9']
    + ['401.9', '162.9']
  + doc(last 150 chars):
['719.50', 'E928.9', '955.2', '379.22', '789.0', '582.9', '799.9', '786.50', '274.0', '582.9', '274.0', '585.6', '458.9', '388.30', '794.31', 'MULTUM:8322', 'NDC:64764091830', 'MULTUM:2573', 'NDC:11845014628', 'NDC:00115981101', 'MULTUM:5466', 'NDC:54092025490', '414.00', 'MULTUM:7246', 'V45.11', '427.31', '424.1', '411.1', '403.91', '285.9', '274.9', '585.5', '133.0', '585.6', '136.9', '692.9', 'K62.1', 'MED:69860', 'MED:61895', 'MED:81159', 'MED:167651', 'MED:61939', 'MED:162541', 'MED:106362', 'NDC:00247024100', 'MED:62871', 'MED:60826', 'MED:94350', 'MED:62194', 'MED:132318', 'MULTUM:13202', 'NDC:00247197504']

  + vdoc
    + ['585.6', '458.9', '388.30']
    + ['794.31']
    + ['MULTUM:8322', 'NDC:64764091830', 'MULTUM:2573', 'NDC:11845014628', 'NDC:00115981101', 'MULTUM:5466', 'NDC:54092025490']
    + ['414.00']
    + ['MULTUM:7246']
    + ['V45.11', '427.31', '424.1', '411.1', '403.91', '285.9', '274.9', '585.5']
    + ['133.0', '585.6']
    + ['136.9']
    + ['692.9']
    + ['K62.1', 'MED:69860', 'MED:61895', 'MED:81159', 'MED:167651', 'MED:61939', 'MED:162541', 'MED:106362', 'NDC:00247024100', 'MED:62871', 'MED:60826', 'MED:94350', 'MED:62194', 'MED:132318', 'MULTUM:13202', 'NDC:00247197504']
  + doc(last 150 chars):
['799.9', '799.9', '301.89', '799.9', '799.9', '799.9', '799.9', '799.9', '780.6', '715.90', '466', '493.90', '826.0', 'V82.9', 'V15.82', '786.50', '493.90', '401.9', '414.01', 'MED:61504', 'MED:70400', 'MED:60558', 'MED:63366', 'MED:60802', 'MED:62094', 'MED:61785', 'MED:62055', 'MED:61319', 'MED:62439', 'MED:62967', 'MED:68183']

  + vdoc
    + ['799.9']
    + ['799.9']
    + ['780.6']
    + ['715.90']
    + ['466', '493.90']
    + ['826.0']
    + ['V82.9']
    + ['V15.82', '786.50', '493.90', '401.9', '414.01', 'MED:61504', 'MED:70400', 'MED:60558', 'MED:63366']
    + ['MED:60802', 'MED:62094', 'MED:61785', 'MED:62055', 'MED:61319', 'MED:62439']
    + ['MED:62967', 'MED:68183']
  + doc(last 150 chars):
['MED:167651', 'MED:61703', 'MED:61237', '829.0', 'NDC:00093005801', '829.0', 'V58.61', 'V04.81', '427.31', 'NDC:00536404610', 'NDC:00054055125', 'NDC:00093023333', 'I48.91', 'V58.83', 'Z51.81', '427.31', 'Z51.81', 'I48.91', 'V58.83', '427.31', 'MED:61736', 'Z51.81', 'I48.91', 'V58.83', '427.31', 'NDC:00056017070', 'T14.8', 'unknown', '829.0', 'R63.4', '783.21', '733.01', 'I48.91', 'I105.9', 'V58.61', 'Z79.01', '427.31', '424.0', 'MED:62934', 'MED:60826', 'MED:61703', 'I48.91', 'I105.9', 'V58.61', 'Z79.01', 'R63.4', '783.21', '427.31', '424.0', 'wheelchair', 'Rollator_Walker_With_Seat', 'R63.4', '783.21', 'NDC:50580050110', 'NDC:00049211066', 'R63.4', '783.21', 'I48.91', 'I105.9', 'V58.61', 'Z79.01', '427.31', '424.0', 'I48.91', 'V58.83', 'Z51.81', '427.31', 'I48.91', 'V58.83', 'Z51.81', '427.31', 'R63.4', '783.21', 'MED:62899', 'MED:62934', 'MED:61703', 'MED:62097', 'MED:60826', 'MED:61228', 'MED:63456', 'MED:81761', 'MED:62934', 'MED:167651', 'MED:122364', 'MED:61895', 'MED:61515', 'MED:61703', 'MED:60826', 'MED:60518', 'MED:60481', 'MED:61522', 'MED:61253', 'MED:63182', 'MED:60682', 'MED:61253', 'MED:68349', 'MED:167651', 'MED:61515', 'MED:62513', 'MED:61515', 'MED:61805', 'MED:167651', 'MED:61031', 'MED:61253', 'MED:61055', 'MED:89118', 'MED:60682', 'MED:61805', 'MED:62934', 'MED:61515', 'MED:61460', 'MED:61836', 'MED:167651', 'MED:61159', 'MED:61460', 'MED:61836', 'MED:61159', 'MED:99323', 'MED:61836', 'MED:61957', 'MED:98292', 'MED:60972', 'MED:61836', 'MED:61159', 'MED:158823', 'MED:158823', 'MED:61055', 'MED:61055', 'MED:63055', 'MED:102424', 'MED:158823', 'MED:61515', 'MED:61678', 'MED:63404', 'MED:61515', 'MED:62355', 'MED:62355', 'MED:89117', 'MED:62355', 'MED:62537', 'MED:62355', 'MED:62537', 'MED:60481', 'MED:158823', 'MED:61515', 'MED:62355', 'MED:62355', 'MED:61805', 'MED:62355', 'MED:62355']

  + vdoc
    + ['MED:62355']
    + ['MED:62355']
    + ['MED:89117', 'MED:62355', 'MED:62537']
    + ['MED:62355', 'MED:62537', 'MED:60481']
    + ['MED:158823', 'MED:61515']
    + ['MED:62355']
    + ['MED:62355']
    + ['MED:61805']
    + ['MED:62355']
    + ['MED:62355']
  + doc(last 150 chars):
['250.00', '786.05', '786.07', 'NDC:00054465025', 'NDC:00093191993', '719.40', 'NDC:00113040378', 'Physical_Therapy', '401.9', 'V03.82', '250.00', 'NDC:00573283010', 'NDC:37000002401', 'NDC:00143125601', 'NDC:00182181089', 'NDC:00067014182', 'NDC:00087607111', '401.9', '278.00', '607.84', '789.00', '250.00', 'NDC:45802064287', 'NDC:00087607111', 'NDC:00143125601', '782.1', '789.00', '250.00', 'Finger_Glucose_Test_Strip_Icd_25000', 'NDC:00049017402', 'NDC:00067619005', 'NDC:00182101701', 'Alcohol_Prep_Swab_1box_For_Diabetes_Care', 'NDC:67618031512', 'lancets', 'NDC:00006095231', 'NDC:00113019402', '401.9', '278.00', '250.00', 'V68.1', 'lancets', 'Finger_Glucose_Test_Strip_Icd_25000', '401.9', '300.00', '724.2', '250.00', 'Alcohol_Prep_Swab_1box_For_Diabetes_Care', 'Finger_Glucose_Test_Strip_Icd_25000', 'NDC:00113021771', 'NDC:00182101701', 'NDC:00006095231', 'NDC:67618031512', 'NDC:00049017402', 'NDC:00087607111', 'lancets', 'NDC:45802064287', 'NDC:00113019402', 'NDC:00143125601', '401.9', '278.00', '455.6', '250.00', 'Finger_Glucose_Test_Strip_Icd_25000', 'NDC:00573287110', '401.9', '278.00', '789.00', '250.00', 'NDC:45802064287', 'NDC:00087607111', 'lancets', 'NDC:00143125601', 'NDC:00006095231', 'NDC:00085128801', 'Finger_Glucose_Test_Strip_Icd_25000', 'NDC:00573287110', 'NDC:00093733801', 'NDC:00224180184', 'NDC:67618031512', 'Alcohol_Prep_Swab_1box_For_Diabetes_Care', 'NDC:00113021771', 'NDC:00049017402', 'NDC:00182101701', 'NDC:00113019402', '401.9', 'V72.83', '250.00', '401.9', '364.81', '366.16', '715.90', '724.5', '536.8', '250.00', '530.81', '401.9', '278.00', '250.00', 'NDC:00113021771', 'Alcohol_Prep_Swab_1box_For_Diabetes_Care', 'NDC:00049017402', 'NDC:00006095231', 'NDC:00224180184', 'NDC:00093733801', 'NDC:00085128801', 'NDC:00143125601', 'Finger_Glucose_Test_Strip_Icd_25000', 'NDC:00573287110', 'NDC:67618031512', 'NDC:00087607111', 'lancets', 'NDC:45802064287', 'NDC:00182101701', 'NDC:00113019402', 'V67.59', '401.9', '716.90', '789.00', '250.00', 'Finger_Glucose_Test_Strip_Icd_25000', 'NDC:00006496300', 'Alcohol_Prep_Swab_1box_For_Diabetes_Care', 'I86.1', '401.9', 'I10', 'E11.9', '788.43', 'R35.1', '250.00', 'Alcohol_Prep_Swab_1box_For_Diabetes_Care', 'NDC:00067950601', 'NDC:00182101701', 'NDC:67618031512', 'NDC:00093733801', 'Finger_Glucose_Test_Strip_Icd_25000', 'NDC:00573287110', 'NDC:00224180184', 'lancets', 'NDC:00049017402', 'NDC:00143125601', 'NDC:45802064287', 'NDC:00006095231', 'NDC:00087607111', 'NDC:00113019402', 'NDC:00247099630', 'Finger_Glucose_Test_Strip_Icd_25000', 'lancets', 'glucometer', 'Alcohol_Prep_Swab_1box_For_Diabetes_Care']

  + vdoc
    + ['401.9', '278.00', '789.00', '250.00', 'NDC:45802064287', 'NDC:00087607111', 'lancets', 'NDC:00143125601', 'NDC:00006095231', 'NDC:00085128801', 'Finger_Glucose_Test_Strip_Icd_25000', 'NDC:00573287110', 'NDC:00093733801', 'NDC:00224180184', 'NDC:67618031512', 'Alcohol_Prep_Swab_1box_For_Diabetes_Care', 'NDC:00113021771', 'NDC:00049017402', 'NDC:00182101701', 'NDC:00113019402']
    + ['401.9', 'V72.83', '250.00']
    + ['401.9', '364.81', '366.16', '715.90', '724.5', '536.8', '250.00', '530.81']
    + ['401.9', '278.00', '250.00', 'NDC:00113021771', 'Alcohol_Prep_Swab_1box_For_Diabetes_Care', 'NDC:00049017402', 'NDC:00006095231', 'NDC:00224180184', 'NDC:00093733801', 'NDC:00085128801', 'NDC:00143125601', 'Finger_Glucose_Test_Strip_Icd_25000', 'NDC:00573287110', 'NDC:67618031512', 'NDC:00087607111', 'lancets', 'NDC:45802064287', 'NDC:00182101701', 'NDC:00113019402']
    + ['V67.59']
    + ['401.9', '716.90', '789.00', '250.00', 'Finger_Glucose_Test_Strip_Icd_25000', 'NDC:00006496300']
    + ['Alcohol_Prep_Swab_1box_For_Diabetes_Care']
    + ['I86.1']
    + ['401.9', 'I10', 'E11.9', '788.43', 'R35.1', '250.00', 'Alcohol_Prep_Swab_1box_For_Diabetes_Care', 'NDC:00067950601', 'NDC:00182101701', 'NDC:67618031512', 'NDC:00093733801', 'Finger_Glucose_Test_Strip_Icd_25000', 'NDC:00573287110', 'NDC:00224180184', 'lancets', 'NDC:00049017402', 'NDC:00143125601', 'NDC:45802064287', 'NDC:00006095231', 'NDC:00087607111', 'NDC:00113019402']
    + ['NDC:00247099630', 'Finger_Glucose_Test_Strip_Icd_25000', 'lancets', 'glucometer', 'Alcohol_Prep_Swab_1box_For_Diabetes_Care']
  + doc(last 150 chars):
['V30.00', '751.4', '745.11', '747.21', '745.69', '746.83', '746.9', '746.02', '745.11', '786.09', '770.8', '372.30', '276.7', 'unknown', '747.3', '745.69', '285.9', '799.9', '799.9', '550.92', '745.11', '420.99', '997.1', '997.3', '747.3', '745.69', '415.1', 'E879.8', '789.00', '550.90', '550.91', '745.11', '745.2']

  + vdoc
    + ['V30.00', '751.4', '745.11', '747.21', '745.69', '746.83']
    + ['746.9', '746.02', '745.11', '786.09', '770.8', '372.30', '276.7', 'unknown', '747.3', '745.69', '285.9']
    + ['799.9']
    + ['799.9']
    + ['550.92']
    + ['745.11', '420.99', '997.1', '997.3', '747.3', '745.69', '415.1', 'E879.8']
    + ['789.00', '550.90']
    + ['550.91']
    + ['745.11']
    + ['745.2']
  + doc(last 150 chars):
['780.52', '782.1', 'MULTUM:450', 'NDC:00093224001', '401.9', '272.4', 'MULTUM:3826', 'MULTUM:450', 'NDC:00067014182', 'NDC:00071015623', 'NDC:00054010220', 'V76.12', '793.80', '401.9', '272.4', 'Knee_Brace', 'MULTUM:450', 'NDC:00067014182', '786.2', '401.9', '272.4', 'NDC:00067014182', 'NDC:00245002414', 'MULTUM:450', 'MULTUM:3826', 'NDC:00071015623', 'NDC:00247028100', 'NDC:21695079100', '401.9', '272.4', 'NDC:00054010220', 'MULTUM:450', 'NDC:00071015623', 'NDC:00247212930', '401.9', '272.4', 'NDC:00054010220', 'NDC:50580022651', 'NDC:00071015623', 'V76.51', '211.3', '569.89', '401.9', '709.9', 'Tegederm_2x2', 'Compression_Stockings_20_To_30mmhg', 'NDC:00113040378', 'NDC:00247132820', '709.9', '401.9', '272.4', 'NDC:00054010220', 'NDC:00071015623', 'NDC:00247231330', '401.9', '272.4', 'NDC:00067014182', 'NDC:00071015623', 'NDC:00113040378', 'NDC:00182125989', 'V76.12', '401.9', '272.4', 'NDC:00054010220', 'NDC:21695079100', 'NDC:00182125989', 'V04.81', '692.9', '401.9', '272.4', 'NDC:00071015623', 'NDC:00064501015', '707.20', '459.81', '958.2', '707.13', '454.2', 'NDC:00004631301', '707.00', 'NDC:00113040378', 'V12.72', '707.00', '401.9', '459.81', '272.4', '707.13', 'MED:62624', 'MED:60926', 'MED:62934', 'MED:72702', 'MED:126292', 'NDC:00054010220', 'V12.72', '401.9', '459.81', '272.4', '707.13', 'MED:63129', 'MED:61124', 'MED:61939', 'MED:60924', 'MED:60826', 'MED:62439', 'MED:122364', 'MED:72702', 'MED:62624', 'MED:126292', 'MED:61697', 'MED:60926', 'MED:72702', 'MED:133119', 'MED:78304', 'Ancillary_Supplies', 'Fu_With_Dr_Morrissey_Regarding_Removal_Of_Piccl', 'MED:78304', '5_Cc_Ns_Pr_And_Post_Infusion', 'NDC:00069031220', 'NDC:00004631301', '3in1_Commode', 'Rolling_Walker', 'V06.1', '709.9', '401.9', '272.4', 'NDC:00182125989', 'NDC:00064501015', 'V76.12', '401.9', '272.4', 'NDC:00054010220', 'NDC:00113040378', 'NDC:00071015623', 'NDC:00023182212', 'NDC:00182125989', '401.9', '272.4', 'NDC:00054010220', 'NDC:00182125989', '796.2', 'R03.0', 'R05', '786.2', 'NDC:00067950601', 'NDC:00574200802', 'NDC:00113040378', 'NDC:00071015623', 'G47.00', '780.52', '783.1', 'R63.5']

  + vdoc
    + ['V12.72', '401.9', '459.81', '272.4', '707.13', 'MED:63129', 'MED:61124', 'MED:61939', 'MED:60924', 'MED:60826', 'MED:62439', 'MED:122364', 'MED:72702', 'MED:62624', 'MED:126292']
    + ['MED:61697', 'MED:60926', 'MED:72702', 'MED:133119']
    + ['MED:78304']
    + ['Ancillary_Supplies', 'Fu_With_Dr_Morrissey_Regarding_Removal_Of_Piccl', 'MED:78304', '5_Cc_Ns_Pr_And_Post_Infusion', 'NDC:00069031220', 'NDC:00004631301']
    + ['3in1_Commode', 'Rolling_Walker']
    + ['V06.1', '709.9', '401.9', '272.4', 'NDC:00182125989', 'NDC:00064501015']
    + ['V76.12', '401.9', '272.4', 'NDC:00054010220', 'NDC:00113040378', 'NDC:00071015623', 'NDC:00023182212', 'NDC:00182125989']
    + ['401.9', '272.4', 'NDC:00054010220', 'NDC:00182125989']
    + ['796.2', 'R03.0', 'R05', '786.2', 'NDC:00067950601', 'NDC:00574200802', 'NDC:00113040378', 'NDC:00071015623']
    + ['G47.00', '780.52', '783.1', 'R63.5']
  + doc(last 150 chars):
['NDC:00143126801', 'NDC:00069267066', '585.6', '588.0', '285.21', 'V56.0', '585.6', '588.0', '285.21', 'V56.0', '585.6', '588.0', '285.21', 'V56.0', 'MED:87669', '585.6', '588.0', '285.21', 'V56.0', '585.6', '588.0', '285.21', 'V56.0', '585.6', '588.0', '285.21', 'V56.0', 'MED:87669', 'V56.0', '585.6', '588.0', '285.21', 'MED:104479', 'V56.0', '585.6', '588.0', '285.21', 'V56.0', '585.6', '588.0', '285.21', 'NDC:00185028401', 'V56.0', '585.6', '588.0', '285.21', 'V56.0', '585.6', '588.0', '285.21', 'V56.0', '585.6', '588.0', '285.21', 'V56.0', '585.6', '588.0', '285.21', 'MED:62511', 'V56.0', '585.6', '588.0', '285.21', 'V56.0', '585.6', '588.0', '285.21', 'V56.0', '585.6', '588.0', '285.21', 'V56.0', '585.6', '588.0', '285.21', 'NDC:00069267066', 'NDC:00074380811', 'NDC:00185028401', 'NDC:00143126801', 'V56.0', '585.6', '588.0', '285.21', 'MED:87669', '789.00', '784.0', '585.6', '585.6', '786.05', '241.0', '585.6', 'MED:61939', 'V68.1', '401.9', 'MED:61853', 'MED:63435', '401.1', '784.2', '784.2', '784.2', '401.9', '367.0', '427.31', '785.1', 'V45.11', '142.1', '527.9', '585.6', '784.2', '530.81', '389.9', '272.4', '403.91', '274.9', 'NDC:00054055125', 'NDC:00173039400', '142.1', '142.1', '142.1', '142.1', '142.1', '142.1', '142.1', '142.1', '142.1', '142.1', '142.1', '142.1', '142.1', '142.1', '142.1', '142.1', '142.1', '142.1', '142.1', '142.1', '142.1', '142.1', '142.1', '142.1', '142.1', '142.1', '142.1', '142.1', '142.1', '142.1', '142.1', '142.1', 'C08.0', 'MED:61736']

  + vdoc
    + ['142.1']
    + ['142.1']
    + ['142.1']
    + ['142.1']
    + ['142.1']
    + ['142.1']
    + ['142.1']
    + ['142.1']
    + ['C08.0']
    + ['MED:61736']
  + doc(last 150 chars):
['V30.00', '779.8', '746.85', '745.0', '786.50', '285.9', '747.3', '799.9', '745.0', '719.40', '518.89', '745.0', '746.02', '745.0', '746.02', '746.02', '381.3', '478.1', '746.02', '747.3', '424.3', '511.9', '746.89', '746.02', '997.3', '745.4', '747.3', '263.1', '745.0', 'E878.2', '512.1', 'MED:67465', 'MED:63182', 'MED:61253', 'MED:67463', 'MED:63060', 'MED:62899', 'MED:62876', 'MED:61836', 'MED:61915', 'MED:61607', 'MED:63182', 'MED:61253', 'MED:67463', 'MED:62784', 'MED:60826', 'MED:67463', 'MED:66091', 'MED:61864', 'MED:61870', 'MED:61836', 'MED:63122', 'MED:60522', 'MED:63141', 'MED:63152', 'MED:66091', 'MED:69488', '746.02', '745.0', '745.0', '746.4', '747.3', 'MED:61619', '416.8', '416.8', '414.00', '786.00', '745.0', 'V21.2', '786.50', '745.10', '745.0', 'V15.1', '756.19', '737.34', '424.1', '287.5', '285.1', '754.82', '745.0', 'MED:89129', 'MED:133116', 'MED:62934', 'MED:61253', 'MED:66016', 'MED:62251', 'MED:62402', 'MED:62062', 'MED:62899', 'MED:86686', 'MED:62751', 'MED:62790', 'MED:62798', 'MED:60826', 'MED:61216', 'MED:61293', 'MED:62444', 'MED:60575', 'MED:60486', 'MED:103931', 'MED:73183', 'MED:67465', 'MED:61253', 'MED:62062', 'MED:63185', 'MED:63543', 'MED:94340', 'MED:61619', 'MED:62286', 'MED:62649', 'MED:62439', 'MED:66016', 'MED:61634', 'MED:60830', 'MED:62876', 'MED:81528', 'MED:60575', 'MED:62934', 'MED:62094', 'MED:103931', 'MED:62934', 'MED:63185', 'MED:102484', 'MED:94340', 'MED:63122', 'MED:61634', 'MED:62094', 'MED:94340', 'MED:62439', 'MED:62685', 'MED:61736', 'MED:62094', 'NDC:00182181089', 'NDC:00378611201', 'NDC:00067014468', 'NDC:00173034414', 'NDC:00054429725', '746.6', '745.10', '745.0', '745.0', '745.0', '745.0', 'Q25.6']

  + vdoc
    + ['MED:62934', 'MED:62094']
    + ['MED:103931', 'MED:62934', 'MED:63185', 'MED:102484', 'MED:94340', 'MED:63122', 'MED:61634', 'MED:62094']
    + ['MED:94340', 'MED:62439']
    + ['MED:62685', 'MED:61736', 'MED:62094', 'NDC:00182181089', 'NDC:00378611201', 'NDC:00067014468', 'NDC:00173034414', 'NDC:00054429725']
    + ['746.6', '745.10']
    + ['745.0']
    + ['745.0']
    + ['745.0']
    + ['745.0']
    + ['Q25.6']
  + doc(last 150 chars):
['565.1', 'V75.8', '129', '401.9', '401.9', '272.4', '288.3', '401.9', '719.45', '401.9', '272.4', '288.3', '401.9', '272.4', '288.3', '401.9', '272.4', '790.21', '455.6', '401.9', '272.4', 'MED:77862', '565.1', 'V67.09', '565.1', '401.9', '272.4', '788.61', '785.6', '288.3', '783.21', '401.9', '272.4', '288.3', '797', '414.00', '401.9', '272.4', '785.6', '414.00', '401.9', '272.4', '288.3', '414.00', '401.9', '272.4', '437.3', '786.59', '413.9', '787.03', '414.00', '401.9', '272.4', '288.3', '437.3', 'V12.72', '211.3', '455.0', 'E849.8', 'E888.9', 'V06.5', '959.7', 'E849.8', 'E885.9', '719.46', '959.7', 'MED:60926', '844.9', '845.00', 'MULTUM:2071', 'E849.8', 'E888.9', '719.16', '924.11', '437.3', 'V45.82', '682.4', '600.00', '401.9', '272.4', '414.01', 'MED:61939', 'MED:62148', 'MED:62453', 'MED:62008', 'MED:62696', 'MED:62439', 'MED:61319', 'MED:63089', 'NDC:00029608612', 'V12.72', 'V76.51', 'E849.8', '936', 'E915', '780.4', 'V12.59', '787.91', '401.9', 'MED:62934', '716.90', '733.00', '788.20', 'V45.82', '682.4', '244.9', '600.00', '401.9', '272.4', '414.01', 'MED:60588', 'MED:61078', 'MED:62008', 'MED:60946', 'MED:61124', 'MED:60582', 'MED:62453', 'MED:62072', 'MED:61939', 'MED:63114', 'MED:62624', 'MED:63518', 'MED:63089', 'MED:158045', 'NDC:00093735501', 'NDC:00093078701', 'MULTUM:1101', 'NDC:00378209601', 'NDC:62107002726', 'NDC:00074455211', 'NDC:65597011430', 'NDC:00071015523', 'MED:60926', 'MED:63089', 'NDC:00093227534', '787.91', '789.00', '401.9', '272.4', 'MED:62934', 'NDC:52083026260']

  + vdoc
    + ['V45.82', '682.4', '600.00', '401.9', '272.4', '414.01', 'MED:61939', 'MED:62148', 'MED:62453']
    + ['MED:62008', 'MED:62696', 'MED:62439', 'MED:61319', 'MED:63089', 'NDC:00029608612']
    + ['V12.72', 'V76.51', 'E849.8', '936', 'E915']
    + ['780.4', 'V12.59', '787.91', '401.9', 'MED:62934']
    + ['716.90', '733.00']
    + ['788.20']
    + ['V45.82', '682.4', '244.9', '600.00', '401.9', '272.4', '414.01', 'MED:60588', 'MED:61078', 'MED:62008', 'MED:60946', 'MED:61124', 'MED:60582', 'MED:62453', 'MED:62072', 'MED:61939', 'MED:63114', 'MED:62624', 'MED:63518', 'MED:63089', 'MED:158045', 'NDC:00093735501', 'NDC:00093078701', 'MULTUM:1101', 'NDC:00378209601', 'NDC:62107002726', 'NDC:00074455211', 'NDC:65597011430', 'NDC:00071015523']
    + ['MED:60926', 'MED:63089']
    + ['NDC:00093227534']
    + ['787.91', '789.00', '401.9', '272.4', 'MED:62934', 'NDC:52083026260']
  + doc(last 150 chars):
['585', '585', '571.40', '571.5', '070.54', '585', '250.41', '250.43', '250.53', '362.01', '362.02', '582.81', 'V42.0', 'V42.0', 'V42.0', 'V42.0', 'V42.0', 'V42.0', 'V42.0', 'V58.69', 'V58.69', 'V42.0', 'V42.0', 'V58.69', 'V42.0', '410.0', 'V42.0', 'V58.69', 'V58.69', 'V42.0', 'V58.69', 'V42.0', 'V42.0', 'V42.0', 'V42.0', 'V42.1', 'V42.0', 'V58.69', 'V42.0', 'V42.0', 'V42.0', 'V42.0', 'V42.0', 'V42.0', 'V42.0', 'V42.0', 'V42.0', 'V42.0', 'V42.0', 'V42.0', 'V42.0', 'V42.0', 'V42.0', 'MED:62511', 'V42.0', 'V42.0', 'V42.0', 'V42.0', 'V58.69', 'V42.0', 'V58.69', 'V42.0', 'V58.69', 'V42.0', 'V58.69', 'V42.0', 'V58.69', 'V42.0', 'V58.69', 'V42.0', 'V58.69', 'V42.0', 'V58.69', 'V42.0', 'V04.81', 'V58.69', 'MED:62511', 'V42.0', 'V58.69', 'V42.0', 'V58.69', 'V42.0', 'V58.69', 'V42.0', 'V58.69', 'V58.69', 'V42.0', 'V42.0', 'V04.81', 'V58.69', 'MED:62511', 'V42.0', 'V58.69', 'V42.0', 'V58.69', 'V42.0', 'V58.69', 'V42.0', 'V58.69', '250.93', 'V04.81', 'V42.0', 'V58.69', '070.54', 'MED:62511', 'V42.0', 'V58.69']

  + vdoc
    + ['V42.0', 'V04.81', 'V58.69']
    + ['MED:62511']
    + ['V42.0', 'V58.69']
    + ['V42.0', 'V58.69']
    + ['V42.0', 'V58.69']
    + ['V42.0', 'V58.69']
    + ['250.93']
    + ['V04.81', 'V42.0', 'V58.69', '070.54']
    + ['MED:62511']
    + ['V42.0', 'V58.69']
  + doc(last 150 chars):
['NDC:00469061711', 'MED:101652', 'NDC:00469061711', 'V42.0', 'V58.69', '996.81', '585.4', '285.21', '788.41', 'MED:87670', 'V58.69', '996.81', 'V42.0', '585.3', '285.21', 'V42.0', 'V58.69', '996.81', '585.4', '285.21', '788.41', 'MED:87670', 'V42.0', '599.0', '585.3', '285.21', 'MED:87670', 'V42.0', 'V58.69', '788.41', '585.3', '285.21', 'V42.0', '585.3', '285.21', 'V42.0', 'V58.69', '788.41', 'V42.0', 'V58.69', 'V42.0', 'V04.81', '585.5', 'MED:158045', 'V42.0', 'V58.69', '996.81', 'V42.0', '272.4', '788.41', '780.60', 'E878.0', '584.9', '590.80', '996.81', '427.89', '276.7', '799.02', '514', '041.49', '289.81', 'MED:62439', 'MED:62934', 'MED:72702', 'MED:126292', 'MED:61471', 'MED:101652', 'MED:122364', 'MED:62439', 'MED:95599', 'MED:63306', 'MED:72702', 'MED:126292', 'MED:60826', 'MED:61471', 'MED:61504', 'MED:101652', 'MED:61471', 'MED:133119', 'MED:62879', 'MED:62685', 'MED:61471', 'MED:62934', 'MED:62934', 'MED:63306', 'MED:61471', 'MED:61460', 'MED:61460', 'MED:62439', 'MED:95599', 'MED:62934', 'MED:133119', 'MED:63306', 'MED:63523', 'MED:68349', 'MED:60826', 'MED:61471', 'MED:61504', 'MED:94350', 'MED:101652', 'MED:62879', 'MED:60972', 'MED:65966', 'MED:61460', 'MED:60972', 'MED:62439', 'MULTUM:3819', 'NDC:68308014501', 'MULTUM:5326', 'MULTUM:3270', 'Pulmonary_Rehab', 'Portable_Oxygen_Concentrator', 'V42.0', 'V58.69', '585.6', '786.05', 'V70.0', '786.05', 'V42.0', '585.6', '416.8', 'V13.02', 'V42.0', '787.01', '599.0', '585.6', 'MED:61253', 'MED:63306', 'MED:61237', 'MED:95599', 'MED:60826', 'MED:61471', 'MED:101652', 'NDC:00054055125', 'V13.09', 'V42.0', '416.8', '416.0', 'V42.0', 'V58.69', '585.6', '786.50', 'V42.0', 'V58.69', '585.6', 'Z94.0', 'Z23', 'I27.2', 'E55.9', 'N18.5']

  + vdoc
    + ['V42.0', 'V58.69', '585.6']
    + ['786.05']
    + ['V70.0', '786.05']
    + ['V42.0', '585.6', '416.8']
    + ['V13.02', 'V42.0', '787.01', '599.0', '585.6', 'MED:61253', 'MED:63306', 'MED:61237', 'MED:95599', 'MED:60826', 'MED:61471', 'MED:101652', 'NDC:00054055125']
    + ['V13.09', 'V42.0', '416.8', '416.0']
    + ['V42.0', 'V58.69', '585.6']
    + ['786.50']
    + ['V42.0', 'V58.69', '585.6']
    + ['Z94.0', 'Z23', 'I27.2', 'E55.9', 'N18.5']
  + doc(last 150 chars):
['996.81', 'V42.0', 'V58.69', '996.81', 'V42.0', 'MED:72705', 'MED:62936', 'MED:62439', 'MED:81254', '996.81', 'V42.0', 'V58.69', '996.81', '288.9', 'MED:60733', 'MED:72705', 'MED:62936', 'MED:62439', '288.9', '288.00', 'V42.0', 'MED:60733', '288.9', '288.00', 'V42.0', 'MED:60733', '996.81', 'V42.0', 'V58.69', '996.81', 'V42.0', 'V58.69', 'MED:60733', 'MED:72705', 'MED:62936', 'MED:62439', '996.81', 'V42.0', 'V58.69', '996.81', 'V42.0', 'MED:62439', 'MED:72705', 'MED:62936', '996.81', 'V42.0', 'V58.69', '996.81', 'V42.0', 'MED:62439', 'MED:62936', 'MED:72705', '996.81', 'V42.0', '996.81', 'V42.0', 'MED:62439', 'MED:72705', 'MED:62936', '996.81', 'V42.0', 'V58.69', 'MED:62439', 'MED:72705', 'MED:62936', '996.81', 'V42.0', 'V58.69', '996.81', 'V42.0', 'MED:62439', 'MED:62936', 'MED:72705', '996.81', 'V42.0', 'MED:62439', 'MED:61814', 'MED:72705', '996.81', 'V42.0', 'V58.69', '996.81', 'V42.0', 'MED:62439', 'MED:61814', 'MED:72705', '996.81', 'V42.0', 'MED:62439', 'MED:72705', 'MED:62936', 'V42.0', 'V58.69', 'V42.0', '996.81', 'MED:72705', 'V42.0', '996.81', 'V42.0', '996.81', 'MED:62439', 'MED:72705', 'MED:62936', 'V42.0', '996.81', 'MED:62439', 'MED:62936', 'MED:72705', 'V42.0', 'V58.69', 'V42.0', '996.81', 'MED:72705', 'MED:62936', 'MED:62439', 'V42.0', '996.81', 'MED:72705', 'MED:62936', 'MED:62439', 'V42.0', 'V42.0', '996.81', 'MED:62439', 'MED:72705', 'MED:62936', 'V42.0', '996.81', 'MED:62439', 'MED:72705', 'MED:62936', 'V42.0', '996.81', 'MED:72705', 'MED:62936', 'V42.0', 'V58.69', 'unknown', 'Z94.0', 'MED:72705', 'MED:62936', 'MED:167651', 'Z94.0', 'Z79.899', 'Z23', 'unknown', 'Z94.0', 'MED:72705', 'MED:62936', 'MED:167651']

  + vdoc
    + ['V42.0', '996.81', 'MED:72705', 'MED:62936', 'MED:62439']
    + ['V42.0', '996.81', 'MED:72705', 'MED:62936', 'MED:62439']
    + ['V42.0']
    + ['V42.0', '996.81', 'MED:62439', 'MED:72705', 'MED:62936']
    + ['V42.0', '996.81', 'MED:62439', 'MED:72705', 'MED:62936']
    + ['V42.0', '996.81', 'MED:72705', 'MED:62936']
    + ['V42.0', 'V58.69']
    + ['unknown', 'Z94.0', 'MED:72705', 'MED:62936', 'MED:167651']
    + ['Z94.0', 'Z79.899', 'Z23']
    + ['unknown', 'Z94.0', 'MED:72705', 'MED:62936', 'MED:167651']
  + doc(last 150 chars):
['V42.0', 'V58.69', '996.81', 'V42.0', 'V58.69', '996.81', 'V42.0', 'V58.69', '996.81', 'V42.0', 'V58.69', '996.81', 'V42.0', 'V58.69', '996.81', 'V42.0', 'V58.69', '996.81', 'V42.0', 'V58.69', '996.81', 'V42.0', '288.00', 'MED:60733', '996.81', '288.60', '996.81', '288.60', 'MED:60733', 'V42.0', 'V58.69', '996.81', 'V42.0', 'V58.69', '996.81', 'V42.0', 'V58.69', '996.81', 'V42.0', 'V58.69', '996.81', 'V42.0', 'V58.69', '996.81', 'V42.0', '285.21', 'V42.0', 'V58.69', '996.81', 'V42.0', 'V58.69', '996.81', 'V42.0', 'V42.0', 'V58.69', '996.81', '585.9', 'V42.0', 'V58.69', '996.81', '268.9', 'V42.0', 'V58.69', '996.81', 'V42.0', 'V42.0', 'V58.69', 'V42.0', 'V58.69', '996.81', '996.81', 'V42.0', 'V58.69', '996.81', 'V42.0', 'V58.69', '996.81', 'V42.0', 'V58.69', 'V04.81', 'MED:133079', 'MED:62439', 'V58.69', 'V42.0', 'V58.69', 'V42.0', 'V70.0', 'V42.0', 'V58.69', 'V58.69', 'V42.0', 'V42.0', '996.81', 'V42.0', 'V58.69', '996.81', 'V42.0', '996.81', 'V42.0', 'MED:63518', 'V42.0', '996.81', 'MED:63518', 'V58.69', 'V42.0', 'V42.0', '996.81', 'V42.0', 'V58.69', 'V42.0', 'V58.69', 'V42.0', 'V42.0', 'V58.69', 'V42.0', 'V42.0', 'V58.69', 'V70.0', 'V42.0', 'V58.69', 'V42.0', 'V58.69', 'Z94.0', 'Z94.0', 'Z79.899', 'M79.604', 'Z94.0', 'unknown', 'Z94.0', 'unknown', 'Z94.0', 'MED:60481', 'unknown', 'Z94.0', 'MED:60481', 'unknown', 'Z94.0', 'MED:60481', 'Z94.0', 'Z94.0', 'Z94.0', 'Z94.0', 'Z79.899', 'Z94.0', 'Z79.899', 'Z94.0', 'Z94.0', 'N39.0', 'N18.9', 'MED:63518']

  + vdoc
    + ['unknown', 'Z94.0', 'MED:60481']
    + ['unknown', 'Z94.0', 'MED:60481']
    + ['Z94.0']
    + ['Z94.0']
    + ['Z94.0']
    + ['Z94.0', 'Z79.899']
    + ['Z94.0', 'Z79.899']
    + ['Z94.0']
    + ['Z94.0', 'N39.0', 'N18.9']
    + ['MED:63518']
  + doc(last 150 chars):
['MED:61471', 'V42.0', 'V58.69', 'V42.0', 'V42.0', 'V58.69', 'V58.69', 'V42.0', '585.5', '285.21', 'MED:87670', 'V42.0', 'V58.69', '996.81', 'V42.0', 'V58.69', '585.5', '285.21', 'MED:87670', 'V42.0', 'V58.69', '996.81', '585.5', '285.21', 'V42.0', '585.5', '285.21', 'MED:87670', 'V42.0', 'V58.69', 'V42.0', '585.4', '285.21', 'MED:87670', 'V42.0', '996.81', 'MED:60481', 'V42.0', '996.81', 'MED:60481', 'V42.0', '996.81', 'MED:60481', 'V42.0', '996.81', '585.4', '285.21', 'MED:60481', 'MED:87670', 'V42.0', 'V58.69', 'V42.0', 'V42.0', 'V58.69', '585.4', '285.21', 'V42.0', '585.4', '285.21', 'MED:87670', 'V42.0', 'V58.69', '585.4', '285.21', 'MED:87670', '585.3', '285.21', 'V42.0', 'V58.69', '280.9', '585.4', '285.21', 'V42.0', 'V58.69', '996.83', 'V42.0', '585.4', '285.21', 'NDC:00078038566', 'NDC:00093050793', 'MED:87670', 'V42.0', '585.4', '285.21', 'MED:87670', 'V56.2', 'V42.0', '401.9', '272.4', 'MULTUM:471', 'NDC:00223172101', 'MULTUM:3270', 'MULTUM:8354', 'NDC:49999058730', 'MED:94350', 'MED:60826', 'MED:60926', 'V42.0', 'V58.69', 'V70.0', '996.81', '585.4', 'V42.0', '996.81', 'MED:60481', 'V42.0', '996.81', '996.81', 'MED:60481', '996.81', 'MED:60481', 'V42.0', 'V58.69', 'V42.0', 'V58.69', '585.4', '285.21', 'MED:87669', 'V42.0', 'V58.69', '585.4', '285.21', 'MED:87669', 'V42.0', 'V58.69', '585.4', '285.21', 'MED:87669', 'V42.0', 'V58.69', '996.81', '585.4', '285.21', 'MED:87669', 'V42.0', 'V58.69', 'Z94.0', 'Z79.899', 'Z94.0', 'Z23', 'Z79.899', 'Z94.0', 'Z79.899', 'Z94.0', 'Z79.899', 'Z94.0', 'Z79.899', 'Z94.0', 'Z79.899', 'unknown']

  + vdoc
    + ['MED:87669']
    + ['V42.0', 'V58.69', '996.81', '585.4', '285.21']
    + ['MED:87669']
    + ['V42.0', 'V58.69']
    + ['Z94.0', 'Z79.899']
    + ['Z94.0', 'Z23', 'Z79.899']
    + ['Z94.0', 'Z79.899']
    + ['Z94.0', 'Z79.899']
    + ['Z94.0', 'Z79.899']
    + ['Z94.0', 'Z79.899', 'unknown']
  + doc(last 150 chars):
['MED:60762', 'MED:61471', 'MED:60481', 'MED:60553', 'MED:61471', 'NDC:00469061711', 'MULTUM:8484', 'NDC:00069154041', 'MED:70402', 'MED:63156', 'MED:60798', 'V42.0', 'V58.69', '996.89', 'V42.0', 'V58.69', '996.81', 'V42.0', 'V58.69', '996.81', 'V42.0', 'V58.69', '996.81', 'V42.0', 'V58.69', '996.81', 'V42.0', 'V42.0', 'V58.69', '996.81', 'V42.0', 'V58.69', '996.81', 'V42.0', 'V58.69', '996.81', 'V42.0', '996.81', 'MED:63518', 'V42.0', 'V58.69', '996.81', 'V42.0', 'E878.0', '996.81', 'MED:63518', 'V42.0', 'V58.69', '996.81', '586', 'V42.0', '996.81', 'V42.0', '996.81', 'MED:63518', 'V42.0', '996.81', 'MED:63518', 'V42.0', '996.81', 'MED:63518', 'V42.0', 'V58.69', '996.81', 'V42.0', '996.81', 'MED:63518', 'V42.0', '996.81', 'MED:63518', 'V42.0', '996.81', 'MED:63518', 'V42.0', '996.81', 'V42.0', '996.81', 'MED:63518', 'V42.0', '996.81', 'MED:63518', 'V42.0', 'V42.0', '996.81', 'MED:63518', 'MED:61579', 'MED:61579', 'V42.0', '996.81', '790.95', 'E878.0', 'V42.0', '996.81', 'MED:63518', 'MED:62852', 'V42.0', '996.81', 'MED:72705', 'MED:62936', 'MED:63055', 'MED:62439', 'MED:62679', 'V42.0', '996.81', 'V42.0', 'V58.69', '996.81', 'V42.0', '996.81', 'MED:63518', 'V42.0', '996.81', 'MED:63518', 'V42.0', '996.81', 'MED:63518', 'V42.0', '996.81', 'MED:63518', 'V42.0', '996.81', 'MED:63518', 'V42.0', 'V58.69', 'V04.81', 'MED:158045', 'V42.0', '996.81', 'MED:63518', 'V42.0', '996.81', 'MED:63518', 'V58.69', 'V42.0', 'V42.0', '996.81', 'V42.0', '996.81', 'V42.0', 'V58.69', '996.81', '996.81', 'V42.0', 'V42.0', 'V58.69', 'unknown', 'Z94.0', 'N18.6', 'Z94.0', 'Z79.899']

  + vdoc
    + ['V42.0', '996.81', 'MED:63518']
    + ['V58.69', 'V42.0']
    + ['V42.0', '996.81']
    + ['V42.0', '996.81']
    + ['V42.0', 'V58.69', '996.81']
    + ['996.81']
    + ['V42.0']
    + ['V42.0', 'V58.69']
    + ['unknown', 'Z94.0', 'N18.6']
    + ['Z94.0', 'Z79.899']
  + avgL: 3.401748, max n_tokens_in_visit: 71, min: 1, std: 4.775765
  + avgV: 90.685169, max n_visits_in_doc:   1082, min: 1, std: 114.666660
visitToDocment> size(V):2360 -> size(Dv):214017 (E[nVperDoc]=90.685169)
> D:
[['813.42', '813.42', '813.42', '813.42', '813.42', '813.42', '813.42', '813.42', '813.42', '813.42', '813.42', '813.42', '813.42', '813.42', '813.42', '813.42', '813.42', '813.42', '813.42', '813.42', '813.42', '813.42', '813.42', '813.42', '813.42', '813.42', '813.42', '813.42', '813.42', '813.42', '813.42', '813.42', '813.42', '813.42', '813.42', '813.42', '813.42', '813.42', '813.42', '813.42', '813.42', '813.42', '813.42', '813.42', '813.42', '813.42', '813.42', '813.42', '813.42', '813.42', '813.42', '813.42', '813.42', '813.42', '813.42', '813.42', '813.42', '813.42', '813.42', '813.42', '813.42', '813.42', '813.42', '813.42', '813.42', '813.42', '813.42', '813.42', '813.42', '813.42', '813.42'], ['813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41'], ['813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41'], ['813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41'], ['813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41'], ['813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41'], ['813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41'], ['813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41'], ['813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41'], ['813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41']]

    + computing document vectors nD:2360 => nDEff: 214017 ...
makeTSetVisit> model dir: /Users/pleiades/Documents/work/tpheno/seqmaker/data/CKD/model
getDocVec> method: pv-dm2, model ID: smallCKD, segment_by_visit? True, load precomputed? True
getDocVecPV> prior to labelDocuments, already labeled? False, example: ['813.42', '813.42', '813.42', '813.42', '813.42', '813.42', '813.42', '813.42', '813.42', '813.42', '813.42', '813.42', '813.42', '813.42', '813.42', '813.42', '813.42', '813.42', '813.42', '813.42', '813.42', '813.42', '813.42', '813.42', '813.42', '813.42', '813.42', '813.42', '813.42', '813.42', '813.42', '813.42', '813.42', '813.42', '813.42', '813.42', '813.42', '813.42', '813.42', '813.42', '813.42', '813.42', '813.42', '813.42', '813.42', '813.42', '813.42', '813.42', '813.42', '813.42', '813.42', '813.42', '813.42', '813.42', '813.42', '813.42', '813.42', '813.42', '813.42', '813.42', '813.42', '813.42', '813.42', '813.42', '813.42', '813.42', '813.42', '813.42', '813.42', '813.42', '813.42'], type: <type 'list'>
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
Doc2Vec Parameters
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
  + current d2v method: pv-dm2
  + number of features: 50
  + window size: 10
  + ignore tokens with total freq less than 2
  + number of epochs: 20
  + training method: negative sampling  + number of negative samples: 15  + use concatenation of context vectors? False

getDocVecPV> total: 214017
getDocVecPV> Params summary of d2v models (n_workers: 18, n_iter: 20) ...
  + n_features: 50, window: 10
  + negative sample? 15
  + min count: 2

D2V.load> Info: model path:
/Users/pleiades/Documents/work/tpheno/seqmaker/data/CKD/model/Pf50w10i20-smallCKD.dm

D2V.load> Info: model path:
/Users/pleiades/Documents/work/tpheno/seqmaker/data/CKD/model/Pf50w10i20-smallCKD.dbow

check> input prior to consolidateVisits dim(X): (214017, 100), len(visitDocIDs): 214017
(check) contatenated vector dim: 5000 | lastN=50, indv fDim=100
(check) visit idx:
[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2]
(check) scope idx:
[0, 14, 97, 110, 112, 338, 429, 459, 503, 529, 606, 645, 712, 741, 951, 1075, 1198, 1212, 1372, 1508, 1715, 1794, 1844, 2002, 2011, 2389, 2561, 2958, 2986, 3087, 3103, 3162, 3459, 3530, 3619, 3625, 3778, 3841, 3990, 4012, 4070, 4123, 4223, 4226, 4665, 4813, 4932, 5178, 5549, 5676, 5688, 5716, 5805, 5921, 6438, 6445, 6463, 6562, 6641, 6751, 6825, 7009, 7053, 7074, 7079, 7175, 7245, 7326, 7590, 8072, 8132, 8135, 8147, 8186, 8241, 8587, 8595, 8709, 8737, 8831, 8847, 8968, 9000, 9059, 9167, 10166, 10315, 10501, 10553, 10577, 11085, 11192, 11221, 11887, 11969, 12067, 12116, 12120, 12461, 12569]

verify> mean dim: 9068.516949, median: 4900.000000, std: 11466.665963
(check) flatterned X, dim(Xp): (2360,)
tsHandler> save document vectors (cv=0), sparse? False ...
  + params: dim(X):(2360, 5000), index:0, n(docIDs):2360, d2v:pv-dm2, cohort:CKD, ctype:regular, shuffle? False, meta: smallCKD
tsHandler> training set dir: /Users/pleiades/Documents/work/tpheno/seqmaker/data/CKD/combined
prepareTrainingSet> n_classes: 11
TSet> Params: cohort: CKD, file id: regular-pv-dm2-smallCKD
TSet.saveDataFrame> tset params (cohort:CKD d2v:pv-dm2, ctype:regular, suffix=smallCKD)
TSet.saveDataFrame> Saving (cohort=CKD, d2v=pv-dm2, suffix=smallCKD) dataset to:
/Users/pleiades/Documents/work/tpheno/seqmaker/data/CKD/combined/tset-n0-IDregular-pv-dm2-smallCKD-GCKD.csv

status> Model computation complete (@nTrial=0)
info> each doc is repr by the last 50 visits
TSet> Params: cohort: CKD, file id: regular-pv-dm2-smallCKD
TSet.load> loading training set (cohort=CKD, suffix=smallCKD) from:
/Users/pleiades/Documents/work/tpheno/seqmaker/data/CKD/combined/tset-n0-IDregular-pv-dm2-smallCKD-GCKD.csv

tsHandler.profile> Found 11 unique labels ...
  + label=CKD Stage 3a => N=215
  + label=Unknown => N=411
  + label=CKD Stage 3b => N=135
  + label=ESRD on dialysis => N=41
  + label=CKD G1-control => N=87
  + label=CKD G1A1-control => N=108
  + label=CKD Stage 5 => N=31
  + label=CKD Stage 4 => N=56
  + label=ESRD after transplant => N=686
  + label=CKD Stage 2 => N=528
  + label=CKD Stage 1 => N=62
loadTSetCombined> Modifying training data ...
> Prior to re-labeling ...
tsHandler.profile> Found 11 unique labels ...
  + label=CKD Stage 3a => N=215
  + label=Unknown => N=411
  + label=CKD Stage 3b => N=135
  + label=ESRD on dialysis => N=41
  + label=CKD G1-control => N=87
  + label=CKD G1A1-control => N=108
  + label=CKD Stage 5 => N=31
  + label=CKD Stage 4 => N=56
  + label=ESRD after transplant => N=686
  + label=CKD Stage 2 => N=528
  + label=CKD Stage 1 => N=62
  + (before) unique labels:
['CKD Stage 3a' 'CKD Stage 2' 'Unknown' 'CKD Stage 3b' 'CKD Stage 4'
 'ESRD after transplant' 'ESRD on dialysis' 'CKD G1A1-control'
 'CKD Stage 1' 'CKD G1-control' 'CKD Stage 5']

  + CKD Stage 5 <- ['ESRD after transplant', 'ESRD on dialysis']
  + CKD Stage 3 <- ['CKD Stage 3a', 'CKD Stage 3b']
  + Others <- ['CKD G1-control', 'CKD G1A1-control', 'Unknown']
merge> n_labels: 11 -> 6
  + (after) unique labels:
['CKD Stage 3' 'CKD Stage 2' 'Others' 'CKD Stage 4' 'CKD Stage 5'
 'CKD Stage 1']

> After re-labeling ...
tsHandler.profile> Found 6 unique labels ...
  + label=Others => N=606
  + label=CKD Stage 5 => N=758
  + label=CKD Stage 4 => N=56
  + label=CKD Stage 3 => N=350
  + label=CKD Stage 2 => N=528
  + label=CKD Stage 1 => N=62
loadTSet> number of classes: 6
... cohort=CKD, ctype=regular, d2v=pv-dm2, meta=smallCKD
  + is_simplified? False, ... 
  + classification mode: multiclass
  + classifiers:
[]
  + training set type:dense
  + training set dim:2360
  + n classes:6

d_classify> dim(ts): (2360, 5002) > n_timesteps: 50, n_features: 100
  + dim(X <- ts): (2360, 5000)
d_classify> reshaped X: (2360, 50, 100) | n_classes=6

<<< Experimental Settings >>>

   + tset type dense, maxNPerClass: None, drop control? False
  + cohort: CKD, ctype: regular

  + D2V: pv-dm2, params> window: 10, n_features: 50
       + n_iter: 20, min_count: 2

  + userFileID: smallCKD

... data: 

... params (model selection): 

model_selection> trying {'n_units': 150, 'dropout_rate': 0.2} ...

make_lstm> n_units=150, r_dropout=0.200000, n_layers=1, n_classes=6
WARNING:tensorflow:From dnn_utils.py:154: streaming_auc (from tensorflow.contrib.metrics.python.ops.metric_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Please switch to tf.metrics.auc. Note that the order of the labels and predictions arguments has been switched.
  + lookup:
{'Others': 5, 'CKD Stage 5': 4, 'CKD Stage 4': 3, 'CKD Stage 3': 2, 'CKD Stage 2': 1, 'CKD Stage 1': 0}

... class weights:
{0: 6.344086021505376, 1: 0.74494949494949492, 2: 1.1238095238095238, 3: 7.0238095238095237, 4: 0.51890941072999119, 5: 0.64906490649064907}

====================================================================================================
... early stopping>
       + patience: 20, model='max'
... model training>
       + batch_size: 32, epochs: 60, shuffle? True, metric: auc_roc
====================================================================================================
Train on 1652 samples, validate on 708 samples
Epoch 1/60
2018-07-01 15:18:56.955444: I tensorflow/core/platform/cpu_feature_guard.cc:140] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA
1652/1652 [==============================] - 5s 3ms/step - loss: 1.6651 - acc: 0.2772 - auc_roc: 0.6337 - val_loss: 1.7473 - val_acc: 0.4266 - val_auc_roc: 0.6951
Epoch 2/60
1652/1652 [==============================] - 5s 3ms/step - loss: 1.4902 - acc: 0.4292 - auc_roc: 0.7156 - val_loss: 1.7911 - val_acc: 0.3517 - val_auc_roc: 0.7178
Epoch 3/60
1652/1652 [==============================] - 4s 3ms/step - loss: 1.2814 - acc: 0.4958 - auc_roc: 0.7321 - val_loss: 1.4467 - val_acc: 0.6328 - val_auc_roc: 0.7550
Epoch 4/60
1652/1652 [==============================] - 5s 3ms/step - loss: 1.2292 - acc: 0.4939 - auc_roc: 0.7684 - val_loss: 1.5296 - val_acc: 0.6497 - val_auc_roc: 0.7808
Epoch 5/60
1652/1652 [==============================] - 5s 3ms/step - loss: 1.1063 - acc: 0.5200 - auc_roc: 0.7906 - val_loss: 1.7658 - val_acc: 0.5240 - val_auc_roc: 0.7958
Epoch 6/60
1652/1652 [==============================] - 5s 3ms/step - loss: 1.0409 - acc: 0.5587 - auc_roc: 0.7998 - val_loss: 1.4676 - val_acc: 0.6483 - val_auc_roc: 0.8081
Epoch 7/60
1652/1652 [==============================] - 4s 3ms/step - loss: 0.9278 - acc: 0.5811 - auc_roc: 0.8140 - val_loss: 1.7668 - val_acc: 0.5946 - val_auc_roc: 0.8200
Epoch 8/60
1652/1652 [==============================] - 4s 2ms/step - loss: 0.8358 - acc: 0.6132 - auc_roc: 0.8251 - val_loss: 1.6412 - val_acc: 0.6144 - val_auc_roc: 0.8306
Epoch 9/60
1652/1652 [==============================] - 4s 3ms/step - loss: 0.8021 - acc: 0.6392 - auc_roc: 0.8353 - val_loss: 1.7227 - val_acc: 0.6017 - val_auc_roc: 0.8399
Epoch 10/60
1652/1652 [==============================] - 4s 2ms/step - loss: 0.7656 - acc: 0.6429 - auc_roc: 0.8429 - val_loss: 1.8491 - val_acc: 0.6850 - val_auc_roc: 0.8477
Epoch 11/60
1652/1652 [==============================] - 4s 2ms/step - loss: 0.6845 - acc: 0.6683 - auc_roc: 0.8515 - val_loss: 1.9572 - val_acc: 0.7133 - val_auc_roc: 0.8560
Epoch 12/60
1652/1652 [==============================] - 4s 2ms/step - loss: 0.6306 - acc: 0.6816 - auc_roc: 0.8597 - val_loss: 1.7677 - val_acc: 0.5876 - val_auc_roc: 0.8625
Epoch 13/60
1652/1652 [==============================] - 4s 2ms/step - loss: 0.6694 - acc: 0.6616 - auc_roc: 0.8643 - val_loss: 2.0976 - val_acc: 0.6427 - val_auc_roc: 0.8667
Epoch 14/60
1652/1652 [==============================] - 4s 2ms/step - loss: 0.5962 - acc: 0.6998 - auc_roc: 0.8691 - val_loss: 2.0525 - val_acc: 0.6977 - val_auc_roc: 0.8721
Epoch 15/60
1652/1652 [==============================] - 4s 2ms/step - loss: 0.5103 - acc: 0.7506 - auc_roc: 0.8747 - val_loss: 2.3313 - val_acc: 0.6257 - val_auc_roc: 0.8772
Epoch 16/60
1652/1652 [==============================] - 4s 2ms/step - loss: 0.4596 - acc: 0.7863 - auc_roc: 0.8796 - val_loss: 2.3208 - val_acc: 0.7076 - val_auc_roc: 0.8824
Epoch 17/60
1652/1652 [==============================] - 4s 2ms/step - loss: 0.4198 - acc: 0.8021 - auc_roc: 0.8849 - val_loss: 2.4992 - val_acc: 0.6921 - val_auc_roc: 0.8876
Epoch 18/60
1652/1652 [==============================] - 4s 2ms/step - loss: 0.3553 - acc: 0.8329 - auc_roc: 0.8900 - val_loss: 2.4348 - val_acc: 0.6935 - val_auc_roc: 0.8926
Epoch 19/60
1652/1652 [==============================] - 4s 2ms/step - loss: 0.4273 - acc: 0.8099 - auc_roc: 0.8945 - val_loss: 2.5872 - val_acc: 0.7119 - val_auc_roc: 0.8965
Epoch 20/60
1652/1652 [==============================] - 4s 2ms/step - loss: 0.4935 - acc: 0.7942 - auc_roc: 0.8981 - val_loss: 2.1976 - val_acc: 0.7090 - val_auc_roc: 0.8997
Epoch 21/60
1652/1652 [==============================] - 4s 2ms/step - loss: 0.4919 - acc: 0.7760 - auc_roc: 0.9008 - val_loss: 2.2128 - val_acc: 0.7189 - val_auc_roc: 0.9023
Epoch 22/60
1652/1652 [==============================] - 5s 3ms/step - loss: 0.3567 - acc: 0.8481 - auc_roc: 0.9039 - val_loss: 2.5603 - val_acc: 0.7203 - val_auc_roc: 0.9056
Epoch 23/60
1652/1652 [==============================] - 5s 3ms/step - loss: 0.2610 - acc: 0.8814 - auc_roc: 0.9072 - val_loss: 2.8649 - val_acc: 0.7175 - val_auc_roc: 0.9090
Epoch 00023: early stopping
... history of metrics comprising: ['acc', 'loss', 'val_auc_roc', 'auc_roc', 'val_acc', 'val_loss']
... ... metric (acc): [0.69975786953803698, 0.75060532687651327, 0.78631961287944141, 0.80205811152446649, 0.83292978179368216, 0.80992736077481842, 0.79418886227411445, 0.77602905597871497, 0.84806295428379974, 0.88135593220338981] (n=23)
output> saving performance to:
/Users/pleiades/Documents/work/tpheno/seqmaker/data/CKD/plot/model_evalation-ep200b16.tif

... ... metric (loss): [0.59623588387094462, 0.51033653192600958, 0.45957235706920485, 0.4198366280906714, 0.3553364577074028, 0.42726780889109317, 0.49351685965032321, 0.49189010341865963, 0.3566679799383547, 0.26099775251695667] (n=23)
output> saving performance to:
/Users/pleiades/Documents/work/tpheno/seqmaker/data/CKD/plot/model_evalation-ep200b16.tif


model_selection> trying {'n_units': 200, 'dropout_rate': 0.2} ...

make_lstm> n_units=200, r_dropout=0.200000, n_layers=1, n_classes=6
  + lookup:
{'Others': 5, 'CKD Stage 5': 4, 'CKD Stage 4': 3, 'CKD Stage 3': 2, 'CKD Stage 2': 1, 'CKD Stage 1': 0}

... class weights:
{0: 6.344086021505376, 1: 0.74494949494949492, 2: 1.1238095238095238, 3: 7.0238095238095237, 4: 0.51890941072999119, 5: 0.64906490649064907}

====================================================================================================
... early stopping>
       + patience: 20, model='max'
... model training>
       + batch_size: 32, epochs: 60, shuffle? True, metric: auc_roc
====================================================================================================
Train on 1652 samples, validate on 708 samples
Epoch 1/60
1652/1652 [==============================] - 5s 3ms/step - loss: 1.6476 - acc: 0.3033 - auc_roc: 0.6094 - val_loss: 1.5936 - val_acc: 0.4506 - val_auc_roc: 0.6894
Epoch 2/60
1652/1652 [==============================] - 4s 2ms/step - loss: 1.4283 - acc: 0.4734 - auc_roc: 0.7228 - val_loss: 1.5374 - val_acc: 0.5028 - val_auc_roc: 0.7437
Epoch 3/60
1652/1652 [==============================] - 4s 2ms/step - loss: 1.2286 - acc: 0.5260 - auc_roc: 0.7619 - val_loss: 1.4789 - val_acc: 0.6116 - val_auc_roc: 0.7827
Epoch 4/60
1652/1652 [==============================] - 4s 2ms/step - loss: 1.1590 - acc: 0.5109 - auc_roc: 0.7921 - val_loss: 1.7393 - val_acc: 0.6709 - val_auc_roc: 0.8041
Epoch 5/60
1652/1652 [==============================] - 4s 3ms/step - loss: 1.0730 - acc: 0.5551 - auc_roc: 0.8131 - val_loss: 1.4516 - val_acc: 0.6638 - val_auc_roc: 0.8213
Epoch 6/60
1652/1652 [==============================] - 4s 3ms/step - loss: 0.9546 - acc: 0.5944 - auc_roc: 0.8286 - val_loss: 1.6981 - val_acc: 0.6709 - val_auc_roc: 0.8344
Epoch 7/60
1652/1652 [==============================] - 4s 3ms/step - loss: 0.8890 - acc: 0.6005 - auc_roc: 0.8392 - val_loss: 2.0554 - val_acc: 0.3941 - val_auc_roc: 0.8389
Epoch 8/60
1652/1652 [==============================] - 4s 3ms/step - loss: 0.8604 - acc: 0.6144 - auc_roc: 0.8392 - val_loss: 1.8382 - val_acc: 0.5904 - val_auc_roc: 0.8438
Epoch 9/60
1652/1652 [==============================] - 4s 3ms/step - loss: 0.8578 - acc: 0.6005 - auc_roc: 0.8467 - val_loss: 1.9387 - val_acc: 0.6596 - val_auc_roc: 0.8493
Epoch 10/60
1652/1652 [==============================] - 4s 3ms/step - loss: 0.7883 - acc: 0.6429 - auc_roc: 0.8523 - val_loss: 1.7923 - val_acc: 0.6398 - val_auc_roc: 0.8553
Epoch 11/60
1652/1652 [==============================] - 4s 2ms/step - loss: 0.6492 - acc: 0.6955 - auc_roc: 0.8586 - val_loss: 1.8378 - val_acc: 0.6879 - val_auc_roc: 0.8627
Epoch 12/60
1652/1652 [==============================] - 4s 2ms/step - loss: 0.6144 - acc: 0.7191 - auc_roc: 0.8660 - val_loss: 2.0686 - val_acc: 0.6328 - val_auc_roc: 0.8691
Epoch 13/60
1652/1652 [==============================] - 4s 3ms/step - loss: 0.5633 - acc: 0.7300 - auc_roc: 0.8717 - val_loss: 1.9668 - val_acc: 0.6102 - val_auc_roc: 0.8741
Epoch 14/60
1652/1652 [==============================] - 4s 3ms/step - loss: 0.5404 - acc: 0.7439 - auc_roc: 0.8762 - val_loss: 1.8906 - val_acc: 0.6709 - val_auc_roc: 0.8792
Epoch 15/60
1652/1652 [==============================] - 4s 2ms/step - loss: 0.5279 - acc: 0.7391 - auc_roc: 0.8814 - val_loss: 2.1455 - val_acc: 0.7133 - val_auc_roc: 0.8842
Epoch 16/60
1652/1652 [==============================] - 4s 2ms/step - loss: 0.4579 - acc: 0.7700 - auc_roc: 0.8866 - val_loss: 2.1153 - val_acc: 0.7105 - val_auc_roc: 0.8893
Epoch 17/60
1652/1652 [==============================] - 4s 2ms/step - loss: 0.3787 - acc: 0.8196 - auc_roc: 0.8918 - val_loss: 2.5541 - val_acc: 0.5749 - val_auc_roc: 0.8937
Epoch 18/60
1652/1652 [==============================] - 4s 2ms/step - loss: 0.3905 - acc: 0.8142 - auc_roc: 0.8950 - val_loss: 2.1069 - val_acc: 0.7076 - val_auc_roc: 0.8975
Epoch 19/60
1652/1652 [==============================] - 4s 3ms/step - loss: 0.3240 - acc: 0.8402 - auc_roc: 0.8996 - val_loss: 2.1193 - val_acc: 0.7076 - val_auc_roc: 0.9020
Epoch 20/60
1652/1652 [==============================] - 4s 3ms/step - loss: 0.2716 - acc: 0.8850 - auc_roc: 0.9040 - val_loss: 2.4524 - val_acc: 0.6907 - val_auc_roc: 0.9062
Epoch 21/60
1652/1652 [==============================] - 4s 2ms/step - loss: 0.2686 - acc: 0.8808 - auc_roc: 0.9079 - val_loss: 2.2170 - val_acc: 0.6977 - val_auc_roc: 0.9099
Epoch 22/60
1652/1652 [==============================] - 4s 3ms/step - loss: 0.2102 - acc: 0.9056 - auc_roc: 0.9117 - val_loss: 2.5514 - val_acc: 0.7076 - val_auc_roc: 0.9137
Epoch 23/60
1652/1652 [==============================] - 4s 3ms/step - loss: 0.1921 - acc: 0.9159 - auc_roc: 0.9152 - val_loss: 2.4496 - val_acc: 0.6963 - val_auc_roc: 0.9170
Epoch 24/60
1652/1652 [==============================] - 4s 3ms/step - loss: 0.1724 - acc: 0.9231 - auc_roc: 0.9184 - val_loss: 2.7591 - val_acc: 0.6483 - val_auc_roc: 0.9199
Epoch 25/60
1652/1652 [==============================] - 4s 3ms/step - loss: 0.1870 - acc: 0.9134 - auc_roc: 0.9211 - val_loss: 2.4320 - val_acc: 0.7203 - val_auc_roc: 0.9226
Epoch 00025: early stopping
... history of metrics comprising: ['acc', 'loss', 'val_auc_roc', 'auc_roc', 'val_acc', 'val_loss']
... ... metric (acc): [0.76997578692493951, 0.8196125909433527, 0.8141646487660904, 0.84019370445616304, 0.88498789331814853, 0.88075060547119766, 0.90556900711960131, 0.91585956402032775, 0.92312348653848753, 0.91343825651427446] (n=25)
output> saving performance to:
/Users/pleiades/Documents/work/tpheno/seqmaker/data/CKD/plot/model_evalation-ep200b16.tif

... ... metric (loss): [0.45791136569030061, 0.37868689047510917, 0.3904670543661995, 0.32396651223554451, 0.27161725128822695, 0.26863484838684304, 0.21018544647653223, 0.19210626134427927, 0.17237650446106678, 0.18696403777628198] (n=25)
output> saving performance to:
/Users/pleiades/Documents/work/tpheno/seqmaker/data/CKD/plot/model_evalation-ep200b16.tif


model_selection> trying {'n_units': 300, 'dropout_rate': 0.2} ...

make_lstm> n_units=300, r_dropout=0.200000, n_layers=1, n_classes=6
  + lookup:
{'Others': 5, 'CKD Stage 5': 4, 'CKD Stage 4': 3, 'CKD Stage 3': 2, 'CKD Stage 2': 1, 'CKD Stage 1': 0}

... class weights:
{0: 6.344086021505376, 1: 0.74494949494949492, 2: 1.1238095238095238, 3: 7.0238095238095237, 4: 0.51890941072999119, 5: 0.64906490649064907}

====================================================================================================
... early stopping>
       + patience: 20, model='max'
... model training>
       + batch_size: 32, epochs: 60, shuffle? True, metric: auc_roc
====================================================================================================
Train on 1652 samples, validate on 708 samples
Epoch 1/60
1652/1652 [==============================] - 7s 4ms/step - loss: 1.6033 - acc: 0.3481 - auc_roc: 0.6408 - val_loss: 1.7023 - val_acc: 0.4562 - val_auc_roc: 0.7248
Epoch 2/60
1652/1652 [==============================] - 9s 5ms/step - loss: 1.4172 - acc: 0.4286 - auc_roc: 0.7372 - val_loss: 1.9202 - val_acc: 0.4689 - val_auc_roc: 0.7516
Epoch 3/60
1652/1652 [==============================] - 7s 4ms/step - loss: 1.2558 - acc: 0.4806 - auc_roc: 0.7621 - val_loss: 1.7268 - val_acc: 0.3743 - val_auc_roc: 0.7615
Epoch 4/60
1652/1652 [==============================] - 7s 4ms/step - loss: 1.1322 - acc: 0.5291 - auc_roc: 0.7688 - val_loss: 1.6594 - val_acc: 0.5621 - val_auc_roc: 0.7808
Epoch 5/60
1652/1652 [==============================] - 7s 4ms/step - loss: 1.0599 - acc: 0.5230 - auc_roc: 0.7899 - val_loss: 1.8598 - val_acc: 0.6483 - val_auc_roc: 0.7992
Epoch 6/60
1652/1652 [==============================] - 7s 4ms/step - loss: 0.9566 - acc: 0.5962 - auc_roc: 0.8085 - val_loss: 1.5927 - val_acc: 0.5847 - val_auc_roc: 0.8158
Epoch 7/60
1652/1652 [==============================] - 7s 4ms/step - loss: 0.9415 - acc: 0.5787 - auc_roc: 0.8216 - val_loss: 1.7775 - val_acc: 0.3672 - val_auc_roc: 0.8228
Epoch 8/60
1652/1652 [==============================] - 8s 5ms/step - loss: 0.9047 - acc: 0.5969 - auc_roc: 0.8235 - val_loss: 1.6122 - val_acc: 0.6949 - val_auc_roc: 0.8294
Epoch 9/60
1652/1652 [==============================] - 7s 4ms/step - loss: 0.7472 - acc: 0.6538 - auc_roc: 0.8353 - val_loss: 1.6803 - val_acc: 0.6709 - val_auc_roc: 0.8407
Epoch 10/60
1652/1652 [==============================] - 7s 4ms/step - loss: 0.6820 - acc: 0.6755 - auc_roc: 0.8452 - val_loss: 1.9271 - val_acc: 0.7062 - val_auc_roc: 0.8505
Epoch 11/60
1652/1652 [==============================] - 6s 4ms/step - loss: 0.7200 - acc: 0.6640 - auc_roc: 0.8542 - val_loss: 1.9965 - val_acc: 0.4816 - val_auc_roc: 0.8558
Epoch 12/60
1652/1652 [==============================] - 6s 4ms/step - loss: 0.6256 - acc: 0.7004 - auc_roc: 0.8579 - val_loss: 2.2288 - val_acc: 0.5763 - val_auc_roc: 0.8605
Epoch 13/60
1652/1652 [==============================] - 7s 4ms/step - loss: 0.5625 - acc: 0.7300 - auc_roc: 0.8631 - val_loss: 2.0553 - val_acc: 0.6836 - val_auc_roc: 0.8667
Epoch 14/60
1652/1652 [==============================] - 9s 5ms/step - loss: 0.5060 - acc: 0.7591 - auc_roc: 0.8697 - val_loss: 2.1152 - val_acc: 0.7218 - val_auc_roc: 0.8735
Epoch 15/60
1652/1652 [==============================] - 7s 4ms/step - loss: 0.4277 - acc: 0.7918 - auc_roc: 0.8768 - val_loss: 2.1256 - val_acc: 0.7246 - val_auc_roc: 0.8804
Epoch 16/60
1652/1652 [==============================] - 6s 4ms/step - loss: 0.4465 - acc: 0.7881 - auc_roc: 0.8834 - val_loss: 2.0089 - val_acc: 0.7048 - val_auc_roc: 0.8861
Epoch 17/60
1652/1652 [==============================] - 6s 4ms/step - loss: 0.3649 - acc: 0.8305 - auc_roc: 0.8887 - val_loss: 2.3513 - val_acc: 0.7062 - val_auc_roc: 0.8918
Epoch 18/60
1652/1652 [==============================] - 7s 4ms/step - loss: 0.2853 - acc: 0.8680 - auc_roc: 0.8944 - val_loss: 2.4237 - val_acc: 0.7218 - val_auc_roc: 0.8973
Epoch 19/60
1652/1652 [==============================] - 6s 4ms/step - loss: 0.2316 - acc: 0.8910 - auc_roc: 0.8999 - val_loss: 2.5811 - val_acc: 0.6780 - val_auc_roc: 0.9024
Epoch 20/60
1652/1652 [==============================] - 6s 4ms/step - loss: 0.2181 - acc: 0.9031 - auc_roc: 0.9045 - val_loss: 2.4435 - val_acc: 0.7161 - val_auc_roc: 0.9070
Epoch 21/60
1652/1652 [==============================] - 6s 4ms/step - loss: 0.1741 - acc: 0.9304 - auc_roc: 0.9090 - val_loss: 2.7480 - val_acc: 0.7119 - val_auc_roc: 0.9114
Epoch 22/60
1652/1652 [==============================] - 6s 4ms/step - loss: 0.2872 - acc: 0.8910 - auc_roc: 0.9131 - val_loss: 2.5346 - val_acc: 0.6963 - val_auc_roc: 0.9147
Epoch 23/60
1652/1652 [==============================] - 6s 4ms/step - loss: 0.2936 - acc: 0.8862 - auc_roc: 0.9161 - val_loss: 2.6869 - val_acc: 0.6455 - val_auc_roc: 0.9174
Epoch 24/60
1652/1652 [==============================] - 6s 4ms/step - loss: 0.2336 - acc: 0.9044 - auc_roc: 0.9184 - val_loss: 2.6882 - val_acc: 0.7006 - val_auc_roc: 0.9200
Epoch 25/60
1652/1652 [==============================] - 6s 4ms/step - loss: 0.1225 - acc: 0.9498 - auc_roc: 0.9214 - val_loss: 2.9220 - val_acc: 0.7006 - val_auc_roc: 0.9231
Epoch 26/60
1652/1652 [==============================] - 6s 4ms/step - loss: 0.0911 - acc: 0.9673 - auc_roc: 0.9244 - val_loss: 2.8618 - val_acc: 0.7062 - val_auc_roc: 0.9260
Epoch 00026: early stopping
... history of metrics comprising: ['acc', 'loss', 'val_auc_roc', 'auc_roc', 'val_acc', 'val_loss']
... ... metric (acc): [0.83050847428762886, 0.86803874063145448, 0.89104116208328177, 0.90314770004651157, 0.93038740934528974, 0.89104116193896055, 0.88619854750413873, 0.90435835336657466, 0.94975786924939465, 0.96731234852395975] (n=26)
output> saving performance to:
/Users/pleiades/Documents/work/tpheno/seqmaker/data/CKD/plot/model_evalation-ep200b16.tif

... ... metric (loss): [0.36485815206971067, 0.28534032260101588, 0.2315542049182818, 0.21814839715097487, 0.17408592688690952, 0.28717539118508162, 0.29360928034666955, 0.2336311192763631, 0.12246103445857258, 0.091147215473161194] (n=26)
output> saving performance to:
/Users/pleiades/Documents/work/tpheno/seqmaker/data/CKD/plot/model_evalation-ep200b16.tif


model_selection> trying {'n_units': 400, 'dropout_rate': 0.2} ...

make_lstm> n_units=400, r_dropout=0.200000, n_layers=1, n_classes=6
  + lookup:
{'Others': 5, 'CKD Stage 5': 4, 'CKD Stage 4': 3, 'CKD Stage 3': 2, 'CKD Stage 2': 1, 'CKD Stage 1': 0}

... class weights:
{0: 6.344086021505376, 1: 0.74494949494949492, 2: 1.1238095238095238, 3: 7.0238095238095237, 4: 0.51890941072999119, 5: 0.64906490649064907}

====================================================================================================
... early stopping>
       + patience: 20, model='max'
... model training>
       + batch_size: 32, epochs: 60, shuffle? True, metric: auc_roc
====================================================================================================
Train on 1652 samples, validate on 708 samples
Epoch 1/60
1652/1652 [==============================] - 10s 6ms/step - loss: 1.6441 - acc: 0.3305 - auc_roc: 0.6578 - val_loss: 1.8143 - val_acc: 0.2429 - val_auc_roc: 0.6855
Epoch 2/60
1652/1652 [==============================] - 9s 6ms/step - loss: 1.4408 - acc: 0.4243 - auc_roc: 0.7019 - val_loss: 1.9025 - val_acc: 0.4209 - val_auc_roc: 0.7195
Epoch 3/60
1652/1652 [==============================] - 9s 6ms/step - loss: 1.3158 - acc: 0.4600 - auc_roc: 0.7326 - val_loss: 1.5011 - val_acc: 0.6497 - val_auc_roc: 0.7524
Epoch 4/60
1652/1652 [==============================] - 9s 6ms/step - loss: 1.1716 - acc: 0.5085 - auc_roc: 0.7667 - val_loss: 1.8366 - val_acc: 0.4181 - val_auc_roc: 0.7726
Epoch 5/60
1652/1652 [==============================] - 10s 6ms/step - loss: 1.0737 - acc: 0.5448 - auc_roc: 0.7782 - val_loss: 1.6243 - val_acc: 0.5508 - val_auc_roc: 0.7882
Epoch 6/60
1652/1652 [==============================] - 9s 5ms/step - loss: 1.0351 - acc: 0.5539 - auc_roc: 0.7954 - val_loss: 2.1188 - val_acc: 0.5636 - val_auc_roc: 0.8011
Epoch 7/60
1652/1652 [==============================] - 9s 5ms/step - loss: 0.9439 - acc: 0.5872 - auc_roc: 0.8059 - val_loss: 1.8757 - val_acc: 0.6398 - val_auc_roc: 0.8129
Epoch 8/60
1652/1652 [==============================] - 9s 5ms/step - loss: 0.8689 - acc: 0.5902 - auc_roc: 0.8184 - val_loss: 1.6943 - val_acc: 0.4548 - val_auc_roc: 0.8211
Epoch 9/60
1652/1652 [==============================] - 9s 5ms/step - loss: 0.7664 - acc: 0.6344 - auc_roc: 0.8243 - val_loss: 1.9920 - val_acc: 0.6568 - val_auc_roc: 0.8303
Epoch 10/60
1652/1652 [==============================] - 9s 6ms/step - loss: 0.7335 - acc: 0.6544 - auc_roc: 0.8353 - val_loss: 1.8297 - val_acc: 0.6737 - val_auc_roc: 0.8406
Epoch 11/60
1652/1652 [==============================] - 9s 5ms/step - loss: 0.7369 - acc: 0.6677 - auc_roc: 0.8447 - val_loss: 1.7630 - val_acc: 0.6624 - val_auc_roc: 0.8488
Epoch 12/60
1652/1652 [==============================] - 9s 5ms/step - loss: 0.6502 - acc: 0.6931 - auc_roc: 0.8524 - val_loss: 1.7394 - val_acc: 0.6822 - val_auc_roc: 0.8564
Epoch 13/60
1652/1652 [==============================] - 10s 6ms/step - loss: 0.5633 - acc: 0.7258 - auc_roc: 0.8604 - val_loss: 1.8989 - val_acc: 0.6822 - val_auc_roc: 0.8640
Epoch 14/60
1652/1652 [==============================] - 10s 6ms/step - loss: 0.5235 - acc: 0.7367 - auc_roc: 0.8672 - val_loss: 2.1572 - val_acc: 0.7274 - val_auc_roc: 0.8711
Epoch 15/60
1652/1652 [==============================] - 9s 6ms/step - loss: 0.4469 - acc: 0.7742 - auc_roc: 0.8745 - val_loss: 2.3165 - val_acc: 0.6935 - val_auc_roc: 0.8778
Epoch 16/60
1652/1652 [==============================] - 9s 5ms/step - loss: 0.4638 - acc: 0.7627 - auc_roc: 0.8806 - val_loss: 2.3382 - val_acc: 0.4534 - val_auc_roc: 0.8817
Epoch 17/60
1652/1652 [==============================] - 9s 5ms/step - loss: 0.4677 - acc: 0.7682 - auc_roc: 0.8830 - val_loss: 2.2985 - val_acc: 0.5847 - val_auc_roc: 0.8847
Epoch 18/60
1652/1652 [==============================] - 9s 6ms/step - loss: 0.3849 - acc: 0.8117 - auc_roc: 0.8866 - val_loss: 2.3559 - val_acc: 0.6709 - val_auc_roc: 0.8893
Epoch 19/60
1652/1652 [==============================] - 10s 6ms/step - loss: 0.2958 - acc: 0.8541 - auc_roc: 0.8918 - val_loss: 2.1750 - val_acc: 0.7020 - val_auc_roc: 0.8946
Epoch 20/60
1652/1652 [==============================] - 9s 5ms/step - loss: 0.2451 - acc: 0.8814 - auc_roc: 0.8970 - val_loss: 2.5911 - val_acc: 0.7373 - val_auc_roc: 0.8998
Epoch 21/60
1652/1652 [==============================] - 9s 6ms/step - loss: 0.3497 - acc: 0.8584 - auc_roc: 0.9016 - val_loss: 2.6345 - val_acc: 0.7175 - val_auc_roc: 0.9038
Epoch 22/60
1652/1652 [==============================] - 9s 5ms/step - loss: 0.2390 - acc: 0.8923 - auc_roc: 0.9057 - val_loss: 2.5760 - val_acc: 0.6540 - val_auc_roc: 0.9076
Epoch 23/60
1652/1652 [==============================] - 9s 6ms/step - loss: 0.1922 - acc: 0.9225 - auc_roc: 0.9092 - val_loss: 3.0914 - val_acc: 0.7076 - val_auc_roc: 0.9112
Epoch 00023: early stopping
... history of metrics comprising: ['acc', 'loss', 'val_auc_roc', 'auc_roc', 'val_acc', 'val_loss']
... ... metric (acc): [0.73668280857238588, 0.77421307534917505, 0.76271186455110085, 0.76815980658404182, 0.81174334140435833, 0.85411622276029053, 0.8813559320590687, 0.85835351118452607, 0.89225181612495075, 0.92251815951765304] (n=23)
output> saving performance to:
/Users/pleiades/Documents/work/tpheno/seqmaker/data/CKD/plot/model_evalation-ep200b16.tif

... ... metric (loss): [0.52349526671462721, 0.44690335035035456, 0.4637921970635292, 0.46771781583097888, 0.38485460376624048, 0.29578325484335855, 0.24510972548195006, 0.3496875377601919, 0.23900214992192986, 0.19221851323476427] (n=23)
output> saving performance to:
/Users/pleiades/Documents/work/tpheno/seqmaker/data/CKD/plot/model_evalation-ep200b16.tif


model_selection> trying {'n_units': 150, 'dropout_rate': 0.3} ...

make_lstm> n_units=150, r_dropout=0.300000, n_layers=1, n_classes=6
  + lookup:
{'Others': 5, 'CKD Stage 5': 4, 'CKD Stage 4': 3, 'CKD Stage 3': 2, 'CKD Stage 2': 1, 'CKD Stage 1': 0}

... class weights:
{0: 6.344086021505376, 1: 0.74494949494949492, 2: 1.1238095238095238, 3: 7.0238095238095237, 4: 0.51890941072999119, 5: 0.64906490649064907}

====================================================================================================
... early stopping>
       + patience: 20, model='max'
... model training>
       + batch_size: 32, epochs: 60, shuffle? True, metric: auc_roc
====================================================================================================
Train on 1652 samples, validate on 708 samples
Epoch 1/60
1652/1652 [==============================] - 5s 3ms/step - loss: 1.6722 - acc: 0.2833 - auc_roc: 0.6023 - val_loss: 1.7919 - val_acc: 0.5946 - val_auc_roc: 0.7012
Epoch 2/60
1652/1652 [==============================] - 3s 2ms/step - loss: 1.4053 - acc: 0.4528 - auc_roc: 0.7411 - val_loss: 1.6971 - val_acc: 0.5734 - val_auc_roc: 0.7648
Epoch 3/60
1652/1652 [==============================] - 4s 2ms/step - loss: 1.2916 - acc: 0.4952 - auc_roc: 0.7780 - val_loss: 1.6564 - val_acc: 0.5890 - val_auc_roc: 0.7895
Epoch 4/60
1652/1652 [==============================] - 4s 2ms/step - loss: 1.1640 - acc: 0.5133 - auc_roc: 0.7979 - val_loss: 1.4670 - val_acc: 0.5706 - val_auc_roc: 0.8043
Epoch 5/60
1652/1652 [==============================] - 4s 2ms/step - loss: 1.0758 - acc: 0.5527 - auc_roc: 0.8105 - val_loss: 1.8039 - val_acc: 0.5198 - val_auc_roc: 0.8129
Epoch 6/60
1652/1652 [==============================] - 4s 2ms/step - loss: 0.9616 - acc: 0.5587 - auc_roc: 0.8165 - val_loss: 1.5338 - val_acc: 0.6935 - val_auc_roc: 0.8237
Epoch 7/60
1652/1652 [==============================] - 4s 2ms/step - loss: 0.9600 - acc: 0.5835 - auc_roc: 0.8302 - val_loss: 1.4442 - val_acc: 0.6172 - val_auc_roc: 0.8348
Epoch 8/60
1652/1652 [==============================] - 4s 2ms/step - loss: 0.8989 - acc: 0.5962 - auc_roc: 0.8385 - val_loss: 1.4616 - val_acc: 0.6751 - val_auc_roc: 0.8432
Epoch 9/60
1652/1652 [==============================] - 4s 2ms/step - loss: 0.8560 - acc: 0.6132 - auc_roc: 0.8466 - val_loss: 1.5322 - val_acc: 0.7034 - val_auc_roc: 0.8508
Epoch 10/60
1652/1652 [==============================] - 4s 2ms/step - loss: 0.8421 - acc: 0.6023 - auc_roc: 0.8538 - val_loss: 1.5879 - val_acc: 0.6314 - val_auc_roc: 0.8560
Epoch 11/60
1652/1652 [==============================] - 3s 2ms/step - loss: 0.7611 - acc: 0.6386 - auc_roc: 0.8583 - val_loss: 1.9159 - val_acc: 0.6568 - val_auc_roc: 0.8610
Epoch 12/60
1652/1652 [==============================] - 4s 2ms/step - loss: 0.7209 - acc: 0.6465 - auc_roc: 0.8631 - val_loss: 1.7467 - val_acc: 0.6596 - val_auc_roc: 0.8656
Epoch 13/60
1652/1652 [==============================] - 4s 2ms/step - loss: 0.6909 - acc: 0.6640 - auc_roc: 0.8675 - val_loss: 1.9081 - val_acc: 0.6879 - val_auc_roc: 0.8699
Epoch 14/60
1652/1652 [==============================] - 4s 2ms/step - loss: 0.6570 - acc: 0.6816 - auc_roc: 0.8718 - val_loss: 1.8280 - val_acc: 0.7246 - val_auc_roc: 0.8745
Epoch 15/60
1652/1652 [==============================] - 4s 2ms/step - loss: 0.5722 - acc: 0.7076 - auc_roc: 0.8770 - val_loss: 1.9614 - val_acc: 0.7161 - val_auc_roc: 0.8796
Epoch 16/60
1652/1652 [==============================] - 4s 2ms/step - loss: 0.5111 - acc: 0.7482 - auc_roc: 0.8819 - val_loss: 2.2241 - val_acc: 0.6907 - val_auc_roc: 0.8843
Epoch 17/60
1652/1652 [==============================] - 4s 2ms/step - loss: 0.4693 - acc: 0.7651 - auc_roc: 0.8863 - val_loss: 2.0548 - val_acc: 0.6794 - val_auc_roc: 0.8886
Epoch 18/60
1652/1652 [==============================] - 4s 2ms/step - loss: 0.4302 - acc: 0.7821 - auc_roc: 0.8905 - val_loss: 2.0715 - val_acc: 0.6695 - val_auc_roc: 0.8926
Epoch 19/60
1652/1652 [==============================] - 4s 2ms/step - loss: 0.4358 - acc: 0.7893 - auc_roc: 0.8943 - val_loss: 1.8930 - val_acc: 0.6116 - val_auc_roc: 0.8958
Epoch 20/60
1652/1652 [==============================] - 4s 2ms/step - loss: 0.4910 - acc: 0.7645 - auc_roc: 0.8969 - val_loss: 1.8730 - val_acc: 0.7034 - val_auc_roc: 0.8985
Epoch 21/60
1652/1652 [==============================] - 4s 2ms/step - loss: 0.4036 - acc: 0.8027 - auc_roc: 0.9000 - val_loss: 2.4308 - val_acc: 0.7260 - val_auc_roc: 0.9019
Epoch 22/60
1652/1652 [==============================] - 4s 2ms/step - loss: 0.5454 - acc: 0.7712 - auc_roc: 0.9028 - val_loss: 1.9540 - val_acc: 0.7090 - val_auc_roc: 0.9043
Epoch 23/60
1652/1652 [==============================] - 4s 2ms/step - loss: 0.3426 - acc: 0.8426 - auc_roc: 0.9058 - val_loss: 2.5391 - val_acc: 0.6977 - val_auc_roc: 0.9074
Epoch 24/60
1652/1652 [==============================] - 4s 2ms/step - loss: 0.3328 - acc: 0.8547 - auc_roc: 0.9086 - val_loss: 2.2260 - val_acc: 0.7274 - val_auc_roc: 0.9102
Epoch 25/60
1652/1652 [==============================] - 4s 2ms/step - loss: 0.2395 - acc: 0.8910 - auc_roc: 0.9117 - val_loss: 2.3786 - val_acc: 0.7119 - val_auc_roc: 0.9134
Epoch 26/60
1652/1652 [==============================] - 4s 2ms/step - loss: 0.1981 - acc: 0.9128 - auc_roc: 0.9149 - val_loss: 2.5141 - val_acc: 0.7147 - val_auc_roc: 0.9165
Epoch 27/60
1652/1652 [==============================] - 4s 2ms/step - loss: 0.1678 - acc: 0.9316 - auc_roc: 0.9179 - val_loss: 3.1119 - val_acc: 0.5508 - val_auc_roc: 0.9188
Epoch 00027: early stopping
... history of metrics comprising: ['acc', 'loss', 'val_auc_roc', 'auc_roc', 'val_acc', 'val_loss']
... ... metric (acc): [0.78208232459952698, 0.78934624697336564, 0.76452784489199843, 0.80266343811233742, 0.77118644067796616, 0.84261501225085866, 0.85472154934816158, 0.89104116193896055, 0.91283293007072464, 0.93159806280967394] (n=27)
output> saving performance to:
/Users/pleiades/Documents/work/tpheno/seqmaker/data/CKD/plot/model_evalation-ep200b16.tif

... ... metric (loss): [0.43023733928186264, 0.43583014513620744, 0.49097247591318866, 0.40358431460493704, 0.54537803771709414, 0.34260993488764357, 0.33282370086010665, 0.23952675471871587, 0.19809221225558413, 0.16775782720228663] (n=27)
output> saving performance to:
/Users/pleiades/Documents/work/tpheno/seqmaker/data/CKD/plot/model_evalation-ep200b16.tif


model_selection> trying {'n_units': 200, 'dropout_rate': 0.3} ...

make_lstm> n_units=200, r_dropout=0.300000, n_layers=1, n_classes=6
  + lookup:
{'Others': 5, 'CKD Stage 5': 4, 'CKD Stage 4': 3, 'CKD Stage 3': 2, 'CKD Stage 2': 1, 'CKD Stage 1': 0}

... class weights:
{0: 6.344086021505376, 1: 0.74494949494949492, 2: 1.1238095238095238, 3: 7.0238095238095237, 4: 0.51890941072999119, 5: 0.64906490649064907}

====================================================================================================
... early stopping>
       + patience: 20, model='max'
... model training>
       + batch_size: 32, epochs: 60, shuffle? True, metric: auc_roc
====================================================================================================
Train on 1652 samples, validate on 708 samples
Epoch 1/60
1652/1652 [==============================] - 5s 3ms/step - loss: 1.6578 - acc: 0.3027 - auc_roc: 0.6248 - val_loss: 1.8792 - val_acc: 0.3715 - val_auc_roc: 0.6778
Epoch 2/60
1652/1652 [==============================] - 4s 2ms/step - loss: 1.3774 - acc: 0.4377 - auc_roc: 0.7007 - val_loss: 1.5165 - val_acc: 0.5621 - val_auc_roc: 0.7375
Epoch 3/60
1652/1652 [==============================] - 4s 3ms/step - loss: 1.2568 - acc: 0.4613 - auc_roc: 0.7548 - val_loss: 1.2890 - val_acc: 0.6328 - val_auc_roc: 0.7729
Epoch 4/60
1652/1652 [==============================] - 4s 3ms/step - loss: 1.1908 - acc: 0.5091 - auc_roc: 0.7864 - val_loss: 1.5785 - val_acc: 0.4520 - val_auc_roc: 0.7915
Epoch 5/60
1652/1652 [==============================] - 4s 2ms/step - loss: 1.0976 - acc: 0.5369 - auc_roc: 0.7937 - val_loss: 1.7451 - val_acc: 0.5466 - val_auc_roc: 0.8006
Epoch 6/60
1652/1652 [==============================] - 4s 3ms/step - loss: 1.1133 - acc: 0.4770 - auc_roc: 0.8017 - val_loss: 2.1951 - val_acc: 0.3234 - val_auc_roc: 0.7983
Epoch 7/60
1652/1652 [==============================] - 4s 2ms/step - loss: 1.0144 - acc: 0.5345 - auc_roc: 0.8001 - val_loss: 1.6704 - val_acc: 0.5381 - val_auc_roc: 0.8056
Epoch 8/60
1652/1652 [==============================] - 4s 2ms/step - loss: 0.8831 - acc: 0.5944 - auc_roc: 0.8107 - val_loss: 1.8527 - val_acc: 0.5621 - val_auc_roc: 0.8161
Epoch 9/60
1652/1652 [==============================] - 4s 2ms/step - loss: 0.8134 - acc: 0.6180 - auc_roc: 0.8212 - val_loss: 1.7170 - val_acc: 0.6709 - val_auc_roc: 0.8273
Epoch 10/60
1652/1652 [==============================] - 4s 2ms/step - loss: 0.7634 - acc: 0.6374 - auc_roc: 0.8327 - val_loss: 1.6285 - val_acc: 0.6723 - val_auc_roc: 0.8374
Epoch 11/60
1652/1652 [==============================] - 4s 2ms/step - loss: 0.7319 - acc: 0.6550 - auc_roc: 0.8413 - val_loss: 1.8573 - val_acc: 0.6497 - val_auc_roc: 0.8453
Epoch 12/60
1652/1652 [==============================] - 4s 2ms/step - loss: 0.6916 - acc: 0.6780 - auc_roc: 0.8490 - val_loss: 1.8210 - val_acc: 0.6737 - val_auc_roc: 0.8528
Epoch 13/60
1652/1652 [==============================] - 4s 3ms/step - loss: 0.6243 - acc: 0.6979 - auc_roc: 0.8563 - val_loss: 1.9995 - val_acc: 0.6864 - val_auc_roc: 0.8599
Epoch 14/60
1652/1652 [==============================] - 4s 2ms/step - loss: 0.6826 - acc: 0.6864 - auc_roc: 0.8628 - val_loss: 1.8338 - val_acc: 0.6497 - val_auc_roc: 0.8654
Epoch 15/60
1652/1652 [==============================] - 4s 2ms/step - loss: 0.5872 - acc: 0.7203 - auc_roc: 0.8680 - val_loss: 1.9089 - val_acc: 0.7006 - val_auc_roc: 0.8709
Epoch 16/60
1652/1652 [==============================] - 4s 2ms/step - loss: 0.4919 - acc: 0.7621 - auc_roc: 0.8738 - val_loss: 2.0584 - val_acc: 0.6808 - val_auc_roc: 0.8768
Epoch 17/60
1652/1652 [==============================] - 4s 2ms/step - loss: 0.5640 - acc: 0.7215 - auc_roc: 0.8789 - val_loss: 2.0506 - val_acc: 0.6808 - val_auc_roc: 0.8810
Epoch 18/60
1652/1652 [==============================] - 4s 2ms/step - loss: 0.5039 - acc: 0.7591 - auc_roc: 0.8829 - val_loss: 2.0254 - val_acc: 0.6709 - val_auc_roc: 0.8851
Epoch 19/60
1652/1652 [==============================] - 4s 2ms/step - loss: 0.4251 - acc: 0.7845 - auc_roc: 0.8872 - val_loss: 2.2467 - val_acc: 0.6836 - val_auc_roc: 0.8893
Epoch 20/60
1652/1652 [==============================] - 4s 2ms/step - loss: 0.3762 - acc: 0.8208 - auc_roc: 0.8913 - val_loss: 2.3262 - val_acc: 0.7006 - val_auc_roc: 0.8937
Epoch 21/60
1652/1652 [==============================] - 4s 2ms/step - loss: 0.3241 - acc: 0.8529 - auc_roc: 0.8957 - val_loss: 2.3610 - val_acc: 0.7048 - val_auc_roc: 0.8980
Epoch 22/60
1652/1652 [==============================] - 4s 3ms/step - loss: 0.2777 - acc: 0.8656 - auc_roc: 0.9000 - val_loss: 2.2510 - val_acc: 0.6949 - val_auc_roc: 0.9022
Epoch 23/60
1652/1652 [==============================] - 4s 2ms/step - loss: 0.2220 - acc: 0.9038 - auc_roc: 0.9041 - val_loss: 2.8384 - val_acc: 0.7062 - val_auc_roc: 0.9062
Epoch 00023: early stopping
... history of metrics comprising: ['acc', 'loss', 'val_auc_roc', 'auc_roc', 'val_acc', 'val_loss']
... ... metric (acc): [0.68644067789394114, 0.72033898305084743, 0.76210653753026636, 0.72154963651523174, 0.75907990343634213, 0.78450363196125905, 0.82082324469637924, 0.85290556929590622, 0.86561743355836474, 0.90375302677870373] (n=23)
output> saving performance to:
/Users/pleiades/Documents/work/tpheno/seqmaker/data/CKD/plot/model_evalation-ep200b16.tif

... ... metric (loss): [0.6826144087401198, 0.58718171138451691, 0.49186774590402194, 0.56397148367856376, 0.50390968094726452, 0.42514498946741763, 0.37616544045489869, 0.32407207949398215, 0.27773713625372176, 0.22200173096275791] (n=23)
output> saving performance to:
/Users/pleiades/Documents/work/tpheno/seqmaker/data/CKD/plot/model_evalation-ep200b16.tif


model_selection> trying {'n_units': 300, 'dropout_rate': 0.3} ...

make_lstm> n_units=300, r_dropout=0.300000, n_layers=1, n_classes=6
  + lookup:
{'Others': 5, 'CKD Stage 5': 4, 'CKD Stage 4': 3, 'CKD Stage 3': 2, 'CKD Stage 2': 1, 'CKD Stage 1': 0}

... class weights:
{0: 6.344086021505376, 1: 0.74494949494949492, 2: 1.1238095238095238, 3: 7.0238095238095237, 4: 0.51890941072999119, 5: 0.64906490649064907}

====================================================================================================
... early stopping>
       + patience: 20, model='max'
... model training>
       + batch_size: 32, epochs: 60, shuffle? True, metric: auc_roc
====================================================================================================
Train on 1652 samples, validate on 708 samples
Epoch 1/60
1652/1652 [==============================] - 7s 4ms/step - loss: 1.6731 - acc: 0.3281 - auc_roc: 0.6367 - val_loss: 1.7245 - val_acc: 0.4816 - val_auc_roc: 0.7017
Epoch 2/60
1652/1652 [==============================] - 7s 4ms/step - loss: 1.3913 - acc: 0.4340 - auc_roc: 0.7275 - val_loss: 1.5236 - val_acc: 0.5325 - val_auc_roc: 0.7517
Epoch 3/60
1652/1652 [==============================] - 6s 4ms/step - loss: 1.3119 - acc: 0.4806 - auc_roc: 0.7639 - val_loss: 1.5782 - val_acc: 0.6582 - val_auc_roc: 0.7789
Epoch 4/60
1652/1652 [==============================] - 6s 4ms/step - loss: 1.1265 - acc: 0.5157 - auc_roc: 0.7938 - val_loss: 1.5346 - val_acc: 0.6130 - val_auc_roc: 0.8029
Epoch 5/60
1652/1652 [==============================] - 6s 4ms/step - loss: 1.0470 - acc: 0.5363 - auc_roc: 0.8094 - val_loss: 1.5505 - val_acc: 0.6427 - val_auc_roc: 0.8165
Epoch 6/60
1652/1652 [==============================] - 6s 4ms/step - loss: 0.9783 - acc: 0.5508 - auc_roc: 0.8221 - val_loss: 1.7177 - val_acc: 0.5212 - val_auc_roc: 0.8255
Epoch 7/60
1652/1652 [==============================] - 6s 4ms/step - loss: 0.9385 - acc: 0.5605 - auc_roc: 0.8278 - val_loss: 2.1551 - val_acc: 0.5141 - val_auc_roc: 0.8300
Epoch 8/60
1652/1652 [==============================] - 6s 4ms/step - loss: 0.8485 - acc: 0.6096 - auc_roc: 0.8327 - val_loss: 1.5977 - val_acc: 0.5819 - val_auc_roc: 0.8376
Epoch 9/60
1652/1652 [==============================] - 6s 4ms/step - loss: 0.8038 - acc: 0.5993 - auc_roc: 0.8414 - val_loss: 1.7212 - val_acc: 0.6822 - val_auc_roc: 0.8457
Epoch 10/60
1652/1652 [==============================] - 6s 4ms/step - loss: 0.7341 - acc: 0.6441 - auc_roc: 0.8495 - val_loss: 1.8236 - val_acc: 0.7090 - val_auc_roc: 0.8537
Epoch 11/60
1652/1652 [==============================] - 6s 4ms/step - loss: 0.6460 - acc: 0.6646 - auc_roc: 0.8573 - val_loss: 1.9252 - val_acc: 0.7288 - val_auc_roc: 0.8618
Epoch 12/60
1652/1652 [==============================] - 6s 4ms/step - loss: 0.6891 - acc: 0.6507 - auc_roc: 0.8649 - val_loss: 1.9632 - val_acc: 0.6455 - val_auc_roc: 0.8673
Epoch 13/60
1652/1652 [==============================] - 6s 4ms/step - loss: 0.6605 - acc: 0.6616 - auc_roc: 0.8695 - val_loss: 1.8538 - val_acc: 0.6737 - val_auc_roc: 0.8719
Epoch 14/60
1652/1652 [==============================] - 6s 4ms/step - loss: 0.6313 - acc: 0.6973 - auc_roc: 0.8744 - val_loss: 1.9854 - val_acc: 0.5946 - val_auc_roc: 0.8762
Epoch 15/60
1652/1652 [==============================] - 6s 4ms/step - loss: 0.5794 - acc: 0.7337 - auc_roc: 0.8778 - val_loss: 2.0220 - val_acc: 0.6540 - val_auc_roc: 0.8803
Epoch 16/60
1652/1652 [==============================] - 6s 4ms/step - loss: 0.5132 - acc: 0.7561 - auc_roc: 0.8824 - val_loss: 2.1018 - val_acc: 0.6949 - val_auc_roc: 0.8848
Epoch 17/60
1652/1652 [==============================] - 6s 4ms/step - loss: 0.4666 - acc: 0.7827 - auc_roc: 0.8869 - val_loss: 2.2567 - val_acc: 0.7119 - val_auc_roc: 0.8895
Epoch 18/60
1652/1652 [==============================] - 6s 4ms/step - loss: 0.3900 - acc: 0.8051 - auc_roc: 0.8918 - val_loss: 2.5292 - val_acc: 0.6893 - val_auc_roc: 0.8942
Epoch 19/60
1652/1652 [==============================] - 6s 4ms/step - loss: 0.3135 - acc: 0.8481 - auc_roc: 0.8962 - val_loss: 2.4274 - val_acc: 0.6949 - val_auc_roc: 0.8987
Epoch 20/60
1652/1652 [==============================] - 6s 4ms/step - loss: 0.2719 - acc: 0.8680 - auc_roc: 0.9008 - val_loss: 2.6862 - val_acc: 0.6864 - val_auc_roc: 0.9032
Epoch 21/60
1652/1652 [==============================] - 6s 4ms/step - loss: 0.2651 - acc: 0.8626 - auc_roc: 0.9048 - val_loss: 2.6638 - val_acc: 0.7373 - val_auc_roc: 0.9071
Epoch 22/60
1652/1652 [==============================] - 6s 4ms/step - loss: 0.2278 - acc: 0.8941 - auc_roc: 0.9090 - val_loss: 3.0991 - val_acc: 0.6977 - val_auc_roc: 0.9109
Epoch 00022: early stopping
... history of metrics comprising: ['acc', 'loss', 'val_auc_roc', 'auc_roc', 'val_acc', 'val_loss']
... ... metric (acc): [0.66162227602905566, 0.6973365620319838, 0.73365617418981921, 0.75605326862081201, 0.78268765133171914, 0.80508474605135416, 0.84806295370651508, 0.86803874106441803, 0.86259079874283462, 0.89406779646584833] (n=22)
output> saving performance to:
/Users/pleiades/Documents/work/tpheno/seqmaker/data/CKD/plot/model_evalation-ep200b16.tif

... ... metric (loss): [0.66048111335417259, 0.63134135756885168, 0.57937222978970615, 0.5131644785548527, 0.4666102084062867, 0.39002111662386696, 0.31352676793968998, 0.27188456693515362, 0.2650922749723707, 0.2278270511087436] (n=22)
output> saving performance to:
/Users/pleiades/Documents/work/tpheno/seqmaker/data/CKD/plot/model_evalation-ep200b16.tif


model_selection> trying {'n_units': 400, 'dropout_rate': 0.3} ...

make_lstm> n_units=400, r_dropout=0.300000, n_layers=1, n_classes=6
  + lookup:
{'Others': 5, 'CKD Stage 5': 4, 'CKD Stage 4': 3, 'CKD Stage 3': 2, 'CKD Stage 2': 1, 'CKD Stage 1': 0}

... class weights:
{0: 6.344086021505376, 1: 0.74494949494949492, 2: 1.1238095238095238, 3: 7.0238095238095237, 4: 0.51890941072999119, 5: 0.64906490649064907}

====================================================================================================
... early stopping>
       + patience: 20, model='max'
... model training>
       + batch_size: 32, epochs: 60, shuffle? True, metric: auc_roc
====================================================================================================
Train on 1652 samples, validate on 708 samples
Epoch 1/60
1652/1652 [==============================] - 10s 6ms/step - loss: 1.6402 - acc: 0.3057 - auc_roc: 0.6774 - val_loss: 2.1198 - val_acc: 0.3319 - val_auc_roc: 0.6861
Epoch 2/60
1652/1652 [==============================] - 10s 6ms/step - loss: 1.5138 - acc: 0.4304 - auc_roc: 0.7029 - val_loss: 2.0628 - val_acc: 0.2387 - val_auc_roc: 0.6938
Epoch 3/60
1652/1652 [==============================] - 9s 6ms/step - loss: 1.3454 - acc: 0.4467 - auc_roc: 0.6920 - val_loss: 1.5390 - val_acc: 0.6314 - val_auc_roc: 0.7192
Epoch 4/60
1652/1652 [==============================] - 9s 6ms/step - loss: 1.2083 - acc: 0.4988 - auc_roc: 0.7414 - val_loss: 1.4946 - val_acc: 0.6285 - val_auc_roc: 0.7587
Epoch 5/60
1652/1652 [==============================] - 9s 5ms/step - loss: 1.1483 - acc: 0.4933 - auc_roc: 0.7699 - val_loss: 1.5566 - val_acc: 0.6540 - val_auc_roc: 0.7815
Epoch 6/60
1652/1652 [==============================] - 10s 6ms/step - loss: 1.1123 - acc: 0.4994 - auc_roc: 0.7897 - val_loss: 1.9085 - val_acc: 0.2726 - val_auc_roc: 0.7878
Epoch 7/60
1652/1652 [==============================] - 9s 6ms/step - loss: 0.9942 - acc: 0.5642 - auc_roc: 0.7894 - val_loss: 1.5095 - val_acc: 0.5805 - val_auc_roc: 0.7969
Epoch 8/60
1652/1652 [==============================] - 9s 5ms/step - loss: 0.9021 - acc: 0.5926 - auc_roc: 0.8037 - val_loss: 1.9198 - val_acc: 0.4463 - val_auc_roc: 0.8072
Epoch 9/60
1652/1652 [==============================] - 9s 5ms/step - loss: 0.8713 - acc: 0.5847 - auc_roc: 0.8104 - val_loss: 1.5667 - val_acc: 0.6695 - val_auc_roc: 0.8166
Epoch 10/60
1652/1652 [==============================] - 9s 6ms/step - loss: 0.8131 - acc: 0.6253 - auc_roc: 0.8220 - val_loss: 1.6978 - val_acc: 0.6737 - val_auc_roc: 0.8275
Epoch 11/60
1652/1652 [==============================] - 9s 6ms/step - loss: 0.8153 - acc: 0.6126 - auc_roc: 0.8325 - val_loss: 1.9858 - val_acc: 0.3729 - val_auc_roc: 0.8331
Epoch 12/60
1652/1652 [==============================] - 9s 5ms/step - loss: 0.8677 - acc: 0.6047 - auc_roc: 0.8338 - val_loss: 1.8729 - val_acc: 0.5551 - val_auc_roc: 0.8359
Epoch 13/60
1652/1652 [==============================] - 9s 5ms/step - loss: 0.7115 - acc: 0.6689 - auc_roc: 0.8386 - val_loss: 2.0751 - val_acc: 0.6328 - val_auc_roc: 0.8426
Epoch 14/60
1652/1652 [==============================] - 10s 6ms/step - loss: 0.6209 - acc: 0.6840 - auc_roc: 0.8461 - val_loss: 2.1777 - val_acc: 0.5763 - val_auc_roc: 0.8491
Epoch 15/60
1652/1652 [==============================] - 9s 5ms/step - loss: 0.5418 - acc: 0.7288 - auc_roc: 0.8521 - val_loss: 1.9532 - val_acc: 0.6879 - val_auc_roc: 0.8560
Epoch 16/60
1652/1652 [==============================] - 9s 5ms/step - loss: 0.5572 - acc: 0.7591 - auc_roc: 0.8595 - val_loss: 2.1489 - val_acc: 0.6497 - val_auc_roc: 0.8626
Epoch 17/60
1652/1652 [==============================] - 9s 5ms/step - loss: 0.5460 - acc: 0.7458 - auc_roc: 0.8651 - val_loss: 2.3080 - val_acc: 0.6935 - val_auc_roc: 0.8682
Epoch 18/60
1652/1652 [==============================] - 9s 5ms/step - loss: 0.4552 - acc: 0.7869 - auc_roc: 0.8710 - val_loss: 2.2076 - val_acc: 0.5918 - val_auc_roc: 0.8736
Epoch 19/60
1652/1652 [==============================] - 10s 6ms/step - loss: 0.4359 - acc: 0.7821 - auc_roc: 0.8757 - val_loss: 2.0286 - val_acc: 0.6794 - val_auc_roc: 0.8784
Epoch 20/60
1652/1652 [==============================] - 12s 7ms/step - loss: 0.3240 - acc: 0.8354 - auc_roc: 0.8811 - val_loss: 2.2917 - val_acc: 0.6441 - val_auc_roc: 0.8840
Epoch 21/60
1652/1652 [==============================] - 19s 11ms/step - loss: 0.2721 - acc: 0.8656 - auc_roc: 0.8865 - val_loss: 2.3571 - val_acc: 0.6681 - val_auc_roc: 0.8892
Epoch 22/60
1652/1652 [==============================] - 12s 7ms/step - loss: 0.2235 - acc: 0.9038 - auc_roc: 0.8916 - val_loss: 2.6732 - val_acc: 0.7076 - val_auc_roc: 0.8944
Epoch 23/60
1652/1652 [==============================] - 10s 6ms/step - loss: 0.2150 - acc: 0.9038 - auc_roc: 0.8966 - val_loss: 2.7013 - val_acc: 0.6737 - val_auc_roc: 0.8988
Epoch 24/60
1652/1652 [==============================] - 9s 6ms/step - loss: 0.1904 - acc: 0.9122 - auc_roc: 0.9007 - val_loss: 2.7381 - val_acc: 0.6963 - val_auc_roc: 0.9030
Epoch 00024: early stopping
... history of metrics comprising: ['acc', 'loss', 'val_auc_roc', 'auc_roc', 'val_acc', 'val_loss']
... ... metric (acc): [0.72881355932203384, 0.75907990343634213, 0.7457627120087279, 0.78692493946731235, 0.78208232416656343, 0.83535108987702011, 0.86561743312540118, 0.90375302634574017, 0.90375302692302495, 0.91222760290556903] (n=24)
output> saving performance to:
/Users/pleiades/Documents/work/tpheno/seqmaker/data/CKD/plot/model_evalation-ep200b16.tif

... ... metric (loss): [0.54179270648494471, 0.55719920855746141, 0.54604213477335595, 0.45517159273203001, 0.43591316834489025, 0.32403496037672563, 0.27209512849696899, 0.22349356468451226, 0.21497030177358853, 0.1903633599600261] (n=24)
output> saving performance to:
/Users/pleiades/Documents/work/tpheno/seqmaker/data/CKD/plot/model_evalation-ep200b16.tif


model_selection> trying {'n_units': 150, 'dropout_rate': 0.5} ...

make_lstm> n_units=150, r_dropout=0.500000, n_layers=1, n_classes=6
  + lookup:
{'Others': 5, 'CKD Stage 5': 4, 'CKD Stage 4': 3, 'CKD Stage 3': 2, 'CKD Stage 2': 1, 'CKD Stage 1': 0}

... class weights:
{0: 6.344086021505376, 1: 0.74494949494949492, 2: 1.1238095238095238, 3: 7.0238095238095237, 4: 0.51890941072999119, 5: 0.64906490649064907}

====================================================================================================
... early stopping>
       + patience: 20, model='max'
... model training>
       + batch_size: 32, epochs: 60, shuffle? True, metric: auc_roc
====================================================================================================
Train on 1652 samples, validate on 708 samples
Epoch 1/60
1652/1652 [==============================] - 5s 3ms/step - loss: 1.6962 - acc: 0.2488 - auc_roc: 0.5689 - val_loss: 1.6649 - val_acc: 0.5862 - val_auc_roc: 0.6784
Epoch 2/60
1652/1652 [==============================] - 4s 2ms/step - loss: 1.4485 - acc: 0.4467 - auc_roc: 0.7217 - val_loss: 1.3129 - val_acc: 0.6879 - val_auc_roc: 0.7583
Epoch 3/60
1652/1652 [==============================] - 4s 2ms/step - loss: 1.3432 - acc: 0.4425 - auc_roc: 0.7751 - val_loss: 1.6393 - val_acc: 0.4661 - val_auc_roc: 0.7732
Epoch 4/60
1652/1652 [==============================] - 4s 2ms/step - loss: 1.2190 - acc: 0.4709 - auc_roc: 0.7776 - val_loss: 1.6331 - val_acc: 0.4675 - val_auc_roc: 0.7804
Epoch 5/60
1652/1652 [==============================] - 4s 2ms/step - loss: 1.0934 - acc: 0.5212 - auc_roc: 0.7847 - val_loss: 1.6902 - val_acc: 0.5678 - val_auc_roc: 0.7918
Epoch 6/60
1652/1652 [==============================] - 4s 2ms/step - loss: 1.0450 - acc: 0.5623 - auc_roc: 0.7986 - val_loss: 1.7661 - val_acc: 0.6568 - val_auc_roc: 0.8058
Epoch 7/60
1652/1652 [==============================] - 4s 2ms/step - loss: 0.9408 - acc: 0.5575 - auc_roc: 0.8119 - val_loss: 1.5811 - val_acc: 0.7147 - val_auc_roc: 0.8196
Epoch 8/60
1652/1652 [==============================] - 4s 2ms/step - loss: 0.9510 - acc: 0.5418 - auc_roc: 0.8238 - val_loss: 1.7226 - val_acc: 0.7274 - val_auc_roc: 0.8283
Epoch 9/60
1652/1652 [==============================] - 4s 2ms/step - loss: 0.8561 - acc: 0.6035 - auc_roc: 0.8334 - val_loss: 1.4785 - val_acc: 0.6497 - val_auc_roc: 0.8380
Epoch 10/60
1652/1652 [==============================] - 4s 2ms/step - loss: 0.8221 - acc: 0.6223 - auc_roc: 0.8417 - val_loss: 1.8025 - val_acc: 0.6540 - val_auc_roc: 0.8456
Epoch 11/60
1652/1652 [==============================] - 4s 2ms/step - loss: 0.7466 - acc: 0.6459 - auc_roc: 0.8490 - val_loss: 1.7804 - val_acc: 0.6737 - val_auc_roc: 0.8528
Epoch 12/60
1652/1652 [==============================] - 4s 2ms/step - loss: 0.7007 - acc: 0.6634 - auc_roc: 0.8561 - val_loss: 1.8445 - val_acc: 0.6525 - val_auc_roc: 0.8591
Epoch 13/60
1652/1652 [==============================] - 4s 2ms/step - loss: 0.6589 - acc: 0.6653 - auc_roc: 0.8617 - val_loss: 2.2094 - val_acc: 0.6158 - val_auc_roc: 0.8641
Epoch 14/60
1652/1652 [==============================] - 4s 2ms/step - loss: 0.6219 - acc: 0.6937 - auc_roc: 0.8664 - val_loss: 1.9863 - val_acc: 0.6907 - val_auc_roc: 0.8692
Epoch 15/60
1652/1652 [==============================] - 4s 2ms/step - loss: 0.7031 - acc: 0.6580 - auc_roc: 0.8715 - val_loss: 2.0186 - val_acc: 0.5508 - val_auc_roc: 0.8719
Epoch 16/60
1652/1652 [==============================] - 4s 2ms/step - loss: 0.7156 - acc: 0.6604 - auc_roc: 0.8727 - val_loss: 1.8215 - val_acc: 0.6879 - val_auc_roc: 0.8747
Epoch 17/60
1652/1652 [==============================] - 4s 2ms/step - loss: 0.5802 - acc: 0.7203 - auc_roc: 0.8769 - val_loss: 1.9901 - val_acc: 0.7105 - val_auc_roc: 0.8791
Epoch 18/60
1652/1652 [==============================] - 4s 2ms/step - loss: 0.5218 - acc: 0.7452 - auc_roc: 0.8812 - val_loss: 2.1608 - val_acc: 0.7034 - val_auc_roc: 0.8835
Epoch 19/60
1652/1652 [==============================] - 4s 2ms/step - loss: 0.4842 - acc: 0.7682 - auc_roc: 0.8854 - val_loss: 2.3068 - val_acc: 0.7203 - val_auc_roc: 0.8875
Epoch 20/60
1652/1652 [==============================] - 4s 2ms/step - loss: 0.4733 - acc: 0.7645 - auc_roc: 0.8893 - val_loss: 1.9485 - val_acc: 0.6907 - val_auc_roc: 0.8912
Epoch 21/60
1652/1652 [==============================] - 4s 2ms/step - loss: 0.5085 - acc: 0.7561 - auc_roc: 0.8924 - val_loss: 2.2469 - val_acc: 0.6992 - val_auc_roc: 0.8941
Epoch 22/60
1652/1652 [==============================] - 4s 2ms/step - loss: 0.4544 - acc: 0.7724 - auc_roc: 0.8955 - val_loss: 2.3935 - val_acc: 0.6836 - val_auc_roc: 0.8970
Epoch 00022: early stopping
... history of metrics comprising: ['acc', 'loss', 'val_auc_roc', 'auc_roc', 'val_acc', 'val_loss']
... ... metric (acc): [0.66525423714381438, 0.6937046003399403, 0.65799031476997583, 0.66041162198738668, 0.72033898290652632, 0.74515738469925108, 0.76815980600675715, 0.76452784489199843, 0.75605326890945435, 0.77239709457531391] (n=22)
output> saving performance to:
/Users/pleiades/Documents/work/tpheno/seqmaker/data/CKD/plot/model_evalation-ep200b16.tif

... ... metric (loss): [0.65893422676922331, 0.62191187022096017, 0.70309220647696435, 0.71556075490993098, 0.58021539492988128, 0.52178340385381594, 0.48421371748025999, 0.47329723878287805, 0.50850624329530014, 0.4543901067091824] (n=22)
output> saving performance to:
/Users/pleiades/Documents/work/tpheno/seqmaker/data/CKD/plot/model_evalation-ep200b16.tif


model_selection> trying {'n_units': 200, 'dropout_rate': 0.5} ...

make_lstm> n_units=200, r_dropout=0.500000, n_layers=1, n_classes=6
  + lookup:
{'Others': 5, 'CKD Stage 5': 4, 'CKD Stage 4': 3, 'CKD Stage 3': 2, 'CKD Stage 2': 1, 'CKD Stage 1': 0}

... class weights:
{0: 6.344086021505376, 1: 0.74494949494949492, 2: 1.1238095238095238, 3: 7.0238095238095237, 4: 0.51890941072999119, 5: 0.64906490649064907}

====================================================================================================
... early stopping>
       + patience: 20, model='max'
... model training>
       + batch_size: 32, epochs: 60, shuffle? True, metric: auc_roc
====================================================================================================
Train on 1652 samples, validate on 708 samples
Epoch 1/60
1652/1652 [==============================] - 6s 3ms/step - loss: 1.6644 - acc: 0.2942 - auc_roc: 0.5860 - val_loss: 1.5223 - val_acc: 0.6370 - val_auc_roc: 0.7103
Epoch 2/60
1652/1652 [==============================] - 4s 2ms/step - loss: 1.4607 - acc: 0.3874 - auc_roc: 0.7398 - val_loss: 1.9687 - val_acc: 0.2316 - val_auc_roc: 0.7223
Epoch 3/60
1652/1652 [==============================] - 5s 3ms/step - loss: 1.3101 - acc: 0.4504 - auc_roc: 0.7234 - val_loss: 1.7622 - val_acc: 0.5918 - val_auc_roc: 0.7439
Epoch 4/60
1652/1652 [==============================] - 4s 3ms/step - loss: 1.2031 - acc: 0.4994 - auc_roc: 0.7593 - val_loss: 1.4024 - val_acc: 0.7048 - val_auc_roc: 0.7752
Epoch 5/60
1652/1652 [==============================] - 4s 3ms/step - loss: 1.1457 - acc: 0.5139 - auc_roc: 0.7878 - val_loss: 1.7841 - val_acc: 0.4068 - val_auc_roc: 0.7903
Epoch 6/60
1652/1652 [==============================] - 4s 3ms/step - loss: 1.0552 - acc: 0.5369 - auc_roc: 0.7919 - val_loss: 1.6048 - val_acc: 0.5989 - val_auc_roc: 0.8005
Epoch 7/60
1652/1652 [==============================] - 4s 2ms/step - loss: 0.9979 - acc: 0.5551 - auc_roc: 0.8063 - val_loss: 1.6028 - val_acc: 0.4463 - val_auc_roc: 0.8090
Epoch 8/60
1652/1652 [==============================] - 4s 2ms/step - loss: 0.9585 - acc: 0.5660 - auc_roc: 0.8116 - val_loss: 1.6815 - val_acc: 0.6638 - val_auc_roc: 0.8174
Epoch 9/60
1652/1652 [==============================] - 4s 2ms/step - loss: 0.8916 - acc: 0.6102 - auc_roc: 0.8224 - val_loss: 1.4340 - val_acc: 0.7133 - val_auc_roc: 0.8284
Epoch 10/60
1652/1652 [==============================] - 4s 3ms/step - loss: 0.8532 - acc: 0.6138 - auc_roc: 0.8328 - val_loss: 1.6988 - val_acc: 0.6808 - val_auc_roc: 0.8373
Epoch 11/60
1652/1652 [==============================] - 4s 2ms/step - loss: 0.7698 - acc: 0.6386 - auc_roc: 0.8412 - val_loss: 1.5343 - val_acc: 0.7006 - val_auc_roc: 0.8455
Epoch 12/60
1652/1652 [==============================] - 4s 2ms/step - loss: 0.7054 - acc: 0.6471 - auc_roc: 0.8491 - val_loss: 1.9636 - val_acc: 0.6243 - val_auc_roc: 0.8523
Epoch 13/60
1652/1652 [==============================] - 4s 2ms/step - loss: 0.7064 - acc: 0.6665 - auc_roc: 0.8547 - val_loss: 1.8494 - val_acc: 0.7076 - val_auc_roc: 0.8579
Epoch 14/60
1652/1652 [==============================] - 4s 2ms/step - loss: 0.6906 - acc: 0.6659 - auc_roc: 0.8608 - val_loss: 2.0019 - val_acc: 0.6186 - val_auc_roc: 0.8625
Epoch 15/60
1652/1652 [==============================] - 4s 2ms/step - loss: 0.6343 - acc: 0.6937 - auc_roc: 0.8645 - val_loss: 1.8579 - val_acc: 0.7133 - val_auc_roc: 0.8675
Epoch 16/60
1652/1652 [==============================] - 4s 2ms/step - loss: 0.6029 - acc: 0.7191 - auc_roc: 0.8699 - val_loss: 2.0050 - val_acc: 0.6638 - val_auc_roc: 0.8722
Epoch 17/60
1652/1652 [==============================] - 4s 3ms/step - loss: 0.6323 - acc: 0.6967 - auc_roc: 0.8739 - val_loss: 1.9233 - val_acc: 0.6907 - val_auc_roc: 0.8761
Epoch 18/60
1652/1652 [==============================] - 5s 3ms/step - loss: 0.5281 - acc: 0.7470 - auc_roc: 0.8783 - val_loss: 1.9733 - val_acc: 0.7133 - val_auc_roc: 0.8806
Epoch 19/60
1652/1652 [==============================] - 4s 2ms/step - loss: 0.4805 - acc: 0.7657 - auc_roc: 0.8827 - val_loss: 1.9469 - val_acc: 0.7105 - val_auc_roc: 0.8850
Epoch 20/60
1652/1652 [==============================] - 5s 3ms/step - loss: 0.4199 - acc: 0.7960 - auc_roc: 0.8871 - val_loss: 2.4772 - val_acc: 0.7260 - val_auc_roc: 0.8893
Epoch 21/60
1652/1652 [==============================] - 4s 3ms/step - loss: 0.3866 - acc: 0.8160 - auc_roc: 0.8913 - val_loss: 2.4038 - val_acc: 0.7218 - val_auc_roc: 0.8935
Epoch 22/60
1652/1652 [==============================] - 4s 3ms/step - loss: 0.3557 - acc: 0.8220 - auc_roc: 0.8954 - val_loss: 2.2169 - val_acc: 0.7062 - val_auc_roc: 0.8974
Epoch 23/60
1652/1652 [==============================] - 4s 2ms/step - loss: 0.5207 - acc: 0.7791 - auc_roc: 0.8987 - val_loss: 2.1123 - val_acc: 0.7006 - val_auc_roc: 0.9001
Epoch 24/60
1652/1652 [==============================] - 4s 3ms/step - loss: 0.4179 - acc: 0.8111 - auc_roc: 0.9014 - val_loss: 2.1665 - val_acc: 0.6963 - val_auc_roc: 0.9029
Epoch 00024: early stopping
... history of metrics comprising: ['acc', 'loss', 'val_auc_roc', 'auc_roc', 'val_acc', 'val_loss']
... ... metric (acc): [0.69370460019561919, 0.71912832929782078, 0.69673123515547042, 0.74697336590607577, 0.76573849864502508, 0.79600484247069092, 0.81598062968427276, 0.82203389859372711, 0.77905569036128153, 0.81113801423920273] (n=24)
output> saving performance to:
/Users/pleiades/Documents/work/tpheno/seqmaker/data/CKD/plot/model_evalation-ep200b16.tif

... ... metric (loss): [0.63434218364535466, 0.60291874235536513, 0.63225724167454334, 0.5280645447117942, 0.48045533801683793, 0.41989014440240929, 0.38657939542292397, 0.35567315958314022, 0.52066085269318363, 0.41794014814113589] (n=24)
output> saving performance to:
/Users/pleiades/Documents/work/tpheno/seqmaker/data/CKD/plot/model_evalation-ep200b16.tif


model_selection> trying {'n_units': 300, 'dropout_rate': 0.5} ...

make_lstm> n_units=300, r_dropout=0.500000, n_layers=1, n_classes=6
  + lookup:
{'Others': 5, 'CKD Stage 5': 4, 'CKD Stage 4': 3, 'CKD Stage 3': 2, 'CKD Stage 2': 1, 'CKD Stage 1': 0}

... class weights:
{0: 6.344086021505376, 1: 0.74494949494949492, 2: 1.1238095238095238, 3: 7.0238095238095237, 4: 0.51890941072999119, 5: 0.64906490649064907}

====================================================================================================
... early stopping>
       + patience: 20, model='max'
... model training>
       + batch_size: 32, epochs: 60, shuffle? True, metric: auc_roc
====================================================================================================
Train on 1652 samples, validate on 708 samples
Epoch 1/60
1652/1652 [==============================] - 8s 5ms/step - loss: 1.6367 - acc: 0.3033 - auc_roc: 0.6236 - val_loss: 1.4810 - val_acc: 0.5749 - val_auc_roc: 0.7231
Epoch 2/60
1652/1652 [==============================] - 7s 4ms/step - loss: 1.4448 - acc: 0.4262 - auc_roc: 0.7538 - val_loss: 1.6594 - val_acc: 0.5198 - val_auc_roc: 0.7573
Epoch 3/60
1652/1652 [==============================] - 6s 4ms/step - loss: 1.2891 - acc: 0.4764 - auc_roc: 0.7654 - val_loss: 1.3778 - val_acc: 0.6441 - val_auc_roc: 0.7803
Epoch 4/60
1652/1652 [==============================] - 7s 4ms/step - loss: 1.2455 - acc: 0.4933 - auc_roc: 0.7913 - val_loss: 1.5190 - val_acc: 0.6427 - val_auc_roc: 0.7971
Epoch 5/60
1652/1652 [==============================] - 7s 4ms/step - loss: 1.1399 - acc: 0.5236 - auc_roc: 0.8037 - val_loss: 1.4090 - val_acc: 0.5141 - val_auc_roc: 0.8072
Epoch 6/60
1652/1652 [==============================] - 7s 4ms/step - loss: 1.2435 - acc: 0.4274 - auc_roc: 0.8077 - val_loss: 1.6439 - val_acc: 0.2288 - val_auc_roc: 0.7993
Epoch 7/60
1652/1652 [==============================] - 7s 4ms/step - loss: 1.1007 - acc: 0.4879 - auc_roc: 0.7971 - val_loss: 1.7331 - val_acc: 0.3997 - val_auc_roc: 0.7977
Epoch 8/60
1652/1652 [==============================] - 7s 4ms/step - loss: 0.9687 - acc: 0.5617 - auc_roc: 0.8011 - val_loss: 1.6403 - val_acc: 0.5918 - val_auc_roc: 0.8058
Epoch 9/60
1652/1652 [==============================] - 7s 4ms/step - loss: 0.9035 - acc: 0.5884 - auc_roc: 0.8106 - val_loss: 1.5100 - val_acc: 0.6455 - val_auc_roc: 0.8166
Epoch 10/60
1652/1652 [==============================] - 9s 6ms/step - loss: 0.8214 - acc: 0.6132 - auc_roc: 0.8219 - val_loss: 1.6061 - val_acc: 0.6893 - val_auc_roc: 0.8270
Epoch 11/60
1652/1652 [==============================] - 7s 4ms/step - loss: 0.8016 - acc: 0.6132 - auc_roc: 0.8317 - val_loss: 1.8255 - val_acc: 0.5000 - val_auc_roc: 0.8340
Epoch 12/60
1652/1652 [==============================] - 6s 4ms/step - loss: 0.7922 - acc: 0.6186 - auc_roc: 0.8357 - val_loss: 1.7386 - val_acc: 0.6963 - val_auc_roc: 0.8398
Epoch 13/60
1652/1652 [==============================] - 7s 4ms/step - loss: 0.7015 - acc: 0.6622 - auc_roc: 0.8435 - val_loss: 1.8008 - val_acc: 0.7288 - val_auc_roc: 0.8477
Epoch 14/60
1652/1652 [==============================] - 7s 4ms/step - loss: 0.6763 - acc: 0.6689 - auc_roc: 0.8512 - val_loss: 1.7703 - val_acc: 0.7246 - val_auc_roc: 0.8546
Epoch 15/60
1652/1652 [==============================] - 7s 4ms/step - loss: 0.6123 - acc: 0.6985 - auc_roc: 0.8577 - val_loss: 1.9887 - val_acc: 0.5720 - val_auc_roc: 0.8598
Epoch 16/60
1652/1652 [==============================] - 7s 4ms/step - loss: 0.5847 - acc: 0.7028 - auc_roc: 0.8620 - val_loss: 1.9754 - val_acc: 0.6780 - val_auc_roc: 0.8647
Epoch 17/60
1652/1652 [==============================] - 7s 4ms/step - loss: 0.5404 - acc: 0.7312 - auc_roc: 0.8672 - val_loss: 1.9210 - val_acc: 0.6568 - val_auc_roc: 0.8699
Epoch 18/60
1652/1652 [==============================] - 7s 4ms/step - loss: 0.5340 - acc: 0.7312 - auc_roc: 0.8722 - val_loss: 2.0680 - val_acc: 0.7260 - val_auc_roc: 0.8747
Epoch 19/60
1652/1652 [==============================] - 7s 4ms/step - loss: 0.6156 - acc: 0.7034 - auc_roc: 0.8765 - val_loss: 1.9156 - val_acc: 0.6483 - val_auc_roc: 0.8782
Epoch 20/60
1652/1652 [==============================] - 7s 4ms/step - loss: 0.5189 - acc: 0.7494 - auc_roc: 0.8799 - val_loss: 2.1806 - val_acc: 0.7161 - val_auc_roc: 0.8821
Epoch 21/60
1652/1652 [==============================] - 7s 4ms/step - loss: 0.4790 - acc: 0.7700 - auc_roc: 0.8840 - val_loss: 1.9403 - val_acc: 0.7175 - val_auc_roc: 0.8861
Epoch 22/60
1652/1652 [==============================] - 6s 4ms/step - loss: 0.3977 - acc: 0.8111 - auc_roc: 0.8881 - val_loss: 2.3725 - val_acc: 0.7076 - val_auc_roc: 0.8902
Epoch 23/60
1652/1652 [==============================] - 6s 4ms/step - loss: 0.3270 - acc: 0.8444 - auc_roc: 0.8920 - val_loss: 2.3078 - val_acc: 0.6992 - val_auc_roc: 0.8941
Epoch 00023: early stopping
... history of metrics comprising: ['acc', 'loss', 'val_auc_roc', 'auc_roc', 'val_acc', 'val_loss']
... ... metric (acc): [0.66888619883585787, 0.69854721535204689, 0.70278450377628243, 0.73123486668376603, 0.73123486711672947, 0.70338983079711692, 0.74939467326780784, 0.76997578678061829, 0.81113801423920273, 0.84443099244743514] (n=23)
output> saving performance to:
/Users/pleiades/Documents/work/tpheno/seqmaker/data/CKD/plot/model_evalation-ep200b16.tif

... ... metric (loss): [0.67631243187347856, 0.61228978489559438, 0.58468626998815931, 0.54042214443839487, 0.53402482395310669, 0.61564389758768145, 0.51888380428780656, 0.47899976531472105, 0.39770828349826987, 0.32696927214361565] (n=23)
output> saving performance to:
/Users/pleiades/Documents/work/tpheno/seqmaker/data/CKD/plot/model_evalation-ep200b16.tif


model_selection> trying {'n_units': 400, 'dropout_rate': 0.5} ...

make_lstm> n_units=400, r_dropout=0.500000, n_layers=1, n_classes=6
  + lookup:
{'Others': 5, 'CKD Stage 5': 4, 'CKD Stage 4': 3, 'CKD Stage 3': 2, 'CKD Stage 2': 1, 'CKD Stage 1': 0}

... class weights:
{0: 6.344086021505376, 1: 0.74494949494949492, 2: 1.1238095238095238, 3: 7.0238095238095237, 4: 0.51890941072999119, 5: 0.64906490649064907}

====================================================================================================
... early stopping>
       + patience: 20, model='max'
... model training>
       + batch_size: 32, epochs: 60, shuffle? True, metric: auc_roc
====================================================================================================
Train on 1652 samples, validate on 708 samples
Epoch 1/60
1652/1652 [==============================] - 11s 7ms/step - loss: 1.6575 - acc: 0.3208 - auc_roc: 0.6964 - val_loss: 2.0009 - val_acc: 0.1201 - val_auc_roc: 0.6529
Epoch 2/60
1652/1652 [==============================] - 11s 7ms/step - loss: 1.4541 - acc: 0.4243 - auc_roc: 0.6521 - val_loss: 2.0146 - val_acc: 0.3715 - val_auc_roc: 0.6820
Epoch 3/60
1652/1652 [==============================] - 10s 6ms/step - loss: 1.3357 - acc: 0.4485 - auc_roc: 0.6994 - val_loss: 1.7519 - val_acc: 0.4831 - val_auc_roc: 0.7192
Epoch 4/60
1652/1652 [==============================] - 10s 6ms/step - loss: 1.2156 - acc: 0.5127 - auc_roc: 0.7358 - val_loss: 1.9623 - val_acc: 0.6554 - val_auc_roc: 0.7547
Epoch 5/60
1652/1652 [==============================] - 9s 6ms/step - loss: 1.1226 - acc: 0.5327 - auc_roc: 0.7694 - val_loss: 2.0529 - val_acc: 0.3164 - val_auc_roc: 0.7693
Epoch 6/60
1652/1652 [==============================] - 10s 6ms/step - loss: 1.1104 - acc: 0.5315 - auc_roc: 0.7716 - val_loss: 1.8679 - val_acc: 0.3206 - val_auc_roc: 0.7739
Epoch 7/60
1652/1652 [==============================] - 9s 5ms/step - loss: 1.0861 - acc: 0.5315 - auc_roc: 0.7756 - val_loss: 1.8583 - val_acc: 0.4802 - val_auc_roc: 0.7795
Epoch 8/60
1652/1652 [==============================] - 9s 6ms/step - loss: 0.9685 - acc: 0.5599 - auc_roc: 0.7839 - val_loss: 1.6317 - val_acc: 0.6257 - val_auc_roc: 0.7919
Epoch 9/60
1652/1652 [==============================] - 10s 6ms/step - loss: 0.8911 - acc: 0.5866 - auc_roc: 0.7984 - val_loss: 1.7727 - val_acc: 0.6243 - val_auc_roc: 0.8046
Epoch 10/60
1652/1652 [==============================] - 10s 6ms/step - loss: 0.8535 - acc: 0.5938 - auc_roc: 0.8099 - val_loss: 1.8762 - val_acc: 0.6921 - val_auc_roc: 0.8157
Epoch 11/60
1652/1652 [==============================] - 9s 5ms/step - loss: 0.7997 - acc: 0.6538 - auc_roc: 0.8215 - val_loss: 1.7080 - val_acc: 0.7218 - val_auc_roc: 0.8270
Epoch 12/60
1652/1652 [==============================] - 9s 5ms/step - loss: 0.7622 - acc: 0.6453 - auc_roc: 0.8319 - val_loss: 1.7573 - val_acc: 0.6610 - val_auc_roc: 0.8360
Epoch 13/60
1652/1652 [==============================] - 9s 5ms/step - loss: 0.7066 - acc: 0.6477 - auc_roc: 0.8396 - val_loss: 2.2018 - val_acc: 0.5890 - val_auc_roc: 0.8423
Epoch 14/60
1652/1652 [==============================] - 9s 5ms/step - loss: 0.6891 - acc: 0.6598 - auc_roc: 0.8447 - val_loss: 1.8095 - val_acc: 0.6398 - val_auc_roc: 0.8479
Epoch 15/60
1652/1652 [==============================] - 9s 6ms/step - loss: 0.6625 - acc: 0.6762 - auc_roc: 0.8506 - val_loss: 1.8068 - val_acc: 0.6328 - val_auc_roc: 0.8539
Epoch 16/60
1652/1652 [==============================] - 10s 6ms/step - loss: 0.6318 - acc: 0.6961 - auc_roc: 0.8565 - val_loss: 1.6783 - val_acc: 0.7020 - val_auc_roc: 0.8596
Epoch 17/60
1652/1652 [==============================] - 9s 6ms/step - loss: 0.5624 - acc: 0.7149 - auc_roc: 0.8624 - val_loss: 2.0908 - val_acc: 0.7062 - val_auc_roc: 0.8653
Epoch 18/60
1652/1652 [==============================] - 12s 7ms/step - loss: 0.5021 - acc: 0.7597 - auc_roc: 0.8682 - val_loss: 2.0176 - val_acc: 0.6864 - val_auc_roc: 0.8709
Epoch 19/60
1652/1652 [==============================] - 9s 6ms/step - loss: 0.4401 - acc: 0.7900 - auc_roc: 0.8734 - val_loss: 2.2384 - val_acc: 0.6427 - val_auc_roc: 0.8760
Epoch 20/60
1652/1652 [==============================] - 10s 6ms/step - loss: 0.4541 - acc: 0.7833 - auc_roc: 0.8781 - val_loss: 2.3247 - val_acc: 0.7034 - val_auc_roc: 0.8805
Epoch 21/60
1652/1652 [==============================] - 11s 7ms/step - loss: 0.3843 - acc: 0.8123 - auc_roc: 0.8826 - val_loss: 2.3470 - val_acc: 0.6850 - val_auc_roc: 0.8850
Epoch 22/60
1652/1652 [==============================] - 9s 5ms/step - loss: 0.3720 - acc: 0.8432 - auc_roc: 0.8871 - val_loss: 2.3030 - val_acc: 0.6893 - val_auc_roc: 0.8895
Epoch 23/60
1652/1652 [==============================] - 9s 6ms/step - loss: 0.2970 - acc: 0.8584 - auc_roc: 0.8915 - val_loss: 2.6532 - val_acc: 0.6949 - val_auc_roc: 0.8938
Epoch 24/60
1652/1652 [==============================] - 9s 5ms/step - loss: 0.3268 - acc: 0.8469 - auc_roc: 0.8956 - val_loss: 2.7350 - val_acc: 0.6893 - val_auc_roc: 0.8975
Epoch 25/60
1652/1652 [==============================] - 9s 6ms/step - loss: 0.3083 - acc: 0.8596 - auc_roc: 0.8991 - val_loss: 2.4345 - val_acc: 0.6681 - val_auc_roc: 0.9008
Epoch 26/60
1652/1652 [==============================] - 9s 6ms/step - loss: 0.2692 - acc: 0.8795 - auc_roc: 0.9023 - val_loss: 2.3683 - val_acc: 0.6695 - val_auc_roc: 0.9040
Epoch 27/60
1652/1652 [==============================] - 9s 5ms/step - loss: 0.2531 - acc: 0.8820 - auc_roc: 0.9055 - val_loss: 2.3774 - val_acc: 0.7218 - val_auc_roc: 0.9073
Epoch 28/60
1652/1652 [==============================] - 9s 5ms/step - loss: 0.2548 - acc: 0.8941 - auc_roc: 0.9088 - val_loss: 2.6811 - val_acc: 0.7076 - val_auc_roc: 0.9104
Epoch 00028: early stopping
... history of metrics comprising: ['acc', 'loss', 'val_auc_roc', 'auc_roc', 'val_acc', 'val_loss']
... ... metric (acc): [0.78995157356123658, 0.78329297791959007, 0.81234866799222938, 0.84322033869440849, 0.85835351118452607, 0.84685230038645187, 0.85956416436026806, 0.87953995128520757, 0.88196125893558197, 0.89406779632152711] (n=28)
output> saving performance to:
/Users/pleiades/Documents/work/tpheno/seqmaker/data/CKD/plot/model_evalation-ep200b16.tif

... ... metric (loss): [0.44005437310757994, 0.45405742100306917, 0.38426136609717088, 0.37200265213594597, 0.2970206493615527, 0.32682461946408914, 0.30828947579312266, 0.26916506792673478, 0.25306786362253147, 0.25482230649733373] (n=28)
output> saving performance to:
/Users/pleiades/Documents/work/tpheno/seqmaker/data/CKD/plot/model_evalation-ep200b16.tif


model_selection> trying {'n_units': 150, 'dropout_rate': 0.6} ...

make_lstm> n_units=150, r_dropout=0.600000, n_layers=1, n_classes=6
  + lookup:
{'Others': 5, 'CKD Stage 5': 4, 'CKD Stage 4': 3, 'CKD Stage 3': 2, 'CKD Stage 2': 1, 'CKD Stage 1': 0}

... class weights:
{0: 6.344086021505376, 1: 0.74494949494949492, 2: 1.1238095238095238, 3: 7.0238095238095237, 4: 0.51890941072999119, 5: 0.64906490649064907}

====================================================================================================
... early stopping>
       + patience: 20, model='max'
... model training>
       + batch_size: 32, epochs: 60, shuffle? True, metric: auc_roc
====================================================================================================
Train on 1652 samples, validate on 708 samples
Epoch 1/60
1652/1652 [==============================] - 6s 3ms/step - loss: 1.7053 - acc: 0.2373 - auc_roc: 0.5675 - val_loss: 1.8856 - val_acc: 0.1822 - val_auc_roc: 0.6278
Epoch 2/60
1652/1652 [==============================] - 4s 2ms/step - loss: 1.4458 - acc: 0.4134 - auc_roc: 0.6546 - val_loss: 1.4547 - val_acc: 0.4576 - val_auc_roc: 0.6961
Epoch 3/60
1652/1652 [==============================] - 4s 2ms/step - loss: 1.4196 - acc: 0.3995 - auc_roc: 0.7114 - val_loss: 1.5708 - val_acc: 0.5240 - val_auc_roc: 0.7255
Epoch 4/60
1652/1652 [==============================] - 4s 2ms/step - loss: 1.2452 - acc: 0.4831 - auc_roc: 0.7423 - val_loss: 1.3846 - val_acc: 0.5664 - val_auc_roc: 0.7555
Epoch 5/60
1652/1652 [==============================] - 4s 2ms/step - loss: 1.1944 - acc: 0.5157 - auc_roc: 0.7660 - val_loss: 1.5680 - val_acc: 0.5593 - val_auc_roc: 0.7750
Epoch 6/60
1652/1652 [==============================] - 4s 2ms/step - loss: 1.1341 - acc: 0.4927 - auc_roc: 0.7821 - val_loss: 1.3699 - val_acc: 0.5918 - val_auc_roc: 0.7880
Epoch 7/60
1652/1652 [==============================] - 4s 2ms/step - loss: 1.0031 - acc: 0.5654 - auc_roc: 0.7953 - val_loss: 1.5581 - val_acc: 0.6554 - val_auc_roc: 0.8030
Epoch 8/60
1652/1652 [==============================] - 4s 2ms/step - loss: 1.0101 - acc: 0.5654 - auc_roc: 0.8091 - val_loss: 1.5876 - val_acc: 0.5282 - val_auc_roc: 0.8121
Epoch 9/60
1652/1652 [==============================] - 4s 2ms/step - loss: 0.9051 - acc: 0.5866 - auc_roc: 0.8158 - val_loss: 1.5292 - val_acc: 0.7034 - val_auc_roc: 0.8217
Epoch 10/60
1652/1652 [==============================] - 4s 2ms/step - loss: 0.8988 - acc: 0.5751 - auc_roc: 0.8260 - val_loss: 1.9817 - val_acc: 0.6709 - val_auc_roc: 0.8302
Epoch 11/60
1652/1652 [==============================] - 4s 2ms/step - loss: 0.8668 - acc: 0.5981 - auc_roc: 0.8341 - val_loss: 1.6754 - val_acc: 0.6582 - val_auc_roc: 0.8374
Epoch 12/60
1652/1652 [==============================] - 4s 2ms/step - loss: 0.7961 - acc: 0.6265 - auc_roc: 0.8407 - val_loss: 1.5664 - val_acc: 0.6780 - val_auc_roc: 0.8441
Epoch 13/60
1652/1652 [==============================] - 4s 2ms/step - loss: 0.7521 - acc: 0.6404 - auc_roc: 0.8472 - val_loss: 1.5261 - val_acc: 0.6822 - val_auc_roc: 0.8506
Epoch 14/60
1652/1652 [==============================] - 4s 2ms/step - loss: 0.7378 - acc: 0.6326 - auc_roc: 0.8529 - val_loss: 1.8962 - val_acc: 0.6808 - val_auc_roc: 0.8559
Epoch 15/60
1652/1652 [==============================] - 4s 2ms/step - loss: 0.7931 - acc: 0.6344 - auc_roc: 0.8584 - val_loss: 2.3059 - val_acc: 0.2599 - val_auc_roc: 0.8559
Epoch 16/60
1652/1652 [==============================] - 4s 2ms/step - loss: 0.8376 - acc: 0.5847 - auc_roc: 0.8541 - val_loss: 1.8888 - val_acc: 0.5833 - val_auc_roc: 0.8554
Epoch 17/60
1652/1652 [==============================] - 4s 2ms/step - loss: 0.7157 - acc: 0.6398 - auc_roc: 0.8567 - val_loss: 1.8152 - val_acc: 0.6427 - val_auc_roc: 0.8586
Epoch 18/60
1652/1652 [==============================] - 4s 2ms/step - loss: 0.6571 - acc: 0.6755 - auc_roc: 0.8602 - val_loss: 1.6942 - val_acc: 0.6836 - val_auc_roc: 0.8625
Epoch 19/60
1652/1652 [==============================] - 4s 2ms/step - loss: 0.6044 - acc: 0.6852 - auc_roc: 0.8646 - val_loss: 1.9327 - val_acc: 0.6638 - val_auc_roc: 0.8666
Epoch 20/60
1652/1652 [==============================] - 4s 2ms/step - loss: 0.5597 - acc: 0.7234 - auc_roc: 0.8685 - val_loss: 2.4573 - val_acc: 0.4689 - val_auc_roc: 0.8695
Epoch 21/60
1652/1652 [==============================] - 4s 2ms/step - loss: 0.6134 - acc: 0.6840 - auc_roc: 0.8700 - val_loss: 1.9642 - val_acc: 0.6257 - val_auc_roc: 0.8714
Epoch 22/60
1652/1652 [==============================] - 4s 2ms/step - loss: 0.5250 - acc: 0.7355 - auc_roc: 0.8730 - val_loss: 2.1908 - val_acc: 0.6638 - val_auc_roc: 0.8749
Epoch 23/60
1652/1652 [==============================] - 4s 2ms/step - loss: 0.4738 - acc: 0.7651 - auc_roc: 0.8766 - val_loss: 2.2702 - val_acc: 0.6653 - val_auc_roc: 0.8785
Epoch 24/60
1652/1652 [==============================] - 4s 2ms/step - loss: 0.4458 - acc: 0.7851 - auc_roc: 0.8801 - val_loss: 2.2439 - val_acc: 0.6864 - val_auc_roc: 0.8820
Epoch 25/60
1652/1652 [==============================] - 4s 2ms/step - loss: 0.4463 - acc: 0.7785 - auc_roc: 0.8835 - val_loss: 2.1956 - val_acc: 0.6992 - val_auc_roc: 0.8853
Epoch 26/60
1652/1652 [==============================] - 4s 2ms/step - loss: 0.4844 - acc: 0.7803 - auc_roc: 0.8867 - val_loss: 2.3605 - val_acc: 0.6879 - val_auc_roc: 0.8882
Epoch 00026: early stopping
... history of metrics comprising: ['acc', 'loss', 'val_auc_roc', 'auc_roc', 'val_acc', 'val_loss']
... ... metric (acc): [0.63983050861889745, 0.67554479418886193, 0.68523002406875388, 0.72336561714477166, 0.68401937074869079, 0.73547215525232279, 0.76513317162419059, 0.78510895898209354, 0.7784503629074836, 0.78026634368134473] (n=26)
output> saving performance to:
/Users/pleiades/Documents/work/tpheno/seqmaker/data/CKD/plot/model_evalation-ep200b16.tif

... ... metric (loss): [0.71566293199183573, 0.65713703127230627, 0.60439158034382379, 0.559749939251177, 0.61336775235921936, 0.52495834584963519, 0.47378811088658995, 0.4458262550917434, 0.4463124262218614, 0.48443404554454811] (n=26)
output> saving performance to:
/Users/pleiades/Documents/work/tpheno/seqmaker/data/CKD/plot/model_evalation-ep200b16.tif


model_selection> trying {'n_units': 200, 'dropout_rate': 0.6} ...

make_lstm> n_units=200, r_dropout=0.600000, n_layers=1, n_classes=6
  + lookup:
{'Others': 5, 'CKD Stage 5': 4, 'CKD Stage 4': 3, 'CKD Stage 3': 2, 'CKD Stage 2': 1, 'CKD Stage 1': 0}

... class weights:
{0: 6.344086021505376, 1: 0.74494949494949492, 2: 1.1238095238095238, 3: 7.0238095238095237, 4: 0.51890941072999119, 5: 0.64906490649064907}

====================================================================================================
... early stopping>
       + patience: 20, model='max'
... model training>
       + batch_size: 32, epochs: 60, shuffle? True, metric: auc_roc
====================================================================================================
Train on 1652 samples, validate on 708 samples
Epoch 1/60
1652/1652 [==============================] - 6s 4ms/step - loss: 1.7081 - acc: 0.2609 - auc_roc: 0.5982 - val_loss: 1.8551 - val_acc: 0.3220 - val_auc_roc: 0.6385
Epoch 2/60
1652/1652 [==============================] - 4s 3ms/step - loss: 1.4800 - acc: 0.4268 - auc_roc: 0.6684 - val_loss: 1.7687 - val_acc: 0.5452 - val_auc_roc: 0.7079
Epoch 3/60
1652/1652 [==============================] - 4s 3ms/step - loss: 1.2899 - acc: 0.4740 - auc_roc: 0.7321 - val_loss: 1.7384 - val_acc: 0.4520 - val_auc_roc: 0.7453
Epoch 4/60
1652/1652 [==============================] - 4s 2ms/step - loss: 1.2410 - acc: 0.4758 - auc_roc: 0.7529 - val_loss: 1.4948 - val_acc: 0.6455 - val_auc_roc: 0.7661
Epoch 5/60
1652/1652 [==============================] - 4s 3ms/step - loss: 1.1933 - acc: 0.4812 - auc_roc: 0.7769 - val_loss: 1.9496 - val_acc: 0.3828 - val_auc_roc: 0.7761
Epoch 6/60
1652/1652 [==============================] - 4s 3ms/step - loss: 1.1096 - acc: 0.5230 - auc_roc: 0.7783 - val_loss: 1.8100 - val_acc: 0.4124 - val_auc_roc: 0.7828
Epoch 7/60
1652/1652 [==============================] - 4s 2ms/step - loss: 1.0088 - acc: 0.5442 - auc_roc: 0.7863 - val_loss: 1.4676 - val_acc: 0.5508 - val_auc_roc: 0.7939
Epoch 8/60
1652/1652 [==============================] - 4s 2ms/step - loss: 0.9662 - acc: 0.5787 - auc_roc: 0.7996 - val_loss: 1.6319 - val_acc: 0.5791 - val_auc_roc: 0.8059
Epoch 9/60
1652/1652 [==============================] - 4s 2ms/step - loss: 0.9161 - acc: 0.5914 - auc_roc: 0.8103 - val_loss: 1.6352 - val_acc: 0.6737 - val_auc_roc: 0.8164
Epoch 10/60
1652/1652 [==============================] - 4s 2ms/step - loss: 0.9068 - acc: 0.5690 - auc_roc: 0.8206 - val_loss: 1.7640 - val_acc: 0.7006 - val_auc_roc: 0.8252
Epoch 11/60
1652/1652 [==============================] - 4s 2ms/step - loss: 0.8163 - acc: 0.6211 - auc_roc: 0.8296 - val_loss: 1.9836 - val_acc: 0.6992 - val_auc_roc: 0.8341
Epoch 12/60
1652/1652 [==============================] - 4s 2ms/step - loss: 0.8177 - acc: 0.5884 - auc_roc: 0.8374 - val_loss: 1.8661 - val_acc: 0.6031 - val_auc_roc: 0.8395
Epoch 13/60
1652/1652 [==============================] - 4s 2ms/step - loss: 0.7597 - acc: 0.6344 - auc_roc: 0.8420 - val_loss: 1.8368 - val_acc: 0.6582 - val_auc_roc: 0.8452
Epoch 14/60
1652/1652 [==============================] - 4s 2ms/step - loss: 0.6835 - acc: 0.6580 - auc_roc: 0.8484 - val_loss: 2.0327 - val_acc: 0.6907 - val_auc_roc: 0.8517
Epoch 15/60
1652/1652 [==============================] - 4s 2ms/step - loss: 0.7223 - acc: 0.6519 - auc_roc: 0.8545 - val_loss: 2.0763 - val_acc: 0.4915 - val_auc_roc: 0.8554
Epoch 16/60
1652/1652 [==============================] - 4s 2ms/step - loss: 0.7432 - acc: 0.6344 - auc_roc: 0.8564 - val_loss: 2.0127 - val_acc: 0.6059 - val_auc_roc: 0.8582
Epoch 17/60
1652/1652 [==============================] - 4s 2ms/step - loss: 0.6805 - acc: 0.6646 - auc_roc: 0.8600 - val_loss: 2.1510 - val_acc: 0.6342 - val_auc_roc: 0.8621
Epoch 18/60
1652/1652 [==============================] - 4s 2ms/step - loss: 0.6094 - acc: 0.6846 - auc_roc: 0.8640 - val_loss: 2.4039 - val_acc: 0.6356 - val_auc_roc: 0.8660
Epoch 19/60
1652/1652 [==============================] - 4s 2ms/step - loss: 0.6119 - acc: 0.7040 - auc_roc: 0.8676 - val_loss: 2.2882 - val_acc: 0.6709 - val_auc_roc: 0.8698
Epoch 20/60
1652/1652 [==============================] - 4s 2ms/step - loss: 0.5824 - acc: 0.7197 - auc_roc: 0.8718 - val_loss: 2.2779 - val_acc: 0.6328 - val_auc_roc: 0.8734
Epoch 21/60
1652/1652 [==============================] - 4s 2ms/step - loss: 0.5812 - acc: 0.7300 - auc_roc: 0.8749 - val_loss: 2.1596 - val_acc: 0.6638 - val_auc_roc: 0.8768
Epoch 22/60
1652/1652 [==============================] - 4s 2ms/step - loss: 0.5262 - acc: 0.7306 - auc_roc: 0.8783 - val_loss: 2.1042 - val_acc: 0.7203 - val_auc_roc: 0.8803
Epoch 23/60
1652/1652 [==============================] - 4s 2ms/step - loss: 0.4727 - acc: 0.7633 - auc_roc: 0.8821 - val_loss: 2.1844 - val_acc: 0.6879 - val_auc_roc: 0.8840
Epoch 24/60
1652/1652 [==============================] - 4s 2ms/step - loss: 0.4120 - acc: 0.7972 - auc_roc: 0.8857 - val_loss: 2.4873 - val_acc: 0.6977 - val_auc_roc: 0.8877
Epoch 25/60
1652/1652 [==============================] - 4s 2ms/step - loss: 0.4261 - acc: 0.7851 - auc_roc: 0.8890 - val_loss: 2.5375 - val_acc: 0.6836 - val_auc_roc: 0.8908
Epoch 26/60
1652/1652 [==============================] - 4s 2ms/step - loss: 0.4150 - acc: 0.8057 - auc_roc: 0.8922 - val_loss: 2.4246 - val_acc: 0.7133 - val_auc_roc: 0.8938
Epoch 27/60
1652/1652 [==============================] - 4s 2ms/step - loss: 0.4025 - acc: 0.8202 - auc_roc: 0.8952 - val_loss: 2.3568 - val_acc: 0.7076 - val_auc_roc: 0.8968
Epoch 00027: early stopping
... history of metrics comprising: ['acc', 'loss', 'val_auc_roc', 'auc_roc', 'val_acc', 'val_loss']
... ... metric (acc): [0.68462469719224062, 0.70399515738498786, 0.71973365603001294, 0.73002421321938171, 0.73062953980725265, 0.76331719113897178, 0.79721549636803879, 0.78510895898209354, 0.80569007278354632, 0.82021791738690242] (n=27)
output> saving performance to:
/Users/pleiades/Documents/work/tpheno/seqmaker/data/CKD/plot/model_evalation-ep200b16.tif

... ... metric (loss): [0.60943337971881284, 0.61187656840746973, 0.58243111822276084, 0.58124270407397294, 0.52619221799310123, 0.47268361690257998, 0.41196744551670178, 0.42611901025506543, 0.41498474094827298, 0.40247803551232841] (n=27)
output> saving performance to:
/Users/pleiades/Documents/work/tpheno/seqmaker/data/CKD/plot/model_evalation-ep200b16.tif


model_selection> trying {'n_units': 300, 'dropout_rate': 0.6} ...

make_lstm> n_units=300, r_dropout=0.600000, n_layers=1, n_classes=6
  + lookup:
{'Others': 5, 'CKD Stage 5': 4, 'CKD Stage 4': 3, 'CKD Stage 3': 2, 'CKD Stage 2': 1, 'CKD Stage 1': 0}

... class weights:
{0: 6.344086021505376, 1: 0.74494949494949492, 2: 1.1238095238095238, 3: 7.0238095238095237, 4: 0.51890941072999119, 5: 0.64906490649064907}

====================================================================================================
... early stopping>
       + patience: 20, model='max'
... model training>
       + batch_size: 32, epochs: 60, shuffle? True, metric: auc_roc
====================================================================================================
Train on 1652 samples, validate on 708 samples
Epoch 1/60
1652/1652 [==============================] - 8s 5ms/step - loss: 1.6416 - acc: 0.3396 - auc_roc: 0.6607 - val_loss: 1.7552 - val_acc: 0.5184 - val_auc_roc: 0.7159
Epoch 2/60
1652/1652 [==============================] - 7s 4ms/step - loss: 1.4207 - acc: 0.4364 - auc_roc: 0.7274 - val_loss: 1.5321 - val_acc: 0.5876 - val_auc_roc: 0.7566
Epoch 3/60
1652/1652 [==============================] - 7s 4ms/step - loss: 1.2952 - acc: 0.4818 - auc_roc: 0.7734 - val_loss: 1.5581 - val_acc: 0.5141 - val_auc_roc: 0.7799
Epoch 4/60
1652/1652 [==============================] - 6s 4ms/step - loss: 1.2470 - acc: 0.5018 - auc_roc: 0.7851 - val_loss: 1.4447 - val_acc: 0.6102 - val_auc_roc: 0.7934
Epoch 5/60
1652/1652 [==============================] - 6s 4ms/step - loss: 1.1922 - acc: 0.5073 - auc_roc: 0.7999 - val_loss: 1.5928 - val_acc: 0.6822 - val_auc_roc: 0.8082
Epoch 6/60
1652/1652 [==============================] - 6s 4ms/step - loss: 1.0385 - acc: 0.5224 - auc_roc: 0.8146 - val_loss: 1.3750 - val_acc: 0.6992 - val_auc_roc: 0.8213
Epoch 7/60
1652/1652 [==============================] - 6s 4ms/step - loss: 1.0118 - acc: 0.5303 - auc_roc: 0.8264 - val_loss: 1.5231 - val_acc: 0.6130 - val_auc_roc: 0.8295
Epoch 8/60
1652/1652 [==============================] - 6s 4ms/step - loss: 0.9698 - acc: 0.5660 - auc_roc: 0.8331 - val_loss: 1.4881 - val_acc: 0.6638 - val_auc_roc: 0.8367
Epoch 9/60
1652/1652 [==============================] - 6s 4ms/step - loss: 0.8892 - acc: 0.6084 - auc_roc: 0.8408 - val_loss: 1.7022 - val_acc: 0.6130 - val_auc_roc: 0.8441
Epoch 10/60
1652/1652 [==============================] - 6s 4ms/step - loss: 0.8412 - acc: 0.6096 - auc_roc: 0.8468 - val_loss: 1.6472 - val_acc: 0.6822 - val_auc_roc: 0.8503
Epoch 11/60
1652/1652 [==============================] - 6s 4ms/step - loss: 0.7900 - acc: 0.6320 - auc_roc: 0.8532 - val_loss: 2.0207 - val_acc: 0.4082 - val_auc_roc: 0.8535
Epoch 12/60
1652/1652 [==============================] - 6s 4ms/step - loss: 0.7888 - acc: 0.6205 - auc_roc: 0.8535 - val_loss: 1.6770 - val_acc: 0.6342 - val_auc_roc: 0.8556
Epoch 13/60
1652/1652 [==============================] - 6s 4ms/step - loss: 0.7165 - acc: 0.6525 - auc_roc: 0.8577 - val_loss: 1.7966 - val_acc: 0.6667 - val_auc_roc: 0.8606
Epoch 14/60
1652/1652 [==============================] - 6s 4ms/step - loss: 0.6359 - acc: 0.6883 - auc_roc: 0.8633 - val_loss: 1.7264 - val_acc: 0.7119 - val_auc_roc: 0.8666
Epoch 15/60
1652/1652 [==============================] - 7s 4ms/step - loss: 0.6034 - acc: 0.6979 - auc_roc: 0.8692 - val_loss: 1.7609 - val_acc: 0.6879 - val_auc_roc: 0.8720
Epoch 16/60
1652/1652 [==============================] - 6s 4ms/step - loss: 0.6298 - acc: 0.7022 - auc_roc: 0.8740 - val_loss: 1.9314 - val_acc: 0.7274 - val_auc_roc: 0.8764
Epoch 17/60
1652/1652 [==============================] - 7s 4ms/step - loss: 0.6646 - acc: 0.7022 - auc_roc: 0.8783 - val_loss: 2.0441 - val_acc: 0.7062 - val_auc_roc: 0.8802
Epoch 18/60
1652/1652 [==============================] - 6s 4ms/step - loss: 0.6270 - acc: 0.7149 - auc_roc: 0.8820 - val_loss: 1.8151 - val_acc: 0.7048 - val_auc_roc: 0.8840
Epoch 19/60
1652/1652 [==============================] - 6s 4ms/step - loss: 0.6831 - acc: 0.6816 - auc_roc: 0.8852 - val_loss: 1.9086 - val_acc: 0.6751 - val_auc_roc: 0.8864
Epoch 20/60
1652/1652 [==============================] - 6s 4ms/step - loss: 0.5235 - acc: 0.7627 - auc_roc: 0.8877 - val_loss: 1.8149 - val_acc: 0.6766 - val_auc_roc: 0.8894
Epoch 21/60
1652/1652 [==============================] - 6s 4ms/step - loss: 0.4739 - acc: 0.7718 - auc_roc: 0.8907 - val_loss: 2.0931 - val_acc: 0.7288 - val_auc_roc: 0.8927
Epoch 22/60
1652/1652 [==============================] - 6s 4ms/step - loss: 0.4279 - acc: 0.7918 - auc_roc: 0.8943 - val_loss: 2.2658 - val_acc: 0.6582 - val_auc_roc: 0.8960
Epoch 23/60
1652/1652 [==============================] - 6s 4ms/step - loss: 0.3642 - acc: 0.8196 - auc_roc: 0.8973 - val_loss: 2.2951 - val_acc: 0.7218 - val_auc_roc: 0.8992
Epoch 24/60
1652/1652 [==============================] - 6s 4ms/step - loss: 0.3071 - acc: 0.8414 - auc_roc: 0.9008 - val_loss: 1.9536 - val_acc: 0.7119 - val_auc_roc: 0.9027
Epoch 25/60
1652/1652 [==============================] - 8s 5ms/step - loss: 0.3004 - acc: 0.8571 - auc_roc: 0.9043 - val_loss: 2.0617 - val_acc: 0.7062 - val_auc_roc: 0.9060
Epoch 26/60
1652/1652 [==============================] - 12s 7ms/step - loss: 0.2654 - acc: 0.8765 - auc_roc: 0.9074 - val_loss: 2.1751 - val_acc: 0.7260 - val_auc_roc: 0.9091
Epoch 00026: early stopping
... history of metrics comprising: ['acc', 'loss', 'val_auc_roc', 'auc_roc', 'val_acc', 'val_loss']
... ... metric (acc): [0.70217917675544794, 0.71489104087358524, 0.6815980632426375, 0.76271186426245852, 0.77179176755447942, 0.79176755462374004, 0.8196125909433527, 0.84140435820918968, 0.8571428571428571, 0.87651331690264089] (n=26)
output> saving performance to:
/Users/pleiades/Documents/work/tpheno/seqmaker/data/CKD/plot/model_evalation-ep200b16.tif

... ... metric (loss): [0.66463585446879592, 0.62699987813289171, 0.68314510713766619, 0.52353479613980713, 0.47385287638437951, 0.42789616206656356, 0.36422145186267235, 0.30709722259287109, 0.30037788934915466, 0.26540137762451865] (n=26)
output> saving performance to:
/Users/pleiades/Documents/work/tpheno/seqmaker/data/CKD/plot/model_evalation-ep200b16.tif


model_selection> trying {'n_units': 400, 'dropout_rate': 0.6} ...

make_lstm> n_units=400, r_dropout=0.600000, n_layers=1, n_classes=6
  + lookup:
{'Others': 5, 'CKD Stage 5': 4, 'CKD Stage 4': 3, 'CKD Stage 3': 2, 'CKD Stage 2': 1, 'CKD Stage 1': 0}

... class weights:
{0: 6.344086021505376, 1: 0.74494949494949492, 2: 1.1238095238095238, 3: 7.0238095238095237, 4: 0.51890941072999119, 5: 0.64906490649064907}

====================================================================================================
... early stopping>
       + patience: 20, model='max'
... model training>
       + batch_size: 32, epochs: 60, shuffle? True, metric: auc_roc
====================================================================================================
Train on 1652 samples, validate on 708 samples
Epoch 1/60
1652/1652 [==============================] - 12s 7ms/step - loss: 1.6769 - acc: 0.2918 - auc_roc: 0.6229 - val_loss: 1.7559 - val_acc: 0.3785 - val_auc_roc: 0.6805
Epoch 2/60
1652/1652 [==============================] - 10s 6ms/step - loss: 1.4398 - acc: 0.4473 - auc_roc: 0.6947 - val_loss: 1.5040 - val_acc: 0.5042 - val_auc_roc: 0.7285
Epoch 3/60
1652/1652 [==============================] - 10s 6ms/step - loss: 1.3467 - acc: 0.4758 - auc_roc: 0.7440 - val_loss: 1.6775 - val_acc: 0.5579 - val_auc_roc: 0.7590
Epoch 4/60
1652/1652 [==============================] - 9s 6ms/step - loss: 1.2399 - acc: 0.5109 - auc_roc: 0.7703 - val_loss: 1.3526 - val_acc: 0.6314 - val_auc_roc: 0.7819
Epoch 5/60
1652/1652 [==============================] - 9s 6ms/step - loss: 1.1967 - acc: 0.4958 - auc_roc: 0.7913 - val_loss: 1.4393 - val_acc: 0.6031 - val_auc_roc: 0.7962
Epoch 6/60
1652/1652 [==============================] - 10s 6ms/step - loss: 1.0914 - acc: 0.5375 - auc_roc: 0.8015 - val_loss: 1.7772 - val_acc: 0.5254 - val_auc_roc: 0.8052
Epoch 7/60
1652/1652 [==============================] - 9s 5ms/step - loss: 1.0926 - acc: 0.5139 - auc_roc: 0.8089 - val_loss: 1.6382 - val_acc: 0.5268 - val_auc_roc: 0.8118
Epoch 8/60
1652/1652 [==============================] - 9s 5ms/step - loss: 1.0017 - acc: 0.5442 - auc_roc: 0.8153 - val_loss: 1.6329 - val_acc: 0.6271 - val_auc_roc: 0.8198
Epoch 9/60
1652/1652 [==============================] - 9s 5ms/step - loss: 0.9479 - acc: 0.5732 - auc_roc: 0.8236 - val_loss: 1.7457 - val_acc: 0.5282 - val_auc_roc: 0.8265
Epoch 10/60
1652/1652 [==============================] - 9s 5ms/step - loss: 0.8494 - acc: 0.6029 - auc_roc: 0.8290 - val_loss: 1.7056 - val_acc: 0.6737 - val_auc_roc: 0.8334
Epoch 11/60
1652/1652 [==============================] - 9s 5ms/step - loss: 0.7787 - acc: 0.6295 - auc_roc: 0.8375 - val_loss: 2.2552 - val_acc: 0.5056 - val_auc_roc: 0.8396
Epoch 12/60
1652/1652 [==============================] - 10s 6ms/step - loss: 0.7310 - acc: 0.6453 - auc_roc: 0.8414 - val_loss: 2.0907 - val_acc: 0.6709 - val_auc_roc: 0.8453
Epoch 13/60
1652/1652 [==============================] - 9s 6ms/step - loss: 0.6807 - acc: 0.6731 - auc_roc: 0.8487 - val_loss: 2.0620 - val_acc: 0.5904 - val_auc_roc: 0.8517
Epoch 14/60
1652/1652 [==============================] - 9s 5ms/step - loss: 0.7089 - acc: 0.6889 - auc_roc: 0.8541 - val_loss: 1.9889 - val_acc: 0.6398 - val_auc_roc: 0.8568
Epoch 15/60
1652/1652 [==============================] - 9s 5ms/step - loss: 0.6525 - acc: 0.6877 - auc_roc: 0.8590 - val_loss: 1.8846 - val_acc: 0.6879 - val_auc_roc: 0.8621
Epoch 16/60
1652/1652 [==============================] - 9s 6ms/step - loss: 0.5952 - acc: 0.7076 - auc_roc: 0.8648 - val_loss: 2.1521 - val_acc: 0.6794 - val_auc_roc: 0.8676
Epoch 17/60
1652/1652 [==============================] - 9s 5ms/step - loss: 0.5412 - acc: 0.7337 - auc_roc: 0.8701 - val_loss: 2.2342 - val_acc: 0.6879 - val_auc_roc: 0.8730
Epoch 18/60
1652/1652 [==============================] - 9s 6ms/step - loss: 0.4693 - acc: 0.7676 - auc_roc: 0.8753 - val_loss: 2.3408 - val_acc: 0.6879 - val_auc_roc: 0.8780
Epoch 19/60
1652/1652 [==============================] - 9s 5ms/step - loss: 0.4431 - acc: 0.7857 - auc_roc: 0.8803 - val_loss: 2.0835 - val_acc: 0.6582 - val_auc_roc: 0.8827
Epoch 20/60
1652/1652 [==============================] - 9s 5ms/step - loss: 0.4216 - acc: 0.8039 - auc_roc: 0.8846 - val_loss: 2.2218 - val_acc: 0.6723 - val_auc_roc: 0.8869
Epoch 21/60
1652/1652 [==============================] - 9s 5ms/step - loss: 0.3487 - acc: 0.8438 - auc_roc: 0.8890 - val_loss: 2.4973 - val_acc: 0.7034 - val_auc_roc: 0.8913
Epoch 22/60
1652/1652 [==============================] - 9s 5ms/step - loss: 0.3687 - acc: 0.8208 - auc_roc: 0.8931 - val_loss: 2.2658 - val_acc: 0.6285 - val_auc_roc: 0.8949
Epoch 23/60
1652/1652 [==============================] - 9s 5ms/step - loss: 0.3115 - acc: 0.8680 - auc_roc: 0.8964 - val_loss: 2.5527 - val_acc: 0.7034 - val_auc_roc: 0.8985
Epoch 24/60
1652/1652 [==============================] - 9s 5ms/step - loss: 0.3160 - acc: 0.8668 - auc_roc: 0.9001 - val_loss: 2.4941 - val_acc: 0.7175 - val_auc_roc: 0.9020
Epoch 00024: early stopping
... history of metrics comprising: ['acc', 'loss', 'val_auc_roc', 'auc_roc', 'val_acc', 'val_loss']
... ... metric (acc): [0.68765133186344951, 0.70762711893271013, 0.73365617433414043, 0.76755447970752855, 0.78571428585860692, 0.80387409229832762, 0.84382566614820653, 0.82082324440773691, 0.8680387407757757, 0.86682808716707027] (n=24)
output> saving performance to:
/Users/pleiades/Documents/work/tpheno/seqmaker/data/CKD/plot/model_evalation-ep200b16.tif

... ... metric (loss): [0.6525012803135426, 0.59517667989176637, 0.54116995412558677, 0.46933560813021719, 0.4430769793057846, 0.42162720487423727, 0.34867693249307591, 0.3686638704656689, 0.31148723099768594, 0.31596878910613119] (n=24)
output> saving performance to:
/Users/pleiades/Documents/work/tpheno/seqmaker/data/CKD/plot/model_evalation-ep200b16.tif

result> performance scores ...

... performance ranking (n_models:16 -> 12):
[({'n_units': 300, 'dropout_rate': 0.6}, 0.4637162615759321, 1.5789965561818844), ({'n_units': 200, 'dropout_rate': 0.5}, 0.49787817506466875, 1.6104363833780344), ({'n_units': 200, 'dropout_rate': 0.3}, 0.44546664072872649, 1.7445764852084877), ({'n_units': 400, 'dropout_rate': 0.6}, 0.4467684529703696, 1.8259168843656806), ({'n_units': 300, 'dropout_rate': 0.3}, 0.43193211652536945, 1.9305930369714748), ({'n_units': 150, 'dropout_rate': 0.3}, 0.35868127425776269, 1.9405152771540759), ({'n_units': 400, 'dropout_rate': 0.3}, 0.37610761261845044, 1.9646630217000252), ({'n_units': 150, 'dropout_rate': 0.2}, 0.43716583630796207, 1.968964247110873), ({'n_units': 200, 'dropout_rate': 0.2}, 0.28529161725003838, 2.0904259901599023), ({'n_units': 400, 'dropout_rate': 0.2}, 0.36085644149679247, 2.0925850749268369), ({'n_units': 400, 'dropout_rate': 0.5}, 0.33595657950091307, 2.1103119955693548), ({'n_units': 300, 'dropout_rate': 0.2}, 0.23020110443667408, 2.3938893715859275)]

... under metric (loss), best score: 0.463716, gap: 1.578997
... model config: {'n_units': 300, 'dropout_rate': 0.6}

... performance ranking (n_models:16 -> 6):
[({'n_units': 150, 'dropout_rate': 0.3}, 0.83426150116735731, 0.15205811133684888), ({'n_units': 400, 'dropout_rate': 0.3}, 0.82233656175777359, 0.15312752220975101), ({'n_units': 400, 'dropout_rate': 0.5}, 0.84491525406410273, 0.15776836140873551), ({'n_units': 400, 'dropout_rate': 0.2}, 0.82621065381075509, 0.16138014533617884), ({'n_units': 200, 'dropout_rate': 0.2}, 0.86676755440725839, 0.18060936231686275), ({'n_units': 300, 'dropout_rate': 0.2}, 0.90217917669771952, 0.20387409195195672)]

... under metric (acc), best score: 0.834262, gap: 0.152058
... model config: {'n_units': 150, 'dropout_rate': 0.3}

... performance ranking (n_models:16 -> 16):
[({'n_units': 150, 'dropout_rate': 0.3}, 0.90433925124692571, 0.0016049227423972079), ({'n_units': 150, 'dropout_rate': 0.6}, 0.87198341783253386, 0.0017568504935412399), ({'n_units': 300, 'dropout_rate': 0.6}, 0.89280114254709009, 0.0017570873775051288), ({'n_units': 200, 'dropout_rate': 0.6}, 0.88009239293761166, 0.001839724031545531), ({'n_units': 150, 'dropout_rate': 0.5}, 0.87930177157208078, 0.0019390716727842872), ({'n_units': 200, 'dropout_rate': 0.2}, 0.90514466752440226, 0.0020417900408729039), ({'n_units': 400, 'dropout_rate': 0.5}, 0.89240995821594904, 0.0020643909002524552), ({'n_units': 300, 'dropout_rate': 0.2}, 0.9089871503250363, 0.0021310112185780605), ({'n_units': 200, 'dropout_rate': 0.5}, 0.88432438291302606, 0.0021362341874254787), ({'n_units': 150, 'dropout_rate': 0.2}, 0.89027017503616024, 0.0022336407858484231), ({'n_units': 300, 'dropout_rate': 0.3}, 0.88936048512308707, 0.0023188617414193757), ({'n_units': 300, 'dropout_rate': 0.5}, 0.87307909823791741, 0.0023581779368758715), ({'n_units': 200, 'dropout_rate': 0.3}, 0.88446383974165388, 0.0023980453574338201), ({'n_units': 400, 'dropout_rate': 0.2}, 0.88972329224570323, 0.0024259535606298011), ({'n_units': 400, 'dropout_rate': 0.6}, 0.88128524402440611, 0.0024296860573655987), ({'n_units': 400, 'dropout_rate': 0.3}, 0.87801142015988254, 0.0028234719797137764)]

... under metric (auc_roc), best score: 0.904339, gap: 0.001605
... model config: {'n_units': 150, 'dropout_rate': 0.3}

result> popular 10 model (out of 13 metric-neutral options with topN=5) ...
  + (n_selected=2) model: (('n_units', 150), ('dropout_rate', 0.3))
  + (n_selected=2) model: (('n_units', 300), ('dropout_rate', 0.6))
  + (n_selected=1) model: (('n_units', 150), ('dropout_rate', 0.6))
  + (n_selected=1) model: (('n_units', 400), ('dropout_rate', 0.2))
  + (n_selected=1) model: (('n_units', 200), ('dropout_rate', 0.5))
  + (n_selected=1) model: (('n_units', 300), ('dropout_rate', 0.3))
  + (n_selected=1) model: (('n_units', 200), ('dropout_rate', 0.6))
  + (n_selected=1) model: (('n_units', 400), ('dropout_rate', 0.5))
  + (n_selected=1) model: (('n_units', 200), ('dropout_rate', 0.3))
  + (n_selected=1) model: (('n_units', 150), ('dropout_rate', 0.5))
result> best configuration:
{'n_units': 300, 'dropout_rate': 0.6}

model_select> opt model:
{'n_units': 300, 'dropout_rate': 0.6}

make_lstm> n_units=300, r_dropout=0.600000, n_layers=1, n_classes=6
... classifier name: Sequential
runROCMulticlass> test set ratio: 0.300000
modelEvaluate> dim(X_train):(1651, 50, 100), dim(X_test): (709, 50, 100)
  + lookup:
{'Others': 5, 'CKD Stage 5': 4, 'CKD Stage 4': 3, 'CKD Stage 3': 2, 'CKD Stage 2': 1, 'CKD Stage 1': 0}

... class weights:
{0: 6.344086021505376, 1: 0.74494949494949492, 2: 1.1238095238095238, 3: 7.0238095238095237, 4: 0.51890941072999119, 5: 0.64906490649064907}

====================================================================================================
... early stopping>
       + patience: 20, model='max'
... model training>
       + batch_size: 32, epochs: 80, shuffle? True, metric: auc_roc
====================================================================================================
Epoch 1/80
1651/1651 [==============================] - 7s 4ms/step - loss: 1.7298 - acc: 0.3053 - auc_roc: 0.6058  
/Users/pleiades/anaconda2/lib/python2.7/site-packages/keras/callbacks.py:526: RuntimeWarning:

Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: acc,loss,auc_roc

Epoch 2/80
1651/1651 [==============================] - 6s 3ms/step - loss: 1.5277 - acc: 0.4064 - auc_roc: 0.6809
Epoch 3/80
1651/1651 [==============================] - 5s 3ms/step - loss: 1.3535 - acc: 0.4634 - auc_roc: 0.7300
Epoch 4/80
1651/1651 [==============================] - 6s 3ms/step - loss: 1.2114 - acc: 0.5300 - auc_roc: 0.7596
Epoch 5/80
1651/1651 [==============================] - 5s 3ms/step - loss: 1.1079 - acc: 0.5554 - auc_roc: 0.7826
Epoch 6/80
1651/1651 [==============================] - 5s 3ms/step - loss: 1.0284 - acc: 0.5942 - auc_roc: 0.8027
Epoch 7/80
1651/1651 [==============================] - 5s 3ms/step - loss: 0.9545 - acc: 0.6105 - auc_roc: 0.8169
Epoch 8/80
1651/1651 [==============================] - 5s 3ms/step - loss: 0.9602 - acc: 0.6148 - auc_roc: 0.8288
Epoch 9/80
1651/1651 [==============================] - 5s 3ms/step - loss: 0.8409 - acc: 0.6439 - auc_roc: 0.8390
Epoch 10/80
1651/1651 [==============================] - 5s 3ms/step - loss: 0.8019 - acc: 0.6566 - auc_roc: 0.8482
Epoch 11/80
1651/1651 [==============================] - 6s 3ms/step - loss: 0.7269 - acc: 0.6772 - auc_roc: 0.8569
Epoch 12/80
1651/1651 [==============================] - 5s 3ms/step - loss: 0.7394 - acc: 0.6675 - auc_roc: 0.8630
Epoch 13/80
1651/1651 [==============================] - 5s 3ms/step - loss: 0.6232 - acc: 0.7250 - auc_roc: 0.8699
Epoch 14/80
1651/1651 [==============================] - 5s 3ms/step - loss: 0.6371 - acc: 0.6941 - auc_roc: 0.8772
Epoch 15/80
1651/1651 [==============================] - 5s 3ms/step - loss: 0.6656 - acc: 0.6856 - auc_roc: 0.8809
Epoch 16/80
1651/1651 [==============================] - 5s 3ms/step - loss: 0.5738 - acc: 0.7341 - auc_roc: 0.8848
Epoch 17/80
1651/1651 [==============================] - 5s 3ms/step - loss: 0.4910 - acc: 0.7771 - auc_roc: 0.8904
Epoch 18/80
1651/1651 [==============================] - 5s 3ms/step - loss: 0.4070 - acc: 0.8025 - auc_roc: 0.8961
Epoch 19/80
1651/1651 [==============================] - 5s 3ms/step - loss: 0.5072 - acc: 0.7704 - auc_roc: 0.9013
Epoch 20/80
1651/1651 [==============================] - 6s 3ms/step - loss: 0.4273 - acc: 0.7959 - auc_roc: 0.9055
Epoch 21/80
1651/1651 [==============================] - 5s 3ms/step - loss: 0.3329 - acc: 0.8407 - auc_roc: 0.9101
Epoch 22/80
1651/1651 [==============================] - 5s 3ms/step - loss: 0.3677 - acc: 0.8340 - auc_roc: 0.9145
Epoch 23/80
1651/1651 [==============================] - 5s 3ms/step - loss: 0.3224 - acc: 0.8528 - auc_roc: 0.9184
Epoch 24/80
1651/1651 [==============================] - 5s 3ms/step - loss: 0.3115 - acc: 0.8643 - auc_roc: 0.9223
Epoch 25/80
1651/1651 [==============================] - 5s 3ms/step - loss: 0.2915 - acc: 0.8674 - auc_roc: 0.9257
Epoch 26/80
1651/1651 [==============================] - 5s 3ms/step - loss: 0.2268 - acc: 0.8940 - auc_roc: 0.9293
Epoch 27/80
1651/1651 [==============================] - 5s 3ms/step - loss: 0.1814 - acc: 0.9219 - auc_roc: 0.9329
Epoch 28/80
1651/1651 [==============================] - 6s 4ms/step - loss: 0.1547 - acc: 0.9340 - auc_roc: 0.9364
Epoch 29/80
1651/1651 [==============================] - 7s 4ms/step - loss: 0.1988 - acc: 0.9188 - auc_roc: 0.9397
Epoch 30/80
1651/1651 [==============================] - 7s 4ms/step - loss: 0.2208 - acc: 0.9055 - auc_roc: 0.9423
Epoch 31/80
1651/1651 [==============================] - 6s 4ms/step - loss: 0.1349 - acc: 0.9425 - auc_roc: 0.9450
Epoch 32/80
1651/1651 [==============================] - 7s 4ms/step - loss: 0.0968 - acc: 0.9631 - auc_roc: 0.9477
Epoch 33/80
1651/1651 [==============================] - 5s 3ms/step - loss: 0.0994 - acc: 0.9649 - auc_roc: 0.9504
Epoch 34/80
1651/1651 [==============================] - 6s 3ms/step - loss: 0.1223 - acc: 0.9503 - auc_roc: 0.9527
Epoch 35/80
1651/1651 [==============================] - 6s 4ms/step - loss: 0.0780 - acc: 0.9679 - auc_roc: 0.9549
Epoch 36/80
1651/1651 [==============================] - 6s 3ms/step - loss: 0.0480 - acc: 0.9836 - auc_roc: 0.9571
Epoch 37/80
1651/1651 [==============================] - 5s 3ms/step - loss: 0.0361 - acc: 0.9849 - auc_roc: 0.9592
Epoch 38/80
1651/1651 [==============================] - 5s 3ms/step - loss: 0.0467 - acc: 0.9849 - auc_roc: 0.9612
Epoch 39/80
1651/1651 [==============================] - 5s 3ms/step - loss: 0.0502 - acc: 0.9849 - auc_roc: 0.9630
Epoch 40/80
1651/1651 [==============================] - 5s 3ms/step - loss: 0.1629 - acc: 0.9534 - auc_roc: 0.9646
Epoch 41/80
1651/1651 [==============================] - 5s 3ms/step - loss: 0.3034 - acc: 0.8946 - auc_roc: 0.9656
Epoch 42/80
1651/1651 [==============================] - 5s 3ms/step - loss: 0.1760 - acc: 0.9388 - auc_roc: 0.9666
Epoch 43/80
1651/1651 [==============================] - 5s 3ms/step - loss: 0.1035 - acc: 0.9631 - auc_roc: 0.9676
Epoch 44/80
1651/1651 [==============================] - 5s 3ms/step - loss: 0.0602 - acc: 0.9788 - auc_roc: 0.9688
Epoch 45/80
1651/1651 [==============================] - 5s 3ms/step - loss: 0.0337 - acc: 0.9879 - auc_roc: 0.9701
Epoch 46/80
1651/1651 [==============================] - 5s 3ms/step - loss: 0.0276 - acc: 0.9921 - auc_roc: 0.9713
Epoch 47/80
1651/1651 [==============================] - 5s 3ms/step - loss: 0.0877 - acc: 0.9691 - auc_roc: 0.9724
Epoch 48/80
1651/1651 [==============================] - 5s 3ms/step - loss: 0.1123 - acc: 0.9624 - auc_roc: 0.9732
Epoch 49/80
1651/1651 [==============================] - 5s 3ms/step - loss: 0.0538 - acc: 0.9836 - auc_roc: 0.9741
Epoch 50/80
1651/1651 [==============================] - 5s 3ms/step - loss: 0.0258 - acc: 0.9945 - auc_roc: 0.9750
Epoch 51/80
1651/1651 [==============================] - 5s 3ms/step - loss: 0.0435 - acc: 0.9867 - auc_roc: 0.9759
Epoch 52/80
1651/1651 [==============================] - 5s 3ms/step - loss: 0.0631 - acc: 0.9818 - auc_roc: 0.9767
Epoch 53/80
1651/1651 [==============================] - 5s 3ms/step - loss: 0.1462 - acc: 0.9425 - auc_roc: 0.9773
Epoch 54/80
1651/1651 [==============================] - 5s 3ms/step - loss: 0.0682 - acc: 0.9758 - auc_roc: 0.9779
Epoch 55/80
1651/1651 [==============================] - 5s 3ms/step - loss: 0.0295 - acc: 0.9903 - auc_roc: 0.9786
Epoch 56/80
1651/1651 [==============================] - 5s 3ms/step - loss: 0.0189 - acc: 0.9952 - auc_roc: 0.9793
Epoch 57/80
1651/1651 [==============================] - 5s 3ms/step - loss: 0.0177 - acc: 0.9945 - auc_roc: 0.9800
Epoch 58/80
1651/1651 [==============================] - 5s 3ms/step - loss: 0.0171 - acc: 0.9952 - auc_roc: 0.9807
Epoch 59/80
1651/1651 [==============================] - 6s 4ms/step - loss: 0.0139 - acc: 0.9958 - auc_roc: 0.9813
Epoch 60/80
1651/1651 [==============================] - 5s 3ms/step - loss: 0.0070 - acc: 1.0000 - auc_roc: 0.9819
Epoch 61/80
1651/1651 [==============================] - 5s 3ms/step - loss: 0.0066 - acc: 0.9994 - auc_roc: 0.9825
Epoch 62/80
1651/1651 [==============================] - 5s 3ms/step - loss: 0.0762 - acc: 0.9679 - auc_roc: 0.9830
Epoch 63/80
1651/1651 [==============================] - 5s 3ms/step - loss: 0.1458 - acc: 0.9352 - auc_roc: 0.9833
Epoch 64/80
1651/1651 [==============================] - 5s 3ms/step - loss: 0.0674 - acc: 0.9752 - auc_roc: 0.9836
Epoch 65/80
1651/1651 [==============================] - 5s 3ms/step - loss: 0.0692 - acc: 0.9758 - auc_roc: 0.9840
Epoch 66/80
1651/1651 [==============================] - 5s 3ms/step - loss: 0.1920 - acc: 0.9273 - auc_roc: 0.9843
Epoch 67/80
1651/1651 [==============================] - 5s 3ms/step - loss: 0.2364 - acc: 0.9164 - auc_roc: 0.9845
Epoch 68/80
1651/1651 [==============================] - 5s 3ms/step - loss: 0.1362 - acc: 0.9473 - auc_roc: 0.9846
Epoch 69/80
1651/1651 [==============================] - 5s 3ms/step - loss: 0.0472 - acc: 0.9861 - auc_roc: 0.9850
Epoch 70/80
1651/1651 [==============================] - 5s 3ms/step - loss: 0.0367 - acc: 0.9879 - auc_roc: 0.9853
Epoch 71/80
1651/1651 [==============================] - 5s 3ms/step - loss: 0.0201 - acc: 0.9939 - auc_roc: 0.9857
Epoch 72/80
1651/1651 [==============================] - 5s 3ms/step - loss: 0.0159 - acc: 0.9970 - auc_roc: 0.9861
Epoch 73/80
1651/1651 [==============================] - 6s 4ms/step - loss: 0.0154 - acc: 0.9939 - auc_roc: 0.9864
Epoch 74/80
1651/1651 [==============================] - 6s 3ms/step - loss: 0.0391 - acc: 0.9849 - auc_roc: 0.9867
Epoch 75/80
1651/1651 [==============================] - 5s 3ms/step - loss: 0.0172 - acc: 0.9945 - auc_roc: 0.9870
Epoch 76/80
1651/1651 [==============================] - 5s 3ms/step - loss: 0.0134 - acc: 0.9952 - auc_roc: 0.9874
Epoch 77/80
1651/1651 [==============================] - 5s 3ms/step - loss: 0.0073 - acc: 0.9994 - auc_roc: 0.9877
Epoch 78/80
1651/1651 [==============================] - 5s 3ms/step - loss: 0.0054 - acc: 0.9994 - auc_roc: 0.9880
Epoch 79/80
1651/1651 [==============================] - 5s 3ms/step - loss: 0.0075 - acc: 0.9970 - auc_roc: 0.9883
Epoch 80/80
1651/1651 [==============================] - 5s 3ms/step - loss: 0.0054 - acc: 0.9994 - auc_roc: 0.9885
... history of metrics comprising: ['acc', 'loss', 'auc_roc']
... model fitting complete > starting model evaluation
modelEvaluate> scores:
[('loss', 2.5464601323365827), ('acc', 0.60084626250946305), ('auc_roc', 0.98821616946221746)]

info> infer classifier name from class name ...
runROCMulticlass> find 6 unique labels:
CKD Stage 1, CKD Stage 2, CKD Stage 3, CKD Stage 4, CKD Stage 5, Others

info> given pre-trained model ...
diagnosis> dim(y_score):(709, 6)
>>> test_auc_cv_metrics >>>
  + dimension test 
  + len(roc_auc):8 =?= n_classes (+{micro, macro}):6+2
  + class name: CKD Stage 1, mean_auc: 0.793523
  + ROC curve of class CKD Stage 1 (area = 0.79)
  + class name: CKD Stage 2, mean_auc: 0.754819
  + ROC curve of class CKD Stage 2 (area = 0.75)
  + class name: CKD Stage 3, mean_auc: 0.740550
  + ROC curve of class CKD Stage 3 (area = 0.74)
  + class name: CKD Stage 4, mean_auc: 0.671223
  + ROC curve of class CKD Stage 4 (area = 0.67)
  + class name: CKD Stage 5, mean_auc: 0.954272
  + ROC curve of class CKD Stage 5 (area = 0.95)
  + class name: Others, mean_auc: 0.810847
  + ROC curve of class Others (area = 0.81)
test_auc_cv_metrics> summary of AUCs vs classes ...
  + min | class=CKD Stage 4, auc=0.671223
  + max | class=CKD Stage 5, auc=0.954272
  + micro auc=0.853024 | macro auc=0.788785
  + Ranked AUC scores: 
    + class=CKD Stage 4, auc=0.671223
    + class=CKD Stage 3, auc=0.740550
    + class=CKD Stage 2, auc=0.754819
    + class=CKD Stage 1, auc=0.793523
    + class=Others, auc=0.810847
    + class=CKD Stage 5, auc=0.954272
  => [('CKD Stage 4', 0.67122302158273384), ('CKD Stage 3', 0.74054982817869408), ('CKD Stage 2', 0.75481862666268462), ('CKD Stage 1', 0.79352261135668134), ('Others', 0.81084691561790811), ('CKD Stage 5', 0.95427215472176119)]
output> saving performance to:
/Users/pleiades/Documents/work/tpheno/seqmaker/data/CKD/plot/roc-multiclass-Sequential-CKD-pv-dm2-regular-smallCKD.tif

Traceback (most recent call last):
  File "dnn_utils.py", line 2621, in <module>
    test2()
  File "dnn_utils.py", line 2608, in test2
    last_n_visits=tset['last_n_visits'])
  File "dnn_utils.py", line 2384, in t_deep_classify
    save_model=True, n_trials=nTrials, target_metric=targetMetric)   
  File "dnn_utils.py", line 1281, in modelEvaluateBatch
    model = reinitialize_weights(model)
  File "dnn_utils.py", line 1920, in reinitialize_weights
    new_weights = [glorot_uniform()(w.shape).eval() for w in initial_weights]
  File "/Users/pleiades/anaconda2/lib/python2.7/site-packages/tensorflow/python/framework/ops.py", line 710, in eval
    return _eval_using_default_session(self, feed_dict, self.graph, session)
  File "/Users/pleiades/anaconda2/lib/python2.7/site-packages/tensorflow/python/framework/ops.py", line 5166, in _eval_using_default_session
    raise ValueError("Cannot evaluate tensor using `eval()`: No default "
ValueError: Cannot evaluate tensor using `eval()`: No default session is registered. Use `with sess.as_default()` or pass an explicit session to `eval(session=sess)`
pleiades@~/Documents/work/tpheno/seqmaker\:) python dnn_utils.py 
Using TensorFlow backend.
config> d2v: pv-dm2, user descriptor (model, tset, mcs): smallCKD
        cohort: CKD, ctype: regular
            + augmented? False, simplified? False dir_type=combined
check> sysConfig complete ... meta? smallCKD
load_data> inputs:
['/Users/pleiades/Documents/work/tpheno/seqmaker/data/CKD/condition_drug_labeled_seq-CKD.csv']

================================================================================
1. Read temporal doc files ...
================================================================================
loadDocuments> input files: ['/Users/pleiades/Documents/work/tpheno/seqmaker/data/CKD/condition_drug_labeled_seq-CKD.csv']
readDocFromCSV> input files: ['/Users/pleiades/Documents/work/tpheno/seqmaker/data/CKD/condition_drug_labeled_seq-CKD.csv']
read> reading from 1 source files:
['/Users/pleiades/Documents/work/tpheno/seqmaker/data/CKD/condition_drug_labeled_seq-CKD.csv']

read> processing header sequence ...
read> processing header timestamp ...
read> processing header label ...
    + labels (converted to single-label format, n=11): ['CKD G1-control' 'CKD G1A1-control' 'CKD Stage 1' 'CKD Stage 2'
 'CKD Stage 3a' 'CKD Stage 3b' 'CKD Stage 4' 'CKD Stage 5'
 'ESRD after transplant' 'ESRD on dialysis' 'Unknown']
seqReaderApp.load> nD: 2833, nT: 2833, nL: 2833
  + Stats: n_docs: 2833, n_classes:11 | cohort: CKD
processDocuments> Begin document transformation operations (e.g. simplify, diag-only, etc)
filterDocuments> Policy: Remove empty documents ...
transformDocuments> nD: 2833 (<- 2833), nT: 2833, nL: 2833
  + Stats: n_docs: 2833, n_classes:11
transformDocuments2> nD: 2360, nT: 2360, nL: 2360
  + Stats: n_docs: 2360, n_classes:11 | cohort: ?
    + (after transform) nDoc: 2833 -> 2360, size(D0): 16 -> 16
    + (after transform) nD: 2360, nT: 2360, nL: 2360
  + nD: 2360 | cohort=CKD, ctype=regular, labeled? True, simplified? False
  + doc(last 150 chars):
['203.00', '285.9', 'V68.9', 'V58.11', 'V58.89', 'V70.7', '174.9', '203.00', '285.9', 'V68.9', 'V58.11', 'V58.89', 'V70.7', '174.9', 'V76.12', '573.9', '401.9', '203.00', '285.9', 'V68.9', 'V58.11', 'V58.89', 'V70.7', '174.9', '203.00', '285.9', 'V68.9', 'V58.11', 'V58.89', 'V70.7', '174.9', '203.00', '285.9', 'V68.9', 'V58.11', 'V58.89', 'V70.7', '174.9', 'MED:62439', 'MED:62936', '203.00', '285.9', 'V68.9', 'V58.11', 'V58.89', 'V70.7', '174.9', '203.00', '285.9', 'V68.9', 'V58.11', 'V58.89', 'V70.7', '174.9', '203.00', '285.9', 'V68.9', 'V58.11', 'V58.89', 'V70.7', '174.9', 'MED:62439', 'MED:62791', 'MED:62936', '203.00', '285.9', 'V68.9', 'V58.11', 'V58.89', 'V70.7', '174.9', '203.00', '285.9', 'V68.9', 'V58.11', 'V58.89', 'V70.7', '174.9', '203.00', '518.89', '203.00', '285.9', 'V68.9', 'V58.11', 'V58.89', 'V70.7', '174.9', '203.00', 'MED:62936', '203.00', '238.6', '289.9', 'MED:94350', 'MED:62062', '203.00', '285.9', 'V70.0', 'V68.9', 'V58.11', 'V58.89', 'V70.7', '174.9', '203.00', '285.9', 'V68.9', 'V58.11', 'V58.89', 'V70.7', '174.9', '203.00', '285.9', 'V68.9', 'V58.11', 'V58.89', 'V70.7', '174.9', '203.00', '285.9', 'V68.9', 'V58.11', 'V58.89', 'V70.7', '174.9', 'B18.1', 'C90.00', 'NDC:00247024100', '203.00', 'Z12.11', '203.00', 'B18.1', '070.32', 'C90.00', 'NDC:00247200402', 'NDC:00378001801', 'NDC:62107002726', 'NDC:00247024100', 'NDC:60258018201', 'J98.4', 'J18.9', 'C90.00', '203.00', 'B18.1', '070.32', 'C90.00', 'R06.00', 'V67.59', 'Z09', '786.09', 'NDC:00378459610', 'C90.00']

  + vdoc
    + ['203.00', '285.9', 'V68.9', 'V58.11', 'V58.89', 'V70.7', '174.9']
    + ['B18.1', 'C90.00', 'NDC:00247024100']
    + ['203.00']
    + ['Z12.11']
    + ['203.00', 'B18.1', '070.32', 'C90.00', 'NDC:00247200402', 'NDC:00378001801', 'NDC:62107002726', 'NDC:00247024100', 'NDC:60258018201']
    + ['J98.4']
    + ['J18.9']
    + ['C90.00']
    + ['203.00', 'B18.1', '070.32', 'C90.00', 'R06.00', 'V67.59', 'Z09', '786.09', 'NDC:00378459610']
    + ['C90.00']
  + doc(last 150 chars):
['599.0', '401.9', '272.0', '599.0', '272.0', '272.0', '789.00', '272.0', '428.0', '272.0', '272.0', '424.0', '401.9', '599.0', '183.0', '272.0', '427.31', '424.0', 'V58.69', '424.0', '174.9', '244.9', '424.1', '627.2', '183.0', '783.9', '786.2', '424.0', '782.3', 'V76.12', '627.2', '624.8', '783.21', '401.9', '272.0', '599.0', 'V76.12', '783.21', 'V58.69', '424.0', '401.9', '272.0', '627.3', '626.3', 'V76.12', '424.0', '272.4', 'V72.83', '424.0', 'V58.69', '424.0', '401.9', '272.0', '424.0', '401.9', '374.00', '786.2', 'V58.69', '424.0', '280.9', '530.10', '578.9', '578.1', '578.9', '578.9', '280.9', '578.9', 'V58.69', '578.9', '578.9', '280.9', '211.3', '562.10', '578.9', '153.4', '578.1', 'V58.69', '424.0', '195.2', '153.4', '197.0', '560.1', '424.0', '153.6', '280.9', 'MED:71905', 'MED:67463', 'MED:61951', 'MED:61982', 'MED:61064', 'MED:81318', 'MED:62013', 'MED:61311', 'MED:62961', '153.9', '153.9', '153.9', '153.9', 'V10.05', '786.59', '785.1', '424.0', 'MED:81318', 'MED:63089', 'MED:61951', 'MED:61982', 'MED:60723', '153.9', '287.5', '153.9', '287.9', '153.9', '153.9', '153.9', '153.9', 'V04.81', '153.9', 'MED:104282', 'V76.51', 'V10.05', 'V45.3', '562.10', 'V58.69', '424.0', '272.4', '153.9', '153.9', '153.9', 'V58.69', '272.0', '153.9', '153.9', 'V04.81', '153.9', 'MED:62511', 'V58.69', '424.0', '272.4', '153.9', '153.9', '153.9', '153.9', '153.9', '153.9', '153.9', '153.9', 'V58.69', '153.9', '427.9', '272.4']

  + vdoc
    + ['V58.69', '424.0', '272.4']
    + ['153.9']
    + ['153.9']
    + ['153.9']
    + ['153.9']
    + ['153.9']
    + ['153.9']
    + ['153.9']
    + ['153.9']
    + ['V58.69', '153.9', '427.9', '272.4']
  + doc(last 150 chars):
['719.96', '719.96', '719.96', '719.96', '719.96', '786.59', '726.0', '726.0', '726.0', '726.0', '726.0', '726.0', 'unknown', '995.91', '250.00', '507.0', '427.31', '427.89', '401.9', '427.5']

  + vdoc
    + ['719.96']
    + ['719.96']
    + ['786.59']
    + ['726.0']
    + ['726.0']
    + ['726.0']
    + ['726.0']
    + ['726.0']
    + ['726.0']
    + ['unknown', '995.91', '250.00', '507.0', '427.31', '427.89', '401.9', '427.5']
  + doc(last 150 chars):
['780.6', '411.1', '401.9', '294.1', '401.9', '294.8', '331.9', '331.0', '300.9', '294.8', '781.9', '820.8', '298.9', '707.09', '507.0', '518.82', '518.81', '294.10', '351.0', '331.0', '285.9', 'MED:60924', 'MED:60723', 'MED:61836', 'MED:60875', 'MED:71905', 'MED:61697']

  + vdoc
    + ['780.6', '411.1', '401.9', '294.1']
    + ['401.9', '294.8', '331.9', '331.0', '300.9']
    + ['294.8']
    + ['781.9']
    + ['820.8']
    + ['298.9']
    + ['707.09', '507.0', '518.82', '518.81', '294.10', '351.0', '331.0', '285.9', 'MED:60924', 'MED:60723', 'MED:61836', 'MED:60875']
    + ['MED:71905']
    + ['MED:61697']
  + doc(last 150 chars):
['276.51', '285.9', 'MED:63156', 'MED:61765', 'MED:62439', 'MED:61939', 'MED:61112', 'MED:60582', 'MED:61124', 'MED:60798', 'MED:62111', 'MED:122364', 'MED:101650', 'MED:62934', 'MED:60704', 'MED:62453', 'MED:62987', 'MED:70402', 'MED:63089', 'MULTUM:5432', 'MULTUM:2036', 'MULTUM:1095', 'NDC:68387053730', 'NDC:55289098130', 'MULTUM:3050', 'MULTUM:2391', 'NDC:64764045126', 'MED:62934', 'MULTUM:1095', 'NDC:55289098130', 'NDC:55887046630', 'MULTUM:2036', 'NDC:68387053730', 'NDC:64764045126', 'MULTUM:2391', 'MULTUM:3050', 'MULTUM:608', 'NDC:68180051703', 'MED:60518', '780.79', 'V15.82', '250.00', '401.9', '331.0', '783.7', 'V12.54', 'MED:61522', 'MED:60582', 'MED:63156', 'MED:62439', 'MED:70402', 'MED:62608', 'MED:61124', 'MED:60798', 'MED:61765', 'MED:61112', 'MED:60518', 'MED:104282', 'MED:122364', 'MED:106359', 'MED:101650', 'MED:60704', 'MED:61895', 'MED:61889', 'MED:62608', 'MED:63465', 'MED:62337', 'MED:62111', 'MED:63220', 'MED:62337', 'MED:63220', 'MULTUM:2201', 'V62.4', '562.10', '255.9', '250.00', '437.0', '401.9', '287.5', '438.9', '276.51', '365.89', '276.8', '783.7', '290.40', '311', '276.0', 'MED:61522', 'MED:62439', 'MED:63098', 'MED:63156', 'MED:61895', 'MED:69488', 'MED:61124', 'MED:60798', 'MED:63465', 'MED:60518', 'MED:62111', 'MED:104282', 'MED:62934', 'MED:60704', 'MED:70402', 'MED:61124', 'MED:104282', 'MED:62934', 'MED:61264', 'MED:61437', 'Rolling_Walker', 'MED:61264', 'MED:61309', 'MED:63156', 'MED:61124', 'MED:60798', 'MED:60518', 'MED:62094', 'MED:63098', 'MED:60704', 'MED:63220', 'MED:62453', 'MED:70402', 'MED:63528', 'MED:63098', 'MED:61309', 'MED:69886', 'MED:62934', 'MED:62934', 'MED:81328', 'MED:63199', 'NDC:00052010730', 'NDC:00049496030', 'NDC:00113041178', 'Megace_200mg', 'MULTUM:2200', 'MED:61692', 'MED:63098', 'MED:71459', 'MED:98290', 'MED:61692', 'MED:60884', 'MED:60669', 'MED:62934', 'MED:61692', 'MED:62439', 'MED:61836', 'MED:61692', 'MED:61836', 'MED:60884', 'MED:68339', 'NDC:00143127001', 'MULTUM:2201']

  + vdoc
    + ['MED:63528', 'MED:63098']
    + ['MED:61309', 'MED:69886', 'MED:62934']
    + ['MED:62934']
    + ['MED:81328']
    + ['MED:63199', 'NDC:00052010730', 'NDC:00049496030', 'NDC:00113041178', 'Megace_200mg', 'MULTUM:2200']
    + ['MED:61692', 'MED:63098', 'MED:71459', 'MED:98290']
    + ['MED:61692', 'MED:60884', 'MED:60669', 'MED:62934']
    + ['MED:61692', 'MED:62439', 'MED:61836']
    + ['MED:61692', 'MED:61836', 'MED:60884', 'MED:68339']
    + ['NDC:00143127001', 'MULTUM:2201']
  + doc(last 150 chars):
['389.9', '389.2', '381.01', '719.91', '719.91', '367.4', '719.91', '999999', '410.91', '411.1', '426.3', '786.50', '814.00', '813.81']

  + vdoc
    + ['389.9']
    + ['389.2']
    + ['381.01']
    + ['719.91']
    + ['719.91']
    + ['367.4']
    + ['719.91']
    + ['999999', '410.91', '411.1', '426.3']
    + ['786.50']
    + ['814.00', '813.81']
  + doc(last 150 chars):
['782.1', '366.9', '366.8', '780.79', '401.9', '272.0', '585.3', '729.81', '729.5', 'NDC:00182180989', 'V58.66', '733.00', '427.31', '401.9', '272.4', 'MED:62934']

  + vdoc
    + ['782.1']
    + ['366.9']
    + ['366.8']
    + ['780.79', '401.9', '272.0']
    + ['585.3']
    + ['729.81', '729.5', 'NDC:00182180989']
    + ['V58.66', '733.00', '427.31', '401.9', '272.4', 'MED:62934']
  + doc(last 150 chars):
['NDC:00182055489', 'NDC:49999058730', 'NDC:00067014182', 'NDC:00173054700', 'NDC:00054010222', 'NDC:00093073301', 'NDC:00093723633', 'NDC:00173093308', 'V68.9', 'V04.81', 'V58.11', '202.80', 'MED:71471', 'V68.9', 'V04.81', 'V58.11', '202.80', '202.80', 'V68.9', 'V04.81', 'V58.11', '202.80', 'V68.9', 'V04.81', 'V58.11', 'E849.9', 'E928.8', '564.00', '715.90', '810.00', '562.10', '530.81', '401.9', '202.80', '272.4', '331.83', '414.01', 'MED:63284', 'MED:61155', 'MED:61895', 'MED:62934', 'MED:102035', 'MED:89117', 'MED:60481', 'MED:61522', 'MED:63469', 'MED:61513', 'MED:62439', 'MED:99143', 'MED:61799', 'MED:61124', 'MED:62871', 'MED:62936', 'MED:62170', 'MED:62899', 'MED:62871', 'MED:62439', 'MED:60481', 'MED:63518', 'NDC:00182055489', 'NDC:00054348663', 'NDC:00173093308', 'NDC:00093073301', 'NDC:00093723633', 'NDC:00247103000', 'NDC:49999058730', 'NDC:00247028100', 'NDC:00067014182', 'NDC:00173054700', 'NDC:00054010222', 'NDC:00186504031', 'NDC:00067000308', 'MED:65966', 'MED:62439', 'NDC:00078035906', 'MED:65966', 'MED:61881', 'MED:62936', 'MED:62934', 'MED:63540', 'MED:62439', 'MED:60884', 'MED:61013', 'V68.9', 'V04.81', 'V58.11', '202.80', 'MED:71471', 'V68.9', 'V04.81', 'V58.11', '202.80', 'MED:62936', 'MED:62439', '202.80', 'V68.9', 'V04.81', 'V58.11', '202.80', 'MED:62936', 'MED:62439', '202.80', 'V68.9', 'V04.81', 'V58.11', '202.80', '202.80', '202.80', 'V68.9', 'V04.81', 'V58.11', '202.80', 'MED:61814', 'MED:62871', 'MED:62439', 'V68.9', 'V04.81', 'V58.11', '202.80', 'MULTUM:2395', 'MED:62439', 'MED:61814', 'MED:62871', '202.80', '202.80', '202.80', '202.80', '202.80', '202.80', '202.80', '202.80', '202.80', '202.80', '202.80', '202.80', '780.4', '401.9', '202.80', '272.4', 'V68.9', 'V04.81', 'V58.11', '202.80', 'MED:62402', 'MED:62439', 'MED:61814', 'V68.9', 'V04.81', 'V58.11', '202.80']

  + vdoc
    + ['202.80']
    + ['202.80']
    + ['202.80']
    + ['202.80']
    + ['202.80']
    + ['202.80']
    + ['202.80']
    + ['780.4', '401.9', '202.80', '272.4']
    + ['V68.9', 'V04.81', 'V58.11', '202.80', 'MED:62402', 'MED:62439', 'MED:61814']
    + ['V68.9', 'V04.81', 'V58.11', '202.80']
  + doc(last 150 chars):
['MED:62679', 'MED:60671', 'MED:68180', 'MED:81318', 'MED:114640', 'MED:62968', 'MED:63089', 'MED:89117', 'MED:62834', 'MED:62453', 'MED:62439', 'MED:62616', 'MED:62685', 'MED:70402', 'MED:62987', 'MED:107078', 'MED:63118', 'MED:61895', 'MED:101650', 'MED:63606', 'MED:60920', 'MED:62879', 'MED:62679', 'MED:60946', 'MED:61211', 'MED:63129', 'MED:60612', 'MED:61112', 'MED:61522', 'MED:60465', 'MED:60798', 'MED:61513', 'MED:62679', 'MED:61118', 'MED:63448', 'MED:60843', 'MED:62987', 'MED:61473', 'MED:97890', 'MED:62679', 'MED:60612', 'MED:61361', 'MED:114640', 'MED:81318', 'MED:63408', 'MED:62184', 'MED:60583', 'MED:122364', 'MED:63285', 'MED:62742', 'MED:114640', 'MED:69488', 'MED:61513', 'MED:62679', 'MED:61558', 'MED:62934', 'MED:63596', 'MED:62899', 'MED:97890', 'MED:61361', 'MED:63274', 'MED:63594', 'MED:63408', 'MED:71459', 'MED:61513', 'MED:62184', 'MED:63183', 'MED:61460', 'MED:62679', 'MED:61118', 'MED:63272', 'MED:85037', 'MED:63274', 'MED:63408', 'MED:63590', 'MED:63055', 'MED:61321', 'MED:62127', 'MED:60920', 'MED:61473', 'MED:63272', 'MED:62557', 'MED:124575', 'MED:63413', 'MED:63590', 'MED:60920', 'MED:124575', 'MED:87663', 'MED:68349', 'MED:61473', 'MED:114640', 'MED:62934', 'MED:62659', 'MED:69143', 'MED:62834', 'MED:62800', 'MED:62664', 'MED:62899', 'MED:62184', 'MED:61264', 'MED:61558', 'MED:62899', 'NDC:00113040378', 'NDC:68258303101', 'NDC:00071041813', 'MED:101650', 'MED:61759', 'MED:97890', 'MED:69488', 'MED:62800', 'MED:63284', 'MED:97890', 'MED:61558', 'MED:60920', 'MED:101650', 'MED:62439', 'MED:68349', 'MED:61759', 'MED:62800', 'Nepro_Carb_Steady_Vanilla', 'MULTUM:7003', 'Nebulizer_Machine', 'NDC:00113040378', 'NDC:12843003520', 'NDC:00054001720', 'NDC:00085009101', 'MED:61513', 'MULTUM:3037', 'Diltiazem_Cd_180_Mg', 'NDC:63874060530', 'NDC:00182055589', 'Meplex_Dressing_Apply_To_Sacrum_Every_3_Days', 'NDC:11523723402', 'NDC:00088221905', 'NDC:00182864389', 'NDC:00172541310', 'NDC:00074380711', 'Diltiazem_Cd_180_Mg', 'Ipatropium_Mdi', 'aerochamber', 'NDC:68258303101', 'NDC:00182055589', 'NDC:00904545209', 'MULTUM:3037', 'MULTUM:12431', 'NDC:00085009101', 'NDC:00062535001', 'NDC:00093417773', 'MULTUM:12431', 'MULTUM:3755']

  + vdoc
    + ['MED:101650', 'MED:61759']
    + ['MED:97890']
    + ['MED:69488', 'MED:62800', 'MED:63284', 'MED:97890', 'MED:61558']
    + ['MED:60920']
    + ['MED:101650', 'MED:62439', 'MED:68349', 'MED:61759']
    + ['MED:62800', 'Nepro_Carb_Steady_Vanilla', 'MULTUM:7003', 'Nebulizer_Machine', 'NDC:00113040378', 'NDC:12843003520', 'NDC:00054001720', 'NDC:00085009101', 'MED:61513', 'MULTUM:3037', 'Diltiazem_Cd_180_Mg', 'NDC:63874060530', 'NDC:00182055589', 'Meplex_Dressing_Apply_To_Sacrum_Every_3_Days', 'NDC:11523723402', 'NDC:00088221905', 'NDC:00182864389', 'NDC:00172541310']
    + ['NDC:00074380711', 'Diltiazem_Cd_180_Mg', 'Ipatropium_Mdi', 'aerochamber', 'NDC:68258303101', 'NDC:00182055589', 'NDC:00904545209', 'MULTUM:3037', 'MULTUM:12431', 'NDC:00085009101']
    + ['NDC:00062535001', 'NDC:00093417773']
    + ['MULTUM:12431']
    + ['MULTUM:3755']
  + doc(last 150 chars):
['799.9', '780.4', '386.12', '780.0', 'V03.82', 'V70.0', '272.0', '366.10', '465.9', '272.0', '272.0', '924.20', '845.00', '845.00', '374.30', '367.9', '374.33', '374.30', 'V70.0', '272.0', '611.79', '272.0', 'V72.81', '366.17', '272.0', '272.0', '272.6', '272.0', 'V76.12', '715.90', '715.90', '272.0', '272.0', '719.41', '727.61', '727.61', '727.61', '727.61', '727.61', '727.61', '727.61', '727.61', '727.61', '401.9', '401.9', 'V76.12', '401.9', 'V72.6', '366.00', 'V72.6', 'V76.12', '272.0', '401.9', '733.90', '401.9', '401.9', 'V76.12', '401.9', '401.9', '401.9', '599.9', '357.9', '357.9', '357.9', '357.9', '357.9', '357.9', '357.9', '357.9', '401.9', '250.00', 'V57.21', '719.49', '356.4', '250.00', 'V57.21', '729.5', '356.9', 'V57.21', '729.5', '356.9', 'V57.21', '729.5', '356.9', 'V57.21', '729.5', '356.9', 'V57.21', '729.5', '356.9', 'V57.21', '729.5', '356.9', 'V57.21', '729.5', '356.9', '401.9', '250.00', '401.1', '250.00', '250.00', '294.8', '356.9', '268.9', '611.72', '793.80', '611.89', '174.8', '174.9', 'V86.1', '414.00', 'V15.82', '733.00', '174.8', '174.9', '788.30', '250.00', '401.9', '272.4', '196.3', '294.20', 'V86.1', 'MED:62439', 'MED:65966', 'MULTUM:5432', 'MED:122364', 'MED:63523', 'MED:94350', 'MED:62677', 'MED:60826', 'MULTUM:5381', 'MULTUM:17272', 'MED:62324', 'MED:62787', 'MULTUM:5381', 'MED:62302', 'NDC:00054024324', 'MULTUM:3819', 'NDC:00113040378', '174.9', '174.9', '250.00', '401.9']

  + vdoc
    + ['356.9']
    + ['268.9']
    + ['611.72']
    + ['793.80', '611.89', '174.8', '174.9', 'V86.1']
    + ['414.00']
    + ['V15.82', '733.00', '174.8', '174.9', '788.30', '250.00', '401.9', '272.4', '196.3', '294.20', 'V86.1', 'MED:62439', 'MED:65966', 'MULTUM:5432', 'MED:122364', 'MED:63523', 'MED:94350', 'MED:62677', 'MED:60826', 'MULTUM:5381', 'MULTUM:17272']
    + ['MED:62324', 'MED:62787', 'MULTUM:5381', 'MED:62302', 'NDC:00054024324', 'MULTUM:3819', 'NDC:00113040378']
    + ['174.9']
    + ['174.9']
    + ['250.00', '401.9']
  + doc(last 150 chars):
['V82.9', '530.11', 'MULTUM:6576', 'MULTUM:4061', 'MULTUM:16519', 'NDC:00186504031', 'NDC:00904770418', 'MULTUM:2391', 'MULTUM:2036', '682.4', '729.81', '401.9', '272.4', '311', '682.9', 'MED:62035', 'MED:61864', 'MED:63540', 'NDC:41388000151', 'NDC:00093227534']

  + vdoc
    + ['V82.9']
    + ['530.11', 'MULTUM:6576', 'MULTUM:4061', 'MULTUM:16519', 'NDC:00186504031', 'NDC:00904770418', 'MULTUM:2391', 'MULTUM:2036']
    + ['682.4', '729.81', '401.9', '272.4', '311', '682.9', 'MED:62035', 'MED:61864', 'MED:63540', 'NDC:41388000151', 'NDC:00093227534']
  + doc(last 150 chars):
['MED:61895', 'MED:65966', 'MED:63178', 'MED:62439', 'MED:60972', 'MED:63606', 'MED:63517', 'MED:62355', 'MED:67464', 'NDC:68382013105', 'NDC:00955025050', 'MED:94350', 'MED:62355', 'VitD', 'MED:62355', 'MED:61515', '3in1_Commode', 'NDC:63481013270', 'NDC:00603014621', 'walker', 'NDC:60814011110', 'cane', 'NDC:66336052015', 'NDC:00832121689', 'MED:61504', 'MED:60682', 'V42.0', 'V58.69', '733.42', 'V42.0', 'V58.69', '733.42', 'V42.0', 'V58.69', 'V42.0', 'V58.69', '719.45', 'V42.0', 'V58.69', 'V42.0', 'V58.69', '733.90', '252.00', '268.9', 'V04.81', 'V42.0', 'V58.69', 'MED:62511', 'V42.0', 'V58.69', 'V42.0', 'V58.69', '724.5', 'V42.0', 'V58.69', 'V42.0', 'V58.69', 'V04.81', 'V42.0', 'V58.69', 'MED:122708', 'V42.0', 'V58.69', 'V42.0', 'V58.69', 'V42.0', 'V58.69', 'V42.0', 'V58.69', 'V42.0', 'V58.69', '719.45', '724.5', 'V42.0', 'V58.69', '724.5', 'V42.0', 'V58.69', 'V42.0', 'V58.69', 'V42.0', 'V58.69', 'V42.0', 'V58.69', 'V42.0', 'V58.69', 'V42.0', 'V58.69', 'V42.0', 'V58.69', 'V58.69', 'V04.81', 'V42.0', 'V58.69', 'MED:104282', 'V42.0', 'V58.69', 'V42.0', 'V58.69', 'V42.0', 'MED:63021', 'V42.0', 'V58.69', 'V42.1', 'V58.69', '274.19', 'V42.0', 'V42.0', 'V42.0', 'V58.69', '996.81', 'V42.0', '996.81', 'V42.0', 'V58.69', '252.01', '996.81', 'V04.81', 'V42.0', 'V58.69', 'MED:128621', 'V42.0', 'V58.69', '996.81', '788.41', 'V42.0', 'V58.69', '599.0', 'V42.0', 'V58.69', '996.81', 'V42.0', 'V58.69', '996.81', 'V42.0', '996.81', 'V42.0', '996.81', 'V42.0', 'V58.69', '996.81', 'V42.0', 'V58.69', '996.81', 'V42.0', 'V58.69', '996.81', 'V42.0', 'V58.69', '996.81']

  + vdoc
    + ['V42.0', 'V58.69']
    + ['599.0']
    + ['V42.0', 'V58.69', '996.81']
    + ['V42.0', 'V58.69', '996.81']
    + ['V42.0', '996.81']
    + ['V42.0', '996.81']
    + ['V42.0', 'V58.69', '996.81']
    + ['V42.0', 'V58.69', '996.81']
    + ['V42.0', 'V58.69', '996.81']
    + ['V42.0', 'V58.69', '996.81']
  + doc(last 150 chars):
['581.3', '581.9', '581.9', '581.3', '581.3', '581.9', '272.4', '403.90', '581.9', '272.4', '403.90', '581.9', '581.9', '272.4', '403.90', '593.9', '791.0', '581.3', '791.0', '585.1', '581.3', '581.9', '581.3', '782.3', '453.41', '453.40', 'MED:60921', 'MED:61902', 'MED:62439', 'MED:62013', 'MED:69490', 'NDC:00832121689', 'NDC:00781312168', '791.0', '581.2', '581.3', '997.91', '272.4', '581.3', '401.9', '782.3', '453.41', '415.19', '273.8', 'MED:61648', 'MED:61112', 'MED:60921', 'MED:62355', 'MED:61648', 'MED:61522', 'MED:61951', 'MED:62439', 'MED:61895', 'MED:106708', 'MED:158045', 'MED:69490', 'MED:61648', 'NDC:00075291501', 'NDC:00075062300', 'MULTUM:8487', 'NDC:00006010654', 'V87.46', '581.3', '272.4', 'MED:62936', 'MED:62871', 'MED:60481', '581.3', 'MED:60481', 'MED:62871', 'MED:167651']

  + vdoc
    + ['581.3']
    + ['782.3', '453.41', '453.40']
    + ['MED:60921', 'MED:61902', 'MED:62439', 'MED:62013', 'MED:69490', 'NDC:00832121689', 'NDC:00781312168']
    + ['791.0', '581.2']
    + ['581.3', '997.91', '272.4']
    + ['581.3', '401.9', '782.3', '453.41', '415.19', '273.8', 'MED:61648']
    + ['MED:61112', 'MED:60921', 'MED:62355', 'MED:61648', 'MED:61522', 'MED:61951', 'MED:62439', 'MED:61895', 'MED:106708', 'MED:158045', 'MED:69490']
    + ['MED:61648', 'NDC:00075291501', 'NDC:00075062300', 'MULTUM:8487', 'NDC:00006010654']
    + ['V87.46', '581.3', '272.4', 'MED:62936', 'MED:62871', 'MED:60481']
    + ['581.3', 'MED:60481', 'MED:62871', 'MED:167651']
  + doc(last 150 chars):
['524.60', '462', '583.9', '372.30', '371.82', '530.11', 'E849.8', 'E917.9', '959.4', '379.93', '375.15', '524.60', '784.0', '524.62', '784.0', 'MED:34930', '524.62', '789.01', '338.29', '788.1', '788.1', '789.00', '789.04', '597.80', '788.1', 'NDC:00143126801', '580.9', '585.3', '719.42', '788.1', 'V70.0', '580.9', 'I10', '401.9']

  + vdoc
    + ['788.1']
    + ['788.1', '789.00']
    + ['789.04']
    + ['597.80', '788.1', 'NDC:00143126801']
    + ['580.9']
    + ['585.3']
    + ['719.42']
    + ['788.1']
    + ['V70.0', '580.9']
    + ['I10', '401.9']
  + doc(last 150 chars):
['V49.83', '585.6', '585.6', '585.6', 'V49.83', 'V70.0', '585.6', 'MED:61939', 'MED:63021', '585.6', '327.23', 'V15.82', 'V45.11', '585.6', '583.1', '272.4', '403.91', 'MED:60553', 'MED:60481', 'MED:94350', 'MED:101652', 'MED:60762', 'MED:61632', 'MED:62035', 'MED:62439', 'MED:62659', 'MED:122364', 'MED:60972', 'MED:63523', 'MED:60926', 'MED:61895', 'MED:61262', 'MED:62936', 'MED:63518', 'MED:89117', 'NDC:00093715410', 'NDC:00054008813', 'NDC:62107002726', 'MULTUM:6962', 'MULTUM:2395', 'MULTUM:8322', 'NDC:00009009001', 'MED:60553', 'MED:101652', 'MED:62829', 'MED:62522', 'MED:81159', 'MED:63469', 'MED:69242', 'MED:61078', 'MED:69488', 'MED:63469', 'MED:63596', 'MED:62987', 'NDC:49999058730', 'NDC:00028005101', 'NDC:00121478505', 'NDC:00469061711', 'NDC:00228212710', 'NDC:00093715410', 'NDC:00004003822', 'NDC:13310014501', 'NDC:00469060773', 'NDC:00054055125', 'NDC:00078038666', 'NDC:00781285505', 'MULTUM:6930', 'V42.0', 'V42.0', 'V58.69', 'V42.0', 'V58.69', 'V42.0', 'V58.69', 'V58.69', 'V42.0', 'V42.0', 'V58.69', '996.81', 'V42.0', 'V58.69', 'V42.0', 'V58.69', '996.81', 'V42.0', '996.81', 'V42.0', 'V58.69', 'V42.0', 'V42.0', 'V42.0', 'V58.69', 'V42.0', 'V58.69', 'V58.69', 'V42.0', 'V58.69', '289.0', 'V42.0', 'V58.69', 'Z94.0', 'Z79.899', 'MED:162541']

  + vdoc
    + ['V42.0', 'V58.69']
    + ['V42.0']
    + ['V42.0']
    + ['V42.0', 'V58.69']
    + ['V42.0', 'V58.69']
    + ['V58.69']
    + ['V42.0', 'V58.69']
    + ['289.0']
    + ['V42.0', 'V58.69']
    + ['Z94.0', 'Z79.899', 'MED:162541']
  + doc(last 150 chars):
['585.6', '585.6', 'V42.0', '585.6', 'V76.12', '585.6', '793.80', '585.6', 'MED:63467', '585.6', '585.6', '403.91', 'MED:63588', 'MED:62439', 'MED:69242', 'MED:61262', 'MED:61253', 'MED:62838', 'MED:89117', 'MED:62659', 'MED:61895', 'MED:62147', 'MED:60553', 'MED:63465', 'MED:60762', 'MED:62719', 'MED:61471', 'MED:62936', 'MED:60926', 'MULTUM:608', 'NDC:68180051202', 'NDC:68382006624', 'NDC:51285042410', 'NDC:00083400061', 'MED:69954', 'MED:101652', 'MED:60553', 'MED:60826', 'MED:62522', 'MED:69242', 'MED:69954', 'MED:61471', 'MED:62522', 'MED:62659', 'MED:69954', 'MED:61558', 'MED:62522', 'NDC:67618010160', 'NDC:00469061773', 'NDC:00004003822', 'NDC:13310014501', 'MULTUM:2118', 'NDC:00078038666', 'MULTUM:21858', 'MULTUM:5432', 'MULTUM:2481', 'NDC:68094059962', 'NDC:68382006624', 'MED:61473', 'V42.0', 'V58.69', 'V42.0', 'V58.69', 'V42.0', 'V58.69', 'V42.0', 'V58.69', 'V42.0', 'V58.69', 'V42.0', 'V58.69', 'V42.0', 'V58.69', 'V42.0', 'V42.0', 'V58.69', 'V42.0', 'V58.69', 'V42.0', 'V58.69', 'V42.0', 'V58.69', 'V42.0', 'V58.69', 'V42.0', 'V58.69', 'V42.0', 'V58.69', '793.80', 'V76.12', 'V42.0', 'V58.69', 'V42.0', 'V58.69', 'V04.81', 'V42.0', 'V58.69', 'MED:122708', 'V42.0', 'V58.69', 'V42.0', 'V58.69', 'V42.0', 'V58.69', 'V42.0', 'V58.69', 'V04.81', 'V42.0', 'V58.69', '996.81', 'MED:128621', 'V42.0', 'V58.69', '996.81', 'V42.0', '996.81', 'V42.0', 'V42.0', 'V58.69', '996.81', 'V04.81', 'V42.0', 'V58.69', '996.81', 'MED:133079', 'V42.0', 'V58.69', '787.91', '996.81', 'Z94.0', 'Z79.899']

  + vdoc
    + ['V42.0', 'V58.69']
    + ['V04.81', 'V42.0', 'V58.69', '996.81', 'MED:128621']
    + ['V42.0', 'V58.69', '996.81']
    + ['V42.0', '996.81']
    + ['V42.0']
    + ['V42.0', 'V58.69', '996.81']
    + ['V04.81', 'V42.0', 'V58.69', '996.81']
    + ['MED:133079']
    + ['V42.0', 'V58.69', '787.91', '996.81']
    + ['Z94.0', 'Z79.899']
  + doc(last 150 chars):
['V22.1', '645.11', '655.81', '663.81', '667.02', 'V27.0', '664.11', '493.90', '648.91', 'MED:89274', 'MED:99142', 'NDC:58980010817', 'NDC:54868429500', 'MED:63517', 'NDC:00006011728', 'NDC:00247010703', 'MED:106261', 'MED:62296', 'MED:61619', 'MED:62624', 'MED:61382', 'MED:61895', 'MED:61829', 'MED:61120', 'MED:62994', 'MED:61736', 'MED:62683', 'MED:60926', 'MED:62439', 'NDC:00085113201', 'NDC:00186091706', 'NDC:13811000930', 'NDC:00182181089']

  + vdoc
    + ['V22.1', '645.11', '655.81', '663.81', '667.02', 'V27.0', '664.11', '493.90', '648.91', 'MED:89274', 'MED:99142', 'NDC:58980010817', 'NDC:54868429500', 'MED:63517', 'NDC:00006011728', 'NDC:00247010703', 'MED:106261', 'MED:62296', 'MED:61619', 'MED:62624', 'MED:61382', 'MED:61895', 'MED:61829', 'MED:61120', 'MED:62994', 'MED:61736', 'MED:62683', 'MED:60926', 'MED:62439']
    + ['NDC:00085113201', 'NDC:00186091706', 'NDC:13811000930']
    + ['NDC:00182181089']
  + doc(last 150 chars):
['995.92', '112.3', '690.10', '785.52', '787.91', '785.51', '478.5', '747.0', '518.81', '428.0', '746.4', '747.10', '286.9', '287.5', '276.2', '263.1', '574.20', '444.21', '428.21', '038.11', 'MED:60486', 'MED:62958', 'MED:61661', 'MED:61836', 'MED:63065', 'MED:89129', 'MED:61190', 'MED:133116', 'MED:63543', 'MED:63185', 'MED:62734', 'MED:94350', 'MED:60755', 'MED:60486', 'MED:62595', 'MED:61424', 'MED:61511', 'MED:61013', 'MED:61836', 'MED:62067', 'MED:89129', 'MED:80988', 'MED:69155', 'MED:66016', 'MED:63543', 'MED:81379', 'MED:62062', 'MED:63185', 'MED:62798', 'MED:100184', 'MED:60486', 'MED:61836', 'MED:61013', 'MED:62067', 'MED:89129', 'MED:80988', 'MED:133116', 'MED:69247', 'MED:81379', 'MED:62974', 'MED:63185', 'MED:60486', 'MED:61511', 'MED:61013', 'MED:62067', 'MED:81379', 'MED:73183', 'MED:80988', 'MED:67465', 'MED:86686', 'MED:61096', 'MED:67463', 'MED:62062', 'MED:63185', 'MED:60486', 'MED:61511', 'MED:61013', 'MED:81379', 'MED:80988', 'MED:60486', 'MED:61511', 'MED:61013', 'MED:61502', 'MED:81379', 'MED:73183', 'MED:67463', 'MED:61013', 'MED:62067', 'MED:81379', 'MED:89129', 'MED:80988', 'MED:133116', 'MED:86686', 'MED:61619', 'MED:63543', 'MED:61167', 'MED:62067', 'MED:61013', 'MED:80988', 'MED:103047', 'MED:63182', 'MED:61253', 'MED:63185', 'MED:62564', 'MED:60486', 'MED:61633', 'MED:62067', 'MED:61013', 'MED:81379', 'MED:63122', 'MED:61190', 'MED:63182', 'MED:61096', 'MED:86672', 'MED:61633', 'MED:77638', 'MED:69854', 'MED:66023', 'MED:66053', 'MED:63185', 'MED:104889', 'MED:61911', 'MED:61633', 'MED:61167', 'MED:61511', 'MED:104255', 'MED:61511', 'MED:80988', 'MED:62649', 'MED:81379', 'Nasogastric_Tube_Feeding_Supplies', 'MED:61190', 'MED:61619', 'MED:104889', 'Enfaport_20_Kcaloz_With_Iron', 'MED:61936', 'MED:62140', 'MED:61190', 'MED:69854', 'MED:67463', 'MED:104889', 'MED:60461', 'MED:69854', 'MED:69854', 'MED:104889', 'Actigall_Oral_Susp_25_Mgml', 'Actigall_20_Mgml', 'Prevacid_Oral_Suspension_3_Mgml', 'MULTUM:12552', 'NDC:36652067366']

  + vdoc
    + ['MED:61911', 'MED:61633', 'MED:61167', 'MED:61511', 'MED:104255']
    + ['MED:61511', 'MED:80988']
    + ['MED:62649', 'MED:81379']
    + ['Nasogastric_Tube_Feeding_Supplies', 'MED:61190', 'MED:61619', 'MED:104889', 'Enfaport_20_Kcaloz_With_Iron']
    + ['MED:61936', 'MED:62140', 'MED:61190', 'MED:69854', 'MED:67463']
    + ['MED:104889']
    + ['MED:60461', 'MED:69854']
    + ['MED:69854', 'MED:104889']
    + ['Actigall_Oral_Susp_25_Mgml', 'Actigall_20_Mgml', 'Prevacid_Oral_Suspension_3_Mgml']
    + ['MULTUM:12552', 'NDC:36652067366']
  + doc(last 150 chars):
['MED:63185', 'MED:62564', 'MED:123650', 'MED:149830', 'MED:104245', 'MED:100056', 'MED:61619', 'MED:63182', 'MED:61253', 'MED:63543', 'MED:80988', 'MED:63060', 'MED:63185', 'MED:62564', 'MED:81379', 'MED:104245', 'MED:61253', 'MED:62886', 'MED:63185', 'MED:81379', 'MED:104245', 'MED:61253', 'MED:123650', 'MED:80988', 'MED:67465', 'MED:63185', 'MED:63543', 'MED:104245', 'MED:70466', 'MED:62801', 'MED:63185', 'MED:61253', 'MED:60486', 'MED:61243', 'MED:104245', 'MED:104245', 'MED:61253', 'MED:104245', 'MED:131573', 'MED:66167', 'MED:61093', 'MED:102484', 'MED:66091', 'MED:62704', 'MED:101186', 'MED:66091', 'MED:63286', '1_500cc_Feeding_Bags_Dispense_30month_2_Tega', 'Infant_Scale_Please_Weigh_Infant_At_The_Same_Tim', 'NDC:00113025968', 'MED:66091', 'NDC:00015727675', 'Dispense_One_Portable_Pulse_Oximeter_For_Home_Use', 'NDC:00054329446', 'NDC:00054005746', 'MED:62021', 'NDC:00054005746', 'V15.1', '759.0', '746.89', '745.10', '276.51', '745.69', '787.03', '747.31', 'MED:131573', 'MED:66167', 'MED:66053', 'MED:63465', 'MED:61836', 'NDC:65628008003', 'NDC:00015727675', 'MED:106364', 'MED:61836', 'NDC:00054329446', '745.3', '747.49', '518.82', '428.0', '747.21', '745.3', '745.69', '428.1', '747.31', 'MED:124621', 'MED:106366', 'MED:62062', 'MED:72705', 'MED:94350', 'MED:60481', 'MED:62595', 'MED:133116', 'MED:61836', 'MED:62191', 'MED:106366', 'MED:63540', 'MED:72705', 'MED:63182', 'MED:61253', 'MED:60481', 'MULTUM:15281', 'MULTUM:4911', 'MULTUM:5432', 'MED:131573', 'MED:102218', 'MED:106366', 'MED:62649', 'MED:63182', 'MED:62343', 'MED:60481', 'MED:60743', 'MED:63122', 'MED:63096', 'MED:102484', 'MED:63433', 'MED:62343', 'MED:63465', 'NDC:00015727675', 'NDC:00113025968', 'NDC:00054005746', 'NDC:00054329446', 'V15.1', '759.0', '751.4', '746.89', '745.3', '752.49', 'NDC:00093415073', 'MED:62191', 'MED:71742', 'MED:61253', 'MED:60481', 'MED:63540', 'MED:62586', 'NDC:10106003301', 'MED:61190', 'NDC:00054005746', 'MED:61190', 'MED:131573', 'MED:102484', 'MED:62848', 'V20.2', 'MULTUM:2402', 'NDC:45802042335', 'MED:63465', 'NDC:00029152544', '995.3', '780.60', 'MULTUM:5466', 'NDC:00121477405']

  + vdoc
    + ['MED:102484', 'MED:63433', 'MED:62343']
    + ['MED:63465']
    + ['NDC:00015727675', 'NDC:00113025968', 'NDC:00054005746', 'NDC:00054329446']
    + ['V15.1', '759.0', '751.4', '746.89', '745.3', '752.49', 'NDC:00093415073', 'MED:62191', 'MED:71742', 'MED:61253', 'MED:60481', 'MED:63540', 'MED:62586', 'NDC:10106003301', 'MED:61190', 'NDC:00054005746']
    + ['MED:61190']
    + ['MED:131573', 'MED:102484', 'MED:62848']
    + ['V20.2', 'MULTUM:2402', 'NDC:45802042335', 'MED:63465', 'NDC:00029152544']
    + ['995.3']
    + ['780.60']
    + ['MULTUM:5466', 'NDC:00121477405']
  + doc(last 150 chars):
['585.5', 'V49.83', '585.6', '585.5', '585.6', '585.9', '790.29', 'V45.82', 'V42.0', '583.9', '753.0', '584.9', '600.00', '412', '368.2', '285.1', 'E932.0', '311', '274.9', '300.00', '285.21', '414.01', 'MED:122364', 'NDC:00071015723', 'NDC:30698014401', 'NDC:00247187400', 'NDC:00186504031', 'NDC:62107002726', 'NDC:00028005101', 'NDC:00074307490', 'NDC:00223172101', 'NDC:00378013701', 'NDC:00069153041', 'NDC:00597005801', 'MED:63606', 'MED:62659', 'MED:95599', 'MED:89117', 'MED:63523', 'MED:62439', 'MED:60972', 'MED:62936', 'MED:63518', 'NDC:00006095231', 'MED:61471', 'MED:60826', 'MED:61895', 'MED:61968', 'MED:60926', 'MED:60635', 'MED:60481', 'MED:60553', 'MED:94350', 'MED:101652', 'MED:60762', 'MED:63606', 'MED:69488', 'MED:63089', 'MED:81159', 'MED:133119', 'MED:69242', 'MED:62522', 'MED:60481', 'MED:60553', 'MED:69242', 'MED:62522', 'MED:81159', 'MED:60887', 'NDC:00121478505', 'NDC:00093023333', 'NDC:00004003822', 'NDC:00069153041', 'NDC:00071015723', 'NDC:49999058730', 'MULTUM:8313', 'NDC:00378001801', 'NDC:13310014501', 'NDC:00597005801', 'NDC:00228298311', 'NDC:00078038666', 'NDC:00469061711', 'NDC:00378013701', 'NDC:00363041407', 'NDC:00781285505', 'V42.0', 'V58.69', '580.9', 'V42.0', 'V58.69', '996.81', 'V42.0', 'V58.69', '996.81', 'V42.0', '996.81', 'V42.0', 'V58.69', '996.81', 'V42.0', 'V58.69', '996.81', '996.81', '939.3', 'V42.0', 'V58.69', '996.81', 'V42.0', 'V58.69', '996.81', 'V42.0', 'V58.69', '996.81', '788.41', 'V42.0', 'V58.69', '996.81', 'V42.0', 'V58.69', '996.81', 'V42.0', 'V58.69', '996.81', 'V42.0', 'V58.69', '788.41', 'V42.0', 'V04.81', '996.81', '250.42', 'MED:158045', '585.9', 'V42.0', '272.4', '288.50', '585.9', 'V42.0', 'V58.69', 'V70.0', 'Z94.0', 'Z23', 'Z79.899', 'Z94.0']

  + vdoc
    + ['V42.0', 'V58.69', '996.81']
    + ['V42.0', 'V58.69', '996.81']
    + ['V42.0', 'V58.69', '996.81']
    + ['V42.0', 'V58.69', '788.41']
    + ['V42.0', 'V04.81', '996.81', '250.42', 'MED:158045']
    + ['585.9', 'V42.0', '272.4']
    + ['288.50']
    + ['585.9', 'V42.0', 'V58.69', 'V70.0']
    + ['Z94.0', 'Z23', 'Z79.899']
    + ['Z94.0']
  + avgL: 3.401748, max n_tokens_in_visit: 71, min: 1, std: 4.775765
  + avgV: 90.685169, max n_visits_in_doc:   1082, min: 1, std: 114.666660
visitToDocment> size(V):2360 -> size(Dv):214017 (E[nVperDoc]=90.685169)
> D:
[['813.42', '813.42', '813.42', '813.42', '813.42', '813.42', '813.42', '813.42', '813.42', '813.42', '813.42', '813.42', '813.42', '813.42', '813.42', '813.42', '813.42', '813.42', '813.42', '813.42', '813.42', '813.42', '813.42', '813.42', '813.42', '813.42', '813.42', '813.42', '813.42', '813.42', '813.42', '813.42', '813.42', '813.42', '813.42', '813.42', '813.42', '813.42', '813.42', '813.42', '813.42', '813.42', '813.42', '813.42', '813.42', '813.42', '813.42', '813.42', '813.42', '813.42', '813.42', '813.42', '813.42', '813.42', '813.42', '813.42', '813.42', '813.42', '813.42', '813.42', '813.42', '813.42', '813.42', '813.42', '813.42', '813.42', '813.42', '813.42', '813.42', '813.42', '813.42'], ['813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41'], ['813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41'], ['813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41'], ['813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41'], ['813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41'], ['813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41'], ['813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41'], ['813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41'], ['813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41']]

    + computing document vectors nD:2360 => nDEff: 214017 ...
makeTSetVisit> model dir: /Users/pleiades/Documents/work/tpheno/seqmaker/data/CKD/model
getDocVec> method: pv-dm2, model ID: smallCKD, segment_by_visit? True, load precomputed? True
getDocVecPV> prior to labelDocuments, already labeled? False, example: ['813.42', '813.42', '813.42', '813.42', '813.42', '813.42', '813.42', '813.42', '813.42', '813.42', '813.42', '813.42', '813.42', '813.42', '813.42', '813.42', '813.42', '813.42', '813.42', '813.42', '813.42', '813.42', '813.42', '813.42', '813.42', '813.42', '813.42', '813.42', '813.42', '813.42', '813.42', '813.42', '813.42', '813.42', '813.42', '813.42', '813.42', '813.42', '813.42', '813.42', '813.42', '813.42', '813.42', '813.42', '813.42', '813.42', '813.42', '813.42', '813.42', '813.42', '813.42', '813.42', '813.42', '813.42', '813.42', '813.42', '813.42', '813.42', '813.42', '813.42', '813.42', '813.42', '813.42', '813.42', '813.42', '813.42', '813.42', '813.42', '813.42', '813.42', '813.42'], type: <type 'list'>
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
Doc2Vec Parameters
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
  + current d2v method: pv-dm2
  + number of features: 50
  + window size: 10
  + ignore tokens with total freq less than 2
  + number of epochs: 20
  + training method: negative sampling  + number of negative samples: 15  + use concatenation of context vectors? False

getDocVecPV> total: 214017
getDocVecPV> Params summary of d2v models (n_workers: 18, n_iter: 20) ...
  + n_features: 50, window: 10
  + negative sample? 15
  + min count: 2

D2V.load> Info: model path:
/Users/pleiades/Documents/work/tpheno/seqmaker/data/CKD/model/Pf50w10i20-smallCKD.dm

D2V.load> Info: model path:
/Users/pleiades/Documents/work/tpheno/seqmaker/data/CKD/model/Pf50w10i20-smallCKD.dbow

check> input prior to consolidateVisits dim(X): (214017, 100), len(visitDocIDs): 214017
(check) contatenated vector dim: 5000 | lastN=50, indv fDim=100
(check) visit idx:
[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2]
(check) scope idx:
[0, 14, 97, 110, 112, 338, 429, 459, 503, 529, 606, 645, 712, 741, 951, 1075, 1198, 1212, 1372, 1508, 1715, 1794, 1844, 2002, 2011, 2389, 2561, 2958, 2986, 3087, 3103, 3162, 3459, 3530, 3619, 3625, 3778, 3841, 3990, 4012, 4070, 4123, 4223, 4226, 4665, 4813, 4932, 5178, 5549, 5676, 5688, 5716, 5805, 5921, 6438, 6445, 6463, 6562, 6641, 6751, 6825, 7009, 7053, 7074, 7079, 7175, 7245, 7326, 7590, 8072, 8132, 8135, 8147, 8186, 8241, 8587, 8595, 8709, 8737, 8831, 8847, 8968, 9000, 9059, 9167, 10166, 10315, 10501, 10553, 10577, 11085, 11192, 11221, 11887, 11969, 12067, 12116, 12120, 12461, 12569]

verify> mean dim: 9068.516949, median: 4900.000000, std: 11466.665963
(check) flatterned X, dim(Xp): (2360,)
tsHandler> save document vectors (cv=0), sparse? False ...
  + params: dim(X):(2360, 5000), index:0, n(docIDs):2360, d2v:pv-dm2, cohort:CKD, ctype:regular, shuffle? False, meta: smallCKD
tsHandler> training set dir: /Users/pleiades/Documents/work/tpheno/seqmaker/data/CKD/combined
prepareTrainingSet> n_classes: 11
TSet> Params: cohort: CKD, file id: regular-pv-dm2-smallCKD
TSet.saveDataFrame> tset params (cohort:CKD d2v:pv-dm2, ctype:regular, suffix=smallCKD)
TSet.saveDataFrame> Saving (cohort=CKD, d2v=pv-dm2, suffix=smallCKD) dataset to:
/Users/pleiades/Documents/work/tpheno/seqmaker/data/CKD/combined/tset-n0-IDregular-pv-dm2-smallCKD-GCKD.csv

status> Model computation complete (@nTrial=0)
info> each doc is repr by the last 50 visits
TSet> Params: cohort: CKD, file id: regular-pv-dm2-smallCKD
TSet.load> loading training set (cohort=CKD, suffix=smallCKD) from:
/Users/pleiades/Documents/work/tpheno/seqmaker/data/CKD/combined/tset-n0-IDregular-pv-dm2-smallCKD-GCKD.csv

tsHandler.profile> Found 11 unique labels ...
  + label=CKD Stage 3a => N=215
  + label=Unknown => N=411
  + label=CKD Stage 3b => N=135
  + label=ESRD on dialysis => N=41
  + label=CKD G1-control => N=87
  + label=CKD G1A1-control => N=108
  + label=CKD Stage 5 => N=31
  + label=CKD Stage 4 => N=56
  + label=ESRD after transplant => N=686
  + label=CKD Stage 2 => N=528
  + label=CKD Stage 1 => N=62
loadTSetCombined> Modifying training data ...
> Prior to re-labeling ...
tsHandler.profile> Found 11 unique labels ...
  + label=CKD Stage 3a => N=215
  + label=Unknown => N=411
  + label=CKD Stage 3b => N=135
  + label=ESRD on dialysis => N=41
  + label=CKD G1-control => N=87
  + label=CKD G1A1-control => N=108
  + label=CKD Stage 5 => N=31
  + label=CKD Stage 4 => N=56
  + label=ESRD after transplant => N=686
  + label=CKD Stage 2 => N=528
  + label=CKD Stage 1 => N=62
  + (before) unique labels:
['CKD Stage 3a' 'CKD Stage 2' 'Unknown' 'CKD Stage 3b' 'CKD Stage 4'
 'ESRD after transplant' 'ESRD on dialysis' 'CKD G1A1-control'
 'CKD Stage 1' 'CKD G1-control' 'CKD Stage 5']

  + CKD Stage 5 <- ['ESRD after transplant', 'ESRD on dialysis']
  + CKD Stage 3 <- ['CKD Stage 3a', 'CKD Stage 3b']
  + Others <- ['CKD G1-control', 'CKD G1A1-control', 'Unknown']
merge> n_labels: 11 -> 6
  + (after) unique labels:
['CKD Stage 3' 'CKD Stage 2' 'Others' 'CKD Stage 4' 'CKD Stage 5'
 'CKD Stage 1']

> After re-labeling ...
tsHandler.profile> Found 6 unique labels ...
  + label=Others => N=606
  + label=CKD Stage 5 => N=758
  + label=CKD Stage 4 => N=56
  + label=CKD Stage 3 => N=350
  + label=CKD Stage 2 => N=528
  + label=CKD Stage 1 => N=62
loadTSet> number of classes: 6
... cohort=CKD, ctype=regular, d2v=pv-dm2, meta=smallCKD
  + is_simplified? False, ... 
  + classification mode: multiclass
  + classifiers:
[]
  + training set type:dense
  + training set dim:2360
  + n classes:6

d_classify> dim(ts): (2360, 5002) > n_timesteps: 50, n_features: 100
  + dim(X <- ts): (2360, 5000)
d_classify> reshaped X: (2360, 50, 100) | n_classes=6

<<< Experimental Settings >>>

   + tset type dense, maxNPerClass: None, drop control? False
  + cohort: CKD, ctype: regular

  + D2V: pv-dm2, params> window: 10, n_features: 50
       + n_iter: 20, min_count: 2

  + userFileID: smallCKD

... data: 

... params (model selection): 

model_selection> trying {'n_units': 150, 'dropout_rate': 0.2} ...

make_lstm> n_units=150, r_dropout=0.200000, n_layers=1, n_classes=6
WARNING:tensorflow:From dnn_utils.py:157: streaming_auc (from tensorflow.contrib.metrics.python.ops.metric_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Please switch to tf.metrics.auc. Note that the order of the labels and predictions arguments has been switched.
  + lookup:
{'Others': 5, 'CKD Stage 5': 4, 'CKD Stage 4': 3, 'CKD Stage 3': 2, 'CKD Stage 2': 1, 'CKD Stage 1': 0}

... class weights:
{0: 6.344086021505376, 1: 0.74494949494949492, 2: 1.1238095238095238, 3: 7.0238095238095237, 4: 0.51890941072999119, 5: 0.64906490649064907}

====================================================================================================
... early stopping>
       + patience: 20, model='max'
... model training>
       + batch_size: 32, epochs: 60, shuffle? True, metric: auc_roc
====================================================================================================
^CTraceback (most recent call last):
  File "dnn_utils.py", line 2637, in <module>
    test2()
  File "dnn_utils.py", line 2624, in test2
    last_n_visits=tset['last_n_visits'])
  File "dnn_utils.py", line 2351, in t_deep_classify
    epochs=NNS.epochs_ms, batch_size=NNS.batch_size_ms)  # score_index: 0/loss, 1/accuracy, 2/auc
  File "dnn_utils.py", line 1217, in modelEvaluate0
    callbacks=my_callbacks) 
  File "/Users/pleiades/anaconda2/lib/python2.7/site-packages/keras/models.py", line 1002, in fit
    validation_steps=validation_steps)
  File "/Users/pleiades/anaconda2/lib/python2.7/site-packages/keras/engine/training.py", line 1682, in fit
    self._make_train_function()
  File "/Users/pleiades/anaconda2/lib/python2.7/site-packages/keras/engine/training.py", line 992, in _make_train_function
    loss=self.total_loss)
  File "/Users/pleiades/anaconda2/lib/python2.7/site-packages/keras/legacy/interfaces.py", line 91, in wrapper
    return func(*args, **kwargs)
  File "/Users/pleiades/anaconda2/lib/python2.7/site-packages/keras/optimizers.py", line 445, in get_updates
    grads = self.get_gradients(loss, params)
  File "/Users/pleiades/anaconda2/lib/python2.7/site-packages/keras/optimizers.py", line 78, in get_gradients
    grads = K.gradients(loss, params)
  File "/Users/pleiades/anaconda2/lib/python2.7/site-packages/keras/backend/tensorflow_backend.py", line 2519, in gradients
    return tf.gradients(loss, variables, colocate_gradients_with_ops=True)
  File "/Users/pleiades/anaconda2/lib/python2.7/site-packages/tensorflow/python/ops/gradients_impl.py", line 494, in gradients
    gate_gradients, aggregation_method, stop_gradients)
  File "/Users/pleiades/anaconda2/lib/python2.7/site-packages/tensorflow/python/ops/gradients_impl.py", line 636, in _GradientsHelper
    lambda: grad_fn(op, *out_grads))
  File "/Users/pleiades/anaconda2/lib/python2.7/site-packages/tensorflow/python/ops/gradients_impl.py", line 385, in _MaybeCompile
    return grad_fn()  # Exit early
  File "/Users/pleiades/anaconda2/lib/python2.7/site-packages/tensorflow/python/ops/gradients_impl.py", line 636, in <lambda>
    lambda: grad_fn(op, *out_grads))
  File "/Users/pleiades/anaconda2/lib/python2.7/site-packages/tensorflow/python/ops/array_grad.py", line 266, in _StridedSliceGrad
    x = array_ops.shape(op.inputs[0], out_type=begin.dtype)
  File "/Users/pleiades/anaconda2/lib/python2.7/site-packages/tensorflow/python/ops/array_ops.py", line 285, in shape
    return shape_internal(input, name, optimize=True, out_type=out_type)
  File "/Users/pleiades/anaconda2/lib/python2.7/site-packages/tensorflow/python/ops/array_ops.py", line 312, in shape_internal
    return constant(input_shape.as_list(), out_type, name=name)
  File "/Users/pleiades/anaconda2/lib/python2.7/site-packages/tensorflow/python/framework/constant_op.py", line 220, in constant
    name=name).outputs[0]
  File "/Users/pleiades/anaconda2/lib/python2.7/site-packages/tensorflow/python/framework/ops.py", line 3392, in create_op
    op_def=op_def)
  File "/Users/pleiades/anaconda2/lib/python2.7/site-packages/tensorflow/python/framework/ops.py", line 1650, in __init__
    if node_def.ByteSize() >= (1 << 31) or node_def.ByteSize() < 0:
  File "/Users/pleiades/anaconda2/lib/python2.7/site-packages/google/protobuf/internal/python_message.py", line 1014, in ByteSize
    size += field_descriptor._sizer(field_value)
  File "/Users/pleiades/anaconda2/lib/python2.7/site-packages/google/protobuf/internal/encoder.py", line 360, in FieldSize
    entry_msg = message_type._concrete_class(key=key, value=value)
  File "/Users/pleiades/anaconda2/lib/python2.7/site-packages/google/protobuf/internal/python_message.py", line 518, in init
    copy.MergeFrom(new_val)
  File "/Users/pleiades/anaconda2/lib/python2.7/site-packages/google/protobuf/internal/python_message.py", line 1211, in MergeFrom
    def MergeFrom(self, msg):
KeyboardInterrupt
pleiades@~/Documents/work/tpheno/seqmaker\:) python dnn_utils.py 
Using TensorFlow backend.
config> d2v: pv-dm2, user descriptor (model, tset, mcs): smallCKD
        cohort: CKD, ctype: regular
            + augmented? False, simplified? False dir_type=combined
check> sysConfig complete ... meta? smallCKD
load_data> inputs:
['/Users/pleiades/Documents/work/tpheno/seqmaker/data/CKD/condition_drug_labeled_seq-CKD.csv']

================================================================================
1. Read temporal doc files ...
================================================================================
loadDocuments> input files: ['/Users/pleiades/Documents/work/tpheno/seqmaker/data/CKD/condition_drug_labeled_seq-CKD.csv']
readDocFromCSV> input files: ['/Users/pleiades/Documents/work/tpheno/seqmaker/data/CKD/condition_drug_labeled_seq-CKD.csv']
read> reading from 1 source files:
['/Users/pleiades/Documents/work/tpheno/seqmaker/data/CKD/condition_drug_labeled_seq-CKD.csv']

read> processing header sequence ...
read> processing header timestamp ...
read> processing header label ...
    + labels (converted to single-label format, n=11): ['CKD G1-control' 'CKD G1A1-control' 'CKD Stage 1' 'CKD Stage 2'
 'CKD Stage 3a' 'CKD Stage 3b' 'CKD Stage 4' 'CKD Stage 5'
 'ESRD after transplant' 'ESRD on dialysis' 'Unknown']
seqReaderApp.load> nD: 2833, nT: 2833, nL: 2833
  + Stats: n_docs: 2833, n_classes:11 | cohort: CKD
processDocuments> Begin document transformation operations (e.g. simplify, diag-only, etc)
filterDocuments> Policy: Remove empty documents ...
transformDocuments> nD: 2833 (<- 2833), nT: 2833, nL: 2833
  + Stats: n_docs: 2833, n_classes:11
transformDocuments2> nD: 2360, nT: 2360, nL: 2360
  + Stats: n_docs: 2360, n_classes:11 | cohort: ?
    + (after transform) nDoc: 2833 -> 2360, size(D0): 16 -> 16
    + (after transform) nD: 2360, nT: 2360, nL: 2360
  + nD: 2360 | cohort=CKD, ctype=regular, labeled? True, simplified? False
  + doc(last 150 chars):
['954.9', 'NDC:00093715510', 'NDC:00182845389', 'NDC:00093078701', 'NDC:00186504031', 'MULTUM:11007', 'NDC:00067014182', '401.9', 'NDC:00113040378', 'E000.9', 'E849.8', 'E885.9', '922.1', '920', '401.9', '272.4', '786.52', 'MED:61253', 'NDC:00054465025', 'MED:62439', '530.81', '530.81', '203.00', '401.9', 'V76.12', '203.00', '729.1', '203.00', '719.46', '401.9', '719.41', '719.41', '726.19', '719.41', '726.19', '719.41', '726.19', '203.00', 'V58.11', '714.0', '203.00', 'MED:60998', '203.00', '203.00', '203.00', '719.45', '530.81', '401.9', '272.4', '203.00', '733.14', '338.3', 'MED:61078', 'MED:62439', 'MED:61895', 'MED:63114', 'MED:60926', '203.00', 'MED:62453', 'MED:89117', 'MED:63114', 'MED:122364', 'MED:61522', 'MED:69488', 'MED:102225', 'MED:102225', 'MULTUM:7129', 'MULTUM:471', 'NDC:00093078701', 'NDC:49999058730', 'NDC:00574041202', 'NDC:00247157010', 'NDC:00093715410', 'MULTUM:8313', '578.9', '455.8', 'MED:60972', 'MED:62899', 'V58.11', '719.45', '714.0', '203.00', 'MED:62899', '199.1', '203.00', '203.00', '203.00', '203.00', '203.00', '203.00', '203.00', '203.00', '203.00', 'V58.11', '714.0', '203.00', 'MED:60998', '203.00', '203.00', 'V58.69', '714.0', '425.11', '401.9', '784.0', '272.4', '203.00', 'MED:60926', 'NDC:49999058730', 'NDC:00054055125', '203.00', '203.00', '203.00', '203.00', '203.00', '203.00', '780.2', 'E849.0', 'E885.9', 'V15.88', 'V49.86', 'V66.7', '805.01', '714.0', '707.20', '426.12', '424.1', '530.81', '401.9', '805.02', '203.00', '799.02', '338.3', '707.03', 'MED:61253', 'MED:62439', 'MED:60826', 'MED:158045', 'MED:62934', 'MED:62439', 'MED:62453', 'MED:63182', 'MED:89117', 'MED:61863', 'MED:61895', 'MED:61522', 'MED:60926', 'MED:60492', 'MED:61939', 'MED:61078', 'NDC:00186504031']

  + vdoc
    + ['NDC:49999058730', 'NDC:00054055125']
    + ['203.00']
    + ['203.00']
    + ['203.00']
    + ['203.00']
    + ['203.00']
    + ['203.00']
    + ['780.2', 'E849.0', 'E885.9', 'V15.88', 'V49.86', 'V66.7', '805.01', '714.0', '707.20', '426.12', '424.1', '530.81', '401.9', '805.02', '203.00', '799.02', '338.3', '707.03', 'MED:61253', 'MED:62439', 'MED:60826']
    + ['MED:158045', 'MED:62934', 'MED:62439', 'MED:62453', 'MED:63182', 'MED:89117', 'MED:61863', 'MED:61895', 'MED:61522', 'MED:60926', 'MED:60492', 'MED:61939', 'MED:61078']
    + ['NDC:00186504031']
  + doc(last 150 chars):
['MED:63089', 'MED:63156', 'MED:81152', 'MED:122364', '331.0', '432.1', '290.40', 'NDC:00456320560', 'NDC:00088221905', '290.40', '250.00', '401.9', '272.4', '724.2', 'NDC:00113018771', 'NDC:00067014182', '600.00', '250.00', '414.00', '401.9', '331.0', '272.4', '780.4', 'MED:61703', 'NDC:00049211066', 'MED:63523', 'MED:62934', 'MULTUM:353', '401.9', '437.9', '780.4', 'V12.09', 'NDC:00087607111', 'NDC:00113019402', 'NDC:00088221905', 'NDC:00143125601', 'NDC:00093733801', 'NDC:00113018771', 'NDC:00247212130', 'NDC:00310075139', 'NDC:00067014182', '250.00', '412', '414.8', '437.0', '427.89', '428.0', '290.41', '272.4', '276.8', '600.01', '428.21', '414.01', 'V15.82', 'V58.67', '788.30', 'MED:60920', 'MED:63156', 'MED:61968', 'MED:61785', 'MED:60798', 'MED:61504', 'MED:62094', 'MED:63182', 'MED:73041', 'MED:70402', 'MED:62453', 'MED:167651', 'MED:81152', 'MED:103014', 'MED:60884', 'MED:61331', 'MED:60794', 'MED:73041', 'MED:71158', 'MED:61066', 'MED:60884', 'MED:97607', 'MED:136371', 'MED:81159', 'MED:132302', 'MED:86673', 'MED:81159', 'MED:60490', 'MED:63089', 'MED:69860', 'NDC:00087607111', 'NDC:00006001954', 'NDC:00028005101', 'NDC:00113018771', 'NDC:00113019402', 'NDC:00039006013', 'NDC:00054022020', 'NDC:00247212130', 'NDC:00310075139', 'NDC:00093733801', 'NDC:00067014182', '331.0', 'NDC:00054022020', 'NDC:00028005101', 'NDC:00087607111', 'NDC:00006001954', 'NDC:00247212130', 'NDC:00039006013', 'NDC:00113019402', 'NDC:00067014182', 'NDC:00093733801', 'NDC:00054022020', 'NDC:00310075139', '296.20', 'NDC:00054022020', 'G30.9', '331.0', '290.40', 'F01.50', 'NDC:00310075139', 'NDC:00054022020', 'NDC:00028005101', 'NDC:00113018771', 'NDC:00113019402', 'NDC:00039006013', 'NDC:00093733801', 'NDC:00087607111', 'NDC:00067014182', 'NDC:00247212130', 'I50.9', '428.0', 'NDC:00054429925', 'I50.9', '428.0', 'NDC:00054429925', 'I50.9', '428.0', 'NDC:00054429925', 'NDC:00143126601', 'NDC:00186109205', '250.00', 'I50.9', '428.0', 'G30.9', '331.0', 'E11.9', 'V04.81', 'Z23', '290.40', 'F01.50', 'MED:63182', 'MED:136373', 'MED:63465', 'MED:62899']

  + vdoc
    + ['NDC:00028005101', 'NDC:00087607111', 'NDC:00006001954', 'NDC:00247212130', 'NDC:00039006013', 'NDC:00113019402', 'NDC:00067014182', 'NDC:00093733801', 'NDC:00054022020', 'NDC:00310075139']
    + ['296.20', 'NDC:00054022020']
    + ['G30.9', '331.0', '290.40', 'F01.50', 'NDC:00310075139', 'NDC:00054022020', 'NDC:00028005101', 'NDC:00113018771', 'NDC:00113019402', 'NDC:00039006013', 'NDC:00093733801', 'NDC:00087607111', 'NDC:00067014182', 'NDC:00247212130']
    + ['I50.9', '428.0', 'NDC:00054429925']
    + ['I50.9', '428.0', 'NDC:00054429925']
    + ['I50.9', '428.0', 'NDC:00054429925', 'NDC:00143126601', 'NDC:00186109205']
    + ['250.00', 'I50.9', '428.0', 'G30.9', '331.0', 'E11.9', 'V04.81', 'Z23']
    + ['290.40', 'F01.50']
    + ['MED:63182']
    + ['MED:136373', 'MED:63465', 'MED:62899']
  + doc(last 150 chars):
['MULTUM:12134', 'MULTUM:1228', 'V07.0', 'V49.86', '599.0', '401.9', '345.50', '348.5', '198.3', '276.1', '780.97', '041.49', '410.71', '162.9', 'MED:60468', 'MED:101653', 'MED:61558', 'MED:60468', 'MED:63465', 'MED:61112', 'MED:60798', 'MED:61939', 'MED:61522', 'MED:61895', 'MED:62439', 'MED:63456', 'MED:62714', 'MED:62453', 'MED:81159', 'MED:70402', 'MED:149830', 'MED:101650', 'MED:101653', 'MED:63517', 'MED:99323', 'MED:66048', 'MED:89117', 'MED:62899', 'MED:62552', 'MED:131579', 'MED:60917', 'MULTUM:7727', 'NDC:00169330312', 'NDC:00054418625', 'NDC:00186504031', 'NDC:00093749306', '345.10', '198.3']

  + vdoc
    + ['MULTUM:12134', 'MULTUM:1228']
    + ['V07.0', 'V49.86', '599.0', '401.9', '345.50', '348.5', '198.3', '276.1', '780.97', '041.49', '410.71', '162.9', 'MED:60468', 'MED:101653']
    + ['MED:61558', 'MED:60468', 'MED:63465', 'MED:61112', 'MED:60798', 'MED:61939', 'MED:61522', 'MED:61895', 'MED:62439', 'MED:63456', 'MED:62714', 'MED:62453', 'MED:81159', 'MED:70402', 'MED:149830', 'MED:101650', 'MED:101653', 'MED:63517', 'MED:99323']
    + ['MED:66048', 'MED:89117', 'MED:62899']
    + ['MED:62552']
    + ['MED:131579']
    + ['MED:60917', 'MULTUM:7727', 'NDC:00169330312', 'NDC:00054418625', 'NDC:00186504031', 'NDC:00093749306']
    + ['345.10', '198.3']
  + doc(last 150 chars):
['250.01', '401.9', 'MED:61685', 'MED:33336', 'MED:31650', 'MED:49229', 'MED:58474', '250.00', '401.9', '294.8', '784.0', '272.0', 'V68.1', 'MED:61685', '715.90', '290.0', '784.0', '250.02', '401.9', '272.0', 'E849.8', 'E885.9', '719.45', '719.46', '250.00', '401.9', '959.01', '784.0', 'V15.88', 'V43.64', '716.90', '719.49', '729.5', '584.9', '070.70', '486', '346.90', '401.9', '294.8', '250.60', '357.2', '272.4', '278.00', '276.52', '781.2', '296.90', 'MULTUM:9072', 'NDC:62856024690', 'NDC:64764045126', 'NDC:00169008183', 'NDC:79854051281', 'NDC:54868078802', 'NDC:54868565400', 'NDC:65597010490', 'MULTUM:2036', 'NDC:68387066390', 'NDC:66267001660', 'MED:61895', 'MED:62453', 'MED:63220', 'MULTUM:1822', 'MED:70402', 'MED:60822', 'MED:60607', 'MED:63110', 'MED:98510', 'MED:69488', 'MED:81151', 'MED:61703', 'MED:63156', 'MED:62439', 'MED:101650', 'MED:60887', 'MED:61112', 'MED:60798', 'MED:61685', 'MED:60896', 'MED:61504', 'MED:98511', 'MED:60946', 'MED:62899', 'MED:71158', 'MED:63523', 'MED:61775', 'MED:60946', 'MED:67452', 'MED:61124', 'Raised_Toilet_With_Safety_Frame', 'Semielectric_Hospital_Bed', 'Bedside_Commode', 'MED:62934', 'MED:62873', 'MED:62994', 'MED:61736', 'MED:62439', 'MED:62994', 'MED:62994', 'MED:62994', 'MED:62994', 'MED:63220', 'MULTUM:608', 'NDC:68115026360', '250.00', '401.9', 'V58.67', '070.70', '250.00', '346.90', '401.9', '272.4', '276.1', '294.20', 'V12.54', 'NDC:00006011228', 'NDC:00087607005', 'MED:63156', 'NDC:00310075239', 'MED:73041', 'MED:70402', 'MED:101650', 'MED:62934', 'MED:62899', 'MED:61939', 'MED:60798', 'NDC:00093834401', 'MED:62439', 'MED:63239', 'MED:67864', 'MED:122364', 'MED:68339', 'MED:60975', 'MED:101650', 'MED:101067', 'MED:63110', 'MED:62129', 'MED:60884', 'MED:62994', 'NDC:62856024690', 'NDC:00093834401', 'NDC:00310075239', 'NDC:79854051281', 'NDC:00087607111', 'NDC:00074306330', 'NDC:54868078802', 'MULTUM:1377', 'NDC:64764045126', 'MULTUM:6850', 'MULTUM:7054', 'NDC:00247192630', 'MED:101650']

  + vdoc
    + ['MED:61736', 'MED:62439', 'MED:62994']
    + ['MED:62994']
    + ['MED:62994']
    + ['MED:62994']
    + ['MED:63220']
    + ['MULTUM:608', 'NDC:68115026360']
    + ['250.00', '401.9']
    + ['V58.67', '070.70', '250.00', '346.90', '401.9', '272.4', '276.1', '294.20', 'V12.54', 'NDC:00006011228', 'NDC:00087607005', 'MED:63156', 'NDC:00310075239', 'MED:73041', 'MED:70402', 'MED:101650', 'MED:62934', 'MED:62899', 'MED:61939', 'MED:60798']
    + ['NDC:00093834401', 'MED:62439', 'MED:63239', 'MED:67864', 'MED:122364', 'MED:68339', 'MED:60975', 'MED:101650', 'MED:101067', 'MED:63110', 'MED:62129', 'MED:60884', 'MED:62994']
    + ['NDC:62856024690', 'NDC:00093834401', 'NDC:00310075239', 'NDC:79854051281', 'NDC:00087607111', 'NDC:00074306330', 'NDC:54868078802', 'MULTUM:1377', 'NDC:64764045126', 'MULTUM:6850', 'MULTUM:7054', 'NDC:00247192630', 'MED:101650']
  + doc(last 150 chars):
['V22.0', 'V22.2', 'V72.6', '642.91', '599.0', 'V72.3', 'V72.3', '789.00', '716.50', '883.0', 'V58.3', 'V72.3', 'V76.12', '787.2', '448.1', 'V01.1', 'V01.1', 'V76.12', 'V04.81', '465.9', 'V76.12', '756.15', 'V76.12', '465.9', 'V76.12', '793.80', '793.80', '564.00', '401.9', 'MED:28570', 'MED:30089', '793.89', '793.80', '272.4', '564.00', '793.80', 'V72.31', 'V70.0', 'V74.5', 'V73.81', '565.0', '789.00', '793.89', '786.2', '729.5', 'V76.12', '599.72', '586', '455.6', '455.3', '455.0', 'NDC:00074194912', 'NDC:00093715410', 'MULTUM:608', 'NDC:00093075301', '569.42', 'MED:60926', 'NDC:49999058730', '788.29', 'MED:61666', '585.9', '564.00', '599.0', '788.20', '578.9', '272.4', '280.9', '403.90', '041.49', '414.01', 'MED:62934', 'MED:62879', 'MED:61124', 'MED:61112', 'MED:61171', 'MED:61895', 'MED:61433', 'MED:61522', 'MED:61968', 'MED:62439', 'MED:61939', 'MED:63281', 'MED:61995', 'MED:106708', 'MED:133079', 'MED:122364', 'MED:62934', 'NDC:00093314701', 'NDC:00093733801', 'MED:61433', 'NDC:11523723402', 'MED:69488', 'MED:97778', 'NDC:00245010801', 'NDC:00093715410', '585.3', '791.0', '791.0', '585.3', '585.3', '583.9', '585.3', '585.3', '401.1', '401.1', '585.4', 'V76.12', '585.4', '585.4', 'V49.83', '285.21', 'MED:63518', '285.21', '285.21', '583.9', '285.21', 'MED:72161', 'MED:63518', '285.21', 'MED:63518', 'V72.31', 'V77.0', '627.2', '285.21', '285.21', 'MED:63518', '585.4', '285.21', 'MED:63518', '285.21', 'MED:63518', '285.21', 'MED:63518', 'NDC:00113040378', 'MED:167651', 'D63.1', 'MED:63518', 'D63.1', 'N18.4', 'R07.9', 'N18.4', 'N18.4', 'Z12.11', 'N18.6', 'Z23', 'Z76.82', 'N18.4']

  + vdoc
    + ['285.21', 'MED:63518']
    + ['NDC:00113040378', 'MED:167651']
    + ['D63.1', 'MED:63518']
    + ['D63.1']
    + ['N18.4']
    + ['R07.9', 'N18.4']
    + ['N18.4']
    + ['Z12.11']
    + ['N18.6', 'Z23', 'Z76.82']
    + ['N18.4']
  + doc(last 150 chars):
['309.4', '309.4', '309.4', '309.4', '366.9', '366.9', '366.8', '366.17', '366.17', 'V04.8', '401.9', '786.2', '573.9']

  + vdoc
    + ['309.4']
    + ['309.4']
    + ['366.9']
    + ['366.9']
    + ['366.8']
    + ['366.17']
    + ['366.17']
    + ['V04.8', '401.9']
    + ['786.2']
    + ['573.9']
  + doc(last 150 chars):
['MED:62679', 'MED:60671', 'MED:68180', 'MED:81318', 'MED:114640', 'MED:62968', 'MED:63089', 'MED:89117', 'MED:62834', 'MED:62453', 'MED:62439', 'MED:62616', 'MED:62685', 'MED:70402', 'MED:62987', 'MED:107078', 'MED:63118', 'MED:61895', 'MED:101650', 'MED:63606', 'MED:60920', 'MED:62879', 'MED:62679', 'MED:60946', 'MED:61211', 'MED:63129', 'MED:60612', 'MED:61112', 'MED:61522', 'MED:60465', 'MED:60798', 'MED:61513', 'MED:62679', 'MED:61118', 'MED:63448', 'MED:60843', 'MED:62987', 'MED:61473', 'MED:97890', 'MED:62679', 'MED:60612', 'MED:61361', 'MED:114640', 'MED:81318', 'MED:63408', 'MED:62184', 'MED:60583', 'MED:122364', 'MED:63285', 'MED:62742', 'MED:114640', 'MED:69488', 'MED:61513', 'MED:62679', 'MED:61558', 'MED:62934', 'MED:63596', 'MED:62899', 'MED:97890', 'MED:61361', 'MED:63274', 'MED:63594', 'MED:63408', 'MED:71459', 'MED:61513', 'MED:62184', 'MED:63183', 'MED:61460', 'MED:62679', 'MED:61118', 'MED:63272', 'MED:85037', 'MED:63274', 'MED:63408', 'MED:63590', 'MED:63055', 'MED:61321', 'MED:62127', 'MED:60920', 'MED:61473', 'MED:63272', 'MED:62557', 'MED:124575', 'MED:63413', 'MED:63590', 'MED:60920', 'MED:124575', 'MED:87663', 'MED:68349', 'MED:61473', 'MED:114640', 'MED:62934', 'MED:62659', 'MED:69143', 'MED:62834', 'MED:62800', 'MED:62664', 'MED:62899', 'MED:62184', 'MED:61264', 'MED:61558', 'MED:62899', 'NDC:00113040378', 'NDC:68258303101', 'NDC:00071041813', 'MED:101650', 'MED:61759', 'MED:97890', 'MED:69488', 'MED:62800', 'MED:63284', 'MED:97890', 'MED:61558', 'MED:60920', 'MED:101650', 'MED:62439', 'MED:68349', 'MED:61759', 'MED:62800', 'Nepro_Carb_Steady_Vanilla', 'MULTUM:7003', 'Nebulizer_Machine', 'NDC:00113040378', 'NDC:12843003520', 'NDC:00054001720', 'NDC:00085009101', 'MED:61513', 'MULTUM:3037', 'Diltiazem_Cd_180_Mg', 'NDC:63874060530', 'NDC:00182055589', 'Meplex_Dressing_Apply_To_Sacrum_Every_3_Days', 'NDC:11523723402', 'NDC:00088221905', 'NDC:00182864389', 'NDC:00172541310', 'NDC:00074380711', 'Diltiazem_Cd_180_Mg', 'Ipatropium_Mdi', 'aerochamber', 'NDC:68258303101', 'NDC:00182055589', 'NDC:00904545209', 'MULTUM:3037', 'MULTUM:12431', 'NDC:00085009101', 'NDC:00062535001', 'NDC:00093417773', 'MULTUM:12431', 'MULTUM:3755']

  + vdoc
    + ['MED:101650', 'MED:61759']
    + ['MED:97890']
    + ['MED:69488', 'MED:62800', 'MED:63284', 'MED:97890', 'MED:61558']
    + ['MED:60920']
    + ['MED:101650', 'MED:62439', 'MED:68349', 'MED:61759']
    + ['MED:62800', 'Nepro_Carb_Steady_Vanilla', 'MULTUM:7003', 'Nebulizer_Machine', 'NDC:00113040378', 'NDC:12843003520', 'NDC:00054001720', 'NDC:00085009101', 'MED:61513', 'MULTUM:3037', 'Diltiazem_Cd_180_Mg', 'NDC:63874060530', 'NDC:00182055589', 'Meplex_Dressing_Apply_To_Sacrum_Every_3_Days', 'NDC:11523723402', 'NDC:00088221905', 'NDC:00182864389', 'NDC:00172541310']
    + ['NDC:00074380711', 'Diltiazem_Cd_180_Mg', 'Ipatropium_Mdi', 'aerochamber', 'NDC:68258303101', 'NDC:00182055589', 'NDC:00904545209', 'MULTUM:3037', 'MULTUM:12431', 'NDC:00085009101']
    + ['NDC:00062535001', 'NDC:00093417773']
    + ['MULTUM:12431']
    + ['MULTUM:3755']
  + doc(last 150 chars):
['786.50', '786.50', 'V70.0', '427.9', '311', '401.9', '706.2', '727.41', '401.9', '727.41', '401.9', '401.9', 'V82.9', '401.9', '401.9', '727.3', '401.9', '401.9', '401.9', 'V70.0', '401.9', '401.9', '786.50', '578.1', '578.1', '211.3', '564.0', '401.9', '706.2', '706.2', '706.2', '401.9', '401.9', '789.00', '731.0', 'V14.9', '401.9', 'V62.81', 'V62.89', 'V62.81', 'V62.89', 'V62.81', 'V62.89', '401.9', '401.9', '706.2', '702.19', '706.2', '401.9', '701.9', '701.9', '701.9', '401.9', '530.81', '401.9', '731.0', 'MED:73190', '574.20', 'E928.9', '995.1', 'MED:29498', 'MED:33590', 'MED:28392', 'E928.9', '401.9', '995.1', 'MED:63435', 'MED:63517', 'MED:67867', 'MED:60926', 'MED:62439', 'MED:62038', 'MED:61812', 'MED:60826', 'MED:61895', 'MED:61836', 'MED:60582', 'MED:61112', 'MED:62994', 'MED:61836']

  + vdoc
    + ['701.9']
    + ['401.9']
    + ['530.81']
    + ['401.9']
    + ['731.0', 'MED:73190']
    + ['574.20']
    + ['E928.9', '995.1', 'MED:29498', 'MED:33590', 'MED:28392']
    + ['E928.9', '401.9', '995.1']
    + ['MED:63435', 'MED:63517', 'MED:67867', 'MED:60926', 'MED:62439', 'MED:62038', 'MED:61812', 'MED:60826', 'MED:61895', 'MED:61836', 'MED:60582', 'MED:61112', 'MED:62994']
    + ['MED:61836']
  + doc(last 150 chars):
['V82.9', '715.90', '401.9', '465.9', '250.00', '401.9', '401.9', '401.9', '571.9', '571.40', '401.9', '401.9', '789.00', '789.00', '454.1', '401.9', '454.1', '578.9', '719.41', '923.20', '401.9', '789.06', '455.0', '401.9', '472.0', '388.30', '573.3', '388.30', '571.40', 'V62.89', '465.9', '401.9', '401.9', 'V76.12', '401.9', '682.9', '709.9', '698.3', '719.40', '272.0', '078.10', '454.1', 'E849.8', 'E880.9', 'V14.0', '724.2', '401.9', '110.1', '401.9', '719.04', '401.9', '272.0', '272.0', '110.1', 'V76.12', '272.0', '703.8', '112.3', '112.3', '112.3', '112.3', '573.9', '571.40', '401.9', '784.0', '110.1', '719.41', '719.41', '719.41', '719.41', '719.41', '401.9', '719.41', '719.41', '719.41', '716.90', '786.2', '401.9', '388.70', '780.99', '478.1', 'V70.0', '465.9', '079.99', '486', '401.9', '110.1', '784.7', '401.9', '401.9', '110.1', '401.9', '311', '401.9', '692.9', '110.1', 'V76.12', '389.00']

  + vdoc
    + ['110.1']
    + ['784.7', '401.9']
    + ['401.9']
    + ['110.1']
    + ['401.9', '311']
    + ['401.9']
    + ['692.9']
    + ['110.1']
    + ['V76.12']
    + ['389.00']
  + doc(last 150 chars):
['V70.0', '788.1', '625.9', '788.39', '401.9', '616.0', '599.9', '692.9', '625.9', 'V72.3', 'V72.3', 'V70.0', '401.9', '455.6', '401.9', '451.9', '707.9', '401.9', '788.1', '401.9', '786.50', '786.59', '782.1', '411.1', '401.9', 'MED:63469', 'MED:62685', 'MED:62439', 'MED:63573', 'MED:61785', 'MED:61814', 'MED:61736', '401.9', '789.00', '401.9', '533.90', '401.9', '789.04', '401.9', '401.9', '724.2', '599.9', '401.9', '796.9', '692.9', '616.10', '401.9', '848.9', '401.9', '846.0', '784.7', '401.9', '401.9', '733.00', '401.9', '625.6', '401.9', 'V76.12', 'V68.1', '401.9', 'V67.9', '401.9', 'V76.12', '733.00', '724.2', '272.0', '424.90', 'NDC:11523723701', 'NDC:62037083301', 'NDC:58016653301', 'NDC:50383006104', 'NDC:64455014390', 'NDC:58016061304', '401.9', '272.0', 'NDC:60346059530', 'Vitamin_D_1000_Iu', 'NDC:49999035160', 'NDC:66105050503', '401.9', '272.0', 'NDC:62037083301', 'NDC:68115077730', 'V04.81', 'NDC:62037083301', 'NDC:60346059530', 'NDC:68115077730', '401.9', '272.0', 'V65.40', '401.9', '272.0', 'NDC:68387053730', '401.1', '272.2', 'MULTUM:2396', 'NDC:54868560700', 'NDC:68115077730', 'NDC:58016061304', 'NDC:49999035160', 'Vitamin_D_1000_Iu', 'V72.60', '401.1', '285.9', 'NDC:55887003812', '401.1', '285.9', 'MULTUM:608', 'V72.60', '401.9', '585.1', 'V72.60', '593.9', 'NDC:58864075930', 'MULTUM:8404', '401.1', '593.9', 'NDC:62037083301', 'NDC:55289087630', 'NDC:00245002414', 'V72.60', '709.9', '401.1', 'NDC:11523096307', 'NDC:66267059210', 'V04.81', '401.1', '272.2', 'MULTUM:16417', 'V72.60', '401.1', 'Blood_Pressure_Cuff', 'NDC:00378022201', '401.1', '401.1', 'NDC:00378021301', 'V76.12', '701.1', '401.1', 'MULTUM:1470', '401.9', '585.3']

  + vdoc
    + ['V72.60']
    + ['709.9', '401.1', 'NDC:11523096307', 'NDC:66267059210']
    + ['V04.81', '401.1', '272.2', 'MULTUM:16417']
    + ['V72.60']
    + ['401.1', 'Blood_Pressure_Cuff', 'NDC:00378022201']
    + ['401.1']
    + ['401.1', 'NDC:00378021301']
    + ['V76.12', '701.1', '401.1', 'MULTUM:1470']
    + ['401.9']
    + ['585.3']
  + doc(last 150 chars):
['747.11', 'V20.2', '434.11', '478.31', 'V20.2', '746.9', 'V12.54', 'V20.2', '796.2', 'V07.0', 'V12.49', 'V13.65', 'V15.1', '564.00', '746.81', '478.30', '518.0', '786.09', '747.69', '747.22', '348.89', '742.1', '287.5', '417.8', '747.11', '745.4', 'E878.1', '315.8', '263.0', '315.39', '996.09', '338.18', '079.89', '433.10', '438.20', 'MED:60998', 'MED:60481', 'MED:94350', 'MED:62511', 'MED:133116', 'MED:106366', 'MED:102484', 'MED:72705', 'MED:62062', 'MED:72705', 'MED:60998', 'MED:70466', 'MED:63540', 'MED:61253', 'MED:60998', 'MED:61348', 'MED:63518', 'MED:106366', 'MED:63540', 'MED:156852', 'MED:72705', 'MED:61348', 'MED:107357', 'MED:62343', 'MED:106366', 'MED:156852', 'MED:63518', 'MED:66023', 'MED:69488', 'MED:69488', 'MED:63122', 'MED:61627', 'MED:61229', 'MED:63081', 'MED:77728', 'MED:61995', 'MED:61974', 'NDC:00054329446', 'NDC:00054329446', '478.31', 'V67.59', '746.9', 'V12.54', '478.31', 'V12.49', '682.4', '746.9', 'NDC:00029152544', 'NDC:00009076004', '434.91', '434.91', '434.91', '787.21', '478.30', '436', '758.31', '478.31', 'V04.81', '746.9', '783.40', 'V12.54', '786.09', '784.42', '367.0', '367.20', '681.10', '746.9', 'V12.54', 'NDC:00093417773', 'V72.82', '478.31', 'V12.49', '746.9', '701.1', 'NDC:00245002414', 'V12.49', 'V67.59', '746.81', '786.09', '745.4', 'Albuterol_Spacer', 'NDC:00173068220', '780.39', '788.36', '746.9', '783.40', 'V12.54', 'V13.65', 'V45.01', '706.8', '780.39', '345.90', 'NDC:00064211003', 'NDC:00187065820', 'NDC:00054019959', '478.30', '345.41', 'V12.49', '788.36', '478.30', '783.40', 'diapers', 'V45.01', '348.89', '780.39', '345.90', '438.20', 'MED:61856', '327.23', 'J38.00', '478.30', 'G81.14', 'R26.9', '781.2', '342.12']

  + vdoc
    + ['788.36', '746.9', '783.40', 'V12.54']
    + ['V13.65', 'V45.01', '706.8', '780.39', '345.90', 'NDC:00064211003']
    + ['NDC:00187065820', 'NDC:00054019959']
    + ['478.30']
    + ['345.41']
    + ['V12.49', '788.36', '478.30', '783.40', 'diapers']
    + ['V45.01', '348.89', '780.39', '345.90', '438.20', 'MED:61856']
    + ['327.23']
    + ['J38.00', '478.30']
    + ['G81.14', 'R26.9', '781.2', '342.12']
  + doc(last 150 chars):
['070.54', '070.54', '070.54', '070.54', 'E849.0', 'E920.8', '892.0', 'MED:56017', '573.3', '070.54', '070.54']

  + vdoc
    + ['070.54']
    + ['070.54']
    + ['070.54']
    + ['070.54']
    + ['E849.0', 'E920.8', '892.0', 'MED:56017']
    + ['573.3']
    + ['070.54']
    + ['070.54']
  + doc(last 150 chars):
['585.6', '585.6', '403.91', '585.5', 'MED:101652', 'MED:60762', 'MED:66037', 'MED:60926', 'MED:69242', 'MED:62439', 'MED:61471', 'MED:62838', 'MED:61262', 'MED:61253', 'MED:63156', 'MED:62659', 'MED:62936', 'MED:89117', 'MED:60553', 'MED:61124', 'MED:62522', 'MED:62838', 'MED:71675', 'MED:62636', 'MED:61253', 'MED:61895', 'MED:69954', 'MED:62522', 'MED:69242', 'MED:62522', 'MED:63613', 'MED:69954', 'MED:62659', 'MED:81159', 'MED:60577', 'MED:60635', 'MED:61471', 'MED:61473', 'MED:69242', 'V42.0', 'V58.69', 'V42.0', 'V58.69', 'V42.0', 'V58.69', 'V42.0', 'V58.69', 'V42.0', 'V58.69', 'V42.0', 'V58.69', 'V42.0', 'V58.69', 'V42.0', 'V58.69', '599.0', '585.6', 'V42.0', 'V58.69', 'V42.0', 'V58.69', 'V42.0', 'V58.69', 'V42.0', 'V58.69', 'V58.69', 'V42.0', 'V42.0', 'V58.69', 'V58.69', 'V42.0', 'V42.0', 'V58.69', 'V42.0', 'V58.69', 'V42.0', 'V58.69', 'V04.81', 'V42.0', 'V58.69', 'MED:62511', 'V42.0', 'V58.69', 'V42.0', 'V58.69', 'V42.0', 'V58.69', 'V42.0', 'V58.69', 'V42.0', '794.8', 'V42.0', 'V58.69', '794.8', '793.4', 'V42.0', '782.4', '577.9', '751.69', '576.2', '793.4', 'V42.0', '577.9', '157.0', '230.9', 'V42.0', 'V58.69', 'V42.0', 'V58.69']

  + vdoc
    + ['V42.0', 'V58.69']
    + ['V42.0', 'V58.69']
    + ['V42.0', 'V58.69']
    + ['V42.0', '794.8']
    + ['V42.0', 'V58.69']
    + ['794.8', '793.4', 'V42.0', '782.4', '577.9', '751.69', '576.2']
    + ['793.4', 'V42.0', '577.9', '157.0']
    + ['230.9']
    + ['V42.0', 'V58.69']
    + ['V42.0', 'V58.69']
  + doc(last 150 chars):
['585.2', '585.1', '580.9', '585.2', '791.0', '585.3', '791.0', '585.2', '585.2', 'V42.0', '996.81', 'MED:60481', 'MED:62936', 'MED:62439', '581.1', 'MED:62936', 'MED:62871', 'MED:60481', 'MED:62439', '581.1', 'MED:62439', 'MED:62871', 'MED:60481', 'MED:62936', '581.1', '996.81', 'MED:62871', 'MED:60481', 'MED:62936', 'MED:62439']

  + vdoc
    + ['580.9']
    + ['585.2']
    + ['791.0', '585.3']
    + ['791.0']
    + ['585.2']
    + ['585.2']
    + ['V42.0', '996.81', 'MED:60481', 'MED:62936', 'MED:62439']
    + ['581.1', 'MED:62936', 'MED:62871', 'MED:60481', 'MED:62439']
    + ['581.1', 'MED:62439', 'MED:62871', 'MED:60481', 'MED:62936']
    + ['581.1', '996.81', 'MED:62871', 'MED:60481', 'MED:62936', 'MED:62439']
  + doc(last 150 chars):
['V22.2', 'V22.2', '250.00', '789.06', '649.13', '655.83', '648.03', '250.00', '642.03', '278.00', 'Prenatal_Vitamin', 'MED:62296', 'MED:70402', 'MED:62774', 'MED:60798', 'MED:62309', 'MED:63156', 'MED:61895', 'MED:106359', 'MED:62940', 'MED:62774', 'MULTUM:2741', 'MULTUM:6819', 'NDC:00002831501', '1cc_Syringes', 'Accucheck_Test_Strips', 'MULTUM:5208', 'MULTUM:6819', 'NDC:00002831501', 'MED:62774', '655.93', '655.93', 'V22.2', '644.21', '649.11', '655.81', 'V27.0', '642.71', '250.00', '401.9', '278.00', '648.93', '648.01', 'MED:62296', 'MED:70402', 'MED:106261', 'MED:73041', 'MED:61853', 'MED:62774', 'MED:60798', 'MED:63156', 'MED:61895', 'MED:62309', 'MED:62940', 'MED:101650', 'MED:73041', 'MED:62774', 'MED:61052', 'MED:61632', 'MED:63518', 'MED:73041', 'MED:61853', 'MED:61812', 'MED:73041', 'MED:62774', 'MED:62774', 'MED:62337', 'MED:63540', 'MED:99142', 'MED:103931', 'MED:70402', 'MED:131940', 'MED:106359', 'MED:107078', 'MED:63156', 'MED:60798', 'MED:62994', 'MED:60553', 'MED:61736', 'MED:61972', 'MED:61120', 'MED:62290', 'MED:63596', 'MED:61895', 'MED:60926', 'MED:61870', 'MED:62439', 'MED:73041', 'MED:62309', 'NDC:55111068301', 'MED:70402', 'NDC:00054465025', 'MED:73041', 'MED:69248', 'MED:60798', 'MED:63156', 'MED:70402', 'MED:63156', 'MED:60798', 'V23.9', 'V23.9', '654.23', '633.90', 'MED:60546', '633.01', '633.10', 'V70.0', 'V70.0', 'V70.0', 'V70.0', 'V23.9', 'V70.0', 'V70.0', '632', 'V70.0', '632']

  + vdoc
    + ['633.90', 'MED:60546']
    + ['633.01']
    + ['633.10']
    + ['V70.0']
    + ['V70.0']
    + ['V70.0']
    + ['V70.0', 'V23.9']
    + ['V70.0']
    + ['V70.0', '632']
    + ['V70.0', '632']
  + doc(last 150 chars):
['V22.1', '656.11', 'V02.51', 'V27.0', '664.11', '648.91', 'MED:61382', 'MED:61120', 'MED:60481', 'MED:62994', 'MED:61895', 'MED:62439', 'MED:60926', 'MED:62683', 'MED:61829', 'MED:61736', 'MED:99142', 'MED:63517', 'MED:106261', 'MED:63055', 'MED:62296', 'MED:61253', 'MULTUM:11732', 'MED:62624']

  + vdoc
    + ['V22.1', '656.11', 'V02.51', 'V27.0', '664.11', '648.91', 'MED:61382', 'MED:61120', 'MED:60481', 'MED:62994', 'MED:61895', 'MED:62439', 'MED:60926', 'MED:62683', 'MED:61829', 'MED:61736', 'MED:99142', 'MED:63517', 'MED:106261', 'MED:63055', 'MED:62296', 'MED:61253', 'MULTUM:11732', 'MED:62624']
  + doc(last 150 chars):
['655.83', 'V23.9', 'V67.9', '654.20', '655.83', 'V26.33', '655.83', 'V23.9', '655.83', 'V23.9', 'V67.9', '655.93', 'V23.9', 'V67.9', '796.2', '655.81', '659.41', 'V25.2', 'V27.0', '786.59', '642.31', '642.41', '493.90', '784.0', '648.91', '674.82', '654.21', 'MED:61895', 'MED:62439', 'MED:106359', 'MED:62296', 'MED:62587', 'MED:62290', 'MED:62994', 'MED:63596', 'MED:61895', 'MED:62439', 'MED:61870', 'MED:60926', 'MED:61120', 'MED:106359', 'MED:107078', 'MED:61594', 'MED:103931', 'MED:99142', 'NDC:54868051000', 'NDC:49999058730', 'NDC:00122301733', 'NDC:00904531346', 'MED:99018', 'MED:128621', 'V81.1', 'V72.31', '654.20']

  + vdoc
    + ['655.83', 'V23.9']
    + ['655.83', 'V23.9', 'V67.9']
    + ['655.93']
    + ['V23.9', 'V67.9']
    + ['796.2', '655.81', '659.41', 'V25.2', 'V27.0', '786.59', '642.31', '642.41', '493.90', '784.0', '648.91', '674.82', '654.21', 'MED:61895', 'MED:62439', 'MED:106359', 'MED:62296', 'MED:62587']
    + ['MED:62290', 'MED:62994', 'MED:63596', 'MED:61895', 'MED:62439', 'MED:61870', 'MED:60926', 'MED:61120', 'MED:106359', 'MED:107078', 'MED:61594', 'MED:103931', 'MED:99142']
    + ['NDC:54868051000', 'NDC:49999058730']
    + ['NDC:00122301733', 'NDC:00904531346', 'MED:99018', 'MED:128621']
    + ['V81.1']
    + ['V72.31', '654.20']
  + doc(last 150 chars):
['581.1', 'MED:62525', 'MED:77684', '581.1', 'MED:62525', 'MED:77684', 'MED:61814', 'MED:62439', '581.1', 'MED:62525', 'MED:77684', 'MED:61814', 'MED:62439', '581.1', 'MED:62525', 'MED:77684', 'MED:61814', 'MED:62439']

  + vdoc
    + ['581.1', 'MED:62525', 'MED:77684']
    + ['581.1', 'MED:62525', 'MED:77684', 'MED:61814', 'MED:62439']
    + ['581.1', 'MED:62525', 'MED:77684', 'MED:61814', 'MED:62439']
    + ['581.1', 'MED:62525', 'MED:77684', 'MED:61814', 'MED:62439']
  + doc(last 150 chars):
['MED:98005', 'MED:102484', 'MED:133116', 'MED:66167', 'MED:63122', 'MED:61972', 'MED:102419', 'MED:61911', 'MED:61511', 'MED:60936', 'MED:69155', 'MED:61309', 'MED:61911', 'MED:61511', 'MED:81379', 'MED:62649', 'MED:70786', 'MED:61836', 'MED:61511', 'MED:61309', 'MED:104889', 'MED:63182', 'MED:66136', 'MED:67465', 'MED:61511', 'MED:63465', 'MED:98005', 'MED:100184', 'MED:104889', 'MED:66125', 'MED:66068', 'MED:62666', 'MED:102484', 'MED:62649', 'MED:62274', 'MED:66136', 'MED:106366', 'MED:63540', 'MED:125227', 'MED:63122', 'MED:61836', 'MED:63096', 'MED:69148', 'MED:63433', 'MED:61678', 'MED:61704', 'MED:72705', 'MED:60481', 'MED:62701', 'MED:61309', 'MED:62402', 'MED:102419', 'MED:63465', 'MED:62343', 'MED:60835', 'MED:60755', 'MED:62402', 'MED:61865', 'MED:60481', 'MED:98005', 'MED:126011', 'MED:125229', 'MED:62659', 'MED:63055', 'MED:61836', 'MED:61865', 'MED:62343', 'MED:98005', 'MED:62666', 'MED:63055', 'MED:62899', 'MED:126011', 'MED:102484', 'MED:63182', 'MED:66136', 'MED:125229', 'MED:62402', 'MED:61471', 'MED:60481', 'MED:61216', 'MED:61309', 'MED:62659', 'MED:102419', 'MED:63465', 'MED:62343', 'MED:62829', 'MED:63540', 'MED:133116', 'MED:61865', 'MED:60481', 'MED:70786', 'MED:60481', 'MED:61704', 'MED:62829', 'MED:106366', 'MED:96730', 'MED:63433', 'MED:60984', 'MED:60650', 'MED:62659', 'MED:63182', 'MED:102218', 'MED:149979', 'MED:61704', 'MED:61759', 'MED:61865', 'MED:72705', 'MED:98005', 'MED:62659', 'MED:62666', 'MED:63055', 'MED:126011', 'MED:102484', 'MED:72705', 'MED:66136', 'MED:62934', 'MED:125229', 'MED:61865', 'MED:61759', 'MED:60481', 'MED:61309', 'MED:63433', 'MED:102419', 'MED:62829', 'MED:63465', 'MED:62035', 'MED:61471', 'MED:62829', 'MED:63055', 'MED:63518', 'MED:72705', 'MED:61253', 'MED:63540', 'MED:61836', 'MED:62402', 'MED:61348', 'MED:62829', 'MED:60553', 'MED:60556', 'MED:63055', 'MED:63518', 'MED:72705', 'MED:61253', 'MED:63540', 'MED:133116', 'MED:62934', 'MED:101186', 'MED:62871', 'MED:63414', 'MED:61216']

  + vdoc
    + ['MED:62659', 'MED:63055', 'MED:61836', 'MED:61865', 'MED:62343']
    + ['MED:98005', 'MED:62666', 'MED:63055', 'MED:62899', 'MED:126011', 'MED:102484', 'MED:63182', 'MED:66136', 'MED:125229', 'MED:62402', 'MED:61471', 'MED:60481', 'MED:61216', 'MED:61309', 'MED:62659', 'MED:102419', 'MED:63465', 'MED:62343', 'MED:62829']
    + ['MED:63540', 'MED:133116', 'MED:61865', 'MED:60481']
    + ['MED:70786', 'MED:60481', 'MED:61704', 'MED:62829']
    + ['MED:106366', 'MED:96730', 'MED:63433', 'MED:60984', 'MED:60650']
    + ['MED:62659', 'MED:63182', 'MED:102218', 'MED:149979', 'MED:61704', 'MED:61759', 'MED:61865', 'MED:72705']
    + ['MED:98005', 'MED:62659', 'MED:62666', 'MED:63055', 'MED:126011', 'MED:102484', 'MED:72705', 'MED:66136', 'MED:62934', 'MED:125229', 'MED:61865', 'MED:61759', 'MED:60481', 'MED:61309', 'MED:63433', 'MED:102419', 'MED:62829', 'MED:63465']
    + ['MED:62035', 'MED:61471', 'MED:62829']
    + ['MED:63055', 'MED:63518', 'MED:72705', 'MED:61253', 'MED:63540', 'MED:61836', 'MED:62402', 'MED:61348', 'MED:62829', 'MED:60553', 'MED:60556']
    + ['MED:63055', 'MED:63518', 'MED:72705', 'MED:61253', 'MED:63540', 'MED:133116', 'MED:62934', 'MED:101186', 'MED:62871', 'MED:63414', 'MED:61216']
  + doc(last 150 chars):
['582.9', '585.3', 'V58.65', '791.0', '584.5', '403.10', '588.81', '585.4', '582.9', 'V49.83', 'V49.83', 'V67.59', 'V03.82', '585.6', '585.4', 'MED:99018', '585.6', '585.6', '585.4', '585.3', 'N18.6', 'Z79.52', 'N18.6', 'N18.6', 'N18.4']

  + vdoc
    + ['585.4']
    + ['582.9']
    + ['V49.83']
    + ['V49.83', 'V67.59', 'V03.82', '585.6', '585.4', 'MED:99018']
    + ['585.6']
    + ['585.6', '585.4']
    + ['585.3']
    + ['N18.6']
    + ['Z79.52', 'N18.6']
    + ['N18.6', 'N18.4']
  + avgL: 3.401748, max n_tokens_in_visit: 71, min: 1, std: 4.775765
  + avgV: 90.685169, max n_visits_in_doc:   1082, min: 1, std: 114.666660
visitToDocment> size(V):2360 -> size(Dv):214017 (E[nVperDoc]=90.685169)
> D:
[['813.42', '813.42', '813.42', '813.42', '813.42', '813.42', '813.42', '813.42', '813.42', '813.42', '813.42', '813.42', '813.42', '813.42', '813.42', '813.42', '813.42', '813.42', '813.42', '813.42', '813.42', '813.42', '813.42', '813.42', '813.42', '813.42', '813.42', '813.42', '813.42', '813.42', '813.42', '813.42', '813.42', '813.42', '813.42', '813.42', '813.42', '813.42', '813.42', '813.42', '813.42', '813.42', '813.42', '813.42', '813.42', '813.42', '813.42', '813.42', '813.42', '813.42', '813.42', '813.42', '813.42', '813.42', '813.42', '813.42', '813.42', '813.42', '813.42', '813.42', '813.42', '813.42', '813.42', '813.42', '813.42', '813.42', '813.42', '813.42', '813.42', '813.42', '813.42'], ['813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41'], ['813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41'], ['813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41'], ['813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41'], ['813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41'], ['813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41'], ['813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41'], ['813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41'], ['813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41']]

    + computing document vectors nD:2360 => nDEff: 214017 ...
makeTSetVisit> model dir: /Users/pleiades/Documents/work/tpheno/seqmaker/data/CKD/model
getDocVec> method: pv-dm2, model ID: smallCKD, segment_by_visit? True, load precomputed? True
getDocVecPV> prior to labelDocuments, already labeled? False, example: ['813.42', '813.42', '813.42', '813.42', '813.42', '813.42', '813.42', '813.42', '813.42', '813.42', '813.42', '813.42', '813.42', '813.42', '813.42', '813.42', '813.42', '813.42', '813.42', '813.42', '813.42', '813.42', '813.42', '813.42', '813.42', '813.42', '813.42', '813.42', '813.42', '813.42', '813.42', '813.42', '813.42', '813.42', '813.42', '813.42', '813.42', '813.42', '813.42', '813.42', '813.42', '813.42', '813.42', '813.42', '813.42', '813.42', '813.42', '813.42', '813.42', '813.42', '813.42', '813.42', '813.42', '813.42', '813.42', '813.42', '813.42', '813.42', '813.42', '813.42', '813.42', '813.42', '813.42', '813.42', '813.42', '813.42', '813.42', '813.42', '813.42', '813.42', '813.42'], type: <type 'list'>
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
Doc2Vec Parameters
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
  + current d2v method: pv-dm2
  + number of features: 50
  + window size: 10
  + ignore tokens with total freq less than 2
  + number of epochs: 20
  + training method: negative sampling  + number of negative samples: 15  + use concatenation of context vectors? False

getDocVecPV> total: 214017
getDocVecPV> Params summary of d2v models (n_workers: 18, n_iter: 20) ...
  + n_features: 50, window: 10
  + negative sample? 15
  + min count: 2

D2V.load> Info: model path:
/Users/pleiades/Documents/work/tpheno/seqmaker/data/CKD/model/Pf50w10i20-smallCKD.dm

D2V.load> Info: model path:
/Users/pleiades/Documents/work/tpheno/seqmaker/data/CKD/model/Pf50w10i20-smallCKD.dbow

check> input prior to consolidateVisits dim(X): (214017, 100), len(visitDocIDs): 214017
(check) contatenated vector dim: 5000 | lastN=50, indv fDim=100
(check) visit idx:
[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2]
(check) scope idx:
[0, 14, 97, 110, 112, 338, 429, 459, 503, 529, 606, 645, 712, 741, 951, 1075, 1198, 1212, 1372, 1508, 1715, 1794, 1844, 2002, 2011, 2389, 2561, 2958, 2986, 3087, 3103, 3162, 3459, 3530, 3619, 3625, 3778, 3841, 3990, 4012, 4070, 4123, 4223, 4226, 4665, 4813, 4932, 5178, 5549, 5676, 5688, 5716, 5805, 5921, 6438, 6445, 6463, 6562, 6641, 6751, 6825, 7009, 7053, 7074, 7079, 7175, 7245, 7326, 7590, 8072, 8132, 8135, 8147, 8186, 8241, 8587, 8595, 8709, 8737, 8831, 8847, 8968, 9000, 9059, 9167, 10166, 10315, 10501, 10553, 10577, 11085, 11192, 11221, 11887, 11969, 12067, 12116, 12120, 12461, 12569]

verify> mean dim: 9068.516949, median: 4900.000000, std: 11466.665963
(check) flatterned X, dim(Xp): (2360,)
tsHandler> save document vectors (cv=0), sparse? False ...
  + params: dim(X):(2360, 5000), index:0, n(docIDs):2360, d2v:pv-dm2, cohort:CKD, ctype:regular, shuffle? False, meta: smallCKD
tsHandler> training set dir: /Users/pleiades/Documents/work/tpheno/seqmaker/data/CKD/combined
prepareTrainingSet> n_classes: 11
TSet> Params: cohort: CKD, file id: regular-pv-dm2-smallCKD
TSet.saveDataFrame> tset params (cohort:CKD d2v:pv-dm2, ctype:regular, suffix=smallCKD)
TSet.saveDataFrame> Saving (cohort=CKD, d2v=pv-dm2, suffix=smallCKD) dataset to:
/Users/pleiades/Documents/work/tpheno/seqmaker/data/CKD/combined/tset-n0-IDregular-pv-dm2-smallCKD-GCKD.csv

status> Model computation complete (@nTrial=0)
info> each doc is repr by the last 50 visits
TSet> Params: cohort: CKD, file id: regular-pv-dm2-smallCKD
TSet.load> loading training set (cohort=CKD, suffix=smallCKD) from:
/Users/pleiades/Documents/work/tpheno/seqmaker/data/CKD/combined/tset-n0-IDregular-pv-dm2-smallCKD-GCKD.csv

tsHandler.profile> Found 11 unique labels ...
  + label=CKD Stage 3a => N=215
  + label=Unknown => N=411
  + label=CKD Stage 3b => N=135
  + label=ESRD on dialysis => N=41
  + label=CKD G1-control => N=87
  + label=CKD G1A1-control => N=108
  + label=CKD Stage 5 => N=31
  + label=CKD Stage 4 => N=56
  + label=ESRD after transplant => N=686
  + label=CKD Stage 2 => N=528
  + label=CKD Stage 1 => N=62
loadTSetCombined> Modifying training data ...
> Prior to re-labeling ...
tsHandler.profile> Found 11 unique labels ...
  + label=CKD Stage 3a => N=215
  + label=Unknown => N=411
  + label=CKD Stage 3b => N=135
  + label=ESRD on dialysis => N=41
  + label=CKD G1-control => N=87
  + label=CKD G1A1-control => N=108
  + label=CKD Stage 5 => N=31
  + label=CKD Stage 4 => N=56
  + label=ESRD after transplant => N=686
  + label=CKD Stage 2 => N=528
  + label=CKD Stage 1 => N=62
  + (before) unique labels:
['CKD Stage 3a' 'CKD Stage 2' 'Unknown' 'CKD Stage 3b' 'CKD Stage 4'
 'ESRD after transplant' 'ESRD on dialysis' 'CKD G1A1-control'
 'CKD Stage 1' 'CKD G1-control' 'CKD Stage 5']

  + CKD Stage 5 <- ['ESRD after transplant', 'ESRD on dialysis']
  + CKD Stage 3 <- ['CKD Stage 3a', 'CKD Stage 3b']
  + Others <- ['CKD G1-control', 'CKD G1A1-control', 'Unknown']
merge> n_labels: 11 -> 6
  + (after) unique labels:
['CKD Stage 3' 'CKD Stage 2' 'Others' 'CKD Stage 4' 'CKD Stage 5'
 'CKD Stage 1']

> After re-labeling ...
tsHandler.profile> Found 6 unique labels ...
  + label=Others => N=606
  + label=CKD Stage 5 => N=758
  + label=CKD Stage 4 => N=56
  + label=CKD Stage 3 => N=350
  + label=CKD Stage 2 => N=528
  + label=CKD Stage 1 => N=62
loadTSet> number of classes: 6
... cohort=CKD, ctype=regular, d2v=pv-dm2, meta=smallCKD
  + is_simplified? False, ... 
  + classification mode: multiclass
  + classifiers:
[]
  + training set type:dense
  + training set dim:2360
  + n classes:6

d_classify> dim(ts): (2360, 5002) > n_timesteps: 50, n_features: 100
  + dim(X <- ts): (2360, 5000)
d_classify> reshaped X: (2360, 50, 100) | n_classes=6

<<< Experimental Settings >>>

   + tset type dense, maxNPerClass: None, drop control? False
  + cohort: CKD, ctype: regular

  + D2V: pv-dm2, params> window: 10, n_features: 50
       + n_iter: 20, min_count: 2

  + userFileID: smallCKD

... data: 

... params (model selection): 

model_selection> trying {'n_units': 50, 'dropout_rate': 0.2} ...

make_lstm> n_units=50, r_dropout=0.200000, n_layers=1, n_classes=6
WARNING:tensorflow:From dnn_utils.py:157: streaming_auc (from tensorflow.contrib.metrics.python.ops.metric_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Please switch to tf.metrics.auc. Note that the order of the labels and predictions arguments has been switched.
  + lookup:
{'Others': 5, 'CKD Stage 5': 4, 'CKD Stage 4': 3, 'CKD Stage 3': 2, 'CKD Stage 2': 1, 'CKD Stage 1': 0}

... class weights:
{0: 6.344086021505376, 1: 0.74494949494949492, 2: 1.1238095238095238, 3: 7.0238095238095237, 4: 0.51890941072999119, 5: 0.64906490649064907}

====================================================================================================
... early stopping>
       + patience: 20, model='max'
... model training>
       + batch_size: 32, epochs: 60, shuffle? True, metric: auc_roc
====================================================================================================
Train on 1652 samples, validate on 708 samples
Epoch 1/60
2018-07-01 17:20:03.088307: I tensorflow/core/platform/cpu_feature_guard.cc:140] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA
1652/1652 [==============================] - 4s 2ms/step - loss: 1.6895 - acc: 0.2554 - auc_roc: 0.6217 - val_loss: 1.8713 - val_acc: 0.0904 - val_auc_roc: 0.6412
Epoch 2/60
1652/1652 [==============================] - 3s 2ms/step - loss: 1.5426 - acc: 0.3571 - auc_roc: 0.6460 - val_loss: 1.6664 - val_acc: 0.3715 - val_auc_roc: 0.6750
Epoch 3/60
1652/1652 [==============================] - 3s 2ms/step - loss: 1.3309 - acc: 0.4607 - auc_roc: 0.6979 - val_loss: 1.4207 - val_acc: 0.5749 - val_auc_roc: 0.7257
Epoch 4/60
1652/1652 [==============================] - 3s 2ms/step - loss: 1.2505 - acc: 0.4806 - auc_roc: 0.7449 - val_loss: 1.5239 - val_acc: 0.5749 - val_auc_roc: 0.7601
Epoch 5/60
1652/1652 [==============================] - 3s 2ms/step - loss: 1.1660 - acc: 0.5000 - auc_roc: 0.7713 - val_loss: 1.6423 - val_acc: 0.5268 - val_auc_roc: 0.7782
Epoch 6/60
1652/1652 [==============================] - 3s 2ms/step - loss: 1.1020 - acc: 0.5048 - auc_roc: 0.7837 - val_loss: 1.5058 - val_acc: 0.6568 - val_auc_roc: 0.7923
Epoch 7/60
1652/1652 [==============================] - 3s 2ms/step - loss: 1.0101 - acc: 0.5508 - auc_roc: 0.7999 - val_loss: 1.5720 - val_acc: 0.6243 - val_auc_roc: 0.8063
Epoch 8/60
1652/1652 [==============================] - 3s 2ms/step - loss: 0.9640 - acc: 0.5617 - auc_roc: 0.8112 - val_loss: 1.7574 - val_acc: 0.6497 - val_auc_roc: 0.8169
Epoch 9/60
1652/1652 [==============================] - 3s 2ms/step - loss: 0.9129 - acc: 0.6077 - auc_roc: 0.8215 - val_loss: 1.7435 - val_acc: 0.6483 - val_auc_roc: 0.8264
Epoch 10/60
1652/1652 [==============================] - 3s 2ms/step - loss: 0.9131 - acc: 0.5745 - auc_roc: 0.8297 - val_loss: 1.6594 - val_acc: 0.6511 - val_auc_roc: 0.8330
Epoch 11/60
1652/1652 [==============================] - 3s 2ms/step - loss: 0.8606 - acc: 0.5902 - auc_roc: 0.8359 - val_loss: 1.6962 - val_acc: 0.6836 - val_auc_roc: 0.8397
Epoch 12/60
1652/1652 [==============================] - 3s 2ms/step - loss: 0.7790 - acc: 0.6205 - auc_roc: 0.8433 - val_loss: 1.7852 - val_acc: 0.6766 - val_auc_roc: 0.8463
Epoch 13/60
1652/1652 [==============================] - 3s 2ms/step - loss: 0.7318 - acc: 0.6471 - auc_roc: 0.8490 - val_loss: 1.9969 - val_acc: 0.6921 - val_auc_roc: 0.8524
Epoch 14/60
1652/1652 [==============================] - 3s 2ms/step - loss: 0.7343 - acc: 0.6465 - auc_roc: 0.8549 - val_loss: 1.7996 - val_acc: 0.6949 - val_auc_roc: 0.8576
Epoch 15/60
1652/1652 [==============================] - 3s 2ms/step - loss: 0.6817 - acc: 0.6659 - auc_roc: 0.8602 - val_loss: 1.8959 - val_acc: 0.7062 - val_auc_roc: 0.8629
Epoch 16/60
1652/1652 [==============================] - 3s 2ms/step - loss: 0.7736 - acc: 0.6301 - auc_roc: 0.8643 - val_loss: 1.7888 - val_acc: 0.6751 - val_auc_roc: 0.8661
Epoch 17/60
1652/1652 [==============================] - 3s 2ms/step - loss: 0.6856 - acc: 0.6586 - auc_roc: 0.8678 - val_loss: 1.9996 - val_acc: 0.6836 - val_auc_roc: 0.8698
Epoch 18/60
1652/1652 [==============================] - 3s 2ms/step - loss: 0.6299 - acc: 0.6810 - auc_roc: 0.8716 - val_loss: 1.9281 - val_acc: 0.7076 - val_auc_roc: 0.8735
Epoch 19/60
1652/1652 [==============================] - 3s 2ms/step - loss: 0.5954 - acc: 0.6967 - auc_roc: 0.8752 - val_loss: 2.2416 - val_acc: 0.6907 - val_auc_roc: 0.8771
Epoch 20/60
1652/1652 [==============================] - 3s 2ms/step - loss: 0.5653 - acc: 0.7119 - auc_roc: 0.8787 - val_loss: 2.0354 - val_acc: 0.6780 - val_auc_roc: 0.8805
Epoch 21/60
1652/1652 [==============================] - 3s 2ms/step - loss: 0.5492 - acc: 0.7258 - auc_roc: 0.8818 - val_loss: 2.3445 - val_acc: 0.6610 - val_auc_roc: 0.8834
Epoch 22/60
1652/1652 [==============================] - 3s 2ms/step - loss: 0.5301 - acc: 0.7294 - auc_roc: 0.8844 - val_loss: 2.4274 - val_acc: 0.6638 - val_auc_roc: 0.8859
Epoch 23/60
1652/1652 [==============================] - 3s 2ms/step - loss: 0.5239 - acc: 0.7337 - auc_roc: 0.8871 - val_loss: 2.1858 - val_acc: 0.5734 - val_auc_roc: 0.8879
Epoch 00023: early stopping
... history of metrics comprising: ['acc', 'loss', 'val_auc_roc', 'auc_roc', 'val_acc', 'val_loss']
... ... metric (acc): [0.64648910440486507, 0.66585956402032775, 0.6301452787390055, 0.65859564179081032, 0.68099273636612423, 0.69673123515547042, 0.71186440692398223, 0.72578692493946728, 0.729418886054226, 0.73365617418981921] (n=23)
output> saving performance to:
/Users/pleiades/Documents/work/tpheno/seqmaker/data/CKD/plot/model_evalation-ep200b16.tif

... ... metric (loss): [0.73427880315457361, 0.68165362891504322, 0.77358232543197147, 0.68559723038938947, 0.62992783594362378, 0.59536843380685578, 0.56529396072426952, 0.5492072175403484, 0.53007583771144506, 0.52390399019596945] (n=23)
output> saving performance to:
/Users/pleiades/Documents/work/tpheno/seqmaker/data/CKD/plot/model_evalation-ep200b16.tif


model_selection> trying {'n_units': 100, 'dropout_rate': 0.2} ...

make_lstm> n_units=100, r_dropout=0.200000, n_layers=1, n_classes=6
  + lookup:
{'Others': 5, 'CKD Stage 5': 4, 'CKD Stage 4': 3, 'CKD Stage 3': 2, 'CKD Stage 2': 1, 'CKD Stage 1': 0}

... class weights:
{0: 6.344086021505376, 1: 0.74494949494949492, 2: 1.1238095238095238, 3: 7.0238095238095237, 4: 0.51890941072999119, 5: 0.64906490649064907}

====================================================================================================
... early stopping>
       + patience: 20, model='max'
... model training>
       + batch_size: 32, epochs: 60, shuffle? True, metric: auc_roc
====================================================================================================
Train on 1652 samples, validate on 708 samples
Epoch 1/60
1652/1652 [==============================] - 4s 2ms/step - loss: 1.6620 - acc: 0.3008 - auc_roc: 0.6369 - val_loss: 1.8311 - val_acc: 0.5028 - val_auc_roc: 0.6920
Epoch 2/60
1652/1652 [==============================] - 3s 2ms/step - loss: 1.4214 - acc: 0.4631 - auc_roc: 0.7169 - val_loss: 1.5476 - val_acc: 0.4802 - val_auc_roc: 0.7385
Epoch 3/60
1652/1652 [==============================] - 3s 2ms/step - loss: 1.2530 - acc: 0.4885 - auc_roc: 0.7523 - val_loss: 1.5695 - val_acc: 0.5226 - val_auc_roc: 0.7648
Epoch 4/60
1652/1652 [==============================] - 3s 2ms/step - loss: 1.1490 - acc: 0.5042 - auc_roc: 0.7752 - val_loss: 1.5368 - val_acc: 0.5523 - val_auc_roc: 0.7832
Epoch 5/60
1652/1652 [==============================] - 3s 2ms/step - loss: 1.0711 - acc: 0.5242 - auc_roc: 0.7902 - val_loss: 1.6002 - val_acc: 0.5904 - val_auc_roc: 0.7990
Epoch 6/60
1652/1652 [==============================] - 3s 2ms/step - loss: 0.9927 - acc: 0.5714 - auc_roc: 0.8060 - val_loss: 1.5609 - val_acc: 0.5989 - val_auc_roc: 0.8129
Epoch 7/60
1652/1652 [==============================] - 3s 2ms/step - loss: 0.9461 - acc: 0.5781 - auc_roc: 0.8182 - val_loss: 1.7321 - val_acc: 0.7020 - val_auc_roc: 0.8253
Epoch 8/60
1652/1652 [==============================] - 3s 2ms/step - loss: 0.8308 - acc: 0.6283 - auc_roc: 0.8312 - val_loss: 1.8082 - val_acc: 0.6780 - val_auc_roc: 0.8368
Epoch 9/60
1652/1652 [==============================] - 3s 2ms/step - loss: 0.7748 - acc: 0.6423 - auc_roc: 0.8416 - val_loss: 1.6266 - val_acc: 0.6808 - val_auc_roc: 0.8467
Epoch 10/60
1652/1652 [==============================] - 3s 2ms/step - loss: 0.7474 - acc: 0.6622 - auc_roc: 0.8509 - val_loss: 1.9997 - val_acc: 0.7034 - val_auc_roc: 0.8551
Epoch 11/60
1652/1652 [==============================] - 3s 2ms/step - loss: 0.6860 - acc: 0.6640 - auc_roc: 0.8591 - val_loss: 1.7916 - val_acc: 0.7218 - val_auc_roc: 0.8629
Epoch 12/60
1652/1652 [==============================] - 3s 2ms/step - loss: 0.6537 - acc: 0.6852 - auc_roc: 0.8662 - val_loss: 2.0739 - val_acc: 0.6794 - val_auc_roc: 0.8689
Epoch 13/60
1652/1652 [==============================] - 3s 2ms/step - loss: 0.6602 - acc: 0.6707 - auc_roc: 0.8712 - val_loss: 1.7123 - val_acc: 0.7034 - val_auc_roc: 0.8737
Epoch 14/60
1652/1652 [==============================] - 4s 2ms/step - loss: 0.5903 - acc: 0.7113 - auc_roc: 0.8760 - val_loss: 2.0729 - val_acc: 0.7345 - val_auc_roc: 0.8790
Epoch 15/60
1652/1652 [==============================] - 3s 2ms/step - loss: 0.5305 - acc: 0.7439 - auc_roc: 0.8815 - val_loss: 2.0607 - val_acc: 0.6370 - val_auc_roc: 0.8835
Epoch 16/60
1652/1652 [==============================] - 3s 2ms/step - loss: 0.5022 - acc: 0.7536 - auc_roc: 0.8853 - val_loss: 1.7833 - val_acc: 0.7105 - val_auc_roc: 0.8878
Epoch 17/60
1652/1652 [==============================] - 4s 2ms/step - loss: 0.4594 - acc: 0.7778 - auc_roc: 0.8899 - val_loss: 2.0825 - val_acc: 0.7316 - val_auc_roc: 0.8923
Epoch 18/60
1652/1652 [==============================] - 3s 2ms/step - loss: 0.4096 - acc: 0.8039 - auc_roc: 0.8944 - val_loss: 2.2028 - val_acc: 0.7331 - val_auc_roc: 0.8966
Epoch 19/60
1652/1652 [==============================] - 3s 2ms/step - loss: 0.3728 - acc: 0.8172 - auc_roc: 0.8985 - val_loss: 2.1312 - val_acc: 0.7062 - val_auc_roc: 0.9006
Epoch 20/60
1652/1652 [==============================] - 3s 2ms/step - loss: 0.3588 - acc: 0.8269 - auc_roc: 0.9023 - val_loss: 2.4780 - val_acc: 0.7316 - val_auc_roc: 0.9044
Epoch 21/60
1652/1652 [==============================] - 3s 2ms/step - loss: 0.3171 - acc: 0.8565 - auc_roc: 0.9061 - val_loss: 2.1419 - val_acc: 0.7048 - val_auc_roc: 0.9081
Epoch 22/60
1652/1652 [==============================] - 3s 2ms/step - loss: 0.3420 - acc: 0.8462 - auc_roc: 0.9095 - val_loss: 2.5983 - val_acc: 0.7345 - val_auc_roc: 0.9112
Epoch 23/60
1652/1652 [==============================] - 3s 2ms/step - loss: 0.2808 - acc: 0.8723 - auc_roc: 0.9125 - val_loss: 2.5218 - val_acc: 0.7288 - val_auc_roc: 0.9142
Epoch 24/60
1652/1652 [==============================] - 3s 2ms/step - loss: 0.3300 - acc: 0.8462 - auc_roc: 0.9154 - val_loss: 2.1856 - val_acc: 0.7161 - val_auc_roc: 0.9167
Epoch 00024: early stopping
... history of metrics comprising: ['acc', 'loss', 'val_auc_roc', 'auc_roc', 'val_acc', 'val_loss']
... ... metric (acc): [0.74394673152350921, 0.75363196154772227, 0.77784503603097022, 0.80387409172104285, 0.81719128329297819, 0.82687651302854892, 0.8565375299777015, 0.84624697336561738, 0.87227602876704768, 0.84624697365425983] (n=24)
output> saving performance to:
/Users/pleiades/Documents/work/tpheno/seqmaker/data/CKD/plot/model_evalation-ep200b16.tif

... ... metric (loss): [0.53050223909336491, 0.50219691420294177, 0.45935421186267028, 0.40964168396758111, 0.37284217049654111, 0.35878158308403257, 0.31708825045867345, 0.34203282105071203, 0.28077165923164776, 0.3299676959220203] (n=24)
output> saving performance to:
/Users/pleiades/Documents/work/tpheno/seqmaker/data/CKD/plot/model_evalation-ep200b16.tif


model_selection> trying {'n_units': 200, 'dropout_rate': 0.2} ...

make_lstm> n_units=200, r_dropout=0.200000, n_layers=1, n_classes=6
  + lookup:
{'Others': 5, 'CKD Stage 5': 4, 'CKD Stage 4': 3, 'CKD Stage 3': 2, 'CKD Stage 2': 1, 'CKD Stage 1': 0}

... class weights:
{0: 6.344086021505376, 1: 0.74494949494949492, 2: 1.1238095238095238, 3: 7.0238095238095237, 4: 0.51890941072999119, 5: 0.64906490649064907}

====================================================================================================
... early stopping>
       + patience: 20, model='max'
... model training>
       + batch_size: 32, epochs: 60, shuffle? True, metric: auc_roc
====================================================================================================
Train on 1652 samples, validate on 708 samples
Epoch 1/60
1652/1652 [==============================] - 5s 3ms/step - loss: 1.6451 - acc: 0.2815 - auc_roc: 0.5660 - val_loss: 1.6215 - val_acc: 0.5212 - val_auc_roc: 0.6916
Epoch 2/60
1652/1652 [==============================] - 4s 2ms/step - loss: 1.4358 - acc: 0.4358 - auc_roc: 0.7228 - val_loss: 1.4208 - val_acc: 0.5847 - val_auc_roc: 0.7475
Epoch 3/60
1652/1652 [==============================] - 4s 2ms/step - loss: 1.2449 - acc: 0.4776 - auc_roc: 0.7650 - val_loss: 1.7287 - val_acc: 0.4929 - val_auc_roc: 0.7740
Epoch 4/60
1652/1652 [==============================] - 4s 2ms/step - loss: 1.1727 - acc: 0.4818 - auc_roc: 0.7814 - val_loss: 1.8972 - val_acc: 0.2599 - val_auc_roc: 0.7771
Epoch 5/60
1652/1652 [==============================] - 4s 2ms/step - loss: 1.0993 - acc: 0.5194 - auc_roc: 0.7781 - val_loss: 1.6305 - val_acc: 0.6144 - val_auc_roc: 0.7871
Epoch 6/60
1652/1652 [==============================] - 4s 2ms/step - loss: 0.9569 - acc: 0.5672 - auc_roc: 0.7964 - val_loss: 1.8639 - val_acc: 0.4633 - val_auc_roc: 0.8015
Epoch 7/60
1652/1652 [==============================] - 4s 2ms/step - loss: 0.8684 - acc: 0.6035 - auc_roc: 0.8069 - val_loss: 1.8373 - val_acc: 0.6554 - val_auc_roc: 0.8148
Epoch 8/60
1652/1652 [==============================] - 4s 2ms/step - loss: 0.8780 - acc: 0.5920 - auc_roc: 0.8198 - val_loss: 1.6862 - val_acc: 0.4746 - val_auc_roc: 0.8230
Epoch 9/60
1652/1652 [==============================] - 5s 3ms/step - loss: 0.7697 - acc: 0.6356 - auc_roc: 0.8264 - val_loss: 1.8553 - val_acc: 0.6554 - val_auc_roc: 0.8321
Epoch 10/60
1652/1652 [==============================] - 4s 2ms/step - loss: 0.6763 - acc: 0.6610 - auc_roc: 0.8370 - val_loss: 1.9022 - val_acc: 0.6766 - val_auc_roc: 0.8427
Epoch 11/60
1652/1652 [==============================] - 4s 2ms/step - loss: 0.6225 - acc: 0.6864 - auc_roc: 0.8473 - val_loss: 2.1508 - val_acc: 0.6864 - val_auc_roc: 0.8521
Epoch 12/60
1652/1652 [==============================] - 4s 2ms/step - loss: 0.5813 - acc: 0.7076 - auc_roc: 0.8564 - val_loss: 1.8999 - val_acc: 0.6709 - val_auc_roc: 0.8606
Epoch 13/60
1652/1652 [==============================] - 4s 2ms/step - loss: 0.5797 - acc: 0.7197 - auc_roc: 0.8641 - val_loss: 2.4130 - val_acc: 0.7090 - val_auc_roc: 0.8679
Epoch 14/60
1652/1652 [==============================] - 4s 2ms/step - loss: 0.6322 - acc: 0.7046 - auc_roc: 0.8704 - val_loss: 2.0541 - val_acc: 0.6935 - val_auc_roc: 0.8733
Epoch 15/60
1652/1652 [==============================] - 4s 2ms/step - loss: 0.5582 - acc: 0.7331 - auc_roc: 0.8759 - val_loss: 1.9080 - val_acc: 0.6992 - val_auc_roc: 0.8788
Epoch 16/60
1652/1652 [==============================] - 4s 2ms/step - loss: 0.4942 - acc: 0.7621 - auc_roc: 0.8814 - val_loss: 2.3868 - val_acc: 0.7034 - val_auc_roc: 0.8840
Epoch 17/60
1652/1652 [==============================] - 4s 2ms/step - loss: 0.4187 - acc: 0.7978 - auc_roc: 0.8865 - val_loss: 2.2869 - val_acc: 0.6427 - val_auc_roc: 0.8889
Epoch 18/60
1652/1652 [==============================] - 4s 2ms/step - loss: 0.4329 - acc: 0.7863 - auc_roc: 0.8906 - val_loss: 2.3955 - val_acc: 0.6992 - val_auc_roc: 0.8930
Epoch 19/60
1652/1652 [==============================] - 4s 2ms/step - loss: 0.3370 - acc: 0.8378 - auc_roc: 0.8952 - val_loss: 2.3566 - val_acc: 0.6921 - val_auc_roc: 0.8977
Epoch 20/60
1652/1652 [==============================] - 4s 2ms/step - loss: 0.2995 - acc: 0.8571 - auc_roc: 0.8997 - val_loss: 2.6734 - val_acc: 0.6921 - val_auc_roc: 0.9019
Epoch 21/60
1652/1652 [==============================] - 4s 2ms/step - loss: 0.2784 - acc: 0.8801 - auc_roc: 0.9037 - val_loss: 2.4764 - val_acc: 0.7302 - val_auc_roc: 0.9060
Epoch 22/60
1652/1652 [==============================] - 4s 2ms/step - loss: 0.2528 - acc: 0.8892 - auc_roc: 0.9079 - val_loss: 2.4244 - val_acc: 0.6017 - val_auc_roc: 0.9096
Epoch 00022: early stopping
... history of metrics comprising: ['acc', 'loss', 'val_auc_roc', 'auc_roc', 'val_acc', 'val_loss']
... ... metric (acc): [0.71973365603001294, 0.70460048440582235, 0.7330508477462695, 0.76210653753026636, 0.79782082353319439, 0.78631961230215663, 0.83777239723875219, 0.85714285728717832, 0.88014527830604206, 0.8892251818867053] (n=22)
output> saving performance to:
/Users/pleiades/Documents/work/tpheno/seqmaker/data/CKD/plot/model_evalation-ep200b16.tif

... ... metric (loss): [0.57968986402412304, 0.63219522737128975, 0.55820385682380802, 0.49423318942580324, 0.41869250899654326, 0.43286128309679378, 0.33697384083530807, 0.29950942066622127, 0.27842469163437444, 0.25276843738036353] (n=22)
output> saving performance to:
/Users/pleiades/Documents/work/tpheno/seqmaker/data/CKD/plot/model_evalation-ep200b16.tif


model_selection> trying {'n_units': 300, 'dropout_rate': 0.2} ...

make_lstm> n_units=300, r_dropout=0.200000, n_layers=1, n_classes=6
  + lookup:
{'Others': 5, 'CKD Stage 5': 4, 'CKD Stage 4': 3, 'CKD Stage 3': 2, 'CKD Stage 2': 1, 'CKD Stage 1': 0}

... class weights:
{0: 6.344086021505376, 1: 0.74494949494949492, 2: 1.1238095238095238, 3: 7.0238095238095237, 4: 0.51890941072999119, 5: 0.64906490649064907}

====================================================================================================
... early stopping>
       + patience: 20, model='max'
... model training>
       + batch_size: 32, epochs: 60, shuffle? True, metric: auc_roc
====================================================================================================
Train on 1652 samples, validate on 708 samples
Epoch 1/60
1652/1652 [==============================] - 7s 4ms/step - loss: 1.6736 - acc: 0.2912 - auc_roc: 0.5741 - val_loss: 1.5850 - val_acc: 0.5763 - val_auc_roc: 0.6945
Epoch 2/60
1652/1652 [==============================] - 6s 4ms/step - loss: 1.3527 - acc: 0.4631 - auc_roc: 0.7350 - val_loss: 2.0138 - val_acc: 0.2458 - val_auc_roc: 0.7239
Epoch 3/60
1652/1652 [==============================] - 7s 4ms/step - loss: 1.2987 - acc: 0.4316 - auc_roc: 0.7172 - val_loss: 1.6524 - val_acc: 0.2966 - val_auc_roc: 0.7244
Epoch 4/60
1652/1652 [==============================] - 6s 4ms/step - loss: 1.1458 - acc: 0.5000 - auc_roc: 0.7366 - val_loss: 1.4620 - val_acc: 0.5918 - val_auc_roc: 0.7538
Epoch 5/60
1652/1652 [==============================] - 7s 4ms/step - loss: 1.0332 - acc: 0.5448 - auc_roc: 0.7682 - val_loss: 1.7593 - val_acc: 0.5085 - val_auc_roc: 0.7780
Epoch 6/60
1652/1652 [==============================] - 6s 4ms/step - loss: 0.9740 - acc: 0.5684 - auc_roc: 0.7861 - val_loss: 1.8467 - val_acc: 0.3658 - val_auc_roc: 0.7894
Epoch 7/60
1652/1652 [==============================] - 6s 4ms/step - loss: 0.9280 - acc: 0.5654 - auc_roc: 0.7931 - val_loss: 1.8105 - val_acc: 0.4915 - val_auc_roc: 0.7979
Epoch 8/60
1652/1652 [==============================] - 7s 4ms/step - loss: 0.8513 - acc: 0.6108 - auc_roc: 0.8037 - val_loss: 1.7867 - val_acc: 0.5819 - val_auc_roc: 0.8105
Epoch 9/60
1652/1652 [==============================] - 6s 4ms/step - loss: 0.8210 - acc: 0.6471 - auc_roc: 0.8162 - val_loss: 1.6042 - val_acc: 0.6709 - val_auc_roc: 0.8228
Epoch 10/60
1652/1652 [==============================] - 6s 4ms/step - loss: 0.6976 - acc: 0.6653 - auc_roc: 0.8286 - val_loss: 1.7877 - val_acc: 0.6780 - val_auc_roc: 0.8348
Epoch 11/60
1652/1652 [==============================] - 6s 4ms/step - loss: 0.7050 - acc: 0.6634 - auc_roc: 0.8392 - val_loss: 1.6852 - val_acc: 0.5946 - val_auc_roc: 0.8438
Epoch 12/60
1652/1652 [==============================] - 6s 4ms/step - loss: 0.6421 - acc: 0.6913 - auc_roc: 0.8472 - val_loss: 2.1127 - val_acc: 0.5452 - val_auc_roc: 0.8505
Epoch 13/60
1652/1652 [==============================] - 6s 4ms/step - loss: 0.6999 - acc: 0.6774 - auc_roc: 0.8522 - val_loss: 1.8793 - val_acc: 0.5099 - val_auc_roc: 0.8544
Epoch 14/60
1652/1652 [==============================] - 6s 4ms/step - loss: 0.5771 - acc: 0.7288 - auc_roc: 0.8568 - val_loss: 1.9376 - val_acc: 0.6766 - val_auc_roc: 0.8605
Epoch 15/60
1652/1652 [==============================] - 6s 4ms/step - loss: 0.6152 - acc: 0.7167 - auc_roc: 0.8633 - val_loss: 1.8519 - val_acc: 0.6667 - val_auc_roc: 0.8664
Epoch 16/60
1652/1652 [==============================] - 6s 4ms/step - loss: 0.5596 - acc: 0.7228 - auc_roc: 0.8689 - val_loss: 1.9820 - val_acc: 0.4901 - val_auc_roc: 0.8705
Epoch 17/60
1652/1652 [==============================] - 6s 4ms/step - loss: 0.4290 - acc: 0.7851 - auc_roc: 0.8723 - val_loss: 2.2959 - val_acc: 0.7048 - val_auc_roc: 0.8756
Epoch 18/60
1652/1652 [==============================] - 6s 4ms/step - loss: 0.3566 - acc: 0.8142 - auc_roc: 0.8785 - val_loss: 2.2717 - val_acc: 0.7048 - val_auc_roc: 0.8817
Epoch 19/60
1652/1652 [==============================] - 6s 4ms/step - loss: 0.3019 - acc: 0.8620 - auc_roc: 0.8845 - val_loss: 2.3682 - val_acc: 0.7006 - val_auc_roc: 0.8875
Epoch 20/60
1652/1652 [==============================] - 6s 4ms/step - loss: 0.2898 - acc: 0.8795 - auc_roc: 0.8900 - val_loss: 2.7177 - val_acc: 0.5819 - val_auc_roc: 0.8921
Epoch 21/60
1652/1652 [==============================] - 7s 4ms/step - loss: 0.3044 - acc: 0.8668 - auc_roc: 0.8938 - val_loss: 2.0672 - val_acc: 0.6949 - val_auc_roc: 0.8962
Epoch 22/60
1652/1652 [==============================] - 6s 4ms/step - loss: 0.2385 - acc: 0.8898 - auc_roc: 0.8983 - val_loss: 1.9806 - val_acc: 0.6794 - val_auc_roc: 0.9007
Epoch 23/60
1652/1652 [==============================] - 6s 4ms/step - loss: 0.2188 - acc: 0.9044 - auc_roc: 0.9025 - val_loss: 2.3261 - val_acc: 0.6977 - val_auc_roc: 0.9047
Epoch 24/60
1652/1652 [==============================] - 6s 4ms/step - loss: 0.1605 - acc: 0.9304 - auc_roc: 0.9065 - val_loss: 2.7075 - val_acc: 0.6907 - val_auc_roc: 0.9086
Epoch 00024: early stopping
... history of metrics comprising: ['acc', 'loss', 'val_auc_roc', 'auc_roc', 'val_acc', 'val_loss']
... ... metric (acc): [0.71670702208040993, 0.7227602904125795, 0.78510895912641476, 0.81416464862176929, 0.8619854722992849, 0.87953995128520757, 0.86682808731139138, 0.8898305081859339, 0.90435835379953822, 0.9303874090566473] (n=24)
output> saving performance to:
/Users/pleiades/Documents/work/tpheno/seqmaker/data/CKD/plot/model_evalation-ep200b16.tif

... ... metric (loss): [0.61517285203818262, 0.55955127956792172, 0.42901165166432287, 0.35659021600972651, 0.30194050593179883, 0.28981121393150627, 0.30436470166534257, 0.23848418620827699, 0.21877292116098196, 0.16047124766697318] (n=24)
output> saving performance to:
/Users/pleiades/Documents/work/tpheno/seqmaker/data/CKD/plot/model_evalation-ep200b16.tif


model_selection> trying {'n_units': 400, 'dropout_rate': 0.2} ...

make_lstm> n_units=400, r_dropout=0.200000, n_layers=1, n_classes=6
  + lookup:
{'Others': 5, 'CKD Stage 5': 4, 'CKD Stage 4': 3, 'CKD Stage 3': 2, 'CKD Stage 2': 1, 'CKD Stage 1': 0}

... class weights:
{0: 6.344086021505376, 1: 0.74494949494949492, 2: 1.1238095238095238, 3: 7.0238095238095237, 4: 0.51890941072999119, 5: 0.64906490649064907}

====================================================================================================
... early stopping>
       + patience: 20, model='max'
... model training>
       + batch_size: 32, epochs: 60, shuffle? True, metric: auc_roc
====================================================================================================
Train on 1652 samples, validate on 708 samples
Epoch 1/60
1652/1652 [==============================] - 10s 6ms/step - loss: 1.5922 - acc: 0.3565 - auc_roc: 0.6431 - val_loss: 1.5435 - val_acc: 0.5466 - val_auc_roc: 0.7404
Epoch 2/60
1652/1652 [==============================] - 9s 6ms/step - loss: 1.3391 - acc: 0.4546 - auc_roc: 0.7679 - val_loss: 1.3340 - val_acc: 0.5777 - val_auc_roc: 0.7862
Epoch 3/60
1652/1652 [==============================] - 10s 6ms/step - loss: 1.3890 - acc: 0.4146 - auc_roc: 0.7959 - val_loss: 1.6659 - val_acc: 0.2797 - val_auc_roc: 0.7811
Epoch 4/60
1652/1652 [==============================] - 9s 6ms/step - loss: 1.2826 - acc: 0.4219 - auc_roc: 0.7758 - val_loss: 1.8651 - val_acc: 0.3291 - val_auc_roc: 0.7730
Epoch 5/60
1652/1652 [==============================] - 9s 6ms/step - loss: 1.1898 - acc: 0.4824 - auc_roc: 0.7731 - val_loss: 1.8387 - val_acc: 0.5014 - val_auc_roc: 0.7768
Epoch 6/60
1652/1652 [==============================] - 9s 6ms/step - loss: 1.0532 - acc: 0.5563 - auc_roc: 0.7827 - val_loss: 1.6927 - val_acc: 0.5042 - val_auc_roc: 0.7893
Epoch 7/60
1652/1652 [==============================] - 9s 6ms/step - loss: 0.9594 - acc: 0.5702 - auc_roc: 0.7949 - val_loss: 1.5802 - val_acc: 0.6554 - val_auc_roc: 0.8030
Epoch 8/60
1652/1652 [==============================] - 10s 6ms/step - loss: 0.9275 - acc: 0.5884 - auc_roc: 0.8098 - val_loss: 2.1255 - val_acc: 0.4266 - val_auc_roc: 0.8122
Epoch 9/60
1652/1652 [==============================] - 10s 6ms/step - loss: 0.8911 - acc: 0.6053 - auc_roc: 0.8147 - val_loss: 1.7472 - val_acc: 0.6356 - val_auc_roc: 0.8202
Epoch 10/60
1652/1652 [==============================] - 10s 6ms/step - loss: 0.8069 - acc: 0.6199 - auc_roc: 0.8247 - val_loss: 1.6367 - val_acc: 0.6723 - val_auc_roc: 0.8301
Epoch 11/60
1652/1652 [==============================] - 10s 6ms/step - loss: 0.7201 - acc: 0.6598 - auc_roc: 0.8351 - val_loss: 1.7808 - val_acc: 0.6653 - val_auc_roc: 0.8399
Epoch 12/60
1652/1652 [==============================] - 10s 6ms/step - loss: 0.6827 - acc: 0.6677 - auc_roc: 0.8437 - val_loss: 1.8801 - val_acc: 0.6879 - val_auc_roc: 0.8480
Epoch 13/60
1652/1652 [==============================] - 10s 6ms/step - loss: 0.6259 - acc: 0.6931 - auc_roc: 0.8520 - val_loss: 1.9256 - val_acc: 0.6031 - val_auc_roc: 0.8552
Epoch 14/60
1652/1652 [==============================] - 9s 6ms/step - loss: 0.6078 - acc: 0.7100 - auc_roc: 0.8580 - val_loss: 2.4465 - val_acc: 0.4223 - val_auc_roc: 0.8594
Epoch 15/60
1652/1652 [==============================] - 10s 6ms/step - loss: 0.5988 - acc: 0.6961 - auc_roc: 0.8604 - val_loss: 2.1830 - val_acc: 0.5975 - val_auc_roc: 0.8630
Epoch 16/60
1652/1652 [==============================] - 10s 6ms/step - loss: 0.5639 - acc: 0.7179 - auc_roc: 0.8653 - val_loss: 2.1125 - val_acc: 0.6751 - val_auc_roc: 0.8682
Epoch 17/60
1652/1652 [==============================] - 10s 6ms/step - loss: 0.6105 - acc: 0.7318 - auc_roc: 0.8704 - val_loss: 2.0496 - val_acc: 0.6667 - val_auc_roc: 0.8728
Epoch 18/60
1652/1652 [==============================] - 10s 6ms/step - loss: 0.7059 - acc: 0.7167 - auc_roc: 0.8742 - val_loss: 1.7885 - val_acc: 0.6963 - val_auc_roc: 0.8763
Epoch 19/60
1652/1652 [==============================] - 11s 7ms/step - loss: 0.5061 - acc: 0.7615 - auc_roc: 0.8785 - val_loss: 2.5231 - val_acc: 0.4025 - val_auc_roc: 0.8797
Epoch 20/60
1652/1652 [==============================] - 10s 6ms/step - loss: 0.4845 - acc: 0.7785 - auc_roc: 0.8805 - val_loss: 2.3443 - val_acc: 0.7105 - val_auc_roc: 0.8828
Epoch 21/60
1652/1652 [==============================] - 10s 6ms/step - loss: 0.3583 - acc: 0.8263 - auc_roc: 0.8851 - val_loss: 2.2676 - val_acc: 0.7105 - val_auc_roc: 0.8877
Epoch 22/60
1652/1652 [==============================] - 10s 6ms/step - loss: 0.3048 - acc: 0.8517 - auc_roc: 0.8899 - val_loss: 2.4071 - val_acc: 0.6850 - val_auc_roc: 0.8923
Epoch 00022: early stopping
... history of metrics comprising: ['acc', 'loss', 'val_auc_roc', 'auc_roc', 'val_acc', 'val_loss']
... ... metric (acc): [0.69309927346342703, 0.71004842586147876, 0.6961259078459936, 0.71791767583343657, 0.73184019370460052, 0.71670702208040993, 0.76150121050943187, 0.77845036348476826, 0.8262711865849991, 0.85169491539855846] (n=22)
output> saving performance to:
/Users/pleiades/Documents/work/tpheno/seqmaker/data/CKD/plot/model_evalation-ep200b16.tif

... ... metric (loss): [0.62588060190833505, 0.60776548033476452, 0.5987942487217901, 0.56394230244234744, 0.61045660825387615, 0.70587743151274485, 0.50610817921940987, 0.48447692726195291, 0.35834932320054447, 0.30475732532598204] (n=22)
output> saving performance to:
/Users/pleiades/Documents/work/tpheno/seqmaker/data/CKD/plot/model_evalation-ep200b16.tif


model_selection> trying {'n_units': 500, 'dropout_rate': 0.2} ...

make_lstm> n_units=500, r_dropout=0.200000, n_layers=1, n_classes=6
  + lookup:
{'Others': 5, 'CKD Stage 5': 4, 'CKD Stage 4': 3, 'CKD Stage 3': 2, 'CKD Stage 2': 1, 'CKD Stage 1': 0}

... class weights:
{0: 6.344086021505376, 1: 0.74494949494949492, 2: 1.1238095238095238, 3: 7.0238095238095237, 4: 0.51890941072999119, 5: 0.64906490649064907}

====================================================================================================
... early stopping>
       + patience: 20, model='max'
... model training>
       + batch_size: 32, epochs: 60, shuffle? True, metric: auc_roc
====================================================================================================
Train on 1652 samples, validate on 708 samples
Epoch 1/60
1652/1652 [==============================] - 15s 9ms/step - loss: 1.6099 - acc: 0.3354 - auc_roc: 0.6958 - val_loss: 1.6314 - val_acc: 0.5099 - val_auc_roc: 0.7544
Epoch 2/60
1652/1652 [==============================] - 15s 9ms/step - loss: 1.4246 - acc: 0.4346 - auc_roc: 0.7635 - val_loss: 1.5656 - val_acc: 0.5862 - val_auc_roc: 0.7779
Epoch 3/60
1652/1652 [==============================] - 15s 9ms/step - loss: 1.2856 - acc: 0.4728 - auc_roc: 0.7892 - val_loss: 1.3990 - val_acc: 0.6144 - val_auc_roc: 0.7986
Epoch 4/60
1652/1652 [==============================] - 14s 9ms/step - loss: 1.1766 - acc: 0.5018 - auc_roc: 0.8050 - val_loss: 1.6010 - val_acc: 0.6441 - val_auc_roc: 0.8134
Epoch 5/60
1652/1652 [==============================] - 16s 9ms/step - loss: 1.1871 - acc: 0.4631 - auc_roc: 0.8164 - val_loss: 2.0959 - val_acc: 0.1808 - val_auc_roc: 0.8090
Epoch 6/60
1652/1652 [==============================] - 16s 10ms/step - loss: 1.1280 - acc: 0.5182 - auc_roc: 0.8041 - val_loss: 1.9126 - val_acc: 0.4915 - val_auc_roc: 0.8077
Epoch 7/60
1652/1652 [==============================] - 16s 9ms/step - loss: 0.9723 - acc: 0.5581 - auc_roc: 0.8114 - val_loss: 1.6348 - val_acc: 0.6554 - val_auc_roc: 0.8177
Epoch 8/60
1652/1652 [==============================] - 16s 10ms/step - loss: 0.8675 - acc: 0.6041 - auc_roc: 0.8233 - val_loss: 2.0929 - val_acc: 0.4153 - val_auc_roc: 0.8256
Epoch 9/60
1652/1652 [==============================] - 16s 10ms/step - loss: 0.7870 - acc: 0.6277 - auc_roc: 0.8278 - val_loss: 2.2083 - val_acc: 0.6554 - val_auc_roc: 0.8332
Epoch 10/60
1652/1652 [==============================] - 14s 9ms/step - loss: 0.7478 - acc: 0.6235 - auc_roc: 0.8375 - val_loss: 1.6631 - val_acc: 0.6511 - val_auc_roc: 0.8421
Epoch 11/60
1652/1652 [==============================] - 15s 9ms/step - loss: 0.6912 - acc: 0.6749 - auc_roc: 0.8463 - val_loss: 1.7495 - val_acc: 0.6582 - val_auc_roc: 0.8510
Epoch 12/60
1652/1652 [==============================] - 16s 10ms/step - loss: 0.6571 - acc: 0.6816 - auc_roc: 0.8544 - val_loss: 1.8315 - val_acc: 0.6497 - val_auc_roc: 0.8579
Epoch 13/60
1652/1652 [==============================] - 15s 9ms/step - loss: 0.5906 - acc: 0.7191 - auc_roc: 0.8613 - val_loss: 1.9700 - val_acc: 0.6935 - val_auc_roc: 0.8651
Epoch 14/60
1652/1652 [==============================] - 16s 9ms/step - loss: 0.5186 - acc: 0.7421 - auc_roc: 0.8685 - val_loss: 2.0733 - val_acc: 0.6596 - val_auc_roc: 0.8720
Epoch 15/60
1652/1652 [==============================] - 15s 9ms/step - loss: 0.4539 - acc: 0.7875 - auc_roc: 0.8749 - val_loss: 2.3773 - val_acc: 0.7020 - val_auc_roc: 0.8786
Epoch 16/60
1652/1652 [==============================] - 15s 9ms/step - loss: 0.4020 - acc: 0.8130 - auc_roc: 0.8817 - val_loss: 2.8028 - val_acc: 0.5212 - val_auc_roc: 0.8835
Epoch 17/60
1652/1652 [==============================] - 15s 9ms/step - loss: 0.6856 - acc: 0.7161 - auc_roc: 0.8838 - val_loss: 1.8322 - val_acc: 0.6638 - val_auc_roc: 0.8855
Epoch 18/60
1652/1652 [==============================] - 16s 9ms/step - loss: 0.4428 - acc: 0.7906 - auc_roc: 0.8876 - val_loss: 2.1811 - val_acc: 0.6992 - val_auc_roc: 0.8901
Epoch 19/60
1652/1652 [==============================] - 15s 9ms/step - loss: 0.3451 - acc: 0.8450 - auc_roc: 0.8926 - val_loss: 2.3316 - val_acc: 0.6116 - val_auc_roc: 0.8948
Epoch 20/60
1652/1652 [==============================] - 15s 9ms/step - loss: 0.2809 - acc: 0.8644 - auc_roc: 0.8967 - val_loss: 2.3137 - val_acc: 0.7189 - val_auc_roc: 0.8993
Epoch 21/60
1652/1652 [==============================] - 14s 9ms/step - loss: 0.2098 - acc: 0.9062 - auc_roc: 0.9016 - val_loss: 2.7101 - val_acc: 0.6893 - val_auc_roc: 0.9041
Epoch 22/60
1652/1652 [==============================] - 14s 9ms/step - loss: 0.1887 - acc: 0.9153 - auc_roc: 0.9061 - val_loss: 2.6987 - val_acc: 0.6977 - val_auc_roc: 0.9084
Epoch 23/60
1652/1652 [==============================] - 14s 9ms/step - loss: 0.2324 - acc: 0.9195 - auc_roc: 0.9102 - val_loss: 2.4724 - val_acc: 0.6836 - val_auc_roc: 0.9121
Epoch 00023: early stopping
... history of metrics comprising: ['acc', 'loss', 'val_auc_roc', 'auc_roc', 'val_acc', 'val_loss']
... ... metric (acc): [0.74213075031668452, 0.78753026663246806, 0.81295399515738498, 0.71610169477093311, 0.79055690072639229, 0.84503631946826963, 0.86440677951669576, 0.90617433399611469, 0.91525423699949326, 0.91949152527940758] (n=23)
output> saving performance to:
/Users/pleiades/Documents/work/tpheno/seqmaker/data/CKD/plot/model_evalation-ep200b16.tif

... ... metric (loss): [0.5186039347914172, 0.45388489355475214, 0.40197286940660082, 0.68561878244755636, 0.44275394089285458, 0.34507219273299339, 0.28094787235410101, 0.2097802983357889, 0.18868544697761536, 0.23242710786927986] (n=23)
output> saving performance to:
/Users/pleiades/Documents/work/tpheno/seqmaker/data/CKD/plot/model_evalation-ep200b16.tif


model_selection> trying {'n_units': 50, 'dropout_rate': 0.3} ...

make_lstm> n_units=50, r_dropout=0.300000, n_layers=1, n_classes=6
  + lookup:
{'Others': 5, 'CKD Stage 5': 4, 'CKD Stage 4': 3, 'CKD Stage 3': 2, 'CKD Stage 2': 1, 'CKD Stage 1': 0}

... class weights:
{0: 6.344086021505376, 1: 0.74494949494949492, 2: 1.1238095238095238, 3: 7.0238095238095237, 4: 0.51890941072999119, 5: 0.64906490649064907}

====================================================================================================
... early stopping>
       + patience: 20, model='max'
... model training>
       + batch_size: 32, epochs: 60, shuffle? True, metric: auc_roc
====================================================================================================
Train on 1652 samples, validate on 708 samples
Epoch 1/60
1652/1652 [==============================] - 4s 3ms/step - loss: 1.7352 - acc: 0.2246 - auc_roc: 0.6186 - val_loss: 1.9807 - val_acc: 0.1257 - val_auc_roc: 0.5902
Epoch 2/60
1652/1652 [==============================] - 3s 2ms/step - loss: 1.5706 - acc: 0.3638 - auc_roc: 0.6134 - val_loss: 1.7498 - val_acc: 0.5381 - val_auc_roc: 0.6633
Epoch 3/60
1652/1652 [==============================] - 3s 2ms/step - loss: 1.3827 - acc: 0.4340 - auc_roc: 0.6941 - val_loss: 1.6382 - val_acc: 0.5890 - val_auc_roc: 0.7204
Epoch 4/60
1652/1652 [==============================] - 3s 2ms/step - loss: 1.2795 - acc: 0.4824 - auc_roc: 0.7384 - val_loss: 1.4416 - val_acc: 0.6977 - val_auc_roc: 0.7570
Epoch 5/60
1652/1652 [==============================] - 3s 2ms/step - loss: 1.1742 - acc: 0.4879 - auc_roc: 0.7699 - val_loss: 1.5130 - val_acc: 0.5706 - val_auc_roc: 0.7780
Epoch 6/60
1652/1652 [==============================] - 3s 2ms/step - loss: 1.1030 - acc: 0.5272 - auc_roc: 0.7857 - val_loss: 1.4404 - val_acc: 0.6638 - val_auc_roc: 0.7938
Epoch 7/60
1652/1652 [==============================] - 3s 2ms/step - loss: 1.0514 - acc: 0.5418 - auc_roc: 0.8012 - val_loss: 1.4904 - val_acc: 0.6469 - val_auc_roc: 0.8072
Epoch 8/60
1652/1652 [==============================] - 3s 2ms/step - loss: 0.9732 - acc: 0.5623 - auc_roc: 0.8130 - val_loss: 1.6729 - val_acc: 0.7090 - val_auc_roc: 0.8192
Epoch 9/60
1652/1652 [==============================] - 3s 2ms/step - loss: 0.9121 - acc: 0.5944 - auc_roc: 0.8246 - val_loss: 1.5501 - val_acc: 0.6794 - val_auc_roc: 0.8295
Epoch 10/60
1652/1652 [==============================] - 3s 2ms/step - loss: 0.9100 - acc: 0.5811 - auc_roc: 0.8336 - val_loss: 1.4214 - val_acc: 0.5932 - val_auc_roc: 0.8363
Epoch 11/60
1652/1652 [==============================] - 3s 2ms/step - loss: 0.9539 - acc: 0.5642 - auc_roc: 0.8378 - val_loss: 1.7069 - val_acc: 0.6540 - val_auc_roc: 0.8396
Epoch 12/60
1652/1652 [==============================] - 3s 2ms/step - loss: 0.8801 - acc: 0.5835 - auc_roc: 0.8422 - val_loss: 1.7346 - val_acc: 0.6314 - val_auc_roc: 0.8439
Epoch 13/60
1652/1652 [==============================] - 3s 2ms/step - loss: 0.7838 - acc: 0.6326 - auc_roc: 0.8462 - val_loss: 1.8857 - val_acc: 0.7105 - val_auc_roc: 0.8495
Epoch 14/60
1652/1652 [==============================] - 3s 2ms/step - loss: 0.7748 - acc: 0.6186 - auc_roc: 0.8520 - val_loss: 1.7945 - val_acc: 0.6893 - val_auc_roc: 0.8547
Epoch 15/60
1652/1652 [==============================] - 3s 2ms/step - loss: 0.7555 - acc: 0.6344 - auc_roc: 0.8570 - val_loss: 1.8384 - val_acc: 0.6794 - val_auc_roc: 0.8591
Epoch 16/60
1652/1652 [==============================] - 3s 2ms/step - loss: 0.7503 - acc: 0.6229 - auc_roc: 0.8608 - val_loss: 1.9044 - val_acc: 0.6596 - val_auc_roc: 0.8624
Epoch 17/60
1652/1652 [==============================] - 3s 2ms/step - loss: 0.6904 - acc: 0.6762 - auc_roc: 0.8641 - val_loss: 2.0214 - val_acc: 0.7006 - val_auc_roc: 0.8664
Epoch 18/60
1652/1652 [==============================] - 3s 2ms/step - loss: 0.6722 - acc: 0.6586 - auc_roc: 0.8681 - val_loss: 2.1884 - val_acc: 0.6822 - val_auc_roc: 0.8699
Epoch 19/60
1652/1652 [==============================] - 3s 2ms/step - loss: 0.7400 - acc: 0.6671 - auc_roc: 0.8713 - val_loss: 1.6220 - val_acc: 0.7599 - val_auc_roc: 0.8729
Epoch 20/60
1652/1652 [==============================] - 3s 2ms/step - loss: 1.1124 - acc: 0.4982 - auc_roc: 0.8722 - val_loss: 1.7689 - val_acc: 0.4605 - val_auc_roc: 0.8708
Epoch 21/60
1652/1652 [==============================] - 3s 2ms/step - loss: 0.8283 - acc: 0.5926 - auc_roc: 0.8704 - val_loss: 1.9026 - val_acc: 0.5890 - val_auc_roc: 0.8705
Epoch 22/60
1652/1652 [==============================] - 3s 2ms/step - loss: 0.7125 - acc: 0.6441 - auc_roc: 0.8710 - val_loss: 1.8054 - val_acc: 0.6667 - val_auc_roc: 0.8721
Epoch 23/60
1652/1652 [==============================] - 3s 2ms/step - loss: 0.6619 - acc: 0.6810 - auc_roc: 0.8730 - val_loss: 2.0998 - val_acc: 0.6737 - val_auc_roc: 0.8741
Epoch 24/60
1652/1652 [==============================] - 3s 2ms/step - loss: 0.6439 - acc: 0.6749 - auc_roc: 0.8750 - val_loss: 2.1087 - val_acc: 0.7090 - val_auc_roc: 0.8762
Epoch 25/60
1652/1652 [==============================] - 3s 2ms/step - loss: 0.6102 - acc: 0.6889 - auc_roc: 0.8772 - val_loss: 1.9940 - val_acc: 0.6963 - val_auc_roc: 0.8785
Epoch 26/60
1652/1652 [==============================] - 4s 2ms/step - loss: 0.6121 - acc: 0.7010 - auc_roc: 0.8795 - val_loss: 1.9064 - val_acc: 0.7034 - val_auc_roc: 0.8807
Epoch 27/60
1652/1652 [==============================] - 3s 2ms/step - loss: 0.5755 - acc: 0.7149 - auc_roc: 0.8817 - val_loss: 2.2887 - val_acc: 0.6271 - val_auc_roc: 0.8825
Epoch 28/60
1652/1652 [==============================] - 3s 2ms/step - loss: 0.5556 - acc: 0.7209 - auc_roc: 0.8832 - val_loss: 2.2922 - val_acc: 0.7189 - val_auc_roc: 0.8844
Epoch 29/60
1652/1652 [==============================] - 3s 2ms/step - loss: 0.5232 - acc: 0.7331 - auc_roc: 0.8854 - val_loss: 2.2756 - val_acc: 0.7090 - val_auc_roc: 0.8866
Epoch 30/60
1652/1652 [==============================] - 3s 2ms/step - loss: 0.5067 - acc: 0.7506 - auc_roc: 0.8876 - val_loss: 2.3241 - val_acc: 0.7161 - val_auc_roc: 0.8887
Epoch 00030: early stopping
... history of metrics comprising: ['acc', 'loss', 'val_auc_roc', 'auc_roc', 'val_acc', 'val_loss']
... ... metric (acc): [0.59261501239517989, 0.64406779646584833, 0.68099273622180301, 0.67493946760099099, 0.68886198547215494, 0.70096852329106363, 0.71489104130654879, 0.7209443099273608, 0.73305084745762716, 0.75060532687651327] (n=30)
output> saving performance to:
/Users/pleiades/Documents/work/tpheno/seqmaker/data/CKD/plot/model_evalation-ep200b16.tif

... ... metric (loss): [0.82829186731620219, 0.71246264907407419, 0.66193116043150857, 0.64394382169113895, 0.61022160416942528, 0.61209087524806616, 0.57552801429792411, 0.55562653336628876, 0.52319549273059096, 0.50671999867256845] (n=30)
output> saving performance to:
/Users/pleiades/Documents/work/tpheno/seqmaker/data/CKD/plot/model_evalation-ep200b16.tif


model_selection> trying {'n_units': 100, 'dropout_rate': 0.3} ...

make_lstm> n_units=100, r_dropout=0.300000, n_layers=1, n_classes=6
  + lookup:
{'Others': 5, 'CKD Stage 5': 4, 'CKD Stage 4': 3, 'CKD Stage 3': 2, 'CKD Stage 2': 1, 'CKD Stage 1': 0}

... class weights:
{0: 6.344086021505376, 1: 0.74494949494949492, 2: 1.1238095238095238, 3: 7.0238095238095237, 4: 0.51890941072999119, 5: 0.64906490649064907}

====================================================================================================
... early stopping>
       + patience: 20, model='max'
... model training>
       + batch_size: 32, epochs: 60, shuffle? True, metric: auc_roc
====================================================================================================
Train on 1652 samples, validate on 708 samples
Epoch 1/60
1652/1652 [==============================] - 4s 3ms/step - loss: 1.7056 - acc: 0.2161 - auc_roc: 0.5421 - val_loss: 1.8678 - val_acc: 0.3446 - val_auc_roc: 0.6253
Epoch 2/60
1652/1652 [==============================] - 3s 2ms/step - loss: 1.5051 - acc: 0.3965 - auc_roc: 0.6637 - val_loss: 1.7871 - val_acc: 0.4336 - val_auc_roc: 0.6915
Epoch 3/60
1652/1652 [==============================] - 3s 2ms/step - loss: 1.3321 - acc: 0.4582 - auc_roc: 0.7086 - val_loss: 1.5778 - val_acc: 0.7274 - val_auc_roc: 0.7396
Epoch 4/60
1652/1652 [==============================] - 3s 2ms/step - loss: 1.2198 - acc: 0.5000 - auc_roc: 0.7603 - val_loss: 1.5506 - val_acc: 0.6907 - val_auc_roc: 0.7757
Epoch 5/60
1652/1652 [==============================] - 4s 2ms/step - loss: 1.1466 - acc: 0.5061 - auc_roc: 0.7866 - val_loss: 1.4513 - val_acc: 0.6356 - val_auc_roc: 0.7945
Epoch 6/60
1652/1652 [==============================] - 3s 2ms/step - loss: 1.0421 - acc: 0.5533 - auc_roc: 0.8021 - val_loss: 1.5138 - val_acc: 0.6992 - val_auc_roc: 0.8105
Epoch 7/60
1652/1652 [==============================] - 3s 2ms/step - loss: 1.0014 - acc: 0.5515 - auc_roc: 0.8166 - val_loss: 1.6419 - val_acc: 0.6483 - val_auc_roc: 0.8214
Epoch 8/60
1652/1652 [==============================] - 3s 2ms/step - loss: 0.9052 - acc: 0.5884 - auc_roc: 0.8255 - val_loss: 1.6903 - val_acc: 0.6949 - val_auc_roc: 0.8311
Epoch 9/60
1652/1652 [==============================] - 3s 2ms/step - loss: 0.8476 - acc: 0.6108 - auc_roc: 0.8360 - val_loss: 1.4992 - val_acc: 0.7048 - val_auc_roc: 0.8408
Epoch 10/60
1652/1652 [==============================] - 3s 2ms/step - loss: 0.8337 - acc: 0.5938 - auc_roc: 0.8447 - val_loss: 1.7837 - val_acc: 0.6695 - val_auc_roc: 0.8478
Epoch 11/60
1652/1652 [==============================] - 3s 2ms/step - loss: 0.7596 - acc: 0.6459 - auc_roc: 0.8511 - val_loss: 1.7636 - val_acc: 0.7048 - val_auc_roc: 0.8548
Epoch 12/60
1652/1652 [==============================] - 3s 2ms/step - loss: 0.7180 - acc: 0.6501 - auc_roc: 0.8577 - val_loss: 2.0799 - val_acc: 0.6243 - val_auc_roc: 0.8602
Epoch 13/60
1652/1652 [==============================] - 3s 2ms/step - loss: 0.7816 - acc: 0.6374 - auc_roc: 0.8620 - val_loss: 1.9907 - val_acc: 0.6130 - val_auc_roc: 0.8634
Epoch 14/60
1652/1652 [==============================] - 3s 2ms/step - loss: 0.7243 - acc: 0.6507 - auc_roc: 0.8648 - val_loss: 1.8626 - val_acc: 0.7189 - val_auc_roc: 0.8676
Epoch 15/60
1652/1652 [==============================] - 3s 2ms/step - loss: 0.6283 - acc: 0.6967 - auc_roc: 0.8700 - val_loss: 2.1020 - val_acc: 0.6667 - val_auc_roc: 0.8723
Epoch 16/60
1652/1652 [==============================] - 3s 2ms/step - loss: 0.5711 - acc: 0.7137 - auc_roc: 0.8744 - val_loss: 2.0951 - val_acc: 0.6935 - val_auc_roc: 0.8768
Epoch 17/60
1652/1652 [==============================] - 3s 2ms/step - loss: 0.5334 - acc: 0.7318 - auc_roc: 0.8790 - val_loss: 2.0352 - val_acc: 0.7218 - val_auc_roc: 0.8814
Epoch 18/60
1652/1652 [==============================] - 3s 2ms/step - loss: 0.4779 - acc: 0.7609 - auc_roc: 0.8836 - val_loss: 2.3064 - val_acc: 0.7006 - val_auc_roc: 0.8859
Epoch 19/60
1652/1652 [==============================] - 3s 2ms/step - loss: 0.4841 - acc: 0.7700 - auc_roc: 0.8876 - val_loss: 2.2909 - val_acc: 0.7260 - val_auc_roc: 0.8898
Epoch 20/60
1652/1652 [==============================] - 3s 2ms/step - loss: 0.4179 - acc: 0.8021 - auc_roc: 0.8917 - val_loss: 2.4257 - val_acc: 0.7175 - val_auc_roc: 0.8938
Epoch 21/60
1652/1652 [==============================] - 3s 2ms/step - loss: 0.4839 - acc: 0.7591 - auc_roc: 0.8952 - val_loss: 2.4199 - val_acc: 0.6695 - val_auc_roc: 0.8965
Epoch 22/60
1652/1652 [==============================] - 4s 2ms/step - loss: 0.4351 - acc: 0.7984 - auc_roc: 0.8980 - val_loss: 2.1293 - val_acc: 0.5763 - val_auc_roc: 0.8993
Epoch 23/60
1652/1652 [==============================] - 3s 2ms/step - loss: 0.4331 - acc: 0.7924 - auc_roc: 0.9002 - val_loss: 2.1946 - val_acc: 0.6582 - val_auc_roc: 0.9016
Epoch 24/60
1652/1652 [==============================] - 3s 2ms/step - loss: 0.3429 - acc: 0.8335 - auc_roc: 0.9030 - val_loss: 2.2698 - val_acc: 0.7006 - val_auc_roc: 0.9046
Epoch 25/60
1652/1652 [==============================] - 3s 2ms/step - loss: 0.3138 - acc: 0.8590 - auc_roc: 0.9059 - val_loss: 2.3599 - val_acc: 0.6935 - val_auc_roc: 0.9075
Epoch 00025: early stopping
... history of metrics comprising: ['acc', 'loss', 'val_auc_roc', 'auc_roc', 'val_acc', 'val_loss']
... ... metric (acc): [0.71368038769784337, 0.7318401935602793, 0.76089588377723971, 0.76997578678061829, 0.80205811138014527, 0.7590799031476998, 0.79842614983242299, 0.79237288121161098, 0.83353510867019542, 0.85895883777239712] (n=25)
output> saving performance to:
/Users/pleiades/Documents/work/tpheno/seqmaker/data/CKD/plot/model_evalation-ep200b16.tif

... ... metric (loss): [0.57113183771438225, 0.53339825314413258, 0.47792292961774091, 0.48413937598394713, 0.41788875955646321, 0.48394023325772317, 0.43505988845525007, 0.43312362074563349, 0.34285936632687475, 0.31382550519257424] (n=25)
output> saving performance to:
/Users/pleiades/Documents/work/tpheno/seqmaker/data/CKD/plot/model_evalation-ep200b16.tif


model_selection> trying {'n_units': 200, 'dropout_rate': 0.3} ...

make_lstm> n_units=200, r_dropout=0.300000, n_layers=1, n_classes=6
  + lookup:
{'Others': 5, 'CKD Stage 5': 4, 'CKD Stage 4': 3, 'CKD Stage 3': 2, 'CKD Stage 2': 1, 'CKD Stage 1': 0}

... class weights:
{0: 6.344086021505376, 1: 0.74494949494949492, 2: 1.1238095238095238, 3: 7.0238095238095237, 4: 0.51890941072999119, 5: 0.64906490649064907}

====================================================================================================
... early stopping>
       + patience: 20, model='max'
... model training>
       + batch_size: 32, epochs: 60, shuffle? True, metric: auc_roc
====================================================================================================
Train on 1652 samples, validate on 708 samples
Epoch 1/60
1652/1652 [==============================] - 5s 3ms/step - loss: 1.6466 - acc: 0.3238 - auc_roc: 0.6340 - val_loss: 1.5939 - val_acc: 0.6497 - val_auc_roc: 0.7332
Epoch 2/60
1652/1652 [==============================] - 4s 3ms/step - loss: 1.4092 - acc: 0.4661 - auc_roc: 0.7685 - val_loss: 1.5084 - val_acc: 0.5692 - val_auc_roc: 0.7850
Epoch 3/60
1652/1652 [==============================] - 4s 3ms/step - loss: 1.2215 - acc: 0.5194 - auc_roc: 0.7987 - val_loss: 1.5708 - val_acc: 0.6158 - val_auc_roc: 0.8078
Epoch 4/60
1652/1652 [==============================] - 4s 3ms/step - loss: 1.1916 - acc: 0.5381 - auc_roc: 0.8143 - val_loss: 1.3928 - val_acc: 0.6342 - val_auc_roc: 0.8205
Epoch 5/60
1652/1652 [==============================] - 4s 3ms/step - loss: 1.0776 - acc: 0.5266 - auc_roc: 0.8233 - val_loss: 1.5745 - val_acc: 0.6582 - val_auc_roc: 0.8297
Epoch 6/60
1652/1652 [==============================] - 4s 3ms/step - loss: 0.9956 - acc: 0.5539 - auc_roc: 0.8348 - val_loss: 1.7124 - val_acc: 0.5297 - val_auc_roc: 0.8358
Epoch 7/60
1652/1652 [==============================] - 4s 3ms/step - loss: 0.9945 - acc: 0.5726 - auc_roc: 0.8374 - val_loss: 1.4214 - val_acc: 0.6723 - val_auc_roc: 0.8419
Epoch 8/60
1652/1652 [==============================] - 4s 2ms/step - loss: 0.8423 - acc: 0.6150 - auc_roc: 0.8462 - val_loss: 1.7491 - val_acc: 0.5184 - val_auc_roc: 0.8484
Epoch 9/60
1652/1652 [==============================] - 4s 3ms/step - loss: 0.7992 - acc: 0.6253 - auc_roc: 0.8502 - val_loss: 1.7083 - val_acc: 0.6780 - val_auc_roc: 0.8543
Epoch 10/60
1652/1652 [==============================] - 4s 2ms/step - loss: 0.7294 - acc: 0.6477 - auc_roc: 0.8579 - val_loss: 1.8843 - val_acc: 0.7076 - val_auc_roc: 0.8619
Epoch 11/60
1652/1652 [==============================] - 4s 3ms/step - loss: 0.6863 - acc: 0.6689 - auc_roc: 0.8649 - val_loss: 1.9053 - val_acc: 0.6864 - val_auc_roc: 0.8681
Epoch 12/60
1652/1652 [==============================] - 4s 3ms/step - loss: 0.6425 - acc: 0.6737 - auc_roc: 0.8708 - val_loss: 1.9555 - val_acc: 0.7161 - val_auc_roc: 0.8738
Epoch 13/60
1652/1652 [==============================] - 4s 3ms/step - loss: 0.6231 - acc: 0.6907 - auc_roc: 0.8764 - val_loss: 1.9453 - val_acc: 0.6907 - val_auc_roc: 0.8790
Epoch 14/60
1652/1652 [==============================] - 4s 3ms/step - loss: 0.5409 - acc: 0.7228 - auc_roc: 0.8812 - val_loss: 2.1599 - val_acc: 0.7175 - val_auc_roc: 0.8840
Epoch 15/60
1652/1652 [==============================] - 5s 3ms/step - loss: 0.5248 - acc: 0.7288 - auc_roc: 0.8861 - val_loss: 1.8921 - val_acc: 0.7218 - val_auc_roc: 0.8885
Epoch 16/60
1652/1652 [==============================] - 4s 3ms/step - loss: 0.5236 - acc: 0.7458 - auc_roc: 0.8905 - val_loss: 2.1064 - val_acc: 0.7090 - val_auc_roc: 0.8924
Epoch 17/60
1652/1652 [==============================] - 4s 3ms/step - loss: 0.4718 - acc: 0.7833 - auc_roc: 0.8942 - val_loss: 2.1001 - val_acc: 0.7387 - val_auc_roc: 0.8965
Epoch 18/60
1652/1652 [==============================] - 4s 3ms/step - loss: 0.4405 - acc: 0.7990 - auc_roc: 0.8983 - val_loss: 2.2569 - val_acc: 0.7331 - val_auc_roc: 0.9006
Epoch 19/60
1652/1652 [==============================] - 4s 3ms/step - loss: 0.3560 - acc: 0.8251 - auc_roc: 0.9024 - val_loss: 2.5459 - val_acc: 0.6893 - val_auc_roc: 0.9044
Epoch 20/60
1652/1652 [==============================] - 5s 3ms/step - loss: 0.3547 - acc: 0.8378 - auc_roc: 0.9059 - val_loss: 2.3789 - val_acc: 0.6850 - val_auc_roc: 0.9077
Epoch 21/60
1652/1652 [==============================] - 4s 3ms/step - loss: 0.3310 - acc: 0.8529 - auc_roc: 0.9089 - val_loss: 2.3557 - val_acc: 0.6949 - val_auc_roc: 0.9107
Epoch 22/60
1652/1652 [==============================] - 5s 3ms/step - loss: 0.2632 - acc: 0.8771 - auc_roc: 0.9121 - val_loss: 2.7591 - val_acc: 0.6836 - val_auc_roc: 0.9137
Epoch 23/60
1652/1652 [==============================] - 5s 3ms/step - loss: 0.2390 - acc: 0.8971 - auc_roc: 0.9150 - val_loss: 2.7055 - val_acc: 0.7218 - val_auc_roc: 0.9167
Epoch 24/60
1652/1652 [==============================] - 4s 3ms/step - loss: 0.2019 - acc: 0.9122 - auc_roc: 0.9180 - val_loss: 2.4327 - val_acc: 0.7316 - val_auc_roc: 0.9197
Epoch 00024: early stopping
... history of metrics comprising: ['acc', 'loss', 'val_auc_roc', 'auc_roc', 'val_acc', 'val_loss']
... ... metric (acc): [0.72881355917771273, 0.7457627120087279, 0.78329297849687485, 0.7990314769975787, 0.82506053268765134, 0.8377723973830733, 0.85290556900726389, 0.87711864377915427, 0.89709443113705722, 0.9122276026169267] (n=24)
output> saving performance to:
/Users/pleiades/Documents/work/tpheno/seqmaker/data/CKD/plot/model_evalation-ep200b16.tif

... ... metric (loss): [0.52475638150014259, 0.52363669193974416, 0.4718370345256519, 0.44052730706355764, 0.35601972025474105, 0.35467095142703947, 0.33097377686465912, 0.2632080251599051, 0.23903234804513668, 0.20186780097265219] (n=24)
output> saving performance to:
/Users/pleiades/Documents/work/tpheno/seqmaker/data/CKD/plot/model_evalation-ep200b16.tif


model_selection> trying {'n_units': 300, 'dropout_rate': 0.3} ...

make_lstm> n_units=300, r_dropout=0.300000, n_layers=1, n_classes=6
  + lookup:
{'Others': 5, 'CKD Stage 5': 4, 'CKD Stage 4': 3, 'CKD Stage 3': 2, 'CKD Stage 2': 1, 'CKD Stage 1': 0}

... class weights:
{0: 6.344086021505376, 1: 0.74494949494949492, 2: 1.1238095238095238, 3: 7.0238095238095237, 4: 0.51890941072999119, 5: 0.64906490649064907}

====================================================================================================
... early stopping>
       + patience: 20, model='max'
... model training>
       + batch_size: 32, epochs: 60, shuffle? True, metric: auc_roc
====================================================================================================
Train on 1652 samples, validate on 708 samples
Epoch 1/60
1652/1652 [==============================] - 9s 5ms/step - loss: 1.6283 - acc: 0.3323 - auc_roc: 0.6301 - val_loss: 1.5382 - val_acc: 0.5763 - val_auc_roc: 0.7393
Epoch 2/60
1652/1652 [==============================] - 8s 5ms/step - loss: 1.4545 - acc: 0.4056 - auc_roc: 0.7625 - val_loss: 1.8156 - val_acc: 0.3870 - val_auc_roc: 0.7562
Epoch 3/60
1652/1652 [==============================] - 15s 9ms/step - loss: 1.2789 - acc: 0.4921 - auc_roc: 0.7640 - val_loss: 1.3724 - val_acc: 0.5240 - val_auc_roc: 0.7761
Epoch 4/60
1652/1652 [==============================] - 10s 6ms/step - loss: 1.1393 - acc: 0.5079 - auc_roc: 0.7842 - val_loss: 1.5711 - val_acc: 0.6116 - val_auc_roc: 0.7943
Epoch 5/60
1652/1652 [==============================] - 8s 5ms/step - loss: 1.0545 - acc: 0.5654 - auc_roc: 0.8046 - val_loss: 1.5981 - val_acc: 0.5579 - val_auc_roc: 0.8100
Epoch 6/60
1652/1652 [==============================] - 8s 5ms/step - loss: 0.9740 - acc: 0.5757 - auc_roc: 0.8163 - val_loss: 1.6696 - val_acc: 0.6610 - val_auc_roc: 0.8225
Epoch 7/60
1652/1652 [==============================] - 8s 5ms/step - loss: 0.8571 - acc: 0.6005 - auc_roc: 0.8286 - val_loss: 1.9582 - val_acc: 0.6850 - val_auc_roc: 0.8351
Epoch 8/60
1652/1652 [==============================] - 8s 5ms/step - loss: 0.7966 - acc: 0.6199 - auc_roc: 0.8402 - val_loss: 1.6352 - val_acc: 0.6059 - val_auc_roc: 0.8445
Epoch 9/60
1652/1652 [==============================] - 7s 4ms/step - loss: 0.7470 - acc: 0.6368 - auc_roc: 0.8481 - val_loss: 1.8269 - val_acc: 0.6681 - val_auc_roc: 0.8524
Epoch 10/60
1652/1652 [==============================] - 7s 4ms/step - loss: 0.6607 - acc: 0.6610 - auc_roc: 0.8564 - val_loss: 2.0121 - val_acc: 0.5890 - val_auc_roc: 0.8597
Epoch 11/60
1652/1652 [==============================] - 7s 4ms/step - loss: 0.6899 - acc: 0.6731 - auc_roc: 0.8626 - val_loss: 1.7767 - val_acc: 0.6059 - val_auc_roc: 0.8649
Epoch 12/60
1652/1652 [==============================] - 7s 4ms/step - loss: 0.7106 - acc: 0.6786 - auc_roc: 0.8670 - val_loss: 1.6422 - val_acc: 0.6624 - val_auc_roc: 0.8699
Epoch 13/60
1652/1652 [==============================] - 7s 4ms/step - loss: 0.6656 - acc: 0.6834 - auc_roc: 0.8719 - val_loss: 1.9839 - val_acc: 0.5452 - val_auc_roc: 0.8736
Epoch 14/60
1652/1652 [==============================] - 6s 4ms/step - loss: 0.5786 - acc: 0.7209 - auc_roc: 0.8753 - val_loss: 2.8107 - val_acc: 0.3277 - val_auc_roc: 0.8754
Epoch 15/60
1652/1652 [==============================] - 7s 4ms/step - loss: 0.6728 - acc: 0.6665 - auc_roc: 0.8750 - val_loss: 2.4116 - val_acc: 0.2726 - val_auc_roc: 0.8744
Epoch 16/60
1652/1652 [==============================] - 6s 4ms/step - loss: 0.6175 - acc: 0.6816 - auc_roc: 0.8742 - val_loss: 2.2875 - val_acc: 0.6455 - val_auc_roc: 0.8764
Epoch 17/60
1652/1652 [==============================] - 7s 4ms/step - loss: 0.4642 - acc: 0.7669 - auc_roc: 0.8786 - val_loss: 2.3790 - val_acc: 0.6525 - val_auc_roc: 0.8812
Epoch 18/60
1652/1652 [==============================] - 7s 4ms/step - loss: 0.4274 - acc: 0.7851 - auc_roc: 0.8834 - val_loss: 2.3881 - val_acc: 0.7034 - val_auc_roc: 0.8860
Epoch 19/60
1652/1652 [==============================] - 7s 4ms/step - loss: 0.4221 - acc: 0.8160 - auc_roc: 0.8883 - val_loss: 2.3973 - val_acc: 0.7105 - val_auc_roc: 0.8907
Epoch 20/60
1652/1652 [==============================] - 7s 4ms/step - loss: 0.3681 - acc: 0.8172 - auc_roc: 0.8929 - val_loss: 2.3969 - val_acc: 0.6511 - val_auc_roc: 0.8950
Epoch 21/60
1652/1652 [==============================] - 7s 4ms/step - loss: 0.3037 - acc: 0.8590 - auc_roc: 0.8969 - val_loss: 2.6345 - val_acc: 0.6879 - val_auc_roc: 0.8992
Epoch 22/60
1652/1652 [==============================] - 7s 4ms/step - loss: 0.2447 - acc: 0.8838 - auc_roc: 0.9011 - val_loss: 2.8535 - val_acc: 0.6582 - val_auc_roc: 0.9032
Epoch 23/60
1652/1652 [==============================] - 7s 4ms/step - loss: 0.2062 - acc: 0.9007 - auc_roc: 0.9048 - val_loss: 2.7991 - val_acc: 0.6822 - val_auc_roc: 0.9070
Epoch 00023: early stopping
... history of metrics comprising: ['acc', 'loss', 'val_auc_roc', 'auc_roc', 'val_acc', 'val_loss']
... ... metric (acc): [0.72094430963871847, 0.66646489089684102, 0.68159806295399517, 0.76694915239805173, 0.78510895912641476, 0.81598062953995154, 0.81719128300433586, 0.8589588376280759, 0.88377723970944311, 0.90072639196317361] (n=23)
output> saving performance to:
/Users/pleiades/Documents/work/tpheno/seqmaker/data/CKD/plot/model_evalation-ep200b16.tif

... ... metric (loss): [0.57859018120292316, 0.67282451671203169, 0.61751858576158059, 0.4642445663707308, 0.4273671360627791, 0.42205385499370013, 0.36808493087568817, 0.30368415098502044, 0.24467341930179273, 0.20620890852902762] (n=23)
output> saving performance to:
/Users/pleiades/Documents/work/tpheno/seqmaker/data/CKD/plot/model_evalation-ep200b16.tif


model_selection> trying {'n_units': 400, 'dropout_rate': 0.3} ...

make_lstm> n_units=400, r_dropout=0.300000, n_layers=1, n_classes=6
  + lookup:
{'Others': 5, 'CKD Stage 5': 4, 'CKD Stage 4': 3, 'CKD Stage 3': 2, 'CKD Stage 2': 1, 'CKD Stage 1': 0}

... class weights:
{0: 6.344086021505376, 1: 0.74494949494949492, 2: 1.1238095238095238, 3: 7.0238095238095237, 4: 0.51890941072999119, 5: 0.64906490649064907}

====================================================================================================
... early stopping>
       + patience: 20, model='max'
... model training>
       + batch_size: 32, epochs: 60, shuffle? True, metric: auc_roc
====================================================================================================
Train on 1652 samples, validate on 708 samples
Epoch 1/60
1652/1652 [==============================] - 10s 6ms/step - loss: 1.6035 - acc: 0.3311 - auc_roc: 0.6788 - val_loss: 1.6336 - val_acc: 0.6130 - val_auc_roc: 0.7425
Epoch 2/60
1652/1652 [==============================] - 10s 6ms/step - loss: 1.4412 - acc: 0.4219 - auc_roc: 0.7608 - val_loss: 2.1688 - val_acc: 0.0720 - val_auc_roc: 0.7352
Epoch 3/60
1652/1652 [==============================] - 10s 6ms/step - loss: 1.3633 - acc: 0.4346 - auc_roc: 0.7221 - val_loss: 1.9054 - val_acc: 0.5127 - val_auc_roc: 0.7408
Epoch 4/60
1652/1652 [==============================] - 12s 8ms/step - loss: 1.1598 - acc: 0.4861 - auc_roc: 0.7560 - val_loss: 1.6313 - val_acc: 0.6003 - val_auc_roc: 0.7719
Epoch 5/60
1652/1652 [==============================] - 13s 8ms/step - loss: 1.1304 - acc: 0.5109 - auc_roc: 0.7829 - val_loss: 1.7250 - val_acc: 0.5523 - val_auc_roc: 0.7894
Epoch 6/60
1652/1652 [==============================] - 14s 8ms/step - loss: 1.0187 - acc: 0.5587 - auc_roc: 0.7960 - val_loss: 1.7286 - val_acc: 0.6144 - val_auc_roc: 0.8045
Epoch 7/60
1652/1652 [==============================] - 12s 7ms/step - loss: 0.9571 - acc: 0.5581 - auc_roc: 0.8098 - val_loss: 1.8313 - val_acc: 0.4958 - val_auc_roc: 0.8138
Epoch 8/60
1652/1652 [==============================] - 11s 7ms/step - loss: 0.8786 - acc: 0.5956 - auc_roc: 0.8181 - val_loss: 1.9284 - val_acc: 0.5551 - val_auc_roc: 0.8226
Epoch 9/60
1652/1652 [==============================] - 10s 6ms/step - loss: 0.9326 - acc: 0.5502 - auc_roc: 0.8250 - val_loss: 1.7772 - val_acc: 0.6582 - val_auc_roc: 0.8294
Epoch 10/60
1652/1652 [==============================] - 10s 6ms/step - loss: 0.8375 - acc: 0.6332 - auc_roc: 0.8334 - val_loss: 1.9455 - val_acc: 0.6144 - val_auc_roc: 0.8373
Epoch 11/60
1652/1652 [==============================] - 10s 6ms/step - loss: 0.7847 - acc: 0.6059 - auc_roc: 0.8395 - val_loss: 1.8965 - val_acc: 0.6328 - val_auc_roc: 0.8433
Epoch 12/60
1652/1652 [==============================] - 10s 6ms/step - loss: 0.7036 - acc: 0.6695 - auc_roc: 0.8467 - val_loss: 2.1336 - val_acc: 0.5720 - val_auc_roc: 0.8498
Epoch 13/60
1652/1652 [==============================] - 10s 6ms/step - loss: 0.6917 - acc: 0.6695 - auc_roc: 0.8522 - val_loss: 1.7659 - val_acc: 0.5904 - val_auc_roc: 0.8550
Epoch 14/60
1652/1652 [==============================] - 10s 6ms/step - loss: 0.5823 - acc: 0.7203 - auc_roc: 0.8579 - val_loss: 2.3904 - val_acc: 0.6483 - val_auc_roc: 0.8611
Epoch 15/60
1652/1652 [==============================] - 9s 6ms/step - loss: 0.5274 - acc: 0.7482 - auc_roc: 0.8640 - val_loss: 2.3509 - val_acc: 0.6836 - val_auc_roc: 0.8674
Epoch 16/60
1652/1652 [==============================] - 9s 6ms/step - loss: 0.4667 - acc: 0.7633 - auc_roc: 0.8702 - val_loss: 2.3768 - val_acc: 0.6737 - val_auc_roc: 0.8737
Epoch 17/60
1652/1652 [==============================] - 10s 6ms/step - loss: 0.4341 - acc: 0.8057 - auc_roc: 0.8766 - val_loss: 1.9659 - val_acc: 0.6582 - val_auc_roc: 0.8796
Epoch 18/60
1652/1652 [==============================] - 10s 6ms/step - loss: 0.3586 - acc: 0.8172 - auc_roc: 0.8823 - val_loss: 2.2938 - val_acc: 0.6949 - val_auc_roc: 0.8852
Epoch 19/60
1652/1652 [==============================] - 11s 6ms/step - loss: 0.3196 - acc: 0.8529 - auc_roc: 0.8880 - val_loss: 2.3784 - val_acc: 0.7090 - val_auc_roc: 0.8908
Epoch 20/60
1652/1652 [==============================] - 10s 6ms/step - loss: 0.3450 - acc: 0.8535 - auc_roc: 0.8931 - val_loss: 2.4528 - val_acc: 0.7105 - val_auc_roc: 0.8954
Epoch 21/60
1652/1652 [==============================] - 10s 6ms/step - loss: 0.2851 - acc: 0.8674 - auc_roc: 0.8974 - val_loss: 2.6132 - val_acc: 0.6073 - val_auc_roc: 0.8994
Epoch 22/60
1652/1652 [==============================] - 10s 6ms/step - loss: 0.3266 - acc: 0.8608 - auc_roc: 0.9009 - val_loss: 2.3205 - val_acc: 0.6596 - val_auc_roc: 0.9028
Epoch 23/60
1652/1652 [==============================] - 11s 6ms/step - loss: 0.2991 - acc: 0.8662 - auc_roc: 0.9043 - val_loss: 2.6240 - val_acc: 0.6766 - val_auc_roc: 0.9061
Epoch 24/60
1652/1652 [==============================] - 10s 6ms/step - loss: 0.2066 - acc: 0.9128 - auc_roc: 0.9078 - val_loss: 2.5406 - val_acc: 0.6992 - val_auc_roc: 0.9099
Epoch 00024: early stopping
... history of metrics comprising: ['acc', 'loss', 'val_auc_roc', 'auc_roc', 'val_acc', 'val_loss']
... ... metric (acc): [0.7481840195147812, 0.76331719157193534, 0.80569007249490399, 0.81719128329297819, 0.85290556900726389, 0.8535108961724196, 0.86743341375494121, 0.8607748181132947, 0.86622276057919922, 0.9128329297820823] (n=24)
output> saving performance to:
/Users/pleiades/Documents/work/tpheno/seqmaker/data/CKD/plot/model_evalation-ep200b16.tif

... ... metric (loss): [0.52742013010505329, 0.46668814212877585, 0.43412628517312518, 0.35863324906000504, 0.31959694667243493, 0.34501847660859042, 0.28511528263080493, 0.32662740991998818, 0.29914756339341042, 0.20657153429404876] (n=24)
output> saving performance to:
/Users/pleiades/Documents/work/tpheno/seqmaker/data/CKD/plot/model_evalation-ep200b16.tif


model_selection> trying {'n_units': 500, 'dropout_rate': 0.3} ...

make_lstm> n_units=500, r_dropout=0.300000, n_layers=1, n_classes=6
  + lookup:
{'Others': 5, 'CKD Stage 5': 4, 'CKD Stage 4': 3, 'CKD Stage 3': 2, 'CKD Stage 2': 1, 'CKD Stage 1': 0}

... class weights:
{0: 6.344086021505376, 1: 0.74494949494949492, 2: 1.1238095238095238, 3: 7.0238095238095237, 4: 0.51890941072999119, 5: 0.64906490649064907}

====================================================================================================
... early stopping>
       + patience: 20, model='max'
... model training>
       + batch_size: 32, epochs: 60, shuffle? True, metric: auc_roc
====================================================================================================
Train on 1652 samples, validate on 708 samples
Epoch 1/60
1652/1652 [==============================] - 15s 9ms/step - loss: 1.6372 - acc: 0.3202 - auc_roc: 0.6406 - val_loss: 1.6173 - val_acc: 0.2359 - val_auc_roc: 0.6820
Epoch 2/60
1652/1652 [==============================] - 14s 9ms/step - loss: 1.3872 - acc: 0.4691 - auc_roc: 0.7044 - val_loss: 1.4792 - val_acc: 0.5395 - val_auc_roc: 0.7369
Epoch 3/60
1652/1652 [==============================] - 15s 9ms/step - loss: 1.3282 - acc: 0.4050 - auc_roc: 0.7499 - val_loss: 1.6610 - val_acc: 0.4421 - val_auc_roc: 0.7519
Epoch 4/60
1652/1652 [==============================] - 14s 9ms/step - loss: 1.2113 - acc: 0.4885 - auc_roc: 0.7594 - val_loss: 1.4531 - val_acc: 0.6441 - val_auc_roc: 0.7758
Epoch 5/60
1652/1652 [==============================] - 14s 9ms/step - loss: 1.1237 - acc: 0.5079 - auc_roc: 0.7858 - val_loss: 1.7500 - val_acc: 0.5593 - val_auc_roc: 0.7918
Epoch 6/60
1652/1652 [==============================] - 16s 10ms/step - loss: 1.0510 - acc: 0.5369 - auc_roc: 0.7964 - val_loss: 1.8684 - val_acc: 0.6257 - val_auc_roc: 0.8041
Epoch 7/60
1652/1652 [==============================] - 15s 9ms/step - loss: 0.9769 - acc: 0.5630 - auc_roc: 0.8110 - val_loss: 1.5749 - val_acc: 0.5523 - val_auc_roc: 0.8150
Epoch 8/60
1652/1652 [==============================] - 15s 9ms/step - loss: 0.8826 - acc: 0.5920 - auc_roc: 0.8193 - val_loss: 1.5014 - val_acc: 0.6638 - val_auc_roc: 0.8253
Epoch 9/60
1652/1652 [==============================] - 15s 9ms/step - loss: 0.8317 - acc: 0.6120 - auc_roc: 0.8302 - val_loss: 1.7906 - val_acc: 0.6427 - val_auc_roc: 0.8351
Epoch 10/60
1652/1652 [==============================] - 14s 9ms/step - loss: 0.7396 - acc: 0.6416 - auc_roc: 0.8390 - val_loss: 2.0043 - val_acc: 0.6469 - val_auc_roc: 0.8438
Epoch 11/60
1652/1652 [==============================] - 14s 8ms/step - loss: 0.7164 - acc: 0.6538 - auc_roc: 0.8475 - val_loss: 1.9182 - val_acc: 0.6427 - val_auc_roc: 0.8515
Epoch 12/60
1652/1652 [==============================] - 21s 13ms/step - loss: 0.6892 - acc: 0.6768 - auc_roc: 0.8543 - val_loss: 2.1475 - val_acc: 0.4223 - val_auc_roc: 0.8556
Epoch 13/60
1652/1652 [==============================] - 17s 10ms/step - loss: 0.6781 - acc: 0.6519 - auc_roc: 0.8565 - val_loss: 2.7790 - val_acc: 0.2994 - val_auc_roc: 0.8564
Epoch 14/60
1652/1652 [==============================] - 16s 9ms/step - loss: 0.6815 - acc: 0.6646 - auc_roc: 0.8564 - val_loss: 1.9192 - val_acc: 0.6582 - val_auc_roc: 0.8595
Epoch 15/60
1652/1652 [==============================] - 16s 10ms/step - loss: 0.8095 - acc: 0.6320 - auc_roc: 0.8607 - val_loss: 2.0203 - val_acc: 0.5805 - val_auc_roc: 0.8619
Epoch 16/60
1652/1652 [==============================] - 16s 10ms/step - loss: 0.5471 - acc: 0.7209 - auc_roc: 0.8641 - val_loss: 2.2331 - val_acc: 0.6610 - val_auc_roc: 0.8671
Epoch 17/60
1652/1652 [==============================] - 16s 10ms/step - loss: 0.5022 - acc: 0.7585 - auc_roc: 0.8698 - val_loss: 2.3550 - val_acc: 0.6427 - val_auc_roc: 0.8724
Epoch 18/60
1652/1652 [==============================] - 17s 10ms/step - loss: 0.4142 - acc: 0.7912 - auc_roc: 0.8750 - val_loss: 2.4060 - val_acc: 0.6822 - val_auc_roc: 0.8781
Epoch 19/60
1652/1652 [==============================] - 17s 10ms/step - loss: 0.3827 - acc: 0.8154 - auc_roc: 0.8806 - val_loss: 2.7427 - val_acc: 0.6780 - val_auc_roc: 0.8834
Epoch 20/60
1652/1652 [==============================] - 17s 10ms/step - loss: 0.3210 - acc: 0.8414 - auc_roc: 0.8859 - val_loss: 2.6019 - val_acc: 0.5932 - val_auc_roc: 0.8882
Epoch 21/60
1652/1652 [==============================] - 17s 10ms/step - loss: 0.3349 - acc: 0.8396 - auc_roc: 0.8900 - val_loss: 2.6492 - val_acc: 0.6963 - val_auc_roc: 0.8925
Epoch 22/60
1652/1652 [==============================] - 17s 10ms/step - loss: 0.4100 - acc: 0.8208 - auc_roc: 0.8942 - val_loss: 2.3723 - val_acc: 0.6935 - val_auc_roc: 0.8962
Epoch 23/60
1652/1652 [==============================] - 17s 10ms/step - loss: 0.2790 - acc: 0.8638 - auc_roc: 0.8980 - val_loss: 2.7628 - val_acc: 0.7161 - val_auc_roc: 0.9003
Epoch 24/60
1652/1652 [==============================] - 15s 9ms/step - loss: 0.2176 - acc: 0.8989 - auc_roc: 0.9022 - val_loss: 2.4786 - val_acc: 0.7034 - val_auc_roc: 0.9043
Epoch 00024: early stopping
... history of metrics comprising: ['acc', 'loss', 'val_auc_roc', 'auc_roc', 'val_acc', 'val_loss']
... ... metric (acc): [0.63196125907990319, 0.72094431021600314, 0.75847457598254409, 0.79116222760290555, 0.81537530266343827, 0.84140435849783202, 0.8395883778682921, 0.8208232442634158, 0.86380145292882482, 0.8989104113336337] (n=24)
output> saving performance to:
/Users/pleiades/Documents/work/tpheno/seqmaker/data/CKD/plot/model_evalation-ep200b16.tif

... ... metric (loss): [0.80948471359132856, 0.54708207144286958, 0.50224454827227838, 0.4141596928780073, 0.38270204725334778, 0.32104251495862413, 0.33490283155845385, 0.40996979187822224, 0.27898090002611819, 0.21758790678608503] (n=24)
output> saving performance to:
/Users/pleiades/Documents/work/tpheno/seqmaker/data/CKD/plot/model_evalation-ep200b16.tif


model_selection> trying {'n_units': 50, 'dropout_rate': 0.5} ...

make_lstm> n_units=50, r_dropout=0.500000, n_layers=1, n_classes=6
  + lookup:
{'Others': 5, 'CKD Stage 5': 4, 'CKD Stage 4': 3, 'CKD Stage 3': 2, 'CKD Stage 2': 1, 'CKD Stage 1': 0}

... class weights:
{0: 6.344086021505376, 1: 0.74494949494949492, 2: 1.1238095238095238, 3: 7.0238095238095237, 4: 0.51890941072999119, 5: 0.64906490649064907}

====================================================================================================
... early stopping>
       + patience: 20, model='max'
... model training>
       + batch_size: 32, epochs: 60, shuffle? True, metric: auc_roc
====================================================================================================
Train on 1652 samples, validate on 708 samples
Epoch 1/60
1652/1652 [==============================] - 7s 4ms/step - loss: 1.7369 - acc: 0.2161 - auc_roc: 0.5164 - val_loss: 2.0662 - val_acc: 0.0339 - val_auc_roc: 0.5258
Epoch 2/60
1652/1652 [==============================] - 4s 3ms/step - loss: 1.6708 - acc: 0.2403 - auc_roc: 0.5334 - val_loss: 1.9647 - val_acc: 0.0523 - val_auc_roc: 0.5497
Epoch 3/60
1652/1652 [==============================] - 4s 2ms/step - loss: 1.5529 - acc: 0.3565 - auc_roc: 0.5681 - val_loss: 1.9591 - val_acc: 0.3446 - val_auc_roc: 0.5994
Epoch 4/60
1652/1652 [==============================] - 3s 2ms/step - loss: 1.4320 - acc: 0.4262 - auc_roc: 0.6247 - val_loss: 1.6323 - val_acc: 0.4675 - val_auc_roc: 0.6524
Epoch 5/60
1652/1652 [==============================] - 3s 2ms/step - loss: 1.2583 - acc: 0.4728 - auc_roc: 0.6753 - val_loss: 1.7151 - val_acc: 0.3672 - val_auc_roc: 0.6895
Epoch 6/60
1652/1652 [==============================] - 3s 2ms/step - loss: 1.2423 - acc: 0.4849 - auc_roc: 0.7000 - val_loss: 1.3329 - val_acc: 0.6483 - val_auc_roc: 0.7166
Epoch 7/60
1652/1652 [==============================] - 3s 2ms/step - loss: 1.1356 - acc: 0.5200 - auc_roc: 0.7302 - val_loss: 1.4278 - val_acc: 0.6610 - val_auc_roc: 0.7430
Epoch 8/60
1652/1652 [==============================] - 3s 2ms/step - loss: 1.0700 - acc: 0.5297 - auc_roc: 0.7532 - val_loss: 1.4552 - val_acc: 0.6921 - val_auc_roc: 0.7634
Epoch 9/60
1652/1652 [==============================] - 3s 2ms/step - loss: 1.0453 - acc: 0.5291 - auc_roc: 0.7717 - val_loss: 1.5863 - val_acc: 0.6723 - val_auc_roc: 0.7790
Epoch 10/60
1652/1652 [==============================] - 3s 2ms/step - loss: 1.0410 - acc: 0.5351 - auc_roc: 0.7850 - val_loss: 1.6425 - val_acc: 0.6370 - val_auc_roc: 0.7900
Epoch 11/60
1652/1652 [==============================] - 3s 2ms/step - loss: 0.9717 - acc: 0.5678 - auc_roc: 0.7948 - val_loss: 1.4576 - val_acc: 0.7175 - val_auc_roc: 0.8007
Epoch 12/60
1652/1652 [==============================] - 3s 2ms/step - loss: 0.9210 - acc: 0.5805 - auc_roc: 0.8059 - val_loss: 1.5168 - val_acc: 0.6921 - val_auc_roc: 0.8103
Epoch 13/60
1652/1652 [==============================] - 3s 2ms/step - loss: 0.9063 - acc: 0.5914 - auc_roc: 0.8145 - val_loss: 1.7394 - val_acc: 0.6610 - val_auc_roc: 0.8182
Epoch 14/60
1652/1652 [==============================] - 4s 2ms/step - loss: 0.8629 - acc: 0.6096 - auc_roc: 0.8214 - val_loss: 1.7392 - val_acc: 0.6695 - val_auc_roc: 0.8250
Epoch 15/60
1652/1652 [==============================] - 4s 2ms/step - loss: 0.8354 - acc: 0.5914 - auc_roc: 0.8277 - val_loss: 1.6395 - val_acc: 0.7105 - val_auc_roc: 0.8310
Epoch 16/60
1652/1652 [==============================] - 4s 3ms/step - loss: 0.7912 - acc: 0.6205 - auc_roc: 0.8342 - val_loss: 1.6640 - val_acc: 0.6992 - val_auc_roc: 0.8374
Epoch 17/60
1652/1652 [==============================] - 4s 2ms/step - loss: 0.7753 - acc: 0.6253 - auc_roc: 0.8399 - val_loss: 1.7529 - val_acc: 0.7105 - val_auc_roc: 0.8427
Epoch 18/60
1652/1652 [==============================] - 3s 2ms/step - loss: 0.7489 - acc: 0.6301 - auc_roc: 0.8452 - val_loss: 1.7633 - val_acc: 0.7119 - val_auc_roc: 0.8478
Epoch 19/60
1652/1652 [==============================] - 4s 2ms/step - loss: 0.7019 - acc: 0.6538 - auc_roc: 0.8502 - val_loss: 1.9355 - val_acc: 0.7246 - val_auc_roc: 0.8527
Epoch 20/60
1652/1652 [==============================] - 4s 2ms/step - loss: 0.7136 - acc: 0.6640 - auc_roc: 0.8549 - val_loss: 2.0333 - val_acc: 0.7119 - val_auc_roc: 0.8571
Epoch 21/60
1652/1652 [==============================] - 3s 2ms/step - loss: 0.6729 - acc: 0.6646 - auc_roc: 0.8589 - val_loss: 2.0335 - val_acc: 0.7105 - val_auc_roc: 0.8608
Epoch 22/60
1652/1652 [==============================] - 3s 2ms/step - loss: 0.6442 - acc: 0.6810 - auc_roc: 0.8625 - val_loss: 1.9672 - val_acc: 0.7401 - val_auc_roc: 0.8646
Epoch 23/60
1652/1652 [==============================] - 3s 2ms/step - loss: 0.7244 - acc: 0.6356 - auc_roc: 0.8660 - val_loss: 2.0433 - val_acc: 0.6822 - val_auc_roc: 0.8674
Epoch 24/60
1652/1652 [==============================] - 3s 2ms/step - loss: 0.6915 - acc: 0.6580 - auc_roc: 0.8685 - val_loss: 2.1570 - val_acc: 0.6766 - val_auc_roc: 0.8698
Epoch 25/60
1652/1652 [==============================] - 4s 2ms/step - loss: 0.7348 - acc: 0.6223 - auc_roc: 0.8709 - val_loss: 2.5702 - val_acc: 0.2952 - val_auc_roc: 0.8695
Epoch 26/60
1652/1652 [==============================] - 3s 2ms/step - loss: 0.7745 - acc: 0.5950 - auc_roc: 0.8684 - val_loss: 2.1030 - val_acc: 0.6412 - val_auc_roc: 0.8691
Epoch 00026: early stopping
... history of metrics comprising: ['acc', 'loss', 'val_auc_roc', 'auc_roc', 'val_acc', 'val_loss']
... ... metric (acc): [0.62530266329393547, 0.63014527830604206, 0.65375302677870373, 0.66404358367943017, 0.66464891070026466, 0.68099273593316068, 0.63559322048330424, 0.65799031476997583, 0.62227602920001124, 0.59503631975691196] (n=26)
output> saving performance to:
/Users/pleiades/Documents/work/tpheno/seqmaker/data/CKD/plot/model_evalation-ep200b16.tif

... ... metric (loss): [0.77533080560531797, 0.74893713040732879, 0.70185444112551409, 0.71358969757112412, 0.67287788826963224, 0.64421114664678136, 0.72443177018846783, 0.69149125877939188, 0.73476410532690417, 0.77454028233488881] (n=26)
output> saving performance to:
/Users/pleiades/Documents/work/tpheno/seqmaker/data/CKD/plot/model_evalation-ep200b16.tif


model_selection> trying {'n_units': 100, 'dropout_rate': 0.5} ...

make_lstm> n_units=100, r_dropout=0.500000, n_layers=1, n_classes=6
  + lookup:
{'Others': 5, 'CKD Stage 5': 4, 'CKD Stage 4': 3, 'CKD Stage 3': 2, 'CKD Stage 2': 1, 'CKD Stage 1': 0}

... class weights:
{0: 6.344086021505376, 1: 0.74494949494949492, 2: 1.1238095238095238, 3: 7.0238095238095237, 4: 0.51890941072999119, 5: 0.64906490649064907}

====================================================================================================
... early stopping>
       + patience: 20, model='max'
... model training>
       + batch_size: 32, epochs: 60, shuffle? True, metric: auc_roc
====================================================================================================
Train on 1652 samples, validate on 708 samples
Epoch 1/60
1652/1652 [==============================] - 5s 3ms/step - loss: 1.7497 - acc: 0.2082 - auc_roc: 0.5049 - val_loss: 1.9540 - val_acc: 0.0593 - val_auc_roc: 0.5703
Epoch 2/60
1652/1652 [==============================] - 3s 2ms/step - loss: 1.5701 - acc: 0.3596 - auc_roc: 0.6017 - val_loss: 1.7594 - val_acc: 0.5042 - val_auc_roc: 0.6592
Epoch 3/60
1652/1652 [==============================] - 4s 2ms/step - loss: 1.4161 - acc: 0.4159 - auc_roc: 0.6934 - val_loss: 1.4532 - val_acc: 0.4816 - val_auc_roc: 0.7107
Epoch 4/60
1652/1652 [==============================] - 3s 2ms/step - loss: 1.2619 - acc: 0.4764 - auc_roc: 0.7255 - val_loss: 1.7217 - val_acc: 0.5184 - val_auc_roc: 0.7406
Epoch 5/60
1652/1652 [==============================] - 3s 2ms/step - loss: 1.1850 - acc: 0.5163 - auc_roc: 0.7525 - val_loss: 1.3006 - val_acc: 0.6667 - val_auc_roc: 0.7660
Epoch 6/60
1652/1652 [==============================] - 4s 2ms/step - loss: 1.1362 - acc: 0.5103 - auc_roc: 0.7770 - val_loss: 1.5944 - val_acc: 0.4718 - val_auc_roc: 0.7810
Epoch 7/60
1652/1652 [==============================] - 3s 2ms/step - loss: 1.1211 - acc: 0.5182 - auc_roc: 0.7843 - val_loss: 1.4096 - val_acc: 0.6328 - val_auc_roc: 0.7913
Epoch 8/60
1652/1652 [==============================] - 4s 2ms/step - loss: 1.0000 - acc: 0.5533 - auc_roc: 0.7978 - val_loss: 1.5472 - val_acc: 0.6455 - val_auc_roc: 0.8042
Epoch 9/60
1652/1652 [==============================] - 3s 2ms/step - loss: 0.9338 - acc: 0.5654 - auc_roc: 0.8096 - val_loss: 1.4876 - val_acc: 0.6808 - val_auc_roc: 0.8153
Epoch 10/60
1652/1652 [==============================] - 3s 2ms/step - loss: 0.8865 - acc: 0.6047 - auc_roc: 0.8205 - val_loss: 1.5945 - val_acc: 0.6850 - val_auc_roc: 0.8261
Epoch 11/60
1652/1652 [==============================] - 4s 2ms/step - loss: 0.8605 - acc: 0.6108 - auc_roc: 0.8302 - val_loss: 1.5384 - val_acc: 0.6766 - val_auc_roc: 0.8341
Epoch 12/60
1652/1652 [==============================] - 3s 2ms/step - loss: 0.8743 - acc: 0.5630 - auc_roc: 0.8364 - val_loss: 1.6866 - val_acc: 0.6596 - val_auc_roc: 0.8390
Epoch 13/60
1652/1652 [==============================] - 4s 2ms/step - loss: 0.7920 - acc: 0.6199 - auc_roc: 0.8419 - val_loss: 1.6463 - val_acc: 0.6836 - val_auc_roc: 0.8450
Epoch 14/60
1652/1652 [==============================] - 4s 2ms/step - loss: 0.7334 - acc: 0.6441 - auc_roc: 0.8479 - val_loss: 1.7985 - val_acc: 0.6977 - val_auc_roc: 0.8509
Epoch 15/60
1652/1652 [==============================] - 4s 2ms/step - loss: 0.7183 - acc: 0.6380 - auc_roc: 0.8534 - val_loss: 1.7496 - val_acc: 0.6667 - val_auc_roc: 0.8559
Epoch 16/60
1652/1652 [==============================] - 4s 2ms/step - loss: 0.6961 - acc: 0.6586 - auc_roc: 0.8579 - val_loss: 2.1006 - val_acc: 0.7006 - val_auc_roc: 0.8604
Epoch 17/60
1652/1652 [==============================] - 4s 2ms/step - loss: 0.6413 - acc: 0.6798 - auc_roc: 0.8627 - val_loss: 1.8828 - val_acc: 0.7147 - val_auc_roc: 0.8652
Epoch 18/60
1652/1652 [==============================] - 4s 2ms/step - loss: 0.8298 - acc: 0.6162 - auc_roc: 0.8665 - val_loss: 1.4502 - val_acc: 0.6469 - val_auc_roc: 0.8678
Epoch 19/60
1652/1652 [==============================] - 3s 2ms/step - loss: 0.8150 - acc: 0.5708 - auc_roc: 0.8687 - val_loss: 1.8897 - val_acc: 0.4647 - val_auc_roc: 0.8681
Epoch 20/60
1652/1652 [==============================] - 3s 2ms/step - loss: 0.7391 - acc: 0.6320 - auc_roc: 0.8685 - val_loss: 1.7761 - val_acc: 0.5989 - val_auc_roc: 0.8691
Epoch 21/60
1652/1652 [==============================] - 3s 2ms/step - loss: 0.6494 - acc: 0.6792 - auc_roc: 0.8703 - val_loss: 1.9214 - val_acc: 0.7119 - val_auc_roc: 0.8721
Epoch 22/60
1652/1652 [==============================] - 3s 2ms/step - loss: 0.5865 - acc: 0.6895 - auc_roc: 0.8736 - val_loss: 1.9758 - val_acc: 0.6935 - val_auc_roc: 0.8753
Epoch 23/60
1652/1652 [==============================] - 3s 2ms/step - loss: 0.5408 - acc: 0.7240 - auc_roc: 0.8768 - val_loss: 2.0114 - val_acc: 0.7232 - val_auc_roc: 0.8787
Epoch 24/60
1652/1652 [==============================] - 3s 2ms/step - loss: 0.5462 - acc: 0.7264 - auc_roc: 0.8802 - val_loss: 1.9363 - val_acc: 0.7133 - val_auc_roc: 0.8818
Epoch 25/60
1652/1652 [==============================] - 4s 2ms/step - loss: 0.5110 - acc: 0.7355 - auc_roc: 0.8832 - val_loss: 2.1053 - val_acc: 0.6949 - val_auc_roc: 0.8847
Epoch 00025: early stopping
... history of metrics comprising: ['acc', 'loss', 'val_auc_roc', 'auc_roc', 'val_acc', 'val_loss']
... ... metric (acc): [0.65859564135784676, 0.67978208218013403, 0.61622276043487811, 0.57082324484070046, 0.6319612592242243, 0.67917675530362076, 0.68946731234866832, 0.72397094430992737, 0.72639225196030177, 0.73547215496368035] (n=25)
output> saving performance to:
/Users/pleiades/Documents/work/tpheno/seqmaker/data/CKD/plot/model_evalation-ep200b16.tif

... ... metric (loss): [0.69610204412342558, 0.64125170517198682, 0.8298377150773425, 0.81497162912428811, 0.73906014661234742, 0.64938731386932858, 0.58647994989344343, 0.54080013588034792, 0.54619896339735163, 0.51097154299802983] (n=25)
output> saving performance to:
/Users/pleiades/Documents/work/tpheno/seqmaker/data/CKD/plot/model_evalation-ep200b16.tif


model_selection> trying {'n_units': 200, 'dropout_rate': 0.5} ...

make_lstm> n_units=200, r_dropout=0.500000, n_layers=1, n_classes=6
  + lookup:
{'Others': 5, 'CKD Stage 5': 4, 'CKD Stage 4': 3, 'CKD Stage 3': 2, 'CKD Stage 2': 1, 'CKD Stage 1': 0}

... class weights:
{0: 6.344086021505376, 1: 0.74494949494949492, 2: 1.1238095238095238, 3: 7.0238095238095237, 4: 0.51890941072999119, 5: 0.64906490649064907}

====================================================================================================
... early stopping>
       + patience: 20, model='max'
... model training>
       + batch_size: 32, epochs: 60, shuffle? True, metric: auc_roc
====================================================================================================
Train on 1652 samples, validate on 708 samples
Epoch 1/60
1652/1652 [==============================] - 6s 4ms/step - loss: 1.6574 - acc: 0.3335 - auc_roc: 0.6774 - val_loss: 1.8029 - val_acc: 0.4251 - val_auc_roc: 0.7077
Epoch 2/60
1652/1652 [==============================] - 4s 3ms/step - loss: 1.4125 - acc: 0.4679 - auc_roc: 0.7230 - val_loss: 1.5984 - val_acc: 0.5169 - val_auc_roc: 0.7436
Epoch 3/60
1652/1652 [==============================] - 4s 3ms/step - loss: 1.2934 - acc: 0.4861 - auc_roc: 0.7590 - val_loss: 1.4121 - val_acc: 0.6342 - val_auc_roc: 0.7745
Epoch 4/60
1652/1652 [==============================] - 4s 3ms/step - loss: 1.2157 - acc: 0.4843 - auc_roc: 0.7858 - val_loss: 1.7188 - val_acc: 0.5862 - val_auc_roc: 0.7909
Epoch 5/60
1652/1652 [==============================] - 4s 3ms/step - loss: 1.0996 - acc: 0.5430 - auc_roc: 0.7982 - val_loss: 1.6161 - val_acc: 0.6342 - val_auc_roc: 0.8065
Epoch 6/60
1652/1652 [==============================] - 4s 3ms/step - loss: 1.0612 - acc: 0.5321 - auc_roc: 0.8119 - val_loss: 1.5792 - val_acc: 0.5198 - val_auc_roc: 0.8150
Epoch 7/60
1652/1652 [==============================] - 4s 3ms/step - loss: 1.0243 - acc: 0.5400 - auc_roc: 0.8182 - val_loss: 1.5498 - val_acc: 0.6511 - val_auc_roc: 0.8228
Epoch 8/60
1652/1652 [==============================] - 4s 3ms/step - loss: 0.9223 - acc: 0.5745 - auc_roc: 0.8273 - val_loss: 1.6194 - val_acc: 0.6780 - val_auc_roc: 0.8318
Epoch 9/60
1652/1652 [==============================] - 5s 3ms/step - loss: 0.8894 - acc: 0.5902 - auc_roc: 0.8359 - val_loss: 1.8168 - val_acc: 0.6681 - val_auc_roc: 0.8394
Epoch 10/60
1652/1652 [==============================] - 5s 3ms/step - loss: 0.8138 - acc: 0.6144 - auc_roc: 0.8431 - val_loss: 1.9441 - val_acc: 0.7105 - val_auc_roc: 0.8470
Epoch 11/60
1652/1652 [==============================] - 4s 3ms/step - loss: 0.8879 - acc: 0.5896 - auc_roc: 0.8495 - val_loss: 1.5115 - val_acc: 0.6427 - val_auc_roc: 0.8522
Epoch 12/60
1652/1652 [==============================] - 4s 3ms/step - loss: 0.7538 - acc: 0.6368 - auc_roc: 0.8546 - val_loss: 1.8616 - val_acc: 0.7119 - val_auc_roc: 0.8578
Epoch 13/60
1652/1652 [==============================] - 4s 2ms/step - loss: 0.7442 - acc: 0.6604 - auc_roc: 0.8607 - val_loss: 1.7564 - val_acc: 0.7161 - val_auc_roc: 0.8635
Epoch 14/60
1652/1652 [==============================] - 4s 3ms/step - loss: 0.6587 - acc: 0.6610 - auc_roc: 0.8661 - val_loss: 1.9962 - val_acc: 0.7133 - val_auc_roc: 0.8687
Epoch 15/60
1652/1652 [==============================] - 4s 2ms/step - loss: 0.6072 - acc: 0.6949 - auc_roc: 0.8714 - val_loss: 1.7518 - val_acc: 0.7105 - val_auc_roc: 0.8741
Epoch 16/60
1652/1652 [==============================] - 4s 3ms/step - loss: 0.5679 - acc: 0.7167 - auc_roc: 0.8764 - val_loss: 1.9443 - val_acc: 0.7020 - val_auc_roc: 0.8789
Epoch 17/60
1652/1652 [==============================] - 4s 2ms/step - loss: 0.5106 - acc: 0.7439 - auc_roc: 0.8812 - val_loss: 1.9776 - val_acc: 0.7147 - val_auc_roc: 0.8836
Epoch 18/60
1652/1652 [==============================] - 4s 3ms/step - loss: 0.5302 - acc: 0.7476 - auc_roc: 0.8855 - val_loss: 2.0648 - val_acc: 0.7048 - val_auc_roc: 0.8876
Epoch 19/60
1652/1652 [==============================] - 4s 2ms/step - loss: 0.4651 - acc: 0.7748 - auc_roc: 0.8895 - val_loss: 2.1713 - val_acc: 0.6963 - val_auc_roc: 0.8915
Epoch 20/60
1652/1652 [==============================] - 4s 3ms/step - loss: 0.4473 - acc: 0.7845 - auc_roc: 0.8931 - val_loss: 2.3149 - val_acc: 0.7359 - val_auc_roc: 0.8951
Epoch 21/60
1652/1652 [==============================] - 4s 3ms/step - loss: 0.4030 - acc: 0.8039 - auc_roc: 0.8969 - val_loss: 2.3405 - val_acc: 0.7175 - val_auc_roc: 0.8988
Epoch 22/60
1652/1652 [==============================] - 4s 3ms/step - loss: 0.4181 - acc: 0.8057 - auc_roc: 0.9004 - val_loss: 2.1423 - val_acc: 0.6935 - val_auc_roc: 0.9019
Epoch 23/60
1652/1652 [==============================] - 4s 3ms/step - loss: 0.4350 - acc: 0.8075 - auc_roc: 0.9032 - val_loss: 2.4919 - val_acc: 0.7246 - val_auc_roc: 0.9046
Epoch 00023: early stopping
... history of metrics comprising: ['acc', 'loss', 'val_auc_roc', 'auc_roc', 'val_acc', 'val_loss']
... ... metric (acc): [0.66101694900822117, 0.69491525394864584, 0.71670702193608871, 0.74394673137918799, 0.74757869263826793, 0.77481840164840365, 0.78450363210558027, 0.80387409200968518, 0.80569007292786754, 0.80750605341308634] (n=23)
output> saving performance to:
/Users/pleiades/Documents/work/tpheno/seqmaker/data/CKD/plot/model_evalation-ep200b16.tif

... ... metric (loss): [0.65865668921436005, 0.60717969858617526, 0.56794449030342753, 0.51064654268306331, 0.53015795155241185, 0.46512470147222928, 0.44727631097267095, 0.40296331011931485, 0.4181145711037495, 0.43500577400440743] (n=23)
output> saving performance to:
/Users/pleiades/Documents/work/tpheno/seqmaker/data/CKD/plot/model_evalation-ep200b16.tif


model_selection> trying {'n_units': 300, 'dropout_rate': 0.5} ...

make_lstm> n_units=300, r_dropout=0.500000, n_layers=1, n_classes=6
  + lookup:
{'Others': 5, 'CKD Stage 5': 4, 'CKD Stage 4': 3, 'CKD Stage 3': 2, 'CKD Stage 2': 1, 'CKD Stage 1': 0}

... class weights:
{0: 6.344086021505376, 1: 0.74494949494949492, 2: 1.1238095238095238, 3: 7.0238095238095237, 4: 0.51890941072999119, 5: 0.64906490649064907}

====================================================================================================
... early stopping>
       + patience: 20, model='max'
... model training>
       + batch_size: 32, epochs: 60, shuffle? True, metric: auc_roc
====================================================================================================
Train on 1652 samples, validate on 708 samples
Epoch 1/60
1652/1652 [==============================] - 9s 5ms/step - loss: 1.6592 - acc: 0.2984 - auc_roc: 0.5658 - val_loss: 1.7036 - val_acc: 0.2542 - val_auc_roc: 0.6546
Epoch 2/60
1652/1652 [==============================] - 6s 4ms/step - loss: 1.4556 - acc: 0.4237 - auc_roc: 0.6771 - val_loss: 1.7253 - val_acc: 0.1949 - val_auc_roc: 0.6837
Epoch 3/60
1652/1652 [==============================] - 6s 4ms/step - loss: 1.3261 - acc: 0.4407 - auc_roc: 0.6892 - val_loss: 1.6381 - val_acc: 0.4816 - val_auc_roc: 0.7115
Epoch 4/60
1652/1652 [==============================] - 7s 4ms/step - loss: 1.1897 - acc: 0.5012 - auc_roc: 0.7291 - val_loss: 1.6114 - val_acc: 0.5551 - val_auc_roc: 0.7451
Epoch 5/60
1652/1652 [==============================] - 6s 4ms/step - loss: 1.1097 - acc: 0.4933 - auc_roc: 0.7553 - val_loss: 2.1624 - val_acc: 0.3234 - val_auc_roc: 0.7590
Epoch 6/60
1652/1652 [==============================] - 7s 4ms/step - loss: 1.0775 - acc: 0.5400 - auc_roc: 0.7634 - val_loss: 1.6894 - val_acc: 0.5749 - val_auc_roc: 0.7737
Epoch 7/60
1652/1652 [==============================] - 6s 4ms/step - loss: 0.9864 - acc: 0.5781 - auc_roc: 0.7823 - val_loss: 1.8433 - val_acc: 0.5339 - val_auc_roc: 0.7879
Epoch 8/60
1652/1652 [==============================] - 7s 4ms/step - loss: 0.8783 - acc: 0.5902 - auc_roc: 0.7937 - val_loss: 1.7950 - val_acc: 0.6497 - val_auc_roc: 0.8019
Epoch 9/60
1652/1652 [==============================] - 7s 4ms/step - loss: 0.7877 - acc: 0.6320 - auc_roc: 0.8088 - val_loss: 1.8124 - val_acc: 0.6808 - val_auc_roc: 0.8165
Epoch 10/60
1652/1652 [==============================] - 7s 4ms/step - loss: 0.7858 - acc: 0.6398 - auc_roc: 0.8226 - val_loss: 1.6855 - val_acc: 0.6751 - val_auc_roc: 0.8281
Epoch 11/60
1652/1652 [==============================] - 7s 4ms/step - loss: 0.7277 - acc: 0.6513 - auc_roc: 0.8334 - val_loss: 1.8168 - val_acc: 0.5960 - val_auc_roc: 0.8376
Epoch 12/60
1652/1652 [==============================] - 8s 5ms/step - loss: 0.7688 - acc: 0.6217 - auc_roc: 0.8407 - val_loss: 1.7431 - val_acc: 0.6102 - val_auc_roc: 0.8436
Epoch 13/60
1652/1652 [==============================] - 8s 5ms/step - loss: 0.7347 - acc: 0.6616 - auc_roc: 0.8459 - val_loss: 1.8331 - val_acc: 0.6356 - val_auc_roc: 0.8495
Epoch 14/60
1652/1652 [==============================] - 8s 5ms/step - loss: 0.6337 - acc: 0.6973 - auc_roc: 0.8524 - val_loss: 2.0998 - val_acc: 0.7076 - val_auc_roc: 0.8562
Epoch 15/60
1652/1652 [==============================] - 9s 5ms/step - loss: 0.5602 - acc: 0.7191 - auc_roc: 0.8596 - val_loss: 2.1538 - val_acc: 0.6822 - val_auc_roc: 0.8630
Epoch 16/60
1652/1652 [==============================] - 14s 8ms/step - loss: 0.5360 - acc: 0.7331 - auc_roc: 0.8658 - val_loss: 1.9788 - val_acc: 0.6836 - val_auc_roc: 0.8691
Epoch 17/60
1652/1652 [==============================] - 8s 5ms/step - loss: 0.5244 - acc: 0.7355 - auc_roc: 0.8716 - val_loss: 2.1019 - val_acc: 0.6921 - val_auc_roc: 0.8743
Epoch 18/60
1652/1652 [==============================] - 8s 5ms/step - loss: 0.4424 - acc: 0.7778 - auc_roc: 0.8769 - val_loss: 1.9737 - val_acc: 0.7090 - val_auc_roc: 0.8798
Epoch 19/60
1652/1652 [==============================] - 8s 5ms/step - loss: 0.3659 - acc: 0.8172 - auc_roc: 0.8825 - val_loss: 2.1536 - val_acc: 0.6907 - val_auc_roc: 0.8852
Epoch 20/60
1652/1652 [==============================] - 7s 4ms/step - loss: 0.3498 - acc: 0.8311 - auc_roc: 0.8875 - val_loss: 2.3026 - val_acc: 0.6610 - val_auc_roc: 0.8900
Epoch 21/60
1652/1652 [==============================] - 7s 4ms/step - loss: 0.3398 - acc: 0.8366 - auc_roc: 0.8920 - val_loss: 2.4344 - val_acc: 0.6836 - val_auc_roc: 0.8943
Epoch 22/60
1652/1652 [==============================] - 7s 4ms/step - loss: 0.2897 - acc: 0.8602 - auc_roc: 0.8962 - val_loss: 2.9545 - val_acc: 0.6893 - val_auc_roc: 0.8985
Epoch 23/60
1652/1652 [==============================] - 7s 4ms/step - loss: 0.2371 - acc: 0.8898 - auc_roc: 0.9004 - val_loss: 2.3322 - val_acc: 0.6709 - val_auc_roc: 0.9025
Epoch 24/60
1652/1652 [==============================] - 7s 4ms/step - loss: 0.2362 - acc: 0.8850 - auc_roc: 0.9042 - val_loss: 2.6662 - val_acc: 0.6836 - val_auc_roc: 0.9061
Epoch 00024: early stopping
... history of metrics comprising: ['acc', 'loss', 'val_auc_roc', 'auc_roc', 'val_acc', 'val_loss']
... ... metric (acc): [0.71912832900917845, 0.73305084745762716, 0.73547215510800157, 0.77784503660825499, 0.81719128358162052, 0.83111380130846335, 0.83656174363004676, 0.86016949152542377, 0.88983050833025512, 0.88498789331814853] (n=24)
output> saving performance to:
/Users/pleiades/Documents/work/tpheno/seqmaker/data/CKD/plot/model_evalation-ep200b16.tif

... ... metric (loss): [0.56022225150761829, 0.53602751923531078, 0.52439237030597341, 0.44240318992813332, 0.36586865999219492, 0.34983896058206121, 0.33980494874730238, 0.28968457282311116, 0.23712113615098357, 0.23622498370833317] (n=24)
output> saving performance to:
/Users/pleiades/Documents/work/tpheno/seqmaker/data/CKD/plot/model_evalation-ep200b16.tif


model_selection> trying {'n_units': 400, 'dropout_rate': 0.5} ...

make_lstm> n_units=400, r_dropout=0.500000, n_layers=1, n_classes=6
  + lookup:
{'Others': 5, 'CKD Stage 5': 4, 'CKD Stage 4': 3, 'CKD Stage 3': 2, 'CKD Stage 2': 1, 'CKD Stage 1': 0}

... class weights:
{0: 6.344086021505376, 1: 0.74494949494949492, 2: 1.1238095238095238, 3: 7.0238095238095237, 4: 0.51890941072999119, 5: 0.64906490649064907}

====================================================================================================
... early stopping>
       + patience: 20, model='max'
... model training>
       + batch_size: 32, epochs: 60, shuffle? True, metric: auc_roc
====================================================================================================
Train on 1652 samples, validate on 708 samples
Epoch 1/60
1652/1652 [==============================] - 11s 7ms/step - loss: 1.6580 - acc: 0.3166 - auc_roc: 0.6115 - val_loss: 1.6529 - val_acc: 0.5537 - val_auc_roc: 0.7464
Epoch 2/60
1652/1652 [==============================] - 10s 6ms/step - loss: 1.4234 - acc: 0.4528 - auc_roc: 0.7680 - val_loss: 1.4432 - val_acc: 0.5932 - val_auc_roc: 0.7835
Epoch 3/60
1652/1652 [==============================] - 10s 6ms/step - loss: 1.2905 - acc: 0.4933 - auc_roc: 0.7924 - val_loss: 1.4098 - val_acc: 0.5763 - val_auc_roc: 0.8032
Epoch 4/60
1652/1652 [==============================] - 10s 6ms/step - loss: 1.1901 - acc: 0.5018 - auc_roc: 0.8091 - val_loss: 1.4827 - val_acc: 0.5311 - val_auc_roc: 0.8140
Epoch 5/60
1652/1652 [==============================] - 10s 6ms/step - loss: 1.2155 - acc: 0.4588 - auc_roc: 0.8129 - val_loss: 1.6658 - val_acc: 0.4534 - val_auc_roc: 0.8104
Epoch 6/60
1652/1652 [==============================] - 10s 6ms/step - loss: 1.0563 - acc: 0.5472 - auc_roc: 0.8128 - val_loss: 1.4716 - val_acc: 0.6257 - val_auc_roc: 0.8188
Epoch 7/60
1652/1652 [==============================] - 10s 6ms/step - loss: 1.0279 - acc: 0.5575 - auc_roc: 0.8236 - val_loss: 1.5937 - val_acc: 0.6893 - val_auc_roc: 0.8286
Epoch 8/60
1652/1652 [==============================] - 10s 6ms/step - loss: 0.9319 - acc: 0.5932 - auc_roc: 0.8336 - val_loss: 1.8060 - val_acc: 0.4986 - val_auc_roc: 0.8357
Epoch 9/60
1652/1652 [==============================] - 10s 6ms/step - loss: 0.8368 - acc: 0.6205 - auc_roc: 0.8382 - val_loss: 1.5588 - val_acc: 0.7105 - val_auc_roc: 0.8433
Epoch 10/60
1652/1652 [==============================] - 10s 6ms/step - loss: 0.8028 - acc: 0.6416 - auc_roc: 0.8478 - val_loss: 1.5730 - val_acc: 0.6638 - val_auc_roc: 0.8515
Epoch 11/60
1652/1652 [==============================] - 10s 6ms/step - loss: 0.7338 - acc: 0.6495 - auc_roc: 0.8548 - val_loss: 1.7682 - val_acc: 0.6511 - val_auc_roc: 0.8583
Epoch 12/60
1652/1652 [==============================] - 10s 6ms/step - loss: 0.6647 - acc: 0.6707 - auc_roc: 0.8613 - val_loss: 1.8347 - val_acc: 0.6864 - val_auc_roc: 0.8647
Epoch 13/60
1652/1652 [==============================] - 11s 7ms/step - loss: 0.6657 - acc: 0.6774 - auc_roc: 0.8675 - val_loss: 1.9988 - val_acc: 0.7133 - val_auc_roc: 0.8706
Epoch 14/60
1652/1652 [==============================] - 11s 7ms/step - loss: 0.6081 - acc: 0.7125 - auc_roc: 0.8732 - val_loss: 2.1435 - val_acc: 0.6554 - val_auc_roc: 0.8757
Epoch 15/60
1652/1652 [==============================] - 11s 7ms/step - loss: 0.5508 - acc: 0.7337 - auc_roc: 0.8780 - val_loss: 2.0302 - val_acc: 0.6864 - val_auc_roc: 0.8804
Epoch 16/60
1652/1652 [==============================] - 11s 6ms/step - loss: 0.5806 - acc: 0.7228 - auc_roc: 0.8823 - val_loss: 1.7195 - val_acc: 0.6554 - val_auc_roc: 0.8845
Epoch 17/60
1652/1652 [==============================] - 11s 6ms/step - loss: 0.5975 - acc: 0.7197 - auc_roc: 0.8861 - val_loss: 2.1456 - val_acc: 0.5805 - val_auc_roc: 0.8873
Epoch 18/60
1652/1652 [==============================] - 11s 7ms/step - loss: 0.5133 - acc: 0.7524 - auc_roc: 0.8885 - val_loss: 2.0747 - val_acc: 0.7316 - val_auc_roc: 0.8908
Epoch 19/60
1652/1652 [==============================] - 11s 7ms/step - loss: 0.4534 - acc: 0.7948 - auc_roc: 0.8929 - val_loss: 2.0148 - val_acc: 0.6497 - val_auc_roc: 0.8950
Epoch 20/60
1652/1652 [==============================] - 10s 6ms/step - loss: 0.4572 - acc: 0.7887 - auc_roc: 0.8965 - val_loss: 2.0559 - val_acc: 0.6977 - val_auc_roc: 0.8985
Epoch 21/60
1652/1652 [==============================] - 10s 6ms/step - loss: 0.3561 - acc: 0.8341 - auc_roc: 0.9003 - val_loss: 2.2067 - val_acc: 0.7203 - val_auc_roc: 0.9025
Epoch 22/60
1652/1652 [==============================] - 11s 6ms/step - loss: 0.3144 - acc: 0.8499 - auc_roc: 0.9041 - val_loss: 2.3083 - val_acc: 0.6808 - val_auc_roc: 0.9061
Epoch 23/60
1652/1652 [==============================] - 10s 6ms/step - loss: 0.3027 - acc: 0.8499 - auc_roc: 0.9076 - val_loss: 2.2942 - val_acc: 0.5763 - val_auc_roc: 0.9091
Epoch 00023: early stopping
... history of metrics comprising: ['acc', 'loss', 'val_auc_roc', 'auc_roc', 'val_acc', 'val_loss']
... ... metric (acc): [0.71246973351185316, 0.73365617447846165, 0.72276029026825839, 0.71973365588569183, 0.75242130750605329, 0.7947941888619855, 0.78874092038549459, 0.83414043597967225, 0.84987893448037621, 0.84987893491333966] (n=23)
output> saving performance to:
/Users/pleiades/Documents/work/tpheno/seqmaker/data/CKD/plot/model_evalation-ep200b16.tif

... ... metric (loss): [0.60808473089416726, 0.55082075907589445, 0.58061093294014365, 0.5974562673245446, 0.5133186900586828, 0.45339909073226964, 0.45722636125855526, 0.35611081051191462, 0.31442855684578275, 0.30274277377070874] (n=23)
output> saving performance to:
/Users/pleiades/Documents/work/tpheno/seqmaker/data/CKD/plot/model_evalation-ep200b16.tif


model_selection> trying {'n_units': 500, 'dropout_rate': 0.5} ...

make_lstm> n_units=500, r_dropout=0.500000, n_layers=1, n_classes=6
  + lookup:
{'Others': 5, 'CKD Stage 5': 4, 'CKD Stage 4': 3, 'CKD Stage 3': 2, 'CKD Stage 2': 1, 'CKD Stage 1': 0}

... class weights:
{0: 6.344086021505376, 1: 0.74494949494949492, 2: 1.1238095238095238, 3: 7.0238095238095237, 4: 0.51890941072999119, 5: 0.64906490649064907}

====================================================================================================
... early stopping>
       + patience: 20, model='max'
... model training>
       + batch_size: 32, epochs: 60, shuffle? True, metric: auc_roc
====================================================================================================
Train on 1652 samples, validate on 708 samples
Epoch 1/60
1652/1652 [==============================] - 17s 10ms/step - loss: 1.6551 - acc: 0.3269 - auc_roc: 0.6377 - val_loss: 1.7706 - val_acc: 0.3912 - val_auc_roc: 0.6967
Epoch 2/60
1652/1652 [==============================] - 15s 9ms/step - loss: 1.4152 - acc: 0.4522 - auc_roc: 0.7229 - val_loss: 1.4432 - val_acc: 0.6398 - val_auc_roc: 0.7566
Epoch 3/60
1652/1652 [==============================] - 15s 9ms/step - loss: 1.2683 - acc: 0.4764 - auc_roc: 0.7758 - val_loss: 1.4811 - val_acc: 0.6045 - val_auc_roc: 0.7843
Epoch 4/60
1652/1652 [==============================] - 16s 9ms/step - loss: 1.2446 - acc: 0.5387 - auc_roc: 0.7948 - val_loss: 1.8749 - val_acc: 0.4449 - val_auc_roc: 0.7972
Epoch 5/60
1652/1652 [==============================] - 16s 10ms/step - loss: 1.1579 - acc: 0.5188 - auc_roc: 0.7975 - val_loss: 1.6282 - val_acc: 0.5904 - val_auc_roc: 0.8058
Epoch 6/60
1652/1652 [==============================] - 16s 10ms/step - loss: 1.0465 - acc: 0.5460 - auc_roc: 0.8130 - val_loss: 1.6681 - val_acc: 0.5946 - val_auc_roc: 0.8184
Epoch 7/60
1652/1652 [==============================] - 15s 9ms/step - loss: 1.0501 - acc: 0.5169 - auc_roc: 0.8220 - val_loss: 1.8966 - val_acc: 0.4195 - val_auc_roc: 0.8212
Epoch 8/60
1652/1652 [==============================] - 16s 9ms/step - loss: 0.9054 - acc: 0.5932 - auc_roc: 0.8228 - val_loss: 1.6713 - val_acc: 0.6455 - val_auc_roc: 0.8278
Epoch 9/60
1652/1652 [==============================] - 16s 10ms/step - loss: 0.8528 - acc: 0.6156 - auc_roc: 0.8323 - val_loss: 1.5886 - val_acc: 0.6638 - val_auc_roc: 0.8367
Epoch 10/60
1652/1652 [==============================] - 16s 10ms/step - loss: 0.8076 - acc: 0.6338 - auc_roc: 0.8408 - val_loss: 1.7698 - val_acc: 0.6469 - val_auc_roc: 0.8449
Epoch 11/60
1652/1652 [==============================] - 16s 10ms/step - loss: 0.7337 - acc: 0.6610 - auc_roc: 0.8487 - val_loss: 1.7072 - val_acc: 0.6907 - val_auc_roc: 0.8528
Epoch 12/60
1652/1652 [==============================] - 16s 9ms/step - loss: 0.6915 - acc: 0.6749 - auc_roc: 0.8561 - val_loss: 1.9094 - val_acc: 0.6455 - val_auc_roc: 0.8595
Epoch 13/60
1652/1652 [==============================] - 16s 9ms/step - loss: 0.5982 - acc: 0.7004 - auc_roc: 0.8624 - val_loss: 2.0653 - val_acc: 0.6822 - val_auc_roc: 0.8660
Epoch 14/60
1652/1652 [==============================] - 15s 9ms/step - loss: 0.6926 - acc: 0.6846 - auc_roc: 0.8683 - val_loss: 1.9929 - val_acc: 0.6766 - val_auc_roc: 0.8709
Epoch 15/60
1652/1652 [==============================] - 15s 9ms/step - loss: 0.5891 - acc: 0.7070 - auc_roc: 0.8731 - val_loss: 2.1284 - val_acc: 0.6299 - val_auc_roc: 0.8754
Epoch 16/60
1652/1652 [==============================] - 14s 9ms/step - loss: 0.5155 - acc: 0.7458 - auc_roc: 0.8776 - val_loss: 1.9055 - val_acc: 0.7274 - val_auc_roc: 0.8807
Epoch 17/60
1652/1652 [==============================] - 16s 9ms/step - loss: 0.5160 - acc: 0.7682 - auc_roc: 0.8831 - val_loss: 2.1341 - val_acc: 0.6977 - val_auc_roc: 0.8856
Epoch 18/60
1652/1652 [==============================] - 15s 9ms/step - loss: 0.4212 - acc: 0.7972 - auc_roc: 0.8880 - val_loss: 1.9385 - val_acc: 0.6921 - val_auc_roc: 0.8905
Epoch 19/60
1652/1652 [==============================] - 15s 9ms/step - loss: 0.3411 - acc: 0.8414 - auc_roc: 0.8927 - val_loss: 2.0863 - val_acc: 0.6949 - val_auc_roc: 0.8953
Epoch 20/60
1652/1652 [==============================] - 20s 12ms/step - loss: 0.2935 - acc: 0.8644 - auc_roc: 0.8975 - val_loss: 2.3461 - val_acc: 0.7119 - val_auc_roc: 0.9001
Epoch 21/60
1652/1652 [==============================] - 18s 11ms/step - loss: 0.5777 - acc: 0.7312 - auc_roc: 0.9009 - val_loss: 1.9201 - val_acc: 0.6893 - val_auc_roc: 0.9021
Epoch 22/60
1652/1652 [==============================] - 18s 11ms/step - loss: 0.3241 - acc: 0.8462 - auc_roc: 0.9037 - val_loss: 2.4730 - val_acc: 0.6921 - val_auc_roc: 0.9056
Epoch 00022: early stopping
... history of metrics comprising: ['acc', 'loss', 'val_auc_roc', 'auc_roc', 'val_acc', 'val_loss']
... ... metric (acc): [0.70036319612590803, 0.68462469704791939, 0.70702179205619686, 0.74576271172008557, 0.76815980615107837, 0.7972154965123599, 0.84140435849783202, 0.86440677980533809, 0.73123486711672947, 0.84624697307697505] (n=22)
output> saving performance to:
/Users/pleiades/Documents/work/tpheno/seqmaker/data/CKD/plot/model_evalation-ep200b16.tif

... ... metric (loss): [0.59817922721474859, 0.69257252989900597, 0.58908287664879899, 0.51552065838913075, 0.51602632326883491, 0.42121936579304803, 0.3410707255396947, 0.29354967447516417, 0.57770168665823574, 0.32409710020332011] (n=22)
output> saving performance to:
/Users/pleiades/Documents/work/tpheno/seqmaker/data/CKD/plot/model_evalation-ep200b16.tif


model_selection> trying {'n_units': 50, 'dropout_rate': 0.6} ...

make_lstm> n_units=50, r_dropout=0.600000, n_layers=1, n_classes=6
  + lookup:
{'Others': 5, 'CKD Stage 5': 4, 'CKD Stage 4': 3, 'CKD Stage 3': 2, 'CKD Stage 2': 1, 'CKD Stage 1': 0}

... class weights:
{0: 6.344086021505376, 1: 0.74494949494949492, 2: 1.1238095238095238, 3: 7.0238095238095237, 4: 0.51890941072999119, 5: 0.64906490649064907}

====================================================================================================
... early stopping>
       + patience: 20, model='max'
... model training>
       + batch_size: 32, epochs: 60, shuffle? True, metric: auc_roc
====================================================================================================
Train on 1652 samples, validate on 708 samples
Epoch 1/60
1652/1652 [==============================] - 6s 4ms/step - loss: 1.7351 - acc: 0.2070 - auc_roc: 0.5127 - val_loss: 1.9144 - val_acc: 0.1102 - val_auc_roc: 0.5624
Epoch 2/60
1652/1652 [==============================] - 4s 2ms/step - loss: 1.6466 - acc: 0.3081 - auc_roc: 0.5957 - val_loss: 1.6973 - val_acc: 0.4718 - val_auc_roc: 0.6350
Epoch 3/60
1652/1652 [==============================] - 4s 2ms/step - loss: 1.5061 - acc: 0.3904 - auc_roc: 0.6631 - val_loss: 1.5498 - val_acc: 0.5212 - val_auc_roc: 0.6867
Epoch 4/60
1652/1652 [==============================] - 3s 2ms/step - loss: 1.4088 - acc: 0.4274 - auc_roc: 0.7044 - val_loss: 1.5237 - val_acc: 0.4379 - val_auc_roc: 0.7160
Epoch 5/60
1652/1652 [==============================] - 3s 2ms/step - loss: 1.3289 - acc: 0.4528 - auc_roc: 0.7241 - val_loss: 1.4182 - val_acc: 0.5791 - val_auc_roc: 0.7369
Epoch 6/60
1652/1652 [==============================] - 3s 2ms/step - loss: 1.2725 - acc: 0.5012 - auc_roc: 0.7465 - val_loss: 1.3889 - val_acc: 0.5833 - val_auc_roc: 0.7561
Epoch 7/60
1652/1652 [==============================] - 3s 2ms/step - loss: 1.1834 - acc: 0.5206 - auc_roc: 0.7638 - val_loss: 1.5510 - val_acc: 0.5254 - val_auc_roc: 0.7698
Epoch 8/60
1652/1652 [==============================] - 3s 2ms/step - loss: 1.1056 - acc: 0.5097 - auc_roc: 0.7742 - val_loss: 1.4786 - val_acc: 0.5989 - val_auc_roc: 0.7797
Epoch 9/60
1652/1652 [==============================] - 3s 2ms/step - loss: 1.0593 - acc: 0.5315 - auc_roc: 0.7852 - val_loss: 1.4930 - val_acc: 0.6780 - val_auc_roc: 0.7908
Epoch 10/60
1652/1652 [==============================] - 3s 2ms/step - loss: 1.0246 - acc: 0.5666 - auc_roc: 0.7963 - val_loss: 1.6051 - val_acc: 0.5734 - val_auc_roc: 0.7999
Epoch 11/60
1652/1652 [==============================] - 3s 2ms/step - loss: 1.0201 - acc: 0.5375 - auc_roc: 0.8031 - val_loss: 1.7086 - val_acc: 0.3701 - val_auc_roc: 0.8018
Epoch 12/60
1652/1652 [==============================] - 3s 2ms/step - loss: 0.9637 - acc: 0.5448 - auc_roc: 0.8016 - val_loss: 1.4100 - val_acc: 0.7147 - val_auc_roc: 0.8065
Epoch 13/60
1652/1652 [==============================] - 3s 2ms/step - loss: 0.9002 - acc: 0.6084 - auc_roc: 0.8109 - val_loss: 1.4118 - val_acc: 0.6653 - val_auc_roc: 0.8149
Epoch 14/60
1652/1652 [==============================] - 3s 2ms/step - loss: 0.8468 - acc: 0.6253 - auc_roc: 0.8187 - val_loss: 1.5700 - val_acc: 0.7218 - val_auc_roc: 0.8229
Epoch 15/60
1652/1652 [==============================] - 3s 2ms/step - loss: 0.8602 - acc: 0.6029 - auc_roc: 0.8263 - val_loss: 1.6390 - val_acc: 0.6314 - val_auc_roc: 0.8293
Epoch 16/60
1652/1652 [==============================] - 3s 2ms/step - loss: 0.8650 - acc: 0.6053 - auc_roc: 0.8314 - val_loss: 1.4125 - val_acc: 0.6794 - val_auc_roc: 0.8341
Epoch 17/60
1652/1652 [==============================] - 3s 2ms/step - loss: 0.7837 - acc: 0.6435 - auc_roc: 0.8367 - val_loss: 1.5116 - val_acc: 0.7062 - val_auc_roc: 0.8396
Epoch 18/60
1652/1652 [==============================] - 3s 2ms/step - loss: 0.7309 - acc: 0.6610 - auc_roc: 0.8423 - val_loss: 1.6543 - val_acc: 0.6992 - val_auc_roc: 0.8451
Epoch 19/60
1652/1652 [==============================] - 3s 2ms/step - loss: 0.7252 - acc: 0.6501 - auc_roc: 0.8473 - val_loss: 1.5755 - val_acc: 0.7020 - val_auc_roc: 0.8496
Epoch 20/60
1652/1652 [==============================] - 3s 2ms/step - loss: 0.7671 - acc: 0.6156 - auc_roc: 0.8515 - val_loss: 1.5241 - val_acc: 0.6723 - val_auc_roc: 0.8530
Epoch 21/60
1652/1652 [==============================] - 3s 2ms/step - loss: 0.7285 - acc: 0.6477 - auc_roc: 0.8546 - val_loss: 1.5328 - val_acc: 0.7203 - val_auc_roc: 0.8567
Epoch 22/60
1652/1652 [==============================] - 3s 2ms/step - loss: 0.7450 - acc: 0.6441 - auc_roc: 0.8582 - val_loss: 1.7751 - val_acc: 0.6836 - val_auc_roc: 0.8598
Epoch 23/60
1652/1652 [==============================] - 3s 2ms/step - loss: 0.6735 - acc: 0.6713 - auc_roc: 0.8612 - val_loss: 1.7307 - val_acc: 0.6935 - val_auc_roc: 0.8630
Epoch 24/60
1652/1652 [==============================] - 3s 2ms/step - loss: 0.6454 - acc: 0.6840 - auc_roc: 0.8646 - val_loss: 1.7379 - val_acc: 0.6935 - val_auc_roc: 0.8663
Epoch 25/60
1652/1652 [==============================] - 3s 2ms/step - loss: 0.6176 - acc: 0.7046 - auc_roc: 0.8677 - val_loss: 1.9422 - val_acc: 0.7147 - val_auc_roc: 0.8694
Epoch 26/60
1652/1652 [==============================] - 4s 2ms/step - loss: 0.6318 - acc: 0.6937 - auc_roc: 0.8706 - val_loss: 1.6337 - val_acc: 0.6737 - val_auc_roc: 0.8718
Epoch 00026: early stopping
... history of metrics comprising: ['acc', 'loss', 'val_auc_roc', 'auc_roc', 'val_acc', 'val_loss']
... ... metric (acc): [0.6434624700222985, 0.6610169492968635, 0.65012106523098145, 0.61561743312540118, 0.64769975758060705, 0.64406779661016944, 0.67130750605326872, 0.68401937060436957, 0.70460048440582235, 0.69370460019561919] (n=26)
output> saving performance to:
/Users/pleiades/Documents/work/tpheno/seqmaker/data/CKD/plot/model_evalation-ep200b16.tif

... ... metric (loss): [0.78373485053134018, 0.7309360618164118, 0.72517703563768698, 0.76713363815450786, 0.7285412394105667, 0.74499647265196423, 0.67354429908295232, 0.64537909966115514, 0.61759907844280215, 0.63182356571169795] (n=26)
output> saving performance to:
/Users/pleiades/Documents/work/tpheno/seqmaker/data/CKD/plot/model_evalation-ep200b16.tif


model_selection> trying {'n_units': 100, 'dropout_rate': 0.6} ...

make_lstm> n_units=100, r_dropout=0.600000, n_layers=1, n_classes=6
  + lookup:
{'Others': 5, 'CKD Stage 5': 4, 'CKD Stage 4': 3, 'CKD Stage 3': 2, 'CKD Stage 2': 1, 'CKD Stage 1': 0}

... class weights:
{0: 6.344086021505376, 1: 0.74494949494949492, 2: 1.1238095238095238, 3: 7.0238095238095237, 4: 0.51890941072999119, 5: 0.64906490649064907}

====================================================================================================
... early stopping>
       + patience: 20, model='max'
... model training>
       + batch_size: 32, epochs: 60, shuffle? True, metric: auc_roc
====================================================================================================
Train on 1652 samples, validate on 708 samples
Epoch 1/60
1652/1652 [==============================] - 7s 4ms/step - loss: 1.7300 - acc: 0.2506 - auc_roc: 0.5771 - val_loss: 1.9246 - val_acc: 0.1893 - val_auc_roc: 0.6044
Epoch 2/60
1652/1652 [==============================] - 4s 2ms/step - loss: 1.5376 - acc: 0.3789 - auc_roc: 0.6321 - val_loss: 1.8397 - val_acc: 0.3573 - val_auc_roc: 0.6580
Epoch 3/60
1652/1652 [==============================] - 4s 3ms/step - loss: 1.4029 - acc: 0.4449 - auc_roc: 0.6807 - val_loss: 1.7971 - val_acc: 0.4520 - val_auc_roc: 0.7002
Epoch 4/60
1652/1652 [==============================] - 5s 3ms/step - loss: 1.2923 - acc: 0.5024 - auc_roc: 0.7175 - val_loss: 1.4720 - val_acc: 0.6158 - val_auc_roc: 0.7379
Epoch 5/60
1652/1652 [==============================] - 4s 2ms/step - loss: 1.2029 - acc: 0.5109 - auc_roc: 0.7524 - val_loss: 1.4229 - val_acc: 0.5960 - val_auc_roc: 0.7648
Epoch 6/60
1652/1652 [==============================] - 4s 2ms/step - loss: 1.1108 - acc: 0.5109 - auc_roc: 0.7734 - val_loss: 1.5395 - val_acc: 0.6031 - val_auc_roc: 0.7823
Epoch 7/60
1652/1652 [==============================] - 4s 2ms/step - loss: 1.0733 - acc: 0.5357 - auc_roc: 0.7884 - val_loss: 1.6167 - val_acc: 0.4732 - val_auc_roc: 0.7931
Epoch 8/60
1652/1652 [==============================] - 4s 2ms/step - loss: 1.0371 - acc: 0.5297 - auc_roc: 0.7971 - val_loss: 1.6884 - val_acc: 0.6201 - val_auc_roc: 0.8017
Epoch 9/60
1652/1652 [==============================] - 4s 2ms/step - loss: 1.0040 - acc: 0.5515 - auc_roc: 0.8065 - val_loss: 1.3946 - val_acc: 0.6653 - val_auc_roc: 0.8121
Epoch 10/60
1652/1652 [==============================] - 4s 2ms/step - loss: 0.9047 - acc: 0.5884 - auc_roc: 0.8166 - val_loss: 1.7242 - val_acc: 0.6638 - val_auc_roc: 0.8217
Epoch 11/60
1652/1652 [==============================] - 4s 2ms/step - loss: 0.8769 - acc: 0.6059 - auc_roc: 0.8257 - val_loss: 1.6935 - val_acc: 0.6370 - val_auc_roc: 0.8294
Epoch 12/60
1652/1652 [==============================] - 4s 2ms/step - loss: 0.8216 - acc: 0.6144 - auc_roc: 0.8330 - val_loss: 2.0089 - val_acc: 0.5212 - val_auc_roc: 0.8351
Epoch 13/60
1652/1652 [==============================] - 4s 2ms/step - loss: 0.7917 - acc: 0.6132 - auc_roc: 0.8373 - val_loss: 1.6720 - val_acc: 0.6257 - val_auc_roc: 0.8400
Epoch 14/60
1652/1652 [==============================] - 4s 2ms/step - loss: 0.7481 - acc: 0.6459 - auc_roc: 0.8427 - val_loss: 1.7952 - val_acc: 0.6144 - val_auc_roc: 0.8455
Epoch 15/60
1652/1652 [==============================] - 4s 2ms/step - loss: 0.7119 - acc: 0.6743 - auc_roc: 0.8480 - val_loss: 2.0911 - val_acc: 0.6059 - val_auc_roc: 0.8504
Epoch 16/60
1652/1652 [==============================] - 4s 2ms/step - loss: 0.7061 - acc: 0.6429 - auc_roc: 0.8526 - val_loss: 1.8650 - val_acc: 0.5593 - val_auc_roc: 0.8545
Epoch 17/60
1652/1652 [==============================] - 3s 2ms/step - loss: 0.7184 - acc: 0.6580 - auc_roc: 0.8559 - val_loss: 1.7186 - val_acc: 0.6921 - val_auc_roc: 0.8585
Epoch 18/60
1652/1652 [==============================] - 4s 2ms/step - loss: 0.6468 - acc: 0.6858 - auc_roc: 0.8608 - val_loss: 1.7494 - val_acc: 0.6638 - val_auc_roc: 0.8631
Epoch 19/60
1652/1652 [==============================] - 4s 2ms/step - loss: 0.7449 - acc: 0.6586 - auc_roc: 0.8646 - val_loss: 1.7753 - val_acc: 0.6144 - val_auc_roc: 0.8660
Epoch 20/60
1652/1652 [==============================] - 4s 2ms/step - loss: 0.6106 - acc: 0.6973 - auc_roc: 0.8675 - val_loss: 2.0238 - val_acc: 0.6751 - val_auc_roc: 0.8695
Epoch 21/60
1652/1652 [==============================] - 4s 2ms/step - loss: 0.5868 - acc: 0.7052 - auc_roc: 0.8710 - val_loss: 2.0690 - val_acc: 0.6766 - val_auc_roc: 0.8729
Epoch 22/60
1652/1652 [==============================] - 4s 2ms/step - loss: 0.5644 - acc: 0.7258 - auc_roc: 0.8744 - val_loss: 2.0901 - val_acc: 0.6582 - val_auc_roc: 0.8761
Epoch 23/60
1652/1652 [==============================] - 4s 2ms/step - loss: 0.5950 - acc: 0.7125 - auc_roc: 0.8774 - val_loss: 2.1699 - val_acc: 0.6554 - val_auc_roc: 0.8788
Epoch 24/60
1652/1652 [==============================] - 4s 2ms/step - loss: 0.6647 - acc: 0.6531 - auc_roc: 0.8794 - val_loss: 2.2931 - val_acc: 0.5551 - val_auc_roc: 0.8799
Epoch 25/60
1652/1652 [==============================] - 3s 2ms/step - loss: 0.5956 - acc: 0.7094 - auc_roc: 0.8805 - val_loss: 2.1028 - val_acc: 0.6511 - val_auc_roc: 0.8817
Epoch 26/60
1652/1652 [==============================] - 4s 2ms/step - loss: 0.4879 - acc: 0.7573 - auc_roc: 0.8829 - val_loss: 2.2006 - val_acc: 0.6935 - val_auc_roc: 0.8845
Epoch 27/60
1652/1652 [==============================] - 4s 2ms/step - loss: 0.4736 - acc: 0.7718 - auc_roc: 0.8858 - val_loss: 2.0951 - val_acc: 0.7020 - val_auc_roc: 0.8873
Epoch 28/60
1652/1652 [==============================] - 4s 2ms/step - loss: 0.4209 - acc: 0.7887 - auc_roc: 0.8886 - val_loss: 2.4130 - val_acc: 0.6398 - val_auc_roc: 0.8899
Epoch 29/60
1652/1652 [==============================] - 3s 2ms/step - loss: 0.4461 - acc: 0.7663 - auc_roc: 0.8909 - val_loss: 2.4156 - val_acc: 0.6808 - val_auc_roc: 0.8921
Epoch 00029: early stopping
... history of metrics comprising: ['acc', 'loss', 'val_auc_roc', 'auc_roc', 'val_acc', 'val_loss']
... ... metric (acc): [0.69733656188766258, 0.70520581099369339, 0.72578692465082495, 0.71246973336753194, 0.65314770004651157, 0.70944309956225005, 0.75726392222951744, 0.77179176769880065, 0.78874091980820993, 0.76634382581018079] (n=29)
output> saving performance to:
/Users/pleiades/Documents/work/tpheno/seqmaker/data/CKD/plot/model_evalation-ep200b16.tif

... ... metric (loss): [0.61059774512528797, 0.58682174399747689, 0.5643641203281089, 0.5949751148789616, 0.6647436895901585, 0.59562775860687145, 0.48789229823082469, 0.47361561692078524, 0.4208602870636356, 0.44609377069565631] (n=29)
output> saving performance to:
/Users/pleiades/Documents/work/tpheno/seqmaker/data/CKD/plot/model_evalation-ep200b16.tif


model_selection> trying {'n_units': 200, 'dropout_rate': 0.6} ...

make_lstm> n_units=200, r_dropout=0.600000, n_layers=1, n_classes=6
  + lookup:
{'Others': 5, 'CKD Stage 5': 4, 'CKD Stage 4': 3, 'CKD Stage 3': 2, 'CKD Stage 2': 1, 'CKD Stage 1': 0}

... class weights:
{0: 6.344086021505376, 1: 0.74494949494949492, 2: 1.1238095238095238, 3: 7.0238095238095237, 4: 0.51890941072999119, 5: 0.64906490649064907}

====================================================================================================
... early stopping>
       + patience: 20, model='max'
... model training>
       + batch_size: 32, epochs: 60, shuffle? True, metric: auc_roc
====================================================================================================
Train on 1652 samples, validate on 708 samples
Epoch 1/60
1652/1652 [==============================] - 7s 4ms/step - loss: 1.6853 - acc: 0.2809 - auc_roc: 0.6014 - val_loss: 1.7236 - val_acc: 0.5381 - val_auc_roc: 0.6899
Epoch 2/60
1652/1652 [==============================] - 5s 3ms/step - loss: 1.4818 - acc: 0.4352 - auc_roc: 0.7262 - val_loss: 1.9223 - val_acc: 0.2020 - val_auc_roc: 0.7098
Epoch 3/60
1652/1652 [==============================] - 5s 3ms/step - loss: 1.4008 - acc: 0.4171 - auc_roc: 0.6968 - val_loss: 1.4894 - val_acc: 0.6045 - val_auc_roc: 0.7218
Epoch 4/60
1652/1652 [==============================] - 5s 3ms/step - loss: 1.3554 - acc: 0.4594 - auc_roc: 0.7376 - val_loss: 1.4885 - val_acc: 0.5650 - val_auc_roc: 0.7443
Epoch 5/60
1652/1652 [==============================] - 5s 3ms/step - loss: 1.1585 - acc: 0.5012 - auc_roc: 0.7548 - val_loss: 1.3602 - val_acc: 0.6116 - val_auc_roc: 0.7669
Epoch 6/60
1652/1652 [==============================] - 5s 3ms/step - loss: 1.1554 - acc: 0.4909 - auc_roc: 0.7752 - val_loss: 1.4285 - val_acc: 0.6667 - val_auc_roc: 0.7853
Epoch 7/60
1652/1652 [==============================] - 5s 3ms/step - loss: 1.0535 - acc: 0.5454 - auc_roc: 0.7938 - val_loss: 1.6844 - val_acc: 0.6398 - val_auc_roc: 0.8003
Epoch 8/60
1652/1652 [==============================] - 5s 3ms/step - loss: 0.9830 - acc: 0.5714 - auc_roc: 0.8059 - val_loss: 1.6202 - val_acc: 0.6780 - val_auc_roc: 0.8123
Epoch 9/60
1652/1652 [==============================] - 4s 3ms/step - loss: 0.9105 - acc: 0.5781 - auc_roc: 0.8178 - val_loss: 1.7331 - val_acc: 0.6794 - val_auc_roc: 0.8230
Epoch 10/60
1652/1652 [==============================] - 5s 3ms/step - loss: 0.8653 - acc: 0.5944 - auc_roc: 0.8277 - val_loss: 1.4452 - val_acc: 0.6681 - val_auc_roc: 0.8323
Epoch 11/60
1652/1652 [==============================] - 4s 3ms/step - loss: 0.8374 - acc: 0.6186 - auc_roc: 0.8363 - val_loss: 1.5295 - val_acc: 0.7147 - val_auc_roc: 0.8405
Epoch 12/60
1652/1652 [==============================] - 5s 3ms/step - loss: 0.8528 - acc: 0.5950 - auc_roc: 0.8435 - val_loss: 1.9134 - val_acc: 0.5749 - val_auc_roc: 0.8456
Epoch 13/60
1652/1652 [==============================] - 5s 3ms/step - loss: 0.8023 - acc: 0.6168 - auc_roc: 0.8473 - val_loss: 1.7354 - val_acc: 0.6864 - val_auc_roc: 0.8502
Epoch 14/60
1652/1652 [==============================] - 4s 3ms/step - loss: 0.7359 - acc: 0.6483 - auc_roc: 0.8528 - val_loss: 1.6038 - val_acc: 0.6963 - val_auc_roc: 0.8559
Epoch 15/60
1652/1652 [==============================] - 4s 3ms/step - loss: 0.6730 - acc: 0.6755 - auc_roc: 0.8586 - val_loss: 1.9142 - val_acc: 0.7232 - val_auc_roc: 0.8617
Epoch 16/60
1652/1652 [==============================] - 5s 3ms/step - loss: 0.6372 - acc: 0.6846 - auc_roc: 0.8643 - val_loss: 2.2009 - val_acc: 0.6977 - val_auc_roc: 0.8668
Epoch 17/60
1652/1652 [==============================] - 5s 3ms/step - loss: 0.6099 - acc: 0.7016 - auc_roc: 0.8690 - val_loss: 2.0743 - val_acc: 0.7034 - val_auc_roc: 0.8714
Epoch 18/60
1652/1652 [==============================] - 5s 3ms/step - loss: 0.5486 - acc: 0.7343 - auc_roc: 0.8735 - val_loss: 2.1155 - val_acc: 0.7147 - val_auc_roc: 0.8760
Epoch 19/60
1652/1652 [==============================] - 5s 3ms/step - loss: 0.5582 - acc: 0.7264 - auc_roc: 0.8779 - val_loss: 2.2249 - val_acc: 0.6963 - val_auc_roc: 0.8800
Epoch 20/60
1652/1652 [==============================] - 5s 3ms/step - loss: 0.5238 - acc: 0.7403 - auc_roc: 0.8816 - val_loss: 2.3113 - val_acc: 0.7203 - val_auc_roc: 0.8836
Epoch 21/60
1652/1652 [==============================] - 4s 3ms/step - loss: 0.4666 - acc: 0.7688 - auc_roc: 0.8854 - val_loss: 2.5191 - val_acc: 0.7189 - val_auc_roc: 0.8874
Epoch 22/60
1652/1652 [==============================] - 5s 3ms/step - loss: 0.4338 - acc: 0.7990 - auc_roc: 0.8890 - val_loss: 2.1206 - val_acc: 0.7034 - val_auc_roc: 0.8909
Epoch 23/60
1652/1652 [==============================] - 4s 3ms/step - loss: 0.3930 - acc: 0.8063 - auc_roc: 0.8926 - val_loss: 2.4018 - val_acc: 0.7119 - val_auc_roc: 0.8945
Epoch 24/60
1652/1652 [==============================] - 4s 3ms/step - loss: 0.3685 - acc: 0.8299 - auc_roc: 0.8961 - val_loss: 2.3468 - val_acc: 0.6893 - val_auc_roc: 0.8978
Epoch 25/60
1652/1652 [==============================] - 4s 3ms/step - loss: 0.3893 - acc: 0.8027 - auc_roc: 0.8990 - val_loss: 2.5991 - val_acc: 0.7218 - val_auc_roc: 0.9006
Epoch 00025: early stopping
... history of metrics comprising: ['acc', 'loss', 'val_auc_roc', 'auc_roc', 'val_acc', 'val_loss']
... ... metric (acc): [0.68462469762520406, 0.70157384959029223, 0.73426150092201137, 0.72639225181598066, 0.74031477026442927, 0.76876513317191286, 0.79903147670893637, 0.8062953996600597, 0.82990314769975781, 0.8026634379680162] (n=25)
output> saving performance to:
/Users/pleiades/Documents/work/tpheno/seqmaker/data/CKD/plot/model_evalation-ep200b16.tif

... ... metric (loss): [0.6372374796982827, 0.60993677796232215, 0.54863012125647959, 0.55819434165665949, 0.52375886876127042, 0.466620949870449, 0.43382806076553199, 0.39298417110708667, 0.36850038322351747, 0.38926875944864953] (n=25)
output> saving performance to:
/Users/pleiades/Documents/work/tpheno/seqmaker/data/CKD/plot/model_evalation-ep200b16.tif


model_selection> trying {'n_units': 300, 'dropout_rate': 0.6} ...

make_lstm> n_units=300, r_dropout=0.600000, n_layers=1, n_classes=6
  + lookup:
{'Others': 5, 'CKD Stage 5': 4, 'CKD Stage 4': 3, 'CKD Stage 3': 2, 'CKD Stage 2': 1, 'CKD Stage 1': 0}

... class weights:
{0: 6.344086021505376, 1: 0.74494949494949492, 2: 1.1238095238095238, 3: 7.0238095238095237, 4: 0.51890941072999119, 5: 0.64906490649064907}

====================================================================================================
... early stopping>
       + patience: 20, model='max'
... model training>
       + batch_size: 32, epochs: 60, shuffle? True, metric: auc_roc
====================================================================================================
Train on 1652 samples, validate on 708 samples
Epoch 1/60
1652/1652 [==============================] - 9s 6ms/step - loss: 1.6666 - acc: 0.3172 - auc_roc: 0.6114 - val_loss: 1.7195 - val_acc: 0.3898 - val_auc_roc: 0.6838
Epoch 2/60
1652/1652 [==============================] - 7s 4ms/step - loss: 1.4234 - acc: 0.4340 - auc_roc: 0.7085 - val_loss: 1.8212 - val_acc: 0.3107 - val_auc_roc: 0.7186
Epoch 3/60
1652/1652 [==============================] - 7s 4ms/step - loss: 1.3749 - acc: 0.4340 - auc_roc: 0.7286 - val_loss: 1.5988 - val_acc: 0.2712 - val_auc_roc: 0.7292
Epoch 4/60
1652/1652 [==============================] - 7s 4ms/step - loss: 1.2719 - acc: 0.4824 - auc_roc: 0.7362 - val_loss: 1.7695 - val_acc: 0.4732 - val_auc_roc: 0.7465
Epoch 5/60
1652/1652 [==============================] - 7s 4ms/step - loss: 1.1022 - acc: 0.5212 - auc_roc: 0.7547 - val_loss: 1.3279 - val_acc: 0.6497 - val_auc_roc: 0.7696
Epoch 6/60
1652/1652 [==============================] - 7s 4ms/step - loss: 1.0936 - acc: 0.5315 - auc_roc: 0.7806 - val_loss: 1.3286 - val_acc: 0.5918 - val_auc_roc: 0.7889
Epoch 7/60
1652/1652 [==============================] - 7s 4ms/step - loss: 0.9985 - acc: 0.5581 - auc_roc: 0.7961 - val_loss: 1.5820 - val_acc: 0.6271 - val_auc_roc: 0.8027
Epoch 8/60
1652/1652 [==============================] - 7s 4ms/step - loss: 0.9272 - acc: 0.5944 - auc_roc: 0.8091 - val_loss: 1.9103 - val_acc: 0.6568 - val_auc_roc: 0.8156
Epoch 9/60
1652/1652 [==============================] - 7s 4ms/step - loss: 0.8504 - acc: 0.6011 - auc_roc: 0.8205 - val_loss: 2.1234 - val_acc: 0.6045 - val_auc_roc: 0.8252
Epoch 10/60
1652/1652 [==============================] - 7s 4ms/step - loss: 0.8544 - acc: 0.5932 - auc_roc: 0.8287 - val_loss: 1.5344 - val_acc: 0.6751 - val_auc_roc: 0.8332
Epoch 11/60
1652/1652 [==============================] - 8s 5ms/step - loss: 0.8207 - acc: 0.5993 - auc_roc: 0.8367 - val_loss: 2.3081 - val_acc: 0.6045 - val_auc_roc: 0.8394
Epoch 12/60
1652/1652 [==============================] - 7s 4ms/step - loss: 0.7458 - acc: 0.6441 - auc_roc: 0.8423 - val_loss: 1.8164 - val_acc: 0.6850 - val_auc_roc: 0.8463
Epoch 13/60
1652/1652 [==============================] - 7s 4ms/step - loss: 0.7113 - acc: 0.6513 - auc_roc: 0.8496 - val_loss: 1.8215 - val_acc: 0.6554 - val_auc_roc: 0.8527
Epoch 14/60
1652/1652 [==============================] - 7s 4ms/step - loss: 0.6477 - acc: 0.6731 - auc_roc: 0.8555 - val_loss: 1.9507 - val_acc: 0.6879 - val_auc_roc: 0.8588
Epoch 15/60
1652/1652 [==============================] - 7s 4ms/step - loss: 0.5983 - acc: 0.6949 - auc_roc: 0.8616 - val_loss: 1.8828 - val_acc: 0.6808 - val_auc_roc: 0.8644
Epoch 16/60
1652/1652 [==============================] - 7s 4ms/step - loss: 0.5809 - acc: 0.7125 - auc_roc: 0.8670 - val_loss: 2.3341 - val_acc: 0.6907 - val_auc_roc: 0.8695
Epoch 17/60
1652/1652 [==============================] - 8s 5ms/step - loss: 0.6181 - acc: 0.6943 - auc_roc: 0.8713 - val_loss: 1.7932 - val_acc: 0.6356 - val_auc_roc: 0.8734
Epoch 18/60
1652/1652 [==============================] - 9s 5ms/step - loss: 0.7104 - acc: 0.6689 - auc_roc: 0.8748 - val_loss: 1.7769 - val_acc: 0.6893 - val_auc_roc: 0.8766
Epoch 19/60
1652/1652 [==============================] - 8s 5ms/step - loss: 0.5541 - acc: 0.7324 - auc_roc: 0.8785 - val_loss: 1.9031 - val_acc: 0.6653 - val_auc_roc: 0.8806
Epoch 20/60
1652/1652 [==============================] - 7s 4ms/step - loss: 0.4827 - acc: 0.7700 - auc_roc: 0.8825 - val_loss: 2.1161 - val_acc: 0.6836 - val_auc_roc: 0.8847
Epoch 21/60
1652/1652 [==============================] - 6s 4ms/step - loss: 0.4162 - acc: 0.7948 - auc_roc: 0.8867 - val_loss: 2.3283 - val_acc: 0.6992 - val_auc_roc: 0.8889
Epoch 22/60
1652/1652 [==============================] - 6s 4ms/step - loss: 0.3542 - acc: 0.8214 - auc_roc: 0.8908 - val_loss: 2.3407 - val_acc: 0.7133 - val_auc_roc: 0.8930
Epoch 23/60
1652/1652 [==============================] - 6s 4ms/step - loss: 0.4454 - acc: 0.8008 - auc_roc: 0.8946 - val_loss: 2.4275 - val_acc: 0.7133 - val_auc_roc: 0.8965
Epoch 24/60
1652/1652 [==============================] - 6520s 4s/step - loss: 0.3839 - acc: 0.8257 - auc_roc: 0.8979 - val_loss: 2.2081 - val_acc: 0.7090 - val_auc_roc: 0.8998
Epoch 25/60
1652/1652 [==============================] - 6s 4ms/step - loss: 0.3174 - acc: 0.8692 - auc_roc: 0.9015 - val_loss: 2.4227 - val_acc: 0.6992 - val_auc_roc: 0.9032
Epoch 00025: early stopping
... history of metrics comprising: ['acc', 'loss', 'val_auc_roc', 'auc_roc', 'val_acc', 'val_loss']
... ... metric (acc): [0.71246973336753194, 0.69430992764941712, 0.66888619825857309, 0.73244552029247145, 0.76997578678061829, 0.7947941888619855, 0.82142857113992906, 0.80084745777143984, 0.8256658594198435, 0.86924939438448112] (n=25)
output> saving performance to:
/Users/pleiades/Documents/work/tpheno/seqmaker/data/CKD/plot/model_evalation-ep200b16.tif

... ... metric (loss): [0.58089322876410676, 0.61808679626293972, 0.71041708131102033, 0.55407612253043614, 0.48269974766862883, 0.41617245326319274, 0.35424675346864049, 0.44544317603977196, 0.3838569114196676, 0.31743195486992382] (n=25)
output> saving performance to:
/Users/pleiades/Documents/work/tpheno/seqmaker/data/CKD/plot/model_evalation-ep200b16.tif


model_selection> trying {'n_units': 400, 'dropout_rate': 0.6} ...

make_lstm> n_units=400, r_dropout=0.600000, n_layers=1, n_classes=6
  + lookup:
{'Others': 5, 'CKD Stage 5': 4, 'CKD Stage 4': 3, 'CKD Stage 3': 2, 'CKD Stage 2': 1, 'CKD Stage 1': 0}

... class weights:
{0: 6.344086021505376, 1: 0.74494949494949492, 2: 1.1238095238095238, 3: 7.0238095238095237, 4: 0.51890941072999119, 5: 0.64906490649064907}

====================================================================================================
... early stopping>
       + patience: 20, model='max'
... model training>
       + batch_size: 32, epochs: 60, shuffle? True, metric: auc_roc
====================================================================================================
Train on 1652 samples, validate on 708 samples
Epoch 1/60
1652/1652 [==============================] - 11s 7ms/step - loss: 1.6683 - acc: 0.2918 - auc_roc: 0.6166 - val_loss: 1.7488 - val_acc: 0.3785 - val_auc_roc: 0.6858
Epoch 2/60
1652/1652 [==============================] - 8s 5ms/step - loss: 1.4858 - acc: 0.3783 - auc_roc: 0.6930 - val_loss: 1.4536 - val_acc: 0.6045 - val_auc_roc: 0.7240
Epoch 3/60
1652/1652 [==============================] - 8s 5ms/step - loss: 1.4250 - acc: 0.4140 - auc_roc: 0.7434 - val_loss: 1.8202 - val_acc: 0.4859 - val_auc_roc: 0.7458
Epoch 4/60
1652/1652 [==============================] - 9s 6ms/step - loss: 1.3216 - acc: 0.4292 - auc_roc: 0.7531 - val_loss: 1.4064 - val_acc: 0.5678 - val_auc_roc: 0.7614
Epoch 5/60
1652/1652 [==============================] - 9s 5ms/step - loss: 1.1499 - acc: 0.4933 - auc_roc: 0.7717 - val_loss: 1.4519 - val_acc: 0.5212 - val_auc_roc: 0.7805
Epoch 6/60
1652/1652 [==============================] - 9s 6ms/step - loss: 1.0951 - acc: 0.5418 - auc_roc: 0.7876 - val_loss: 1.3949 - val_acc: 0.6186 - val_auc_roc: 0.7955
Epoch 7/60
1652/1652 [==============================] - 9s 5ms/step - loss: 1.0089 - acc: 0.5593 - auc_roc: 0.8021 - val_loss: 1.7697 - val_acc: 0.5664 - val_auc_roc: 0.8068
Epoch 8/60
1652/1652 [==============================] - 9s 5ms/step - loss: 0.9473 - acc: 0.5672 - auc_roc: 0.8118 - val_loss: 1.6960 - val_acc: 0.5777 - val_auc_roc: 0.8167
Epoch 9/60
1652/1652 [==============================] - 8s 5ms/step - loss: 0.9052 - acc: 0.5811 - auc_roc: 0.8211 - val_loss: 1.7926 - val_acc: 0.6285 - val_auc_roc: 0.8254
Epoch 10/60
1652/1652 [==============================] - 8s 5ms/step - loss: 0.8445 - acc: 0.6053 - auc_roc: 0.8295 - val_loss: 1.7635 - val_acc: 0.5127 - val_auc_roc: 0.8320
Epoch 11/60
1652/1652 [==============================] - 8s 5ms/step - loss: 0.8192 - acc: 0.5775 - auc_roc: 0.8338 - val_loss: 2.1668 - val_acc: 0.4011 - val_auc_roc: 0.8346
Epoch 12/60
1652/1652 [==============================] - 9s 5ms/step - loss: 0.8343 - acc: 0.6162 - auc_roc: 0.8353 - val_loss: 1.8770 - val_acc: 0.6653 - val_auc_roc: 0.8386
Epoch 13/60
1652/1652 [==============================] - 9s 5ms/step - loss: 0.7060 - acc: 0.6525 - auc_roc: 0.8421 - val_loss: 2.0557 - val_acc: 0.6695 - val_auc_roc: 0.8459
Epoch 14/60
1652/1652 [==============================] - 9s 5ms/step - loss: 0.6611 - acc: 0.6895 - auc_roc: 0.8492 - val_loss: 1.9522 - val_acc: 0.6441 - val_auc_roc: 0.8525
Epoch 15/60
1652/1652 [==============================] - 9s 6ms/step - loss: 0.6064 - acc: 0.7064 - auc_roc: 0.8553 - val_loss: 2.1695 - val_acc: 0.7006 - val_auc_roc: 0.8587
Epoch 16/60
1652/1652 [==============================] - 9s 5ms/step - loss: 0.5268 - acc: 0.7421 - auc_roc: 0.8617 - val_loss: 2.4905 - val_acc: 0.6441 - val_auc_roc: 0.8648
Epoch 17/60
1652/1652 [==============================] - 9s 5ms/step - loss: 0.5263 - acc: 0.7403 - auc_roc: 0.8671 - val_loss: 2.4252 - val_acc: 0.4661 - val_auc_roc: 0.8685
Epoch 18/60
1652/1652 [==============================] - 8s 5ms/step - loss: 0.6590 - acc: 0.6913 - auc_roc: 0.8690 - val_loss: 1.8128 - val_acc: 0.6751 - val_auc_roc: 0.8712
Epoch 19/60
1652/1652 [==============================] - 8s 5ms/step - loss: 0.5244 - acc: 0.7415 - auc_roc: 0.8732 - val_loss: 2.2238 - val_acc: 0.6780 - val_auc_roc: 0.8756
Epoch 20/60
1652/1652 [==============================] - 9s 5ms/step - loss: 0.4356 - acc: 0.7875 - auc_roc: 0.8780 - val_loss: 2.4907 - val_acc: 0.6695 - val_auc_roc: 0.8802
Epoch 21/60
1652/1652 [==============================] - 8s 5ms/step - loss: 0.3874 - acc: 0.8148 - auc_roc: 0.8821 - val_loss: 2.4703 - val_acc: 0.6794 - val_auc_roc: 0.8845
Epoch 22/60
1652/1652 [==============================] - 8s 5ms/step - loss: 0.5944 - acc: 0.7730 - auc_roc: 0.8862 - val_loss: 1.9267 - val_acc: 0.6624 - val_auc_roc: 0.8877
Epoch 23/60
1652/1652 [==============================] - 10s 6ms/step - loss: 0.4433 - acc: 0.8057 - auc_roc: 0.8894 - val_loss: 2.3381 - val_acc: 0.6638 - val_auc_roc: 0.8912
Epoch 24/60
1652/1652 [==============================] - 9s 5ms/step - loss: 0.3316 - acc: 0.8462 - auc_roc: 0.8929 - val_loss: 2.3135 - val_acc: 0.7076 - val_auc_roc: 0.8950
Epoch 25/60
1652/1652 [==============================] - 9s 5ms/step - loss: 0.3172 - acc: 0.8541 - auc_roc: 0.8966 - val_loss: 2.5772 - val_acc: 0.6836 - val_auc_roc: 0.8985
Epoch 26/60
1652/1652 [==============================] - 9s 5ms/step - loss: 0.2274 - acc: 0.8892 - auc_roc: 0.9002 - val_loss: 2.6340 - val_acc: 0.6921 - val_auc_roc: 0.9022
Epoch 00026: early stopping
... history of metrics comprising: ['acc', 'loss', 'val_auc_roc', 'auc_roc', 'val_acc', 'val_loss']
... ... metric (acc): [0.7403147696871446, 0.69128329297820823, 0.74152542401745591, 0.78753026663246806, 0.81476997564260378, 0.77300242130750607, 0.80569007249490399, 0.84624697322129627, 0.8541162224716482, 0.8892251818867053] (n=26)
output> saving performance to:
/Users/pleiades/Documents/work/tpheno/seqmaker/data/CKD/plot/model_evalation-ep200b16.tif

... ... metric (loss): [0.52627466810240298, 0.65899510100736458, 0.52444734397292425, 0.43555479065557945, 0.38736187567433777, 0.59442402779623038, 0.44332746602143847, 0.33163546931368387, 0.31716611281434215, 0.22737155526371325] (n=26)
output> saving performance to:
/Users/pleiades/Documents/work/tpheno/seqmaker/data/CKD/plot/model_evalation-ep200b16.tif


model_selection> trying {'n_units': 500, 'dropout_rate': 0.6} ...

make_lstm> n_units=500, r_dropout=0.600000, n_layers=1, n_classes=6
  + lookup:
{'Others': 5, 'CKD Stage 5': 4, 'CKD Stage 4': 3, 'CKD Stage 3': 2, 'CKD Stage 2': 1, 'CKD Stage 1': 0}

... class weights:
{0: 6.344086021505376, 1: 0.74494949494949492, 2: 1.1238095238095238, 3: 7.0238095238095237, 4: 0.51890941072999119, 5: 0.64906490649064907}

====================================================================================================
... early stopping>
       + patience: 20, model='max'
... model training>
       + batch_size: 32, epochs: 60, shuffle? True, metric: auc_roc
====================================================================================================
Train on 1652 samples, validate on 708 samples
Epoch 1/60
1652/1652 [==============================] - 16s 10ms/step - loss: 1.6467 - acc: 0.3015 - auc_roc: 0.6612 - val_loss: 1.7299 - val_acc: 0.2895 - val_auc_roc: 0.6857
Epoch 2/60
1652/1652 [==============================] - 14s 8ms/step - loss: 1.4198 - acc: 0.4510 - auc_roc: 0.7151 - val_loss: 1.2008 - val_acc: 0.6257 - val_auc_roc: 0.7499
Epoch 3/60
1652/1652 [==============================] - 13s 8ms/step - loss: 1.3238 - acc: 0.4576 - auc_roc: 0.7684 - val_loss: 1.4482 - val_acc: 0.6271 - val_auc_roc: 0.7823
Epoch 4/60
1652/1652 [==============================] - 12s 8ms/step - loss: 1.2469 - acc: 0.4921 - auc_roc: 0.7913 - val_loss: 1.6392 - val_acc: 0.4915 - val_auc_roc: 0.7971
Epoch 5/60
1652/1652 [==============================] - 12s 7ms/step - loss: 1.2476 - acc: 0.4437 - auc_roc: 0.7986 - val_loss: 1.7277 - val_acc: 0.4647 - val_auc_roc: 0.7988
Epoch 6/60
1652/1652 [==============================] - 13s 8ms/step - loss: 1.1434 - acc: 0.5121 - auc_roc: 0.8016 - val_loss: 1.6751 - val_acc: 0.4251 - val_auc_roc: 0.8028
Epoch 7/60
1652/1652 [==============================] - 13s 8ms/step - loss: 1.0623 - acc: 0.5109 - auc_roc: 0.8041 - val_loss: 1.5018 - val_acc: 0.4972 - val_auc_roc: 0.8074
Epoch 8/60
1652/1652 [==============================] - 13s 8ms/step - loss: 0.9835 - acc: 0.5648 - auc_roc: 0.8107 - val_loss: 1.7147 - val_acc: 0.5579 - val_auc_roc: 0.8144
Epoch 9/60
1652/1652 [==============================] - 13s 8ms/step - loss: 0.9192 - acc: 0.5962 - auc_roc: 0.8181 - val_loss: 1.9741 - val_acc: 0.5819 - val_auc_roc: 0.8223
Epoch 10/60
1652/1652 [==============================] - 13s 8ms/step - loss: 0.9589 - acc: 0.5533 - auc_roc: 0.8254 - val_loss: 1.5474 - val_acc: 0.5805 - val_auc_roc: 0.8286
Epoch 11/60
1652/1652 [==============================] - 13s 8ms/step - loss: 0.8585 - acc: 0.5696 - auc_roc: 0.8317 - val_loss: 1.7343 - val_acc: 0.6342 - val_auc_roc: 0.8354
Epoch 12/60
1652/1652 [==============================] - 13s 8ms/step - loss: 0.8334 - acc: 0.6017 - auc_roc: 0.8385 - val_loss: 1.9452 - val_acc: 0.6285 - val_auc_roc: 0.8413
Epoch 13/60
1652/1652 [==============================] - 14s 8ms/step - loss: 0.7299 - acc: 0.6386 - auc_roc: 0.8442 - val_loss: 2.1719 - val_acc: 0.4534 - val_auc_roc: 0.8460
Epoch 14/60
1652/1652 [==============================] - 14s 8ms/step - loss: 0.7045 - acc: 0.6598 - auc_roc: 0.8475 - val_loss: 1.9046 - val_acc: 0.6370 - val_auc_roc: 0.8507
Epoch 15/60
1652/1652 [==============================] - 14s 9ms/step - loss: 0.6371 - acc: 0.6695 - auc_roc: 0.8532 - val_loss: 2.2179 - val_acc: 0.6441 - val_auc_roc: 0.8565
Epoch 16/60
1652/1652 [==============================] - 14s 8ms/step - loss: 0.6230 - acc: 0.6931 - auc_roc: 0.8593 - val_loss: 2.4915 - val_acc: 0.4788 - val_auc_roc: 0.8604
Epoch 17/60
1652/1652 [==============================] - 14s 8ms/step - loss: 0.8093 - acc: 0.6320 - auc_roc: 0.8605 - val_loss: 1.8979 - val_acc: 0.6582 - val_auc_roc: 0.8623
Epoch 18/60
1652/1652 [==============================] - 15s 9ms/step - loss: 0.6106 - acc: 0.7052 - auc_roc: 0.8646 - val_loss: 2.2429 - val_acc: 0.6483 - val_auc_roc: 0.8669
Epoch 19/60
1652/1652 [==============================] - 15s 9ms/step - loss: 0.5419 - acc: 0.7264 - auc_roc: 0.8689 - val_loss: 2.3807 - val_acc: 0.6836 - val_auc_roc: 0.8715
Epoch 20/60
1652/1652 [==============================] - 15s 9ms/step - loss: 0.5065 - acc: 0.7548 - auc_roc: 0.8736 - val_loss: 2.0665 - val_acc: 0.6977 - val_auc_roc: 0.8761
Epoch 21/60
1652/1652 [==============================] - 15s 9ms/step - loss: 0.4439 - acc: 0.7821 - auc_roc: 0.8780 - val_loss: 2.5253 - val_acc: 0.6977 - val_auc_roc: 0.8806
Epoch 22/60
1652/1652 [==============================] - 15s 9ms/step - loss: 0.3789 - acc: 0.8021 - auc_roc: 0.8827 - val_loss: 2.2488 - val_acc: 0.7076 - val_auc_roc: 0.8851
Epoch 00022: early stopping
... history of metrics comprising: ['acc', 'loss', 'val_auc_roc', 'auc_roc', 'val_acc', 'val_loss']
... ... metric (acc): [0.63861985486587081, 0.65980629525519452, 0.66949152542372881, 0.69309927360774815, 0.63196125936854552, 0.70520581099369339, 0.72639225181598066, 0.75484261530074892, 0.78208232431088465, 0.80205811138014527] (n=22)
output> saving performance to:
/Users/pleiades/Documents/work/tpheno/seqmaker/data/CKD/plot/model_evalation-ep200b16.tif

... ... metric (loss): [0.7298637510211935, 0.70454403476622718, 0.63714182391293694, 0.62304345776324699, 0.80929660566205264, 0.6105618632734543, 0.54186032687203356, 0.50654800687228796, 0.44391700185240035, 0.37893515680950435] (n=22)
output> saving performance to:
/Users/pleiades/Documents/work/tpheno/seqmaker/data/CKD/plot/model_evalation-ep200b16.tif

result> performance scores ...

... performance ranking (n_models:24 -> 22):
[({'n_units': 100, 'dropout_rate': 0.5}, 0.65550611461478925, 1.2494593967031911), ({'n_units': 50, 'dropout_rate': 0.2}, 0.62688892638134885, 1.4377704664355233), ({'n_units': 50, 'dropout_rate': 0.3}, 0.62300120169977868, 1.4767646411501469), ({'n_units': 500, 'dropout_rate': 0.5}, 0.48690201680899825, 1.6121273147484967), ({'n_units': 200, 'dropout_rate': 0.5}, 0.504307004001181, 1.6152414379651936), ({'n_units': 500, 'dropout_rate': 0.6}, 0.59857120288053378, 1.6162240703587956), ({'n_units': 400, 'dropout_rate': 0.5}, 0.47341989734126644, 1.6259167576841613), ({'n_units': 100, 'dropout_rate': 0.6}, 0.54455921454377665, 1.6427382750218684), ({'n_units': 400, 'dropout_rate': 0.2}, 0.5366408428181747, 1.6681472163800755), ({'n_units': 300, 'dropout_rate': 0.6}, 0.48633242255983278, 1.6787487889101085), ({'n_units': 200, 'dropout_rate': 0.6}, 0.49289599137502488, 1.7985499846661066), ({'n_units': 100, 'dropout_rate': 0.3}, 0.44932897699947222, 1.8033458072466655), ({'n_units': 100, 'dropout_rate': 0.2}, 0.3903179229370185, 1.8282896406852354), ({'n_units': 400, 'dropout_rate': 0.6}, 0.44465584106220168, 1.8765761652620117), ({'n_units': 200, 'dropout_rate': 0.2}, 0.42835523202546294, 1.9091582352567624), ({'n_units': 300, 'dropout_rate': 0.2}, 0.34741707758450335, 1.9094790684698184), ({'n_units': 300, 'dropout_rate': 0.5}, 0.38815885929810218, 1.9170133194404326), ({'n_units': 200, 'dropout_rate': 0.3}, 0.37065300377532295, 1.9826960536539318), ({'n_units': 500, 'dropout_rate': 0.2}, 0.37597473393629594, 2.0033557432327092), ({'n_units': 400, 'dropout_rate': 0.3}, 0.35689450199862371, 2.0348097482589438), ({'n_units': 500, 'dropout_rate': 0.3}, 0.42181570186453354, 2.0403739003475097), ({'n_units': 300, 'dropout_rate': 0.3}, 0.43052502507952745, 2.1053003341524805)]

... under metric (loss), best score: 0.655506, gap: 1.249459
... model config: {'n_units': 100, 'dropout_rate': 0.5}

... performance ranking (n_models:24 -> 6):
[({'n_units': 100, 'dropout_rate': 0.2}, 0.81446731229093972, 0.10104923319489445), ({'n_units': 200, 'dropout_rate': 0.3}, 0.82590799032920204, 0.11503228411451272), ({'n_units': 300, 'dropout_rate': 0.5}, 0.80853510898770209, 0.12393058921369082), ({'n_units': 400, 'dropout_rate': 0.3}, 0.83480629542838014, 0.15754640842273038), ({'n_units': 500, 'dropout_rate': 0.2}, 0.82996368028638445, 0.16527441474966131), ({'n_units': 300, 'dropout_rate': 0.2}, 0.8371670702179177, 0.17600887812752231)]

... under metric (acc), best score: 0.814467, gap: 0.101049
... model config: {'n_units': 100, 'dropout_rate': 0.2}

... performance ranking (n_models:24 -> 24):
[({'n_units': 50, 'dropout_rate': 0.3}, 0.87841417938110045, 0.0010231211985954891), ({'n_units': 100, 'dropout_rate': 0.6}, 0.87982889246421059, 0.0014296662913300118), ({'n_units': 100, 'dropout_rate': 0.5}, 0.87083483792967731, 0.0014937509251179426), ({'n_units': 50, 'dropout_rate': 0.5}, 0.85855259521532867, 0.001597545274906742), ({'n_units': 300, 'dropout_rate': 0.3}, 0.88704702113788869, 0.0018009213356359188), ({'n_units': 50, 'dropout_rate': 0.2}, 0.87259735356808865, 0.0018702712821037082), ({'n_units': 100, 'dropout_rate': 0.3}, 0.89185923397108069, 0.0018756143935176883), ({'n_units': 200, 'dropout_rate': 0.3}, 0.90313338358812134, 0.0019444090065405817), ({'n_units': 50, 'dropout_rate': 0.6}, 0.8554551984582629, 0.001979843342467702), ({'n_units': 400, 'dropout_rate': 0.6}, 0.88347182653429424, 0.0019845864626552023), ({'n_units': 100, 'dropout_rate': 0.2}, 0.89954575239601786, 0.0019883770053670258), ({'n_units': 400, 'dropout_rate': 0.5}, 0.89095236738426631, 0.0020344237967591106), ({'n_units': 300, 'dropout_rate': 0.6}, 0.88456663196369756, 0.002057290481308649), ({'n_units': 200, 'dropout_rate': 0.6}, 0.88282993165979096, 0.0020784648172886833), ({'n_units': 200, 'dropout_rate': 0.5}, 0.88636900231278248, 0.0021141330304891293), ({'n_units': 400, 'dropout_rate': 0.2}, 0.87143393131491642, 0.0023071781101489108), ({'n_units': 500, 'dropout_rate': 0.6}, 0.86326294554347849, 0.0023438192404885427), ({'n_units': 500, 'dropout_rate': 0.3}, 0.88206357585027217, 0.0023795476452391773), ({'n_units': 500, 'dropout_rate': 0.2}, 0.89037119242527285, 0.0024652289997867394), ({'n_units': 500, 'dropout_rate': 0.5}, 0.88473400063722529, 0.0024800361116824599), ({'n_units': 300, 'dropout_rate': 0.2}, 0.88585208566367757, 0.0025656048235536133), ({'n_units': 200, 'dropout_rate': 0.2}, 0.88753603558274796, 0.0025766745847111139), ({'n_units': 400, 'dropout_rate': 0.3}, 0.88844752912082614, 0.0025781034653566959), ({'n_units': 300, 'dropout_rate': 0.5}, 0.88367983737811628, 0.0026058604295836618)]

... under metric (auc_roc), best score: 0.878414, gap: 0.001023
... model config: {'n_units': 50, 'dropout_rate': 0.3}

result> popular 10 model (out of 13 metric-neutral options with topN=5) ...
  + (n_selected=2) model: (('n_units', 100), ('dropout_rate', 0.5))
  + (n_selected=2) model: (('n_units', 50), ('dropout_rate', 0.3))
  + (n_selected=1) model: (('n_units', 100), ('dropout_rate', 0.2))
  + (n_selected=1) model: (('n_units', 300), ('dropout_rate', 0.3))
  + (n_selected=1) model: (('n_units', 200), ('dropout_rate', 0.5))
  + (n_selected=1) model: (('n_units', 300), ('dropout_rate', 0.5))
  + (n_selected=1) model: (('n_units', 200), ('dropout_rate', 0.3))
  + (n_selected=1) model: (('n_units', 500), ('dropout_rate', 0.2))
  + (n_selected=1) model: (('n_units', 50), ('dropout_rate', 0.5))
  + (n_selected=1) model: (('n_units', 50), ('dropout_rate', 0.2))
result> best configuration:
{'n_units': 100, 'dropout_rate': 0.5}

model_select> opt model:
{'n_units': 100, 'dropout_rate': 0.5}

make_lstm> n_units=100, r_dropout=0.500000, n_layers=1, n_classes=6
... classifier name: Sequential
runROCMulticlass> test set ratio: 0.300000
modelEvaluate> dim(X_train):(1651, 50, 100), dim(X_test): (709, 50, 100)
  + lookup:
{'Others': 5, 'CKD Stage 5': 4, 'CKD Stage 4': 3, 'CKD Stage 3': 2, 'CKD Stage 2': 1, 'CKD Stage 1': 0}

... class weights:
{0: 6.344086021505376, 1: 0.74494949494949492, 2: 1.1238095238095238, 3: 7.0238095238095237, 4: 0.51890941072999119, 5: 0.64906490649064907}

====================================================================================================
... early stopping>
       + patience: 20, model='max'
... model training>
       + batch_size: 32, epochs: 80, shuffle? True, metric: auc_roc
====================================================================================================
Epoch 1/80
1651/1651 [==============================] - 6s 3ms/step - loss: 1.7418 - acc: 0.2810 - auc_roc: 0.5874  
/Users/pleiades/anaconda2/lib/python2.7/site-packages/keras/callbacks.py:526: RuntimeWarning:

Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: acc,loss,auc_roc

Epoch 2/80
1651/1651 [==============================] - 3s 2ms/step - loss: 1.5078 - acc: 0.4288 - auc_roc: 0.6791
Epoch 3/80
1651/1651 [==============================] - 4s 2ms/step - loss: 1.3820 - acc: 0.4500 - auc_roc: 0.7069
Epoch 4/80
1651/1651 [==============================] - 4s 2ms/step - loss: 1.2644 - acc: 0.4870 - auc_roc: 0.7382
Epoch 5/80
1651/1651 [==============================] - 4s 2ms/step - loss: 1.1536 - acc: 0.5366 - auc_roc: 0.7607
Epoch 6/80
1651/1651 [==============================] - 3s 2ms/step - loss: 1.0791 - acc: 0.5572 - auc_roc: 0.7819
Epoch 7/80
1651/1651 [==============================] - 3s 2ms/step - loss: 1.0297 - acc: 0.5766 - auc_roc: 0.7980
Epoch 8/80
1651/1651 [==============================] - 3s 2ms/step - loss: 0.9407 - acc: 0.5887 - auc_roc: 0.8108
Epoch 9/80
1651/1651 [==============================] - 3s 2ms/step - loss: 0.9081 - acc: 0.6190 - auc_roc: 0.8225
Epoch 10/80
1651/1651 [==============================] - 4s 2ms/step - loss: 0.8341 - acc: 0.6227 - auc_roc: 0.8323
Epoch 11/80
1651/1651 [==============================] - 4s 2ms/step - loss: 0.8103 - acc: 0.6463 - auc_roc: 0.8412
Epoch 12/80
1651/1651 [==============================] - 3s 2ms/step - loss: 0.7591 - acc: 0.6451 - auc_roc: 0.8480
Epoch 13/80
1651/1651 [==============================] - 3s 2ms/step - loss: 0.7586 - acc: 0.6644 - auc_roc: 0.8548
Epoch 14/80
1651/1651 [==============================] - 3s 2ms/step - loss: 0.6695 - acc: 0.6753 - auc_roc: 0.8614
Epoch 15/80
1651/1651 [==============================] - 3s 2ms/step - loss: 0.6446 - acc: 0.6838 - auc_roc: 0.8672
Epoch 16/80
1651/1651 [==============================] - 3s 2ms/step - loss: 0.6270 - acc: 0.6984 - auc_roc: 0.8724
Epoch 17/80
1651/1651 [==============================] - 4s 2ms/step - loss: 0.6260 - acc: 0.7081 - auc_roc: 0.8776
Epoch 18/80
1651/1651 [==============================] - 4s 2ms/step - loss: 0.5836 - acc: 0.7365 - auc_roc: 0.8822
Epoch 19/80
1651/1651 [==============================] - 4s 2ms/step - loss: 0.5346 - acc: 0.7389 - auc_roc: 0.8870
Epoch 20/80
1651/1651 [==============================] - 4s 2ms/step - loss: 0.4920 - acc: 0.7583 - auc_roc: 0.8914
Epoch 21/80
1651/1651 [==============================] - 4s 2ms/step - loss: 0.4808 - acc: 0.7638 - auc_roc: 0.8959
Epoch 22/80
1651/1651 [==============================] - 4s 2ms/step - loss: 0.4630 - acc: 0.7741 - auc_roc: 0.8995
Epoch 23/80
1651/1651 [==============================] - 4s 2ms/step - loss: 0.4330 - acc: 0.7916 - auc_roc: 0.9034
Epoch 24/80
1651/1651 [==============================] - 4s 2ms/step - loss: 0.4225 - acc: 0.7916 - auc_roc: 0.9069
Epoch 25/80
1651/1651 [==============================] - 4s 2ms/step - loss: 0.3686 - acc: 0.8159 - auc_roc: 0.9104
Epoch 26/80
1651/1651 [==============================] - 3s 2ms/step - loss: 0.3750 - acc: 0.8141 - auc_roc: 0.9138
Epoch 27/80
1651/1651 [==============================] - 4s 2ms/step - loss: 0.3705 - acc: 0.8243 - auc_roc: 0.9170
Epoch 28/80
1651/1651 [==============================] - 3s 2ms/step - loss: 0.3203 - acc: 0.8455 - auc_roc: 0.9200
Epoch 29/80
1651/1651 [==============================] - 4s 2ms/step - loss: 0.2961 - acc: 0.8565 - auc_roc: 0.9232
Epoch 30/80
1651/1651 [==============================] - 4s 2ms/step - loss: 0.2673 - acc: 0.8795 - auc_roc: 0.9261
Epoch 31/80
1651/1651 [==============================] - 3s 2ms/step - loss: 0.2713 - acc: 0.8783 - auc_roc: 0.9290
Epoch 32/80
1651/1651 [==============================] - 4s 2ms/step - loss: 0.5662 - acc: 0.7680 - auc_roc: 0.9310
Epoch 33/80
1651/1651 [==============================] - 4s 2ms/step - loss: 0.3782 - acc: 0.8286 - auc_roc: 0.9325
Epoch 34/80
1651/1651 [==============================] - 4s 2ms/step - loss: 0.3829 - acc: 0.8328 - auc_roc: 0.9344
Epoch 35/80
1651/1651 [==============================] - 3s 2ms/step - loss: 0.3373 - acc: 0.8449 - auc_roc: 0.9360
Epoch 36/80
1651/1651 [==============================] - 4s 2ms/step - loss: 0.2281 - acc: 0.8928 - auc_roc: 0.9381
Epoch 37/80
1651/1651 [==============================] - 4s 2ms/step - loss: 0.1983 - acc: 0.9110 - auc_roc: 0.9402
Epoch 38/80
1651/1651 [==============================] - 4s 2ms/step - loss: 0.1964 - acc: 0.9140 - auc_roc: 0.9423
Epoch 39/80
1651/1651 [==============================] - 3s 2ms/step - loss: 0.2210 - acc: 0.9001 - auc_roc: 0.9443
Epoch 40/80
1651/1651 [==============================] - 3s 2ms/step - loss: 0.1567 - acc: 0.9297 - auc_roc: 0.9462
Epoch 41/80
1651/1651 [==============================] - 4s 2ms/step - loss: 0.1607 - acc: 0.9249 - auc_roc: 0.9481
Epoch 42/80
1651/1651 [==============================] - 4s 2ms/step - loss: 0.2232 - acc: 0.9013 - auc_roc: 0.9498
Epoch 43/80
1651/1651 [==============================] - 4s 2ms/step - loss: 0.2307 - acc: 0.9188 - auc_roc: 0.9512
Epoch 44/80
1651/1651 [==============================] - 3s 2ms/step - loss: 0.2239 - acc: 0.9055 - auc_roc: 0.9527
Epoch 45/80
1651/1651 [==============================] - 4s 2ms/step - loss: 0.1754 - acc: 0.9291 - auc_roc: 0.9540
Epoch 46/80
1651/1651 [==============================] - 4s 2ms/step - loss: 0.1134 - acc: 0.9570 - auc_roc: 0.9555
Epoch 47/80
1651/1651 [==============================] - 4s 2ms/step - loss: 0.1122 - acc: 0.9552 - auc_roc: 0.9569
Epoch 48/80
1651/1651 [==============================] - 4s 2ms/step - loss: 0.0846 - acc: 0.9727 - auc_roc: 0.9584
Epoch 49/80
1651/1651 [==============================] - 4s 2ms/step - loss: 0.3626 - acc: 0.8692 - auc_roc: 0.9594
Epoch 50/80
1651/1651 [==============================] - 4s 2ms/step - loss: 0.2106 - acc: 0.9152 - auc_roc: 0.9602
Epoch 51/80
1651/1651 [==============================] - 4s 2ms/step - loss: 0.1493 - acc: 0.9419 - auc_roc: 0.9612
Epoch 52/80
1651/1651 [==============================] - 4s 2ms/step - loss: 0.0980 - acc: 0.9649 - auc_roc: 0.9623
Epoch 53/80
1651/1651 [==============================] - 4s 2ms/step - loss: 0.0839 - acc: 0.9697 - auc_roc: 0.9635
Epoch 54/80
1651/1651 [==============================] - 3s 2ms/step - loss: 0.0787 - acc: 0.9727 - auc_roc: 0.9646
Epoch 55/80
1651/1651 [==============================] - 4s 2ms/step - loss: 0.0647 - acc: 0.9794 - auc_roc: 0.9657
Epoch 56/80
1651/1651 [==============================] - 4s 2ms/step - loss: 0.0506 - acc: 0.9836 - auc_roc: 0.9668
Epoch 57/80
1651/1651 [==============================] - 4s 2ms/step - loss: 0.0664 - acc: 0.9709 - auc_roc: 0.9678
Epoch 58/80
1651/1651 [==============================] - 4s 2ms/step - loss: 0.0932 - acc: 0.9715 - auc_roc: 0.9687
Epoch 59/80
1651/1651 [==============================] - 3s 2ms/step - loss: 0.1094 - acc: 0.9588 - auc_roc: 0.9695
Epoch 60/80
1651/1651 [==============================] - 4s 2ms/step - loss: 0.0640 - acc: 0.9764 - auc_roc: 0.9703
Epoch 61/80
1651/1651 [==============================] - 4s 2ms/step - loss: 0.0464 - acc: 0.9873 - auc_roc: 0.9712
Epoch 62/80
1651/1651 [==============================] - 4s 2ms/step - loss: 0.0320 - acc: 0.9903 - auc_roc: 0.9720
Epoch 63/80
1651/1651 [==============================] - 4s 2ms/step - loss: 0.0316 - acc: 0.9909 - auc_roc: 0.9728
Epoch 64/80
1651/1651 [==============================] - 4s 2ms/step - loss: 0.0699 - acc: 0.9782 - auc_roc: 0.9736
Epoch 65/80
1651/1651 [==============================] - 4s 2ms/step - loss: 0.0509 - acc: 0.9861 - auc_roc: 0.9743
Epoch 66/80
1651/1651 [==============================] - 4s 2ms/step - loss: 0.0357 - acc: 0.9903 - auc_roc: 0.9749
Epoch 67/80
1651/1651 [==============================] - 4s 2ms/step - loss: 0.0259 - acc: 0.9927 - auc_roc: 0.9756
Epoch 68/80
1651/1651 [==============================] - 4s 2ms/step - loss: 0.0222 - acc: 0.9927 - auc_roc: 0.9763
Epoch 69/80
1651/1651 [==============================] - 4s 2ms/step - loss: 0.0225 - acc: 0.9927 - auc_roc: 0.9769
Epoch 70/80
1651/1651 [==============================] - 4s 2ms/step - loss: 0.0677 - acc: 0.9788 - auc_roc: 0.9776
Epoch 71/80
1651/1651 [==============================] - 4s 2ms/step - loss: 0.1216 - acc: 0.9534 - auc_roc: 0.9780
Epoch 72/80
1651/1651 [==============================] - 4s 2ms/step - loss: 0.0836 - acc: 0.9758 - auc_roc: 0.9784
Epoch 73/80
1651/1651 [==============================] - 4s 3ms/step - loss: 0.1613 - acc: 0.9334 - auc_roc: 0.9788
Epoch 74/80
1651/1651 [==============================] - 4s 2ms/step - loss: 0.0976 - acc: 0.9661 - auc_roc: 0.9792
Epoch 75/80
1651/1651 [==============================] - 4s 2ms/step - loss: 0.1233 - acc: 0.9564 - auc_roc: 0.9795
Epoch 76/80
1651/1651 [==============================] - 4s 2ms/step - loss: 0.1186 - acc: 0.9655 - auc_roc: 0.9799
Epoch 77/80
1651/1651 [==============================] - 4s 2ms/step - loss: 0.3197 - acc: 0.8643 - auc_roc: 0.9801
Epoch 78/80
1651/1651 [==============================] - 4s 2ms/step - loss: 0.1508 - acc: 0.9346 - auc_roc: 0.9802
Epoch 79/80
1651/1651 [==============================] - 4s 2ms/step - loss: 0.1057 - acc: 0.9631 - auc_roc: 0.9805
Epoch 80/80
1651/1651 [==============================] - 4s 2ms/step - loss: 0.0817 - acc: 0.9703 - auc_roc: 0.9809
... history of metrics comprising: ['acc', 'loss', 'auc_roc']
... model fitting complete > starting model evaluation
modelEvaluate> scores:
[('loss', 1.943959528031235), ('acc', 0.60225669966093742), ('auc_roc', 0.98063528705887459)]

info> infer classifier name from class name ...
runROCMulticlass> find 6 unique labels:
CKD Stage 1, CKD Stage 2, CKD Stage 3, CKD Stage 4, CKD Stage 5, Others

info> given pre-trained model ...
diagnosis> dim(y_score):(709, 6)
>>> test_auc_cv_metrics >>>
  + dimension test 
  + len(roc_auc):8 =?= n_classes (+{micro, macro}):6+2
  + class name: CKD Stage 1, mean_auc: 0.833519
  + ROC curve of class CKD Stage 1 (area = 0.83)
  + class name: CKD Stage 2, mean_auc: 0.763158
  + ROC curve of class CKD Stage 2 (area = 0.76)
  + class name: CKD Stage 3, mean_auc: 0.755208
  + ROC curve of class CKD Stage 3 (area = 0.76)
  + class name: CKD Stage 4, mean_auc: 0.717360
  + ROC curve of class CKD Stage 4 (area = 0.72)
  + class name: CKD Stage 5, mean_auc: 0.951816
  + ROC curve of class CKD Stage 5 (area = 0.95)
  + class name: Others, mean_auc: 0.817881
  + ROC curve of class Others (area = 0.82)
test_auc_cv_metrics> summary of AUCs vs classes ...
  + min | class=CKD Stage 4, auc=0.717360
  + max | class=CKD Stage 5, auc=0.951816
  + micro auc=0.872955 | macro auc=0.807485
  + Ranked AUC scores: 
    + class=CKD Stage 4, auc=0.717360
    + class=CKD Stage 3, auc=0.755208
    + class=CKD Stage 2, auc=0.763158
    + class=Others, auc=0.817881
    + class=CKD Stage 1, auc=0.833519
    + class=CKD Stage 5, auc=0.951816
  => [('CKD Stage 4', 0.7173601147776183), ('CKD Stage 3', 0.75520781586355346), ('CKD Stage 2', 0.76315789473684215), ('Others', 0.81788125013224999), ('CKD Stage 1', 0.83351926977687629), ('CKD Stage 5', 0.95181591950084754)]
output> saving performance to:
/Users/pleiades/Documents/work/tpheno/seqmaker/data/CKD/plot/roc-multiclass-Sequential-CKD-pv-dm2-regular-smallCKD.tif

runROCMulticlass> test set ratio: 0.300000
modelEvaluate> dim(X_train):(1651, 50, 100), dim(X_test): (709, 50, 100)
  + lookup:
{'Others': 5, 'CKD Stage 5': 4, 'CKD Stage 4': 3, 'CKD Stage 3': 2, 'CKD Stage 2': 1, 'CKD Stage 1': 0}

... class weights:
{0: 6.344086021505376, 1: 0.74494949494949492, 2: 1.1238095238095238, 3: 7.0238095238095237, 4: 0.51890941072999119, 5: 0.64906490649064907}

====================================================================================================
... early stopping>
       + patience: 20, model='max'
... model training>
       + batch_size: 32, epochs: 80, shuffle? True, metric: auc_roc
====================================================================================================
Epoch 1/80
1651/1651 [==============================] - 3s 2ms/step - loss: 1.7830 - acc: 0.2392 - auc_roc: 0.9795
Epoch 2/80
1651/1651 [==============================] - 4s 2ms/step - loss: 1.6869 - acc: 0.3071 - auc_roc: 0.9780
Epoch 3/80
1651/1651 [==============================] - 4s 2ms/step - loss: 1.5650 - acc: 0.4228 - auc_roc: 0.9766
Epoch 4/80
1651/1651 [==============================] - 4s 2ms/step - loss: 1.4171 - acc: 0.4282 - auc_roc: 0.9755
Epoch 5/80
1651/1651 [==============================] - 4s 2ms/step - loss: 1.2746 - acc: 0.5009 - auc_roc: 0.9745
Epoch 6/80
1651/1651 [==============================] - 4s 2ms/step - loss: 1.2489 - acc: 0.5027 - auc_roc: 0.9736
Epoch 7/80
1651/1651 [==============================] - 4s 2ms/step - loss: 1.2167 - acc: 0.4870 - auc_roc: 0.9725
Epoch 8/80
1651/1651 [==============================] - 4s 2ms/step - loss: 1.0806 - acc: 0.5463 - auc_roc: 0.9717
Epoch 9/80
1651/1651 [==============================] - 4s 2ms/step - loss: 1.0043 - acc: 0.5863 - auc_roc: 0.9711
Epoch 10/80
1651/1651 [==============================] - 4s 2ms/step - loss: 0.9631 - acc: 0.5984 - auc_roc: 0.9704
Epoch 11/80
1651/1651 [==============================] - 4s 2ms/step - loss: 0.9463 - acc: 0.6002 - auc_roc: 0.9698
Epoch 12/80
1651/1651 [==============================] - 4s 2ms/step - loss: 0.9000 - acc: 0.6184 - auc_roc: 0.9693
Epoch 13/80
1651/1651 [==============================] - 4s 2ms/step - loss: 0.8445 - acc: 0.6323 - auc_roc: 0.9688
Epoch 14/80
1651/1651 [==============================] - 4s 2ms/step - loss: 0.7776 - acc: 0.6420 - auc_roc: 0.9683
Epoch 15/80
1651/1651 [==============================] - 4s 2ms/step - loss: 0.7620 - acc: 0.6505 - auc_roc: 0.9679
Epoch 16/80
1651/1651 [==============================] - 4s 3ms/step - loss: 0.7448 - acc: 0.6626 - auc_roc: 0.9676
Epoch 17/80
1651/1651 [==============================] - 4s 2ms/step - loss: 0.7766 - acc: 0.6475 - auc_roc: 0.9672
Epoch 18/80
1651/1651 [==============================] - 4s 3ms/step - loss: 0.6725 - acc: 0.6796 - auc_roc: 0.9669
Epoch 19/80
1651/1651 [==============================] - 4s 2ms/step - loss: 0.6315 - acc: 0.6947 - auc_roc: 0.9666
Epoch 20/80
1651/1651 [==============================] - 4s 2ms/step - loss: 0.5933 - acc: 0.7081 - auc_roc: 0.9665
Epoch 21/80
1651/1651 [==============================] - 4s 2ms/step - loss: 0.6248 - acc: 0.7044 - auc_roc: 0.9662
Epoch 22/80
1651/1651 [==============================] - 4s 2ms/step - loss: 0.5407 - acc: 0.7317 - auc_roc: 0.9661
Epoch 23/80
1651/1651 [==============================] - 4s 2ms/step - loss: 0.5491 - acc: 0.7311 - auc_roc: 0.9660
Epoch 24/80
1651/1651 [==============================] - 4s 2ms/step - loss: 0.5919 - acc: 0.7159 - auc_roc: 0.9659
Epoch 25/80
1651/1651 [==============================] - 4s 2ms/step - loss: 0.5507 - acc: 0.7371 - auc_roc: 0.9658
Epoch 26/80
1651/1651 [==============================] - 4s 2ms/step - loss: 0.5605 - acc: 0.7420 - auc_roc: 0.9656
Epoch 27/80
1651/1651 [==============================] - 4s 2ms/step - loss: 0.6011 - acc: 0.7268 - auc_roc: 0.9655
Epoch 28/80
1651/1651 [==============================] - 4s 2ms/step - loss: 0.5129 - acc: 0.7626 - auc_roc: 0.9654
Epoch 29/80
1651/1651 [==============================] - 4s 2ms/step - loss: 0.4754 - acc: 0.7620 - auc_roc: 0.9654
Epoch 30/80
1651/1651 [==============================] - 4s 2ms/step - loss: 0.4285 - acc: 0.7916 - auc_roc: 0.9654
Epoch 31/80
1651/1651 [==============================] - 4s 2ms/step - loss: 0.4035 - acc: 0.8086 - auc_roc: 0.9655
Epoch 32/80
1651/1651 [==============================] - 4s 2ms/step - loss: 0.4582 - acc: 0.7874 - auc_roc: 0.9656
Epoch 33/80
1651/1651 [==============================] - 4s 2ms/step - loss: 0.3760 - acc: 0.8128 - auc_roc: 0.9656
Epoch 34/80
1651/1651 [==============================] - 4s 2ms/step - loss: 0.3538 - acc: 0.8304 - auc_roc: 0.9657
Epoch 35/80
1651/1651 [==============================] - 4s 2ms/step - loss: 0.3267 - acc: 0.8389 - auc_roc: 0.9659
Epoch 36/80
1651/1651 [==============================] - 4s 2ms/step - loss: 0.3067 - acc: 0.8534 - auc_roc: 0.9661
Epoch 37/80
1651/1651 [==============================] - 4s 2ms/step - loss: 0.3090 - acc: 0.8516 - auc_roc: 0.9662
Epoch 38/80
1651/1651 [==============================] - 4s 2ms/step - loss: 0.3361 - acc: 0.8468 - auc_roc: 0.9664
Epoch 39/80
1651/1651 [==============================] - 4s 2ms/step - loss: 0.4431 - acc: 0.7904 - auc_roc: 0.9664
Epoch 40/80
1651/1651 [==============================] - 4s 2ms/step - loss: 0.2962 - acc: 0.8686 - auc_roc: 0.9665
Epoch 41/80
1651/1651 [==============================] - 4s 2ms/step - loss: 0.2588 - acc: 0.8795 - auc_roc: 0.9667
Epoch 42/80
1651/1651 [==============================] - 4s 2ms/step - loss: 0.2082 - acc: 0.9043 - auc_roc: 0.9670
Epoch 43/80
1651/1651 [==============================] - 4s 2ms/step - loss: 0.2070 - acc: 0.9110 - auc_roc: 0.9673
Epoch 44/80
1651/1651 [==============================] - 4s 2ms/step - loss: 0.3870 - acc: 0.8110 - auc_roc: 0.9674
Epoch 45/80
1651/1651 [==============================] - 4s 2ms/step - loss: 0.3041 - acc: 0.8625 - auc_roc: 0.9675
Epoch 46/80
1651/1651 [==============================] - 4s 2ms/step - loss: 0.2401 - acc: 0.8946 - auc_roc: 0.9677
Epoch 47/80
1651/1651 [==============================] - 4s 2ms/step - loss: 0.2462 - acc: 0.8892 - auc_roc: 0.9680
Epoch 48/80
1651/1651 [==============================] - 4s 2ms/step - loss: 0.2721 - acc: 0.8855 - auc_roc: 0.9681
Epoch 49/80
1651/1651 [==============================] - 4s 2ms/step - loss: 0.2289 - acc: 0.8982 - auc_roc: 0.9683
Epoch 50/80
1651/1651 [==============================] - 4s 2ms/step - loss: 0.2451 - acc: 0.9055 - auc_roc: 0.9686
Epoch 51/80
1651/1651 [==============================] - 4s 2ms/step - loss: 0.3233 - acc: 0.8607 - auc_roc: 0.9687
Epoch 52/80
1651/1651 [==============================] - 4s 2ms/step - loss: 0.2842 - acc: 0.8910 - auc_roc: 0.9689
Epoch 53/80
1651/1651 [==============================] - 4s 2ms/step - loss: 0.1765 - acc: 0.9267 - auc_roc: 0.9691
Epoch 54/80
1651/1651 [==============================] - 4s 2ms/step - loss: 0.1667 - acc: 0.9291 - auc_roc: 0.9694
Epoch 55/80
1651/1651 [==============================] - 4s 2ms/step - loss: 0.1280 - acc: 0.9503 - auc_roc: 0.9697
Epoch 56/80
1651/1651 [==============================] - 4s 2ms/step - loss: 0.1108 - acc: 0.9461 - auc_roc: 0.9700
Epoch 57/80
1651/1651 [==============================] - 4s 2ms/step - loss: 0.0920 - acc: 0.9679 - auc_roc: 0.9704
Epoch 58/80
1651/1651 [==============================] - 4s 2ms/step - loss: 0.0943 - acc: 0.9667 - auc_roc: 0.9707
Epoch 59/80
1651/1651 [==============================] - 4s 2ms/step - loss: 0.0849 - acc: 0.9612 - auc_roc: 0.9710
Epoch 60/80
1651/1651 [==============================] - 4s 2ms/step - loss: 0.0711 - acc: 0.9643 - auc_roc: 0.9713
Epoch 61/80
1651/1651 [==============================] - 4s 2ms/step - loss: 0.1917 - acc: 0.9279 - auc_roc: 0.9716
Epoch 62/80
1651/1651 [==============================] - 4s 2ms/step - loss: 0.4356 - acc: 0.8480 - auc_roc: 0.9717
Epoch 63/80
1651/1651 [==============================] - 4s 2ms/step - loss: 0.2247 - acc: 0.9061 - auc_roc: 0.9718
Epoch 64/80
1651/1651 [==============================] - 4s 2ms/step - loss: 0.1472 - acc: 0.9400 - auc_roc: 0.9721
Epoch 65/80
1651/1651 [==============================] - 4s 2ms/step - loss: 0.1112 - acc: 0.9546 - auc_roc: 0.9723
Epoch 66/80
1651/1651 [==============================] - 4s 2ms/step - loss: 0.0937 - acc: 0.9655 - auc_roc: 0.9726
Epoch 67/80
1651/1651 [==============================] - 4s 2ms/step - loss: 0.0779 - acc: 0.9709 - auc_roc: 0.9729
Epoch 68/80
1651/1651 [==============================] - 4s 2ms/step - loss: 0.0615 - acc: 0.9843 - auc_roc: 0.9732
Epoch 69/80
1651/1651 [==============================] - 4s 2ms/step - loss: 0.0554 - acc: 0.9824 - auc_roc: 0.9735
Epoch 70/80
1651/1651 [==============================] - 4s 2ms/step - loss: 0.0418 - acc: 0.9873 - auc_roc: 0.9738
Epoch 71/80
1651/1651 [==============================] - 4s 2ms/step - loss: 0.0674 - acc: 0.9740 - auc_roc: 0.9741
Epoch 72/80
1651/1651 [==============================] - 4s 2ms/step - loss: 0.0567 - acc: 0.9788 - auc_roc: 0.9744
Epoch 73/80
1651/1651 [==============================] - 4s 2ms/step - loss: 0.0654 - acc: 0.9752 - auc_roc: 0.9747
Epoch 74/80
1651/1651 [==============================] - 4s 2ms/step - loss: 0.0640 - acc: 0.9764 - auc_roc: 0.9749
Epoch 75/80
1651/1651 [==============================] - 4s 2ms/step - loss: 0.0610 - acc: 0.9800 - auc_roc: 0.9752
Epoch 76/80
1651/1651 [==============================] - 4s 2ms/step - loss: 0.2396 - acc: 0.8928 - auc_roc: 0.9754
Epoch 77/80
1651/1651 [==============================] - 4s 2ms/step - loss: 0.1528 - acc: 0.9279 - auc_roc: 0.9755
Epoch 78/80
1651/1651 [==============================] - 4s 2ms/step - loss: 0.0924 - acc: 0.9631 - auc_roc: 0.9757
Epoch 79/80
1651/1651 [==============================] - 4s 2ms/step - loss: 0.0578 - acc: 0.9758 - auc_roc: 0.9760
Epoch 80/80
1651/1651 [==============================] - 4s 2ms/step - loss: 0.0415 - acc: 0.9879 - auc_roc: 0.9762
... history of metrics comprising: ['acc', 'loss', 'auc_roc']
... model fitting complete > starting model evaluation
modelEvaluate> scores:
[('loss', 2.3512535767763727), ('acc', 0.588152327263473), ('auc_roc', 0.97609508903473829)]

info> infer classifier name from class name ...
runROCMulticlass> find 6 unique labels:
CKD Stage 1, CKD Stage 2, CKD Stage 3, CKD Stage 4, CKD Stage 5, Others

info> given pre-trained model ...
diagnosis> dim(y_score):(709, 6)
>>> test_auc_cv_metrics >>>
  + dimension test 
  + len(roc_auc):8 =?= n_classes (+{micro, macro}):6+2
  + class name: CKD Stage 1, mean_auc: 0.894469
  + ROC curve of class CKD Stage 1 (area = 0.89)
  + class name: CKD Stage 2, mean_auc: 0.763859
  + ROC curve of class CKD Stage 2 (area = 0.76)
  + class name: CKD Stage 3, mean_auc: 0.700719
  + ROC curve of class CKD Stage 3 (area = 0.70)
  + class name: CKD Stage 4, mean_auc: 0.699232
  + ROC curve of class CKD Stage 4 (area = 0.70)
  + class name: CKD Stage 5, mean_auc: 0.944577
  + ROC curve of class CKD Stage 5 (area = 0.94)
  + class name: Others, mean_auc: 0.819797
  + ROC curve of class Others (area = 0.82)
test_auc_cv_metrics> summary of AUCs vs classes ...
  + min | class=CKD Stage 4, auc=0.699232
  + max | class=CKD Stage 5, auc=0.944577
  + micro auc=0.859212 | macro auc=0.804865
  + Ranked AUC scores: 
    + class=CKD Stage 4, auc=0.699232
    + class=CKD Stage 3, auc=0.700719
    + class=CKD Stage 2, auc=0.763859
    + class=Others, auc=0.819797
    + class=CKD Stage 1, auc=0.894469
    + class=CKD Stage 5, auc=0.944577
  => [('CKD Stage 4', 0.69923150816522572), ('CKD Stage 3', 0.70071865443425074), ('CKD Stage 2', 0.76385857704059368), ('Others', 0.81979679611045309), ('CKD Stage 1', 0.89446870451237259), ('CKD Stage 5', 0.94457702055237991)]
output> saving performance to:
/Users/pleiades/Documents/work/tpheno/seqmaker/data/CKD/plot/roc-multiclass-Sequential-CKD-pv-dm2-regular-smallCKD.tif

runROCMulticlass> test set ratio: 0.300000
modelEvaluate> dim(X_train):(1651, 50, 100), dim(X_test): (709, 50, 100)
  + lookup:
{'Others': 5, 'CKD Stage 5': 4, 'CKD Stage 4': 3, 'CKD Stage 3': 2, 'CKD Stage 2': 1, 'CKD Stage 1': 0}

... class weights:
{0: 6.344086021505376, 1: 0.74494949494949492, 2: 1.1238095238095238, 3: 7.0238095238095237, 4: 0.51890941072999119, 5: 0.64906490649064907}

====================================================================================================
... early stopping>
       + patience: 20, model='max'
... model training>
       + batch_size: 32, epochs: 80, shuffle? True, metric: auc_roc
====================================================================================================
Epoch 1/80
1651/1651 [==============================] - 4s 2ms/step - loss: 1.8351 - acc: 0.2005 - auc_roc: 0.9754
Epoch 2/80
1651/1651 [==============================] - 4s 3ms/step - loss: 1.7247 - acc: 0.2901 - auc_roc: 0.9746
Epoch 3/80
1651/1651 [==============================] - 4s 2ms/step - loss: 1.6306 - acc: 0.3913 - auc_roc: 0.9739
Epoch 4/80
1651/1651 [==============================] - 4s 2ms/step - loss: 1.4660 - acc: 0.4476 - auc_roc: 0.9733
Epoch 5/80
1651/1651 [==============================] - 4s 2ms/step - loss: 1.3061 - acc: 0.4852 - auc_roc: 0.9728
Epoch 6/80
1651/1651 [==============================] - 4s 2ms/step - loss: 1.2359 - acc: 0.4985 - auc_roc: 0.9723
Epoch 7/80
1651/1651 [==============================] - 4s 2ms/step - loss: 1.1114 - acc: 0.5488 - auc_roc: 0.9718
Epoch 8/80
1651/1651 [==============================] - 4s 2ms/step - loss: 1.0519 - acc: 0.5584 - auc_roc: 0.9715
Epoch 9/80
1651/1651 [==============================] - 4s 2ms/step - loss: 1.0134 - acc: 0.5887 - auc_roc: 0.9711
Epoch 10/80
1651/1651 [==============================] - 4s 2ms/step - loss: 0.9240 - acc: 0.6214 - auc_roc: 0.9708
Epoch 11/80
1651/1651 [==============================] - 4s 2ms/step - loss: 0.9102 - acc: 0.6160 - auc_roc: 0.9705
Epoch 12/80
1651/1651 [==============================] - 4s 2ms/step - loss: 1.0086 - acc: 0.5875 - auc_roc: 0.9702
Epoch 13/80
1651/1651 [==============================] - 4s 2ms/step - loss: 0.8927 - acc: 0.6220 - auc_roc: 0.9699
Epoch 14/80
1651/1651 [==============================] - 4s 2ms/step - loss: 0.7750 - acc: 0.6560 - auc_roc: 0.9697
Epoch 15/80
1651/1651 [==============================] - 4s 2ms/step - loss: 0.7362 - acc: 0.6638 - auc_roc: 0.9695
Epoch 16/80
1651/1651 [==============================] - 4s 2ms/step - loss: 0.7031 - acc: 0.6753 - auc_roc: 0.9693
Epoch 17/80
1651/1651 [==============================] - 4s 2ms/step - loss: 0.6863 - acc: 0.6808 - auc_roc: 0.9691
Epoch 18/80
1651/1651 [==============================] - 4s 2ms/step - loss: 0.6982 - acc: 0.6729 - auc_roc: 0.9689
Epoch 19/80
1651/1651 [==============================] - 4s 2ms/step - loss: 0.6295 - acc: 0.7020 - auc_roc: 0.9688
Epoch 20/80
1651/1651 [==============================] - 4s 2ms/step - loss: 0.6033 - acc: 0.7099 - auc_roc: 0.9686
Epoch 21/80
1651/1651 [==============================] - 4s 2ms/step - loss: 0.5757 - acc: 0.7050 - auc_roc: 0.9685
Epoch 22/80
1651/1651 [==============================] - 4s 2ms/step - loss: 0.5637 - acc: 0.7414 - auc_roc: 0.9684
Epoch 23/80
1651/1651 [==============================] - 4s 2ms/step - loss: 0.5516 - acc: 0.7299 - auc_roc: 0.9684
Epoch 24/80
1651/1651 [==============================] - 4s 2ms/step - loss: 0.5441 - acc: 0.7177 - auc_roc: 0.9683
Epoch 25/80
1651/1651 [==============================] - 4s 2ms/step - loss: 0.4918 - acc: 0.7456 - auc_roc: 0.9682
Epoch 26/80
1651/1651 [==============================] - 4s 2ms/step - loss: 0.4559 - acc: 0.7789 - auc_roc: 0.9682
Epoch 27/80
1651/1651 [==============================] - 4s 2ms/step - loss: 0.4497 - acc: 0.7820 - auc_roc: 0.9682
Epoch 28/80
1651/1651 [==============================] - 4s 2ms/step - loss: 0.4426 - acc: 0.7832 - auc_roc: 0.9682
Epoch 29/80
1651/1651 [==============================] - 4s 2ms/step - loss: 0.5528 - acc: 0.7196 - auc_roc: 0.9682
Epoch 30/80
1651/1651 [==============================] - 4s 2ms/step - loss: 0.5916 - acc: 0.7129 - auc_roc: 0.9680
Epoch 31/80
1651/1651 [==============================] - 4s 2ms/step - loss: 0.4562 - acc: 0.7638 - auc_roc: 0.9680
Epoch 32/80
1651/1651 [==============================] - 4s 2ms/step - loss: 0.4118 - acc: 0.7922 - auc_roc: 0.9680
Epoch 33/80
1651/1651 [==============================] - 4s 2ms/step - loss: 0.3650 - acc: 0.8213 - auc_roc: 0.9680
Epoch 34/80
1651/1651 [==============================] - 4s 2ms/step - loss: 0.3515 - acc: 0.8298 - auc_roc: 0.9681
Epoch 35/80
1651/1651 [==============================] - 4s 2ms/step - loss: 0.3423 - acc: 0.8304 - auc_roc: 0.9681
Epoch 36/80
1651/1651 [==============================] - 4s 2ms/step - loss: 0.3261 - acc: 0.8425 - auc_roc: 0.9682
Epoch 37/80
1651/1651 [==============================] - 4s 2ms/step - loss: 0.3083 - acc: 0.8552 - auc_roc: 0.9683
Epoch 38/80
1651/1651 [==============================] - 4s 2ms/step - loss: 0.2897 - acc: 0.8528 - auc_roc: 0.9684
Epoch 39/80
1651/1651 [==============================] - 4s 2ms/step - loss: 0.2609 - acc: 0.8716 - auc_roc: 0.9685
Epoch 40/80
1651/1651 [==============================] - 4s 2ms/step - loss: 0.3524 - acc: 0.8401 - auc_roc: 0.9686
Epoch 41/80
1651/1651 [==============================] - 4s 2ms/step - loss: 0.4737 - acc: 0.7783 - auc_roc: 0.9686
Epoch 42/80
1651/1651 [==============================] - 4s 2ms/step - loss: 0.3792 - acc: 0.8280 - auc_roc: 0.9687
Epoch 43/80
1651/1651 [==============================] - 4s 2ms/step - loss: 0.2855 - acc: 0.8710 - auc_roc: 0.9687
Epoch 44/80
1651/1651 [==============================] - 4s 2ms/step - loss: 0.2712 - acc: 0.8601 - auc_roc: 0.9689
Epoch 45/80
1651/1651 [==============================] - 4s 2ms/step - loss: 0.2127 - acc: 0.9049 - auc_roc: 0.9690
Epoch 46/80
1651/1651 [==============================] - 4s 2ms/step - loss: 0.1956 - acc: 0.9146 - auc_roc: 0.9691
Epoch 47/80
1651/1651 [==============================] - 4s 2ms/step - loss: 0.1834 - acc: 0.9200 - auc_roc: 0.9693
Epoch 48/80
1651/1651 [==============================] - 4s 2ms/step - loss: 0.5434 - acc: 0.7256 - auc_roc: 0.9693
Epoch 49/80
1651/1651 [==============================] - 4s 2ms/step - loss: 0.3906 - acc: 0.8407 - auc_roc: 0.9693
Epoch 50/80
1651/1651 [==============================] - 4s 2ms/step - loss: 0.2753 - acc: 0.8789 - auc_roc: 0.9694
Epoch 51/80
1651/1651 [==============================] - 4s 2ms/step - loss: 0.2256 - acc: 0.9013 - auc_roc: 0.9695
Epoch 52/80
1651/1651 [==============================] - 4s 2ms/step - loss: 0.2463 - acc: 0.8855 - auc_roc: 0.9696
Epoch 53/80
1651/1651 [==============================] - 4s 3ms/step - loss: 0.1919 - acc: 0.9116 - auc_roc: 0.9698
Epoch 54/80
1651/1651 [==============================] - 4s 2ms/step - loss: 0.1777 - acc: 0.9194 - auc_roc: 0.9699
Epoch 55/80
1651/1651 [==============================] - 4s 2ms/step - loss: 0.1396 - acc: 0.9425 - auc_roc: 0.9701
Epoch 56/80
1651/1651 [==============================] - 4s 2ms/step - loss: 0.1264 - acc: 0.9449 - auc_roc: 0.9703
Epoch 57/80
1651/1651 [==============================] - 4s 2ms/step - loss: 0.1387 - acc: 0.9449 - auc_roc: 0.9705
Epoch 58/80
1651/1651 [==============================] - 4s 2ms/step - loss: 0.1289 - acc: 0.9503 - auc_roc: 0.9707
Epoch 59/80
1651/1651 [==============================] - 4s 2ms/step - loss: 0.2813 - acc: 0.8752 - auc_roc: 0.9708
Epoch 60/80
1651/1651 [==============================] - 4s 2ms/step - loss: 0.1631 - acc: 0.9346 - auc_roc: 0.9709
Epoch 61/80
1651/1651 [==============================] - 4s 2ms/step - loss: 0.1072 - acc: 0.9600 - auc_roc: 0.9711
Epoch 62/80
1651/1651 [==============================] - 4s 2ms/step - loss: 0.0814 - acc: 0.9691 - auc_roc: 0.9713
Epoch 63/80
1651/1651 [==============================] - 4s 2ms/step - loss: 0.0749 - acc: 0.9685 - auc_roc: 0.9715
Epoch 64/80
1651/1651 [==============================] - 4s 2ms/step - loss: 0.0694 - acc: 0.9764 - auc_roc: 0.9717
Epoch 65/80
1651/1651 [==============================] - 4s 2ms/step - loss: 0.0707 - acc: 0.9715 - auc_roc: 0.9719
Epoch 66/80
1651/1651 [==============================] - 4s 2ms/step - loss: 0.0706 - acc: 0.9703 - auc_roc: 0.9721
Epoch 67/80
1651/1651 [==============================] - 4s 2ms/step - loss: 0.4229 - acc: 0.8740 - auc_roc: 0.9722
Epoch 68/80
1651/1651 [==============================] - 4s 2ms/step - loss: 0.2841 - acc: 0.8849 - auc_roc: 0.9723
Epoch 69/80
1651/1651 [==============================] - 4s 2ms/step - loss: 0.1768 - acc: 0.9303 - auc_roc: 0.9724
Epoch 70/80
1651/1651 [==============================] - 4s 2ms/step - loss: 0.2665 - acc: 0.9134 - auc_roc: 0.9725
Epoch 71/80
1651/1651 [==============================] - 4s 2ms/step - loss: 0.1489 - acc: 0.9394 - auc_roc: 0.9727
Epoch 72/80
1651/1651 [==============================] - 4s 2ms/step - loss: 0.1186 - acc: 0.9558 - auc_roc: 0.9728
Epoch 73/80
1651/1651 [==============================] - 4s 2ms/step - loss: 0.1001 - acc: 0.9667 - auc_roc: 0.9730
Epoch 74/80
1651/1651 [==============================] - 4s 2ms/step - loss: 0.0925 - acc: 0.9624 - auc_roc: 0.9732
Epoch 75/80
1651/1651 [==============================] - 4s 2ms/step - loss: 0.0647 - acc: 0.9782 - auc_roc: 0.9734
Epoch 76/80
1651/1651 [==============================] - 4s 2ms/step - loss: 0.0593 - acc: 0.9830 - auc_roc: 0.9735
Epoch 77/80
1651/1651 [==============================] - 4s 2ms/step - loss: 0.0490 - acc: 0.9830 - auc_roc: 0.9737
Epoch 78/80
1651/1651 [==============================] - 4s 2ms/step - loss: 0.0408 - acc: 0.9873 - auc_roc: 0.9739
Epoch 79/80
1651/1651 [==============================] - 4s 2ms/step - loss: 0.0552 - acc: 0.9830 - auc_roc: 0.9741
Epoch 80/80
1651/1651 [==============================] - 4s 2ms/step - loss: 0.0489 - acc: 0.9843 - auc_roc: 0.9743
... history of metrics comprising: ['acc', 'loss', 'auc_roc']
... model fitting complete > starting model evaluation
modelEvaluate> scores:
[('loss', 2.2920552382852528), ('acc', 0.59238363909620495), ('auc_roc', 0.9742259369750621)]

info> infer classifier name from class name ...
runROCMulticlass> find 6 unique labels:
CKD Stage 1, CKD Stage 2, CKD Stage 3, CKD Stage 4, CKD Stage 5, Others

info> given pre-trained model ...
diagnosis> dim(y_score):(709, 6)
>>> test_auc_cv_metrics >>>
  + dimension test 
  + len(roc_auc):8 =?= n_classes (+{micro, macro}):6+2
  + class name: CKD Stage 1, mean_auc: 0.857106
  + ROC curve of class CKD Stage 1 (area = 0.86)
  + class name: CKD Stage 2, mean_auc: 0.764699
  + ROC curve of class CKD Stage 2 (area = 0.76)
  + class name: CKD Stage 3, mean_auc: 0.706504
  + ROC curve of class CKD Stage 3 (area = 0.71)
  + class name: CKD Stage 4, mean_auc: 0.822097
  + ROC curve of class CKD Stage 4 (area = 0.82)
  + class name: CKD Stage 5, mean_auc: 0.961638
  + ROC curve of class CKD Stage 5 (area = 0.96)
  + class name: Others, mean_auc: 0.820732
  + ROC curve of class Others (area = 0.82)
test_auc_cv_metrics> summary of AUCs vs classes ...
  + min | class=CKD Stage 3, auc=0.706504
  + max | class=CKD Stage 5, auc=0.961638
  + micro auc=0.866200 | macro auc=0.822970
  + Ranked AUC scores: 
    + class=CKD Stage 3, auc=0.706504
    + class=CKD Stage 2, auc=0.764699
    + class=Others, auc=0.820732
    + class=CKD Stage 4, auc=0.822097
    + class=CKD Stage 1, auc=0.857106
    + class=CKD Stage 5, auc=0.961638
  => [('CKD Stage 3', 0.70650404140257028), ('CKD Stage 2', 0.76469890432231902), ('Others', 0.82073197457812841), ('CKD Stage 4', 0.82209660842754373), ('CKD Stage 1', 0.8571064263855831), ('CKD Stage 5', 0.96163785090165455)]
output> saving performance to:
/Users/pleiades/Documents/work/tpheno/seqmaker/data/CKD/plot/roc-multiclass-Sequential-CKD-pv-dm2-regular-smallCKD.tif

runROCMulticlass> test set ratio: 0.300000
modelEvaluate> dim(X_train):(1651, 50, 100), dim(X_test): (709, 50, 100)
  + lookup:
{'Others': 5, 'CKD Stage 5': 4, 'CKD Stage 4': 3, 'CKD Stage 3': 2, 'CKD Stage 2': 1, 'CKD Stage 1': 0}

... class weights:
{0: 6.344086021505376, 1: 0.74494949494949492, 2: 1.1238095238095238, 3: 7.0238095238095237, 4: 0.51890941072999119, 5: 0.64906490649064907}

====================================================================================================
... early stopping>
       + patience: 20, model='max'
... model training>
       + batch_size: 32, epochs: 80, shuffle? True, metric: auc_roc
====================================================================================================
Epoch 1/80
1651/1651 [==============================] - 3s 2ms/step - loss: 1.7547 - acc: 0.2314 - auc_roc: 0.9738
Epoch 2/80
1651/1651 [==============================] - 3s 2ms/step - loss: 1.6463 - acc: 0.3362 - auc_roc: 0.9733
Epoch 3/80
1651/1651 [==============================] - 4s 2ms/step - loss: 1.4999 - acc: 0.4434 - auc_roc: 0.9728
Epoch 4/80
1651/1651 [==============================] - 4s 2ms/step - loss: 1.3378 - acc: 0.4488 - auc_roc: 0.9724
Epoch 5/80
1651/1651 [==============================] - 4s 2ms/step - loss: 1.2027 - acc: 0.5015 - auc_roc: 0.9721
Epoch 6/80
1651/1651 [==============================] - 4s 2ms/step - loss: 1.2800 - acc: 0.4706 - auc_roc: 0.9718
Epoch 7/80
1651/1651 [==============================] - 4s 2ms/step - loss: 1.0607 - acc: 0.5742 - auc_roc: 0.9715
Epoch 8/80
1651/1651 [==============================] - 4s 2ms/step - loss: 1.0320 - acc: 0.5518 - auc_roc: 0.9712
Epoch 9/80
1651/1651 [==============================] - 4s 2ms/step - loss: 0.9699 - acc: 0.5748 - auc_roc: 0.9710
Epoch 10/80
1651/1651 [==============================] - 4s 2ms/step - loss: 0.8867 - acc: 0.6148 - auc_roc: 0.9708
Epoch 11/80
1651/1651 [==============================] - 4s 2ms/step - loss: 0.8495 - acc: 0.6402 - auc_roc: 0.9706
Epoch 12/80
1651/1651 [==============================] - 4s 2ms/step - loss: 0.8437 - acc: 0.6245 - auc_roc: 0.9704
Epoch 13/80
1651/1651 [==============================] - 4s 2ms/step - loss: 0.7812 - acc: 0.6457 - auc_roc: 0.9703
Epoch 14/80
1651/1651 [==============================] - 4s 2ms/step - loss: 0.7995 - acc: 0.6281 - auc_roc: 0.9701
Epoch 15/80
1651/1651 [==============================] - 4s 2ms/step - loss: 0.7499 - acc: 0.6626 - auc_roc: 0.9699
Epoch 16/80
1651/1651 [==============================] - 4s 2ms/step - loss: 0.7116 - acc: 0.6681 - auc_roc: 0.9698
Epoch 17/80
1651/1651 [==============================] - 4s 2ms/step - loss: 0.6464 - acc: 0.7002 - auc_roc: 0.9697
Epoch 18/80
1651/1651 [==============================] - 4s 2ms/step - loss: 0.7141 - acc: 0.6729 - auc_roc: 0.9696
Epoch 19/80
1651/1651 [==============================] - 4s 2ms/step - loss: 0.6577 - acc: 0.6935 - auc_roc: 0.9694
Epoch 20/80
1651/1651 [==============================] - 4s 2ms/step - loss: 0.6094 - acc: 0.7123 - auc_roc: 0.9694
Epoch 21/80
1651/1651 [==============================] - 4s 2ms/step - loss: 0.5729 - acc: 0.7123 - auc_roc: 0.9693
Epoch 22/80
1651/1651 [==============================] - 4s 2ms/step - loss: 0.5272 - acc: 0.7365 - auc_roc: 0.9692
Epoch 23/80
1651/1651 [==============================] - 4s 2ms/step - loss: 0.5110 - acc: 0.7444 - auc_roc: 0.9692
Epoch 24/80
1651/1651 [==============================] - 4s 2ms/step - loss: 0.5255 - acc: 0.7498 - auc_roc: 0.9691
Epoch 25/80
1651/1651 [==============================] - 4s 2ms/step - loss: 0.4607 - acc: 0.7753 - auc_roc: 0.9691
Epoch 26/80
1651/1651 [==============================] - 4s 2ms/step - loss: 0.4310 - acc: 0.7820 - auc_roc: 0.9691
Epoch 27/80
1651/1651 [==============================] - 4s 2ms/step - loss: 0.4166 - acc: 0.7995 - auc_roc: 0.9691
Epoch 28/80
1651/1651 [==============================] - 4s 2ms/step - loss: 0.5768 - acc: 0.7171 - auc_roc: 0.9691
Epoch 29/80
1651/1651 [==============================] - 4s 2ms/step - loss: 0.4900 - acc: 0.7662 - auc_roc: 0.9690
Epoch 30/80
1651/1651 [==============================] - 4s 2ms/step - loss: 0.4264 - acc: 0.7874 - auc_roc: 0.9690
Epoch 31/80
1651/1651 [==============================] - 4s 2ms/step - loss: 0.4052 - acc: 0.7935 - auc_roc: 0.9690
Epoch 32/80
1651/1651 [==============================] - 4s 2ms/step - loss: 0.3525 - acc: 0.8310 - auc_roc: 0.9690
Epoch 33/80
1651/1651 [==============================] - 4s 2ms/step - loss: 0.3286 - acc: 0.8455 - auc_roc: 0.9690
Epoch 34/80
1651/1651 [==============================] - 4s 2ms/step - loss: 0.3092 - acc: 0.8577 - auc_roc: 0.9691
Epoch 35/80
1651/1651 [==============================] - 4s 2ms/step - loss: 0.3857 - acc: 0.8098 - auc_roc: 0.9692
Epoch 36/80
1651/1651 [==============================] - 3s 2ms/step - loss: 0.3333 - acc: 0.8455 - auc_roc: 0.9692
Epoch 37/80
1651/1651 [==============================] - 4s 2ms/step - loss: 0.2864 - acc: 0.8667 - auc_roc: 0.9693
Epoch 38/80
1651/1651 [==============================] - 4s 2ms/step - loss: 0.3431 - acc: 0.8286 - auc_roc: 0.9693
Epoch 39/80
1651/1651 [==============================] - 4s 2ms/step - loss: 0.3026 - acc: 0.8540 - auc_roc: 0.9694
Epoch 40/80
1651/1651 [==============================] - 4s 2ms/step - loss: 0.3532 - acc: 0.8455 - auc_roc: 0.9694
Epoch 41/80
1651/1651 [==============================] - 4s 2ms/step - loss: 0.2662 - acc: 0.8837 - auc_roc: 0.9695
Epoch 42/80
1651/1651 [==============================] - 4s 2ms/step - loss: 0.2163 - acc: 0.9049 - auc_roc: 0.9696
Epoch 43/80
1651/1651 [==============================] - 4s 2ms/step - loss: 0.1883 - acc: 0.9128 - auc_roc: 0.9697
Epoch 44/80
1651/1651 [==============================] - 4s 2ms/step - loss: 0.1691 - acc: 0.9200 - auc_roc: 0.9698
Epoch 45/80
1651/1651 [==============================] - 4s 2ms/step - loss: 0.1601 - acc: 0.9273 - auc_roc: 0.9699
Epoch 46/80
1651/1651 [==============================] - 4s 2ms/step - loss: 0.1744 - acc: 0.9261 - auc_roc: 0.9700
Epoch 47/80
1651/1651 [==============================] - 4s 2ms/step - loss: 0.1360 - acc: 0.9467 - auc_roc: 0.9702
Epoch 48/80
1651/1651 [==============================] - 4s 2ms/step - loss: 0.2942 - acc: 0.8752 - auc_roc: 0.9703
Epoch 49/80
1651/1651 [==============================] - 4s 2ms/step - loss: 0.2273 - acc: 0.9061 - auc_roc: 0.9703
Epoch 50/80
1651/1651 [==============================] - 4s 2ms/step - loss: 0.2553 - acc: 0.8928 - auc_roc: 0.9704
Epoch 51/80
1651/1651 [==============================] - 4s 2ms/step - loss: 0.2338 - acc: 0.9079 - auc_roc: 0.9705
Epoch 52/80
1651/1651 [==============================] - 4s 2ms/step - loss: 0.2048 - acc: 0.9152 - auc_roc: 0.9706
Epoch 53/80
1651/1651 [==============================] - 4s 2ms/step - loss: 0.1563 - acc: 0.9394 - auc_roc: 0.9707
Epoch 54/80
1651/1651 [==============================] - 4s 2ms/step - loss: 0.1233 - acc: 0.9515 - auc_roc: 0.9709
Epoch 55/80
1651/1651 [==============================] - 4s 2ms/step - loss: 0.0958 - acc: 0.9667 - auc_roc: 0.9710
Epoch 56/80
1651/1651 [==============================] - 4s 2ms/step - loss: 0.0978 - acc: 0.9606 - auc_roc: 0.9712
Epoch 57/80
1651/1651 [==============================] - 4s 2ms/step - loss: 0.1022 - acc: 0.9582 - auc_roc: 0.9713
Epoch 58/80
1651/1651 [==============================] - 4s 2ms/step - loss: 0.0968 - acc: 0.9649 - auc_roc: 0.9714
Epoch 59/80
1651/1651 [==============================] - 4s 2ms/step - loss: 0.0724 - acc: 0.9727 - auc_roc: 0.9716
Epoch 60/80
1651/1651 [==============================] - 4s 2ms/step - loss: 0.0725 - acc: 0.9715 - auc_roc: 0.9717
Epoch 61/80
1651/1651 [==============================] - 3s 2ms/step - loss: 0.0560 - acc: 0.9764 - auc_roc: 0.9719
Epoch 62/80
1651/1651 [==============================] - 4s 2ms/step - loss: 0.0552 - acc: 0.9788 - auc_roc: 0.9721
Epoch 63/80
1651/1651 [==============================] - 4s 2ms/step - loss: 0.0524 - acc: 0.9800 - auc_roc: 0.9722
Epoch 64/80
1651/1651 [==============================] - 4s 2ms/step - loss: 0.0841 - acc: 0.9715 - auc_roc: 0.9724
Epoch 65/80
1651/1651 [==============================] - 4s 2ms/step - loss: 0.1346 - acc: 0.9515 - auc_roc: 0.9725
Epoch 66/80
1651/1651 [==============================] - 4s 2ms/step - loss: 0.1956 - acc: 0.9231 - auc_roc: 0.9726
Epoch 67/80
1651/1651 [==============================] - 4s 3ms/step - loss: 0.0988 - acc: 0.9624 - auc_roc: 0.9727
Epoch 68/80
1651/1651 [==============================] - 4s 2ms/step - loss: 0.1397 - acc: 0.9431 - auc_roc: 0.9728
Epoch 69/80
1651/1651 [==============================] - 3s 2ms/step - loss: 0.1528 - acc: 0.9467 - auc_roc: 0.9730
Epoch 70/80
1651/1651 [==============================] - 3s 2ms/step - loss: 0.3139 - acc: 0.8849 - auc_roc: 0.9730
Epoch 71/80
1651/1651 [==============================] - 3s 2ms/step - loss: 0.1478 - acc: 0.9297 - auc_roc: 0.9731
Epoch 72/80
1651/1651 [==============================] - 3s 2ms/step - loss: 0.0932 - acc: 0.9655 - auc_roc: 0.9732
Epoch 73/80
1651/1651 [==============================] - 3s 2ms/step - loss: 0.0710 - acc: 0.9746 - auc_roc: 0.9734
Epoch 74/80
1651/1651 [==============================] - 3s 2ms/step - loss: 0.0600 - acc: 0.9758 - auc_roc: 0.9735
Epoch 75/80
1651/1651 [==============================] - 3s 2ms/step - loss: 0.0449 - acc: 0.9867 - auc_roc: 0.9736
Epoch 76/80
1651/1651 [==============================] - 3s 2ms/step - loss: 0.0365 - acc: 0.9909 - auc_roc: 0.9738
Epoch 77/80
1651/1651 [==============================] - 3s 2ms/step - loss: 0.0372 - acc: 0.9903 - auc_roc: 0.9739
Epoch 78/80
1651/1651 [==============================] - 3s 2ms/step - loss: 0.1096 - acc: 0.9709 - auc_roc: 0.9741
Epoch 79/80
1651/1651 [==============================] - 3s 2ms/step - loss: 0.2212 - acc: 0.9219 - auc_roc: 0.9742
Epoch 80/80
1651/1651 [==============================] - 3s 2ms/step - loss: 0.1003 - acc: 0.9643 - auc_roc: 0.9743
... history of metrics comprising: ['acc', 'loss', 'auc_roc']
... model fitting complete > starting model evaluation
modelEvaluate> scores:
[('loss', 1.9026417594366249), ('acc', 0.55007052202991435), ('auc_roc', 0.97424716724159011)]

info> infer classifier name from class name ...
runROCMulticlass> find 6 unique labels:
CKD Stage 1, CKD Stage 2, CKD Stage 3, CKD Stage 4, CKD Stage 5, Others

info> given pre-trained model ...
diagnosis> dim(y_score):(709, 6)
>>> test_auc_cv_metrics >>>
  + dimension test 
  + len(roc_auc):8 =?= n_classes (+{micro, macro}):6+2
  + class name: CKD Stage 1, mean_auc: 0.847202
  + ROC curve of class CKD Stage 1 (area = 0.85)
  + class name: CKD Stage 2, mean_auc: 0.738646
  + ROC curve of class CKD Stage 2 (area = 0.74)
  + class name: CKD Stage 3, mean_auc: 0.685045
  + ROC curve of class CKD Stage 3 (area = 0.69)
  + class name: CKD Stage 4, mean_auc: 0.767429
  + ROC curve of class CKD Stage 4 (area = 0.77)
  + class name: CKD Stage 5, mean_auc: 0.955051
  + ROC curve of class CKD Stage 5 (area = 0.96)
  + class name: Others, mean_auc: 0.811571
  + ROC curve of class Others (area = 0.81)
test_auc_cv_metrics> summary of AUCs vs classes ...
  + min | class=CKD Stage 3, auc=0.685045
  + max | class=CKD Stage 5, auc=0.955051
  + micro auc=0.857602 | macro auc=0.801729
  + Ranked AUC scores: 
    + class=CKD Stage 3, auc=0.685045
    + class=CKD Stage 2, auc=0.738646
    + class=CKD Stage 4, auc=0.767429
    + class=Others, auc=0.811571
    + class=CKD Stage 1, auc=0.847202
    + class=CKD Stage 5, auc=0.955051
  => [('CKD Stage 3', 0.68504480830132741), ('CKD Stage 2', 0.73864649231505031), ('CKD Stage 4', 0.76742944317315032), ('Others', 0.81157096157404551), ('CKD Stage 1', 0.84720194647201941), ('CKD Stage 5', 0.95505106108348203)]
output> saving performance to:
/Users/pleiades/Documents/work/tpheno/seqmaker/data/CKD/plot/roc-multiclass-Sequential-CKD-pv-dm2-regular-smallCKD.tif

runROCMulticlass> test set ratio: 0.300000
modelEvaluate> dim(X_train):(1651, 50, 100), dim(X_test): (709, 50, 100)
  + lookup:
{'Others': 5, 'CKD Stage 5': 4, 'CKD Stage 4': 3, 'CKD Stage 3': 2, 'CKD Stage 2': 1, 'CKD Stage 1': 0}

... class weights:
{0: 6.344086021505376, 1: 0.74494949494949492, 2: 1.1238095238095238, 3: 7.0238095238095237, 4: 0.51890941072999119, 5: 0.64906490649064907}

====================================================================================================
... early stopping>
       + patience: 20, model='max'
... model training>
       + batch_size: 32, epochs: 80, shuffle? True, metric: auc_roc
====================================================================================================
Epoch 1/80
1651/1651 [==============================] - 3s 2ms/step - loss: 1.8519 - acc: 0.1339 - auc_roc: 0.9739
Epoch 2/80
1651/1651 [==============================] - 3s 2ms/step - loss: 1.7340 - acc: 0.2877 - auc_roc: 0.9735
Epoch 3/80
1651/1651 [==============================] - 3s 2ms/step - loss: 1.5838 - acc: 0.3798 - auc_roc: 0.9731
Epoch 4/80
1651/1651 [==============================] - 3s 2ms/step - loss: 1.3931 - acc: 0.4609 - auc_roc: 0.9728
Epoch 5/80
1651/1651 [==============================] - 3s 2ms/step - loss: 1.2467 - acc: 0.4985 - auc_roc: 0.9726
Epoch 6/80
1651/1651 [==============================] - 3s 2ms/step - loss: 1.1136 - acc: 0.5657 - auc_roc: 0.9724
Epoch 7/80
1651/1651 [==============================] - 3s 2ms/step - loss: 1.0884 - acc: 0.5663 - auc_roc: 0.9722
Epoch 8/80
1651/1651 [==============================] - 3s 2ms/step - loss: 1.0057 - acc: 0.5869 - auc_roc: 0.9720
Epoch 9/80
1651/1651 [==============================] - 3s 2ms/step - loss: 0.9321 - acc: 0.6148 - auc_roc: 0.9718
Epoch 10/80
1651/1651 [==============================] - 3s 2ms/step - loss: 0.9071 - acc: 0.6227 - auc_roc: 0.9716
Epoch 11/80
1651/1651 [==============================] - 3s 2ms/step - loss: 0.8434 - acc: 0.6396 - auc_roc: 0.9715
Epoch 12/80
1651/1651 [==============================] - 3s 2ms/step - loss: 0.7457 - acc: 0.6632 - auc_roc: 0.9714
Epoch 13/80
1651/1651 [==============================] - 3s 2ms/step - loss: 0.7657 - acc: 0.6439 - auc_roc: 0.9713
Epoch 14/80
1651/1651 [==============================] - 3s 2ms/step - loss: 0.7406 - acc: 0.6596 - auc_roc: 0.9712
Epoch 15/80
1651/1651 [==============================] - 3s 2ms/step - loss: 0.6929 - acc: 0.6844 - auc_roc: 0.9711
Epoch 16/80
1651/1651 [==============================] - 3s 2ms/step - loss: 0.7617 - acc: 0.6529 - auc_roc: 0.9710
Epoch 17/80
1651/1651 [==============================] - 3s 2ms/step - loss: 0.6907 - acc: 0.6796 - auc_roc: 0.9709
Epoch 18/80
1651/1651 [==============================] - 3s 2ms/step - loss: 0.6318 - acc: 0.6917 - auc_roc: 0.9708
Epoch 19/80
1651/1651 [==============================] - 3s 2ms/step - loss: 0.6111 - acc: 0.6959 - auc_roc: 0.9707
Epoch 20/80
1651/1651 [==============================] - 3s 2ms/step - loss: 0.5540 - acc: 0.7426 - auc_roc: 0.9706
Epoch 21/80
1651/1651 [==============================] - 3s 2ms/step - loss: 0.5756 - acc: 0.7093 - auc_roc: 0.9706
Epoch 22/80
1651/1651 [==============================] - 3s 2ms/step - loss: 0.6991 - acc: 0.6990 - auc_roc: 0.9705
Epoch 23/80
1651/1651 [==============================] - 3s 2ms/step - loss: 0.5615 - acc: 0.7341 - auc_roc: 0.9704
Epoch 24/80
1651/1651 [==============================] - 3s 2ms/step - loss: 0.5151 - acc: 0.7565 - auc_roc: 0.9704
Epoch 25/80
1651/1651 [==============================] - 3s 2ms/step - loss: 0.4814 - acc: 0.7595 - auc_roc: 0.9704
Epoch 26/80
1651/1651 [==============================] - 3s 2ms/step - loss: 0.6298 - acc: 0.7232 - auc_roc: 0.9704
Epoch 27/80
1651/1651 [==============================] - 3s 2ms/step - loss: 0.6816 - acc: 0.6972 - auc_roc: 0.9703
Epoch 28/80
1651/1651 [==============================] - 3s 2ms/step - loss: 0.5279 - acc: 0.7456 - auc_roc: 0.9702
Epoch 29/80
1651/1651 [==============================] - 3s 2ms/step - loss: 0.4707 - acc: 0.7771 - auc_roc: 0.9702
Epoch 30/80
1651/1651 [==============================] - 3s 2ms/step - loss: 0.4654 - acc: 0.7747 - auc_roc: 0.9702
Epoch 31/80
1651/1651 [==============================] - 3s 2ms/step - loss: 0.4381 - acc: 0.7850 - auc_roc: 0.9702
Epoch 32/80
1651/1651 [==============================] - 3s 2ms/step - loss: 0.3914 - acc: 0.8177 - auc_roc: 0.9702
Epoch 33/80
1651/1651 [==============================] - 3s 2ms/step - loss: 0.3639 - acc: 0.8298 - auc_roc: 0.9702
Epoch 34/80
1651/1651 [==============================] - 3s 2ms/step - loss: 0.3404 - acc: 0.8353 - auc_roc: 0.9702
Epoch 35/80
1651/1651 [==============================] - 3s 2ms/step - loss: 0.3065 - acc: 0.8522 - auc_roc: 0.9702
Epoch 36/80
1651/1651 [==============================] - 3s 2ms/step - loss: 0.3059 - acc: 0.8504 - auc_roc: 0.9703
Epoch 37/80
1651/1651 [==============================] - 3s 2ms/step - loss: 0.2804 - acc: 0.8613 - auc_roc: 0.9703
Epoch 38/80
1651/1651 [==============================] - 3s 2ms/step - loss: 0.2449 - acc: 0.8873 - auc_roc: 0.9704
Epoch 39/80
1651/1651 [==============================] - 3s 2ms/step - loss: 0.3728 - acc: 0.8280 - auc_roc: 0.9705
Epoch 40/80
1651/1651 [==============================] - 3s 2ms/step - loss: 0.3494 - acc: 0.8340 - auc_roc: 0.9705
Epoch 41/80
1651/1651 [==============================] - 3s 2ms/step - loss: 0.3916 - acc: 0.8153 - auc_roc: 0.9705
Epoch 42/80
1651/1651 [==============================] - 3s 2ms/step - loss: 0.2888 - acc: 0.8625 - auc_roc: 0.9705
Epoch 43/80
1651/1651 [==============================] - 3s 2ms/step - loss: 0.2210 - acc: 0.9013 - auc_roc: 0.9706
Epoch 44/80
1651/1651 [==============================] - 3s 2ms/step - loss: 0.3283 - acc: 0.8643 - auc_roc: 0.9706
Epoch 45/80
1651/1651 [==============================] - 3s 2ms/step - loss: 0.2846 - acc: 0.8770 - auc_roc: 0.9707
Epoch 46/80
1651/1651 [==============================] - 3s 2ms/step - loss: 0.2168 - acc: 0.9104 - auc_roc: 0.9708
Epoch 47/80
1651/1651 [==============================] - 3s 2ms/step - loss: 0.1597 - acc: 0.9243 - auc_roc: 0.9708
Epoch 48/80
1651/1651 [==============================] - 3s 2ms/step - loss: 0.1475 - acc: 0.9388 - auc_roc: 0.9709
Epoch 49/80
1651/1651 [==============================] - 3s 2ms/step - loss: 0.1266 - acc: 0.9485 - auc_roc: 0.9710
Epoch 50/80
1651/1651 [==============================] - 3s 2ms/step - loss: 0.1203 - acc: 0.9522 - auc_roc: 0.9712
Epoch 51/80
1651/1651 [==============================] - 3s 2ms/step - loss: 0.1018 - acc: 0.9618 - auc_roc: 0.9713
Epoch 52/80
1651/1651 [==============================] - 3s 2ms/step - loss: 0.1018 - acc: 0.9564 - auc_roc: 0.9714
Epoch 53/80
1651/1651 [==============================] - 3s 2ms/step - loss: 0.0863 - acc: 0.9624 - auc_roc: 0.9715
Epoch 54/80
1651/1651 [==============================] - 3s 2ms/step - loss: 0.0879 - acc: 0.9582 - auc_roc: 0.9716
Epoch 55/80
1651/1651 [==============================] - 3s 2ms/step - loss: 0.0795 - acc: 0.9679 - auc_roc: 0.9717
Epoch 56/80
1651/1651 [==============================] - 3s 2ms/step - loss: 0.1582 - acc: 0.9364 - auc_roc: 0.9718
Epoch 57/80
1651/1651 [==============================] - 3s 2ms/step - loss: 0.1682 - acc: 0.9231 - auc_roc: 0.9719
Epoch 58/80
1651/1651 [==============================] - 3s 2ms/step - loss: 0.2536 - acc: 0.8904 - auc_roc: 0.9720
Epoch 59/80
1651/1651 [==============================] - 3s 2ms/step - loss: 0.1269 - acc: 0.9491 - auc_roc: 0.9721
Epoch 60/80
1651/1651 [==============================] - 3s 2ms/step - loss: 0.0961 - acc: 0.9618 - auc_roc: 0.9722
Epoch 61/80
1651/1651 [==============================] - 3s 2ms/step - loss: 0.0732 - acc: 0.9764 - auc_roc: 0.9723
Epoch 62/80
1651/1651 [==============================] - 3s 2ms/step - loss: 0.0578 - acc: 0.9806 - auc_roc: 0.9724
Epoch 63/80
1651/1651 [==============================] - 3s 2ms/step - loss: 0.0600 - acc: 0.9806 - auc_roc: 0.9725
Epoch 64/80
1651/1651 [==============================] - 3s 2ms/step - loss: 0.0467 - acc: 0.9849 - auc_roc: 0.9727
Epoch 65/80
1651/1651 [==============================] - 3s 2ms/step - loss: 0.0403 - acc: 0.9873 - auc_roc: 0.9728
Epoch 66/80
1651/1651 [==============================] - 3s 2ms/step - loss: 0.0331 - acc: 0.9909 - auc_roc: 0.9729
Epoch 67/80
1651/1651 [==============================] - 3s 2ms/step - loss: 0.1403 - acc: 0.9594 - auc_roc: 0.9730
Epoch 68/80
1651/1651 [==============================] - 3s 2ms/step - loss: 0.3214 - acc: 0.8873 - auc_roc: 0.9731
Epoch 69/80
1651/1651 [==============================] - 3s 2ms/step - loss: 0.1732 - acc: 0.9291 - auc_roc: 0.9731
Epoch 70/80
1651/1651 [==============================] - 3s 2ms/step - loss: 0.1009 - acc: 0.9618 - auc_roc: 0.9732
Epoch 71/80
1651/1651 [==============================] - 3s 2ms/step - loss: 0.0742 - acc: 0.9727 - auc_roc: 0.9733
Epoch 72/80
1651/1651 [==============================] - 3s 2ms/step - loss: 0.0556 - acc: 0.9818 - auc_roc: 0.9735
Epoch 73/80
1651/1651 [==============================] - 3s 2ms/step - loss: 0.0477 - acc: 0.9843 - auc_roc: 0.9736
Epoch 74/80
1651/1651 [==============================] - 3s 2ms/step - loss: 0.0386 - acc: 0.9873 - auc_roc: 0.9737
Epoch 75/80
1651/1651 [==============================] - 3s 2ms/step - loss: 0.0384 - acc: 0.9873 - auc_roc: 0.9738
Epoch 76/80
1651/1651 [==============================] - 3s 2ms/step - loss: 0.0385 - acc: 0.9867 - auc_roc: 0.9739
Epoch 77/80
1651/1651 [==============================] - 3s 2ms/step - loss: 0.0276 - acc: 0.9945 - auc_roc: 0.9740
Epoch 78/80
1651/1651 [==============================] - 3s 2ms/step - loss: 0.0254 - acc: 0.9933 - auc_roc: 0.9742
Epoch 79/80
1651/1651 [==============================] - 3s 2ms/step - loss: 0.0208 - acc: 0.9939 - auc_roc: 0.9743
Epoch 80/80
1651/1651 [==============================] - 3s 2ms/step - loss: 0.0307 - acc: 0.9921 - auc_roc: 0.9744
... history of metrics comprising: ['acc', 'loss', 'auc_roc']
... model fitting complete > starting model evaluation
modelEvaluate> scores:
[('loss', 2.1735123515297228), ('acc', 0.596614950802834), ('auc_roc', 0.97436696257342403)]

info> infer classifier name from class name ...
runROCMulticlass> find 6 unique labels:
CKD Stage 1, CKD Stage 2, CKD Stage 3, CKD Stage 4, CKD Stage 5, Others

info> given pre-trained model ...
diagnosis> dim(y_score):(709, 6)
>>> test_auc_cv_metrics >>>
  + dimension test 
  + len(roc_auc):8 =?= n_classes (+{micro, macro}):6+2
  + class name: CKD Stage 1, mean_auc: 0.794913
  + ROC curve of class CKD Stage 1 (area = 0.79)
  + class name: CKD Stage 2, mean_auc: 0.776189
  + ROC curve of class CKD Stage 2 (area = 0.78)
  + class name: CKD Stage 3, mean_auc: 0.769595
  + ROC curve of class CKD Stage 3 (area = 0.77)
  + class name: CKD Stage 4, mean_auc: 0.716733
  + ROC curve of class CKD Stage 4 (area = 0.72)
  + class name: CKD Stage 5, mean_auc: 0.942322
  + ROC curve of class CKD Stage 5 (area = 0.94)
  + class name: Others, mean_auc: 0.845478
  + ROC curve of class Others (area = 0.85)
test_auc_cv_metrics> summary of AUCs vs classes ...
  + min | class=CKD Stage 4, auc=0.716733
  + max | class=CKD Stage 5, auc=0.942322
  + micro auc=0.877671 | macro auc=0.808518
  + Ranked AUC scores: 
    + class=CKD Stage 4, auc=0.716733
    + class=CKD Stage 3, auc=0.769595
    + class=CKD Stage 2, auc=0.776189
    + class=CKD Stage 1, auc=0.794913
    + class=Others, auc=0.845478
    + class=CKD Stage 5, auc=0.942322
  => [('CKD Stage 4', 0.71673297966401417), ('CKD Stage 3', 0.76959541913076135), ('CKD Stage 2', 0.77618943692710607), ('CKD Stage 1', 0.79491341991341991), ('Others', 0.84547777847036099), ('CKD Stage 5', 0.9423215638186605)]
output> saving performance to:
/Users/pleiades/Documents/work/tpheno/seqmaker/data/CKD/plot/roc-multiclass-Sequential-CKD-pv-dm2-regular-smallCKD.tif

runROCMulticlass> test set ratio: 0.300000
modelEvaluate> dim(X_train):(1651, 50, 100), dim(X_test): (709, 50, 100)
  + lookup:
{'Others': 5, 'CKD Stage 5': 4, 'CKD Stage 4': 3, 'CKD Stage 3': 2, 'CKD Stage 2': 1, 'CKD Stage 1': 0}

... class weights:
{0: 6.344086021505376, 1: 0.74494949494949492, 2: 1.1238095238095238, 3: 7.0238095238095237, 4: 0.51890941072999119, 5: 0.64906490649064907}

====================================================================================================
... early stopping>
       + patience: 20, model='max'
... model training>
       + batch_size: 32, epochs: 80, shuffle? True, metric: auc_roc
====================================================================================================
Epoch 1/80
1651/1651 [==============================] - 3s 2ms/step - loss: 1.7747 - acc: 0.2090 - auc_roc: 0.9741
Epoch 2/80
1651/1651 [==============================] - 3s 2ms/step - loss: 1.6637 - acc: 0.3101 - auc_roc: 0.9738
Epoch 3/80
1651/1651 [==============================] - 3s 2ms/step - loss: 1.4708 - acc: 0.4640 - auc_roc: 0.9735
Epoch 4/80
1651/1651 [==============================] - 3s 2ms/step - loss: 1.3442 - acc: 0.4500 - auc_roc: 0.9733
Epoch 5/80
1651/1651 [==============================] - 3s 2ms/step - loss: 1.2424 - acc: 0.5130 - auc_roc: 0.9731
Epoch 6/80
1651/1651 [==============================] - 3s 2ms/step - loss: 1.1094 - acc: 0.5518 - auc_roc: 0.9729
Epoch 7/80
1651/1651 [==============================] - 3s 2ms/step - loss: 1.0144 - acc: 0.5736 - auc_roc: 0.9728
Epoch 8/80
1651/1651 [==============================] - 3s 2ms/step - loss: 0.9956 - acc: 0.5815 - auc_roc: 0.9726
Epoch 9/80
1651/1651 [==============================] - 3s 2ms/step - loss: 0.8777 - acc: 0.6124 - auc_roc: 0.9725
Epoch 10/80
1651/1651 [==============================] - 3s 2ms/step - loss: 0.8514 - acc: 0.6214 - auc_roc: 0.9724
Epoch 11/80
1651/1651 [==============================] - 3s 2ms/step - loss: 0.8220 - acc: 0.6354 - auc_roc: 0.9723
Epoch 12/80
1651/1651 [==============================] - 3s 2ms/step - loss: 0.7341 - acc: 0.6638 - auc_roc: 0.9722
Epoch 13/80
1651/1651 [==============================] - 3s 2ms/step - loss: 0.6991 - acc: 0.6644 - auc_roc: 0.9721
Epoch 14/80
1651/1651 [==============================] - 3s 2ms/step - loss: 0.6692 - acc: 0.6978 - auc_roc: 0.9721
Epoch 15/80
1651/1651 [==============================] - 3s 2ms/step - loss: 0.6523 - acc: 0.6766 - auc_roc: 0.9720
Epoch 16/80
1651/1651 [==============================] - 3s 2ms/step - loss: 0.8826 - acc: 0.6227 - auc_roc: 0.9719
Epoch 17/80
1651/1651 [==============================] - 3s 2ms/step - loss: 0.6852 - acc: 0.6923 - auc_roc: 0.9718
Epoch 18/80
1651/1651 [==============================] - 3s 2ms/step - loss: 0.6546 - acc: 0.6941 - auc_roc: 0.9717
Epoch 19/80
1651/1651 [==============================] - 3s 2ms/step - loss: 0.6619 - acc: 0.6863 - auc_roc: 0.9717
Epoch 20/80
1651/1651 [==============================] - 3s 2ms/step - loss: 0.6172 - acc: 0.7062 - auc_roc: 0.9716
Epoch 21/80
1651/1651 [==============================] - 3s 2ms/step - loss: 0.5585 - acc: 0.7359 - auc_roc: 0.9716
Epoch 22/80
1651/1651 [==============================] - 3s 2ms/step - loss: 0.5119 - acc: 0.7456 - auc_roc: 0.9715
Epoch 23/80
1651/1651 [==============================] - 3s 2ms/step - loss: 0.5007 - acc: 0.7377 - auc_roc: 0.9715
Epoch 24/80
1651/1651 [==============================] - 3s 2ms/step - loss: 0.5379 - acc: 0.7523 - auc_roc: 0.9715
Epoch 25/80
1651/1651 [==============================] - 3s 2ms/step - loss: 0.4688 - acc: 0.7729 - auc_roc: 0.9714
Epoch 26/80
1651/1651 [==============================] - 3s 2ms/step - loss: 0.4438 - acc: 0.7844 - auc_roc: 0.9714
Epoch 27/80
1651/1651 [==============================] - 3s 2ms/step - loss: 0.4150 - acc: 0.7989 - auc_roc: 0.9714
Epoch 28/80
1651/1651 [==============================] - 3s 2ms/step - loss: 0.3967 - acc: 0.7989 - auc_roc: 0.9714
Epoch 29/80
1651/1651 [==============================] - 3s 2ms/step - loss: 0.3565 - acc: 0.8165 - auc_roc: 0.9715
Epoch 30/80
1651/1651 [==============================] - 3s 2ms/step - loss: 0.3618 - acc: 0.8256 - auc_roc: 0.9715
Epoch 31/80
1651/1651 [==============================] - 3s 2ms/step - loss: 0.3581 - acc: 0.8147 - auc_roc: 0.9715
Epoch 32/80
1651/1651 [==============================] - 3s 2ms/step - loss: 0.3451 - acc: 0.8322 - auc_roc: 0.9715
Epoch 33/80
1651/1651 [==============================] - 3s 2ms/step - loss: 0.3928 - acc: 0.8080 - auc_roc: 0.9715
Epoch 34/80
1651/1651 [==============================] - 3s 2ms/step - loss: 0.3944 - acc: 0.8189 - auc_roc: 0.9715
Epoch 35/80
1651/1651 [==============================] - 3s 2ms/step - loss: 0.3089 - acc: 0.8571 - auc_roc: 0.9716
Epoch 36/80
1651/1651 [==============================] - 3s 2ms/step - loss: 0.3126 - acc: 0.8625 - auc_roc: 0.9716
Epoch 37/80
1651/1651 [==============================] - 3s 2ms/step - loss: 0.2556 - acc: 0.8789 - auc_roc: 0.9716
Epoch 38/80
1651/1651 [==============================] - 3s 2ms/step - loss: 0.2312 - acc: 0.8873 - auc_roc: 0.9717
Epoch 39/80
1651/1651 [==============================] - 3s 2ms/step - loss: 0.2334 - acc: 0.8873 - auc_roc: 0.9717
Epoch 40/80
1651/1651 [==============================] - 3s 2ms/step - loss: 0.2207 - acc: 0.8952 - auc_roc: 0.9718
Epoch 41/80
1651/1651 [==============================] - 3s 2ms/step - loss: 0.1931 - acc: 0.9085 - auc_roc: 0.9719
Epoch 42/80
1651/1651 [==============================] - 3s 2ms/step - loss: 0.3261 - acc: 0.8546 - auc_roc: 0.9719
Epoch 43/80
1651/1651 [==============================] - 3s 2ms/step - loss: 0.2787 - acc: 0.8776 - auc_roc: 0.9719
Epoch 44/80
1651/1651 [==============================] - 3s 2ms/step - loss: 0.1883 - acc: 0.9200 - auc_roc: 0.9720
Epoch 45/80
1651/1651 [==============================] - 3s 2ms/step - loss: 0.2149 - acc: 0.9031 - auc_roc: 0.9721
Epoch 46/80
1651/1651 [==============================] - 3s 2ms/step - loss: 0.1696 - acc: 0.9261 - auc_roc: 0.9721
Epoch 47/80
1651/1651 [==============================] - 3s 2ms/step - loss: 0.1315 - acc: 0.9388 - auc_roc: 0.9722
Epoch 48/80
1651/1651 [==============================] - 3s 2ms/step - loss: 0.1821 - acc: 0.9291 - auc_roc: 0.9723
Epoch 49/80
1651/1651 [==============================] - 3s 2ms/step - loss: 0.1600 - acc: 0.9291 - auc_roc: 0.9724
Epoch 50/80
1651/1651 [==============================] - 3s 2ms/step - loss: 0.1469 - acc: 0.9449 - auc_roc: 0.9724
Epoch 51/80
1651/1651 [==============================] - 3s 2ms/step - loss: 0.1053 - acc: 0.9546 - auc_roc: 0.9725
Epoch 52/80
1651/1651 [==============================] - 3s 2ms/step - loss: 0.0837 - acc: 0.9679 - auc_roc: 0.9726
Epoch 53/80
1651/1651 [==============================] - 3s 2ms/step - loss: 0.0898 - acc: 0.9606 - auc_roc: 0.9727
Epoch 54/80
1651/1651 [==============================] - 3s 2ms/step - loss: 0.0689 - acc: 0.9764 - auc_roc: 0.9728
Epoch 55/80
1651/1651 [==============================] - 3s 2ms/step - loss: 0.0711 - acc: 0.9721 - auc_roc: 0.9729
Epoch 56/80
1651/1651 [==============================] - 3s 2ms/step - loss: 0.0805 - acc: 0.9703 - auc_roc: 0.9730
Epoch 57/80
1651/1651 [==============================] - 3s 2ms/step - loss: 0.0693 - acc: 0.9721 - auc_roc: 0.9731
Epoch 58/80
1651/1651 [==============================] - 3s 2ms/step - loss: 0.0628 - acc: 0.9752 - auc_roc: 0.9732
Epoch 59/80
1651/1651 [==============================] - 3s 2ms/step - loss: 0.0511 - acc: 0.9794 - auc_roc: 0.9733
Epoch 60/80
1651/1651 [==============================] - 3s 2ms/step - loss: 0.0525 - acc: 0.9788 - auc_roc: 0.9734
Epoch 61/80
1651/1651 [==============================] - 3s 2ms/step - loss: 0.0361 - acc: 0.9885 - auc_roc: 0.9735
Epoch 62/80
1651/1651 [==============================] - 3s 2ms/step - loss: 0.2000 - acc: 0.9310 - auc_roc: 0.9736
Epoch 63/80
1651/1651 [==============================] - 3s 2ms/step - loss: 0.2789 - acc: 0.8758 - auc_roc: 0.9736
Epoch 64/80
1651/1651 [==============================] - 3s 2ms/step - loss: 0.1198 - acc: 0.9558 - auc_roc: 0.9737
Epoch 65/80
1651/1651 [==============================] - 3s 2ms/step - loss: 0.0709 - acc: 0.9776 - auc_roc: 0.9737
Epoch 66/80
1651/1651 [==============================] - 3s 2ms/step - loss: 0.1346 - acc: 0.9467 - auc_roc: 0.9738
Epoch 67/80
1651/1651 [==============================] - 3s 2ms/step - loss: 0.2944 - acc: 0.9037 - auc_roc: 0.9739
Epoch 68/80
1651/1651 [==============================] - 3s 2ms/step - loss: 0.1424 - acc: 0.9455 - auc_roc: 0.9739
Epoch 69/80
1651/1651 [==============================] - 3s 2ms/step - loss: 0.0804 - acc: 0.9697 - auc_roc: 0.9740
Epoch 70/80
1651/1651 [==============================] - 3s 2ms/step - loss: 0.0568 - acc: 0.9800 - auc_roc: 0.9741
Epoch 71/80
1651/1651 [==============================] - 3s 2ms/step - loss: 0.0443 - acc: 0.9855 - auc_roc: 0.9742
Epoch 72/80
1651/1651 [==============================] - 3s 2ms/step - loss: 0.0355 - acc: 0.9909 - auc_roc: 0.9743
Epoch 73/80
1651/1651 [==============================] - 3s 2ms/step - loss: 0.0341 - acc: 0.9867 - auc_roc: 0.9744
Epoch 74/80
1651/1651 [==============================] - 3s 2ms/step - loss: 0.0249 - acc: 0.9921 - auc_roc: 0.9745
Epoch 75/80
1651/1651 [==============================] - 3s 2ms/step - loss: 0.0280 - acc: 0.9891 - auc_roc: 0.9746
Epoch 76/80
1651/1651 [==============================] - 3s 2ms/step - loss: 0.0616 - acc: 0.9794 - auc_roc: 0.9747
Epoch 77/80
1651/1651 [==============================] - 3s 2ms/step - loss: 0.0268 - acc: 0.9933 - auc_roc: 0.9748
Epoch 78/80
1651/1651 [==============================] - 3s 2ms/step - loss: 0.0213 - acc: 0.9939 - auc_roc: 0.9749
Epoch 79/80
1651/1651 [==============================] - 3s 2ms/step - loss: 0.0183 - acc: 0.9958 - auc_roc: 0.9750
Epoch 80/80
1651/1651 [==============================] - 3s 2ms/step - loss: 0.0157 - acc: 0.9988 - auc_roc: 0.9751
... history of metrics comprising: ['acc', 'loss', 'auc_roc']
... model fitting complete > starting model evaluation
modelEvaluate> scores:
[('loss', 2.8642688389389406), ('acc', 0.55571227084598351), ('auc_roc', 0.97503701024734757)]

info> infer classifier name from class name ...
runROCMulticlass> find 6 unique labels:
CKD Stage 1, CKD Stage 2, CKD Stage 3, CKD Stage 4, CKD Stage 5, Others

info> given pre-trained model ...
diagnosis> dim(y_score):(709, 6)
>>> test_auc_cv_metrics >>>
  + dimension test 
  + len(roc_auc):8 =?= n_classes (+{micro, macro}):6+2
  + class name: CKD Stage 1, mean_auc: 0.853338
  + ROC curve of class CKD Stage 1 (area = 0.85)
  + class name: CKD Stage 2, mean_auc: 0.745279
  + ROC curve of class CKD Stage 2 (area = 0.75)
  + class name: CKD Stage 3, mean_auc: 0.732844
  + ROC curve of class CKD Stage 3 (area = 0.73)
  + class name: CKD Stage 4, mean_auc: 0.627994
  + ROC curve of class CKD Stage 4 (area = 0.63)
  + class name: CKD Stage 5, mean_auc: 0.949341
  + ROC curve of class CKD Stage 5 (area = 0.95)
  + class name: Others, mean_auc: 0.814524
  + ROC curve of class Others (area = 0.81)
test_auc_cv_metrics> summary of AUCs vs classes ...
  + min | class=CKD Stage 4, auc=0.627994
  + max | class=CKD Stage 5, auc=0.949341
  + micro auc=0.851780 | macro auc=0.788202
  + Ranked AUC scores: 
    + class=CKD Stage 4, auc=0.627994
    + class=CKD Stage 3, auc=0.732844
    + class=CKD Stage 2, auc=0.745279
    + class=Others, auc=0.814524
    + class=CKD Stage 1, auc=0.853338
    + class=CKD Stage 5, auc=0.949341
  => [('CKD Stage 4', 0.62799389778794812), ('CKD Stage 3', 0.73284403669724774), ('CKD Stage 2', 0.74527946038296833), ('Others', 0.81452425960932573), ('CKD Stage 1', 0.85333817126269951), ('CKD Stage 5', 0.94934092834949624)]
output> saving performance to:
/Users/pleiades/Documents/work/tpheno/seqmaker/data/CKD/plot/roc-multiclass-Sequential-CKD-pv-dm2-regular-smallCKD.tif

runROCMulticlass> test set ratio: 0.300000
modelEvaluate> dim(X_train):(1651, 50, 100), dim(X_test): (709, 50, 100)
  + lookup:
{'Others': 5, 'CKD Stage 5': 4, 'CKD Stage 4': 3, 'CKD Stage 3': 2, 'CKD Stage 2': 1, 'CKD Stage 1': 0}

... class weights:
{0: 6.344086021505376, 1: 0.74494949494949492, 2: 1.1238095238095238, 3: 7.0238095238095237, 4: 0.51890941072999119, 5: 0.64906490649064907}

====================================================================================================
... early stopping>
       + patience: 20, model='max'
... model training>
       + batch_size: 32, epochs: 80, shuffle? True, metric: auc_roc
====================================================================================================
Epoch 1/80
1651/1651 [==============================] - 3s 2ms/step - loss: 1.8624 - acc: 0.1605 - auc_roc: 0.9748
Epoch 2/80
1651/1651 [==============================] - 3s 2ms/step - loss: 1.7278 - acc: 0.3192 - auc_roc: 0.9745
Epoch 3/80
1651/1651 [==============================] - 3s 2ms/step - loss: 1.5134 - acc: 0.3882 - auc_roc: 0.9743
Epoch 4/80
1651/1651 [==============================] - 3s 2ms/step - loss: 1.4249 - acc: 0.4306 - auc_roc: 0.9741
Epoch 5/80
1651/1651 [==============================] - 3s 2ms/step - loss: 1.2636 - acc: 0.5003 - auc_roc: 0.9739
Epoch 6/80
1651/1651 [==============================] - 3s 2ms/step - loss: 1.1464 - acc: 0.5239 - auc_roc: 0.9738
Epoch 7/80
1651/1651 [==============================] - 3s 2ms/step - loss: 1.0945 - acc: 0.5397 - auc_roc: 0.9736
Epoch 8/80
1651/1651 [==============================] - 3s 2ms/step - loss: 1.0316 - acc: 0.5657 - auc_roc: 0.9735
Epoch 9/80
1651/1651 [==============================] - 3s 2ms/step - loss: 0.9503 - acc: 0.5851 - auc_roc: 0.9734
Epoch 10/80
1651/1651 [==============================] - 3s 2ms/step - loss: 0.8907 - acc: 0.6081 - auc_roc: 0.9733
Epoch 11/80
1651/1651 [==============================] - 3s 2ms/step - loss: 0.8240 - acc: 0.6269 - auc_roc: 0.9732
Epoch 12/80
1651/1651 [==============================] - 3s 2ms/step - loss: 0.7962 - acc: 0.6414 - auc_roc: 0.9731
Epoch 13/80
1651/1651 [==============================] - 3s 2ms/step - loss: 0.7948 - acc: 0.6354 - auc_roc: 0.9730
Epoch 14/80
1651/1651 [==============================] - 3s 2ms/step - loss: 0.7283 - acc: 0.6578 - auc_roc: 0.9729
Epoch 15/80
1651/1651 [==============================] - 3s 2ms/step - loss: 0.6561 - acc: 0.6953 - auc_roc: 0.9729
Epoch 16/80
1651/1651 [==============================] - 3s 2ms/step - loss: 0.7359 - acc: 0.6784 - auc_roc: 0.9728
Epoch 17/80
1651/1651 [==============================] - 3s 2ms/step - loss: 0.6022 - acc: 0.7105 - auc_roc: 0.9728
Epoch 18/80
1651/1651 [==============================] - 3s 2ms/step - loss: 0.5678 - acc: 0.7214 - auc_roc: 0.9727
Epoch 19/80
1651/1651 [==============================] - 3s 2ms/step - loss: 0.5536 - acc: 0.7317 - auc_roc: 0.9727
Epoch 20/80
1651/1651 [==============================] - 3s 2ms/step - loss: 0.5463 - acc: 0.7268 - auc_roc: 0.9727
Epoch 21/80
1651/1651 [==============================] - 3s 2ms/step - loss: 0.5376 - acc: 0.7474 - auc_roc: 0.9726
Epoch 22/80
1651/1651 [==============================] - 3s 2ms/step - loss: 0.5182 - acc: 0.7517 - auc_roc: 0.9726
Epoch 23/80
1651/1651 [==============================] - 3s 2ms/step - loss: 0.4847 - acc: 0.7765 - auc_roc: 0.9726
Epoch 24/80
1651/1651 [==============================] - 3s 2ms/step - loss: 0.4231 - acc: 0.7953 - auc_roc: 0.9726
Epoch 25/80
1651/1651 [==============================] - 3s 2ms/step - loss: 0.4082 - acc: 0.7977 - auc_roc: 0.9726
Epoch 26/80
1651/1651 [==============================] - 3s 2ms/step - loss: 0.3750 - acc: 0.8171 - auc_roc: 0.9726
Epoch 27/80
1651/1651 [==============================] - 3s 2ms/step - loss: 0.3545 - acc: 0.8286 - auc_roc: 0.9726
Epoch 28/80
1651/1651 [==============================] - 3s 2ms/step - loss: 0.3214 - acc: 0.8383 - auc_roc: 0.9726
Epoch 29/80
1651/1651 [==============================] - 3s 2ms/step - loss: 0.3143 - acc: 0.8383 - auc_roc: 0.9726
Epoch 30/80
1651/1651 [==============================] - 3s 2ms/step - loss: 0.3267 - acc: 0.8413 - auc_roc: 0.9727
Epoch 31/80
1651/1651 [==============================] - 3s 2ms/step - loss: 0.3349 - acc: 0.8449 - auc_roc: 0.9727
Epoch 32/80
1651/1651 [==============================] - 3s 2ms/step - loss: 0.3099 - acc: 0.8589 - auc_roc: 0.9727
Epoch 33/80
1651/1651 [==============================] - 3s 2ms/step - loss: 0.3626 - acc: 0.8498 - auc_roc: 0.9727
Epoch 34/80
1651/1651 [==============================] - 3s 2ms/step - loss: 0.6126 - acc: 0.7553 - auc_roc: 0.9727
Epoch 35/80
1651/1651 [==============================] - 3s 2ms/step - loss: 0.4425 - acc: 0.8195 - auc_roc: 0.9727
Epoch 36/80
1651/1651 [==============================] - 3s 2ms/step - loss: 0.2888 - acc: 0.8789 - auc_roc: 0.9727
Epoch 37/80
1651/1651 [==============================] - 3s 2ms/step - loss: 0.2718 - acc: 0.8843 - auc_roc: 0.9727
Epoch 38/80
1651/1651 [==============================] - 3s 2ms/step - loss: 0.2926 - acc: 0.8583 - auc_roc: 0.9728
Epoch 39/80
1651/1651 [==============================] - 3s 2ms/step - loss: 0.2913 - acc: 0.8504 - auc_roc: 0.9728
Epoch 40/80
1651/1651 [==============================] - 3s 2ms/step - loss: 0.2810 - acc: 0.8667 - auc_roc: 0.9728
Epoch 41/80
1651/1651 [==============================] - 3s 2ms/step - loss: 0.2275 - acc: 0.8892 - auc_roc: 0.9729
Epoch 42/80
1651/1651 [==============================] - 3s 2ms/step - loss: 0.1882 - acc: 0.9164 - auc_roc: 0.9729
Epoch 43/80
1651/1651 [==============================] - 3s 2ms/step - loss: 0.1531 - acc: 0.9340 - auc_roc: 0.9730
Epoch 44/80
1651/1651 [==============================] - 3s 2ms/step - loss: 0.1305 - acc: 0.9455 - auc_roc: 0.9730
Epoch 45/80
1651/1651 [==============================] - 3s 2ms/step - loss: 0.1326 - acc: 0.9364 - auc_roc: 0.9731
Epoch 46/80
1651/1651 [==============================] - 3s 2ms/step - loss: 0.1254 - acc: 0.9479 - auc_roc: 0.9732
Epoch 47/80
1651/1651 [==============================] - 3s 2ms/step - loss: 0.1278 - acc: 0.9473 - auc_roc: 0.9732
Epoch 48/80
1651/1651 [==============================] - 3s 2ms/step - loss: 0.3383 - acc: 0.8686 - auc_roc: 0.9733
Epoch 49/80
1651/1651 [==============================] - 3s 2ms/step - loss: 0.2752 - acc: 0.8867 - auc_roc: 0.9733
Epoch 50/80
1651/1651 [==============================] - 3s 2ms/step - loss: 0.1691 - acc: 0.9328 - auc_roc: 0.9734
Epoch 51/80
1651/1651 [==============================] - 3s 2ms/step - loss: 0.1104 - acc: 0.9582 - auc_roc: 0.9734
Epoch 52/80
1651/1651 [==============================] - 3s 2ms/step - loss: 0.0929 - acc: 0.9606 - auc_roc: 0.9735
Epoch 53/80
1651/1651 [==============================] - 3s 2ms/step - loss: 0.0700 - acc: 0.9715 - auc_roc: 0.9736
Epoch 54/80
1651/1651 [==============================] - 3s 2ms/step - loss: 0.0691 - acc: 0.9758 - auc_roc: 0.9737
Epoch 55/80
1651/1651 [==============================] - 3s 2ms/step - loss: 0.0733 - acc: 0.9691 - auc_roc: 0.9737
Epoch 56/80
1651/1651 [==============================] - 3s 2ms/step - loss: 0.0802 - acc: 0.9661 - auc_roc: 0.9738
Epoch 57/80
1651/1651 [==============================] - 3s 2ms/step - loss: 0.0570 - acc: 0.9782 - auc_roc: 0.9739
Epoch 58/80
1651/1651 [==============================] - 3s 2ms/step - loss: 0.0452 - acc: 0.9861 - auc_roc: 0.9740
Epoch 59/80
1651/1651 [==============================] - 3s 2ms/step - loss: 0.0397 - acc: 0.9867 - auc_roc: 0.9741
Epoch 60/80
1651/1651 [==============================] - 3s 2ms/step - loss: 0.0611 - acc: 0.9776 - auc_roc: 0.9741
Epoch 61/80
1651/1651 [==============================] - 3s 2ms/step - loss: 0.0582 - acc: 0.9788 - auc_roc: 0.9742
Epoch 62/80
1651/1651 [==============================] - 3s 2ms/step - loss: 0.0517 - acc: 0.9812 - auc_roc: 0.9743
Epoch 63/80
1651/1651 [==============================] - 3s 2ms/step - loss: 0.0932 - acc: 0.9661 - auc_roc: 0.9744
Epoch 64/80
1651/1651 [==============================] - 3s 2ms/step - loss: 0.0817 - acc: 0.9727 - auc_roc: 0.9744
Epoch 65/80
1651/1651 [==============================] - 3s 2ms/step - loss: 0.1609 - acc: 0.9297 - auc_roc: 0.9745
Epoch 66/80
1651/1651 [==============================] - 3s 2ms/step - loss: 0.0673 - acc: 0.9740 - auc_roc: 0.9746
Epoch 67/80
1651/1651 [==============================] - 3s 2ms/step - loss: 0.0425 - acc: 0.9879 - auc_roc: 0.9747
Epoch 68/80
1651/1651 [==============================] - 3s 2ms/step - loss: 0.2088 - acc: 0.9437 - auc_roc: 0.9747
Epoch 69/80
1651/1651 [==============================] - 3s 2ms/step - loss: 0.2977 - acc: 0.8995 - auc_roc: 0.9748
Epoch 70/80
1651/1651 [==============================] - 3s 2ms/step - loss: 0.1581 - acc: 0.9400 - auc_roc: 0.9748
Epoch 71/80
1651/1651 [==============================] - 3s 2ms/step - loss: 0.0783 - acc: 0.9733 - auc_roc: 0.9749
Epoch 72/80
1651/1651 [==============================] - 3s 2ms/step - loss: 0.0585 - acc: 0.9830 - auc_roc: 0.9749
Epoch 73/80
1651/1651 [==============================] - 3s 2ms/step - loss: 0.0380 - acc: 0.9879 - auc_roc: 0.9750
Epoch 74/80
1651/1651 [==============================] - 3s 2ms/step - loss: 0.0304 - acc: 0.9933 - auc_roc: 0.9751
Epoch 75/80
1651/1651 [==============================] - 3s 2ms/step - loss: 0.0238 - acc: 0.9952 - auc_roc: 0.9752
Epoch 76/80
1651/1651 [==============================] - 3s 2ms/step - loss: 0.0279 - acc: 0.9903 - auc_roc: 0.9753
Epoch 77/80
1651/1651 [==============================] - 3s 2ms/step - loss: 0.0238 - acc: 0.9927 - auc_roc: 0.9754
Epoch 78/80
1651/1651 [==============================] - 3s 2ms/step - loss: 0.0195 - acc: 0.9976 - auc_roc: 0.9754
Epoch 79/80
1651/1651 [==============================] - 3s 2ms/step - loss: 0.0166 - acc: 0.9970 - auc_roc: 0.9755
Epoch 80/80
1651/1651 [==============================] - 3s 2ms/step - loss: 0.0141 - acc: 0.9964 - auc_roc: 0.9756
... history of metrics comprising: ['acc', 'loss', 'auc_roc']
... model fitting complete > starting model evaluation
modelEvaluate> scores:
[('loss', 2.4019636537023255), ('acc', 0.59097320177659329), ('auc_roc', 0.97556406831203291)]

info> infer classifier name from class name ...
runROCMulticlass> find 6 unique labels:
CKD Stage 1, CKD Stage 2, CKD Stage 3, CKD Stage 4, CKD Stage 5, Others

info> given pre-trained model ...
diagnosis> dim(y_score):(709, 6)
>>> test_auc_cv_metrics >>>
  + dimension test 
  + len(roc_auc):8 =?= n_classes (+{micro, macro}):6+2
  + class name: CKD Stage 1, mean_auc: 0.853996
  + ROC curve of class CKD Stage 1 (area = 0.85)
  + class name: CKD Stage 2, mean_auc: 0.747526
  + ROC curve of class CKD Stage 2 (area = 0.75)
  + class name: CKD Stage 3, mean_auc: 0.773321
  + ROC curve of class CKD Stage 3 (area = 0.77)
  + class name: CKD Stage 4, mean_auc: 0.747143
  + ROC curve of class CKD Stage 4 (area = 0.75)
  + class name: CKD Stage 5, mean_auc: 0.941298
  + ROC curve of class CKD Stage 5 (area = 0.94)
  + class name: Others, mean_auc: 0.843801
  + ROC curve of class Others (area = 0.84)
test_auc_cv_metrics> summary of AUCs vs classes ...
  + min | class=CKD Stage 4, auc=0.747143
  + max | class=CKD Stage 5, auc=0.941298
  + micro auc=0.866783 | macro auc=0.818902
  + Ranked AUC scores: 
    + class=CKD Stage 4, auc=0.747143
    + class=CKD Stage 2, auc=0.747526
    + class=CKD Stage 3, auc=0.773321
    + class=Others, auc=0.843801
    + class=CKD Stage 1, auc=0.853996
    + class=CKD Stage 5, auc=0.941298
  => [('CKD Stage 4', 0.74714285714285711), ('CKD Stage 2', 0.74752587991718422), ('CKD Stage 3', 0.77332076525624915), ('Others', 0.84380061683196872), ('CKD Stage 1', 0.85399581926354728), ('CKD Stage 5', 0.9412979613638387)]
output> saving performance to:
/Users/pleiades/Documents/work/tpheno/seqmaker/data/CKD/plot/roc-multiclass-Sequential-CKD-pv-dm2-regular-smallCKD.tif

runROCMulticlass> test set ratio: 0.300000
modelEvaluate> dim(X_train):(1651, 50, 100), dim(X_test): (709, 50, 100)
  + lookup:
{'Others': 5, 'CKD Stage 5': 4, 'CKD Stage 4': 3, 'CKD Stage 3': 2, 'CKD Stage 2': 1, 'CKD Stage 1': 0}

... class weights:
{0: 6.344086021505376, 1: 0.74494949494949492, 2: 1.1238095238095238, 3: 7.0238095238095237, 4: 0.51890941072999119, 5: 0.64906490649064907}

====================================================================================================
... early stopping>
       + patience: 20, model='max'
... model training>
       + batch_size: 32, epochs: 80, shuffle? True, metric: auc_roc
====================================================================================================
Epoch 1/80
1651/1651 [==============================] - 3s 2ms/step - loss: 1.8108 - acc: 0.1944 - auc_roc: 0.9754
Epoch 2/80
1651/1651 [==============================] - 3s 2ms/step - loss: 1.6732 - acc: 0.3240 - auc_roc: 0.9752
Epoch 3/80
1651/1651 [==============================] - 3s 2ms/step - loss: 1.4910 - acc: 0.4270 - auc_roc: 0.9750
Epoch 4/80
1651/1651 [==============================] - 3s 2ms/step - loss: 1.2941 - acc: 0.4815 - auc_roc: 0.9748
Epoch 5/80
1651/1651 [==============================] - 3s 2ms/step - loss: 1.1888 - acc: 0.5391 - auc_roc: 0.9747
Epoch 6/80
1651/1651 [==============================] - 3s 2ms/step - loss: 1.1377 - acc: 0.5342 - auc_roc: 0.9745
Epoch 7/80
1651/1651 [==============================] - 3s 2ms/step - loss: 1.0177 - acc: 0.5778 - auc_roc: 0.9744
Epoch 8/80
1651/1651 [==============================] - 3s 2ms/step - loss: 0.9658 - acc: 0.6021 - auc_roc: 0.9743
Epoch 9/80
1651/1651 [==============================] - 3s 2ms/step - loss: 0.9175 - acc: 0.5954 - auc_roc: 0.9742
Epoch 10/80
1651/1651 [==============================] - 3s 2ms/step - loss: 0.8267 - acc: 0.6360 - auc_roc: 0.9741
Epoch 11/80
1651/1651 [==============================] - 3s 2ms/step - loss: 0.7994 - acc: 0.6475 - auc_roc: 0.9741
Epoch 12/80
1651/1651 [==============================] - 3s 2ms/step - loss: 0.7449 - acc: 0.6614 - auc_roc: 0.9740
Epoch 13/80
1651/1651 [==============================] - 3s 2ms/step - loss: 0.7056 - acc: 0.6675 - auc_roc: 0.9739
Epoch 14/80
1651/1651 [==============================] - 3s 2ms/step - loss: 0.6655 - acc: 0.6893 - auc_roc: 0.9739
Epoch 15/80
1651/1651 [==============================] - 3s 2ms/step - loss: 0.6539 - acc: 0.6856 - auc_roc: 0.9738
Epoch 16/80
1651/1651 [==============================] - 3s 2ms/step - loss: 0.6065 - acc: 0.7177 - auc_roc: 0.9738
Epoch 17/80
1651/1651 [==============================] - 3s 2ms/step - loss: 0.5772 - acc: 0.7262 - auc_roc: 0.9737
Epoch 18/80
1651/1651 [==============================] - 3s 2ms/step - loss: 0.5783 - acc: 0.7238 - auc_roc: 0.9737
Epoch 19/80
1651/1651 [==============================] - 3s 2ms/step - loss: 0.5769 - acc: 0.7250 - auc_roc: 0.9737
Epoch 20/80
1651/1651 [==============================] - 3s 2ms/step - loss: 0.5243 - acc: 0.7462 - auc_roc: 0.9736
Epoch 21/80
1651/1651 [==============================] - 3s 2ms/step - loss: 0.5027 - acc: 0.7529 - auc_roc: 0.9736
Epoch 22/80
1651/1651 [==============================] - 3s 2ms/step - loss: 0.4821 - acc: 0.7620 - auc_roc: 0.9736
Epoch 23/80
1651/1651 [==============================] - 3s 2ms/step - loss: 0.4522 - acc: 0.7729 - auc_roc: 0.9736
Epoch 24/80
1651/1651 [==============================] - 3s 2ms/step - loss: 0.4147 - acc: 0.7904 - auc_roc: 0.9736
Epoch 25/80
1651/1651 [==============================] - 3s 2ms/step - loss: 0.4494 - acc: 0.7832 - auc_roc: 0.9736
Epoch 26/80
1651/1651 [==============================] - 3s 2ms/step - loss: 0.4980 - acc: 0.7747 - auc_roc: 0.9736
Epoch 27/80
1651/1651 [==============================] - 3s 2ms/step - loss: 0.4582 - acc: 0.7723 - auc_roc: 0.9736
Epoch 28/80
1651/1651 [==============================] - 3s 2ms/step - loss: 0.4737 - acc: 0.7735 - auc_roc: 0.9735
Epoch 29/80
1651/1651 [==============================] - 3s 2ms/step - loss: 0.3534 - acc: 0.8298 - auc_roc: 0.9735
Epoch 30/80
1651/1651 [==============================] - 3s 2ms/step - loss: 0.3357 - acc: 0.8304 - auc_roc: 0.9735
Epoch 31/80
1651/1651 [==============================] - 3s 2ms/step - loss: 0.3044 - acc: 0.8565 - auc_roc: 0.9736
Epoch 32/80
1651/1651 [==============================] - 3s 2ms/step - loss: 0.3279 - acc: 0.8528 - auc_roc: 0.9736
Epoch 33/80
1651/1651 [==============================] - 3s 2ms/step - loss: 0.2843 - acc: 0.8716 - auc_roc: 0.9736
Epoch 34/80
1651/1651 [==============================] - 3s 2ms/step - loss: 0.2356 - acc: 0.8916 - auc_roc: 0.9736
Epoch 35/80
1651/1651 [==============================] - 3s 2ms/step - loss: 0.2192 - acc: 0.9037 - auc_roc: 0.9737
Epoch 36/80
1651/1651 [==============================] - 3s 2ms/step - loss: 0.2209 - acc: 0.9043 - auc_roc: 0.9737
Epoch 37/80
1651/1651 [==============================] - 3s 2ms/step - loss: 0.2921 - acc: 0.8795 - auc_roc: 0.9737
Epoch 38/80
1651/1651 [==============================] - 3s 2ms/step - loss: 0.2093 - acc: 0.8995 - auc_roc: 0.9738
Epoch 39/80
1651/1651 [==============================] - 3s 2ms/step - loss: 0.2017 - acc: 0.9055 - auc_roc: 0.9738
Epoch 40/80
1651/1651 [==============================] - 3s 2ms/step - loss: 0.1810 - acc: 0.9164 - auc_roc: 0.9739
Epoch 41/80
1651/1651 [==============================] - 3s 2ms/step - loss: 0.1358 - acc: 0.9376 - auc_roc: 0.9739
Epoch 42/80
1651/1651 [==============================] - 3s 2ms/step - loss: 0.1408 - acc: 0.9461 - auc_roc: 0.9740
Epoch 43/80
1651/1651 [==============================] - 3s 2ms/step - loss: 0.2656 - acc: 0.8922 - auc_roc: 0.9740
Epoch 44/80
1651/1651 [==============================] - 3s 2ms/step - loss: 0.2373 - acc: 0.8928 - auc_roc: 0.9740
Epoch 45/80
1651/1651 [==============================] - 3s 2ms/step - loss: 0.1782 - acc: 0.9237 - auc_roc: 0.9741
Epoch 46/80
1651/1651 [==============================] - 3s 2ms/step - loss: 0.1324 - acc: 0.9400 - auc_roc: 0.9741
Epoch 47/80
1651/1651 [==============================] - 3s 2ms/step - loss: 0.1307 - acc: 0.9485 - auc_roc: 0.9742
Epoch 48/80
1651/1651 [==============================] - 3s 2ms/step - loss: 0.0998 - acc: 0.9570 - auc_roc: 0.9742
Epoch 49/80
1651/1651 [==============================] - 3s 2ms/step - loss: 0.0890 - acc: 0.9631 - auc_roc: 0.9743
Epoch 50/80
1651/1651 [==============================] - 3s 2ms/step - loss: 0.0799 - acc: 0.9721 - auc_roc: 0.9744
Epoch 51/80
1651/1651 [==============================] - 3s 2ms/step - loss: 0.0631 - acc: 0.9764 - auc_roc: 0.9744
Epoch 52/80
1651/1651 [==============================] - 3s 2ms/step - loss: 0.0631 - acc: 0.9752 - auc_roc: 0.9745
Epoch 53/80
1651/1651 [==============================] - 3s 2ms/step - loss: 0.0548 - acc: 0.9794 - auc_roc: 0.9746
Epoch 54/80
1651/1651 [==============================] - 3s 2ms/step - loss: 0.0806 - acc: 0.9697 - auc_roc: 0.9746
Epoch 55/80
1651/1651 [==============================] - 3s 2ms/step - loss: 0.2657 - acc: 0.9013 - auc_roc: 0.9747
Epoch 56/80
1651/1651 [==============================] - 3s 2ms/step - loss: 0.2355 - acc: 0.9170 - auc_roc: 0.9747
Epoch 57/80
1651/1651 [==============================] - 3s 2ms/step - loss: 0.2678 - acc: 0.9025 - auc_roc: 0.9747
Epoch 58/80
1651/1651 [==============================] - 3s 2ms/step - loss: 0.1433 - acc: 0.9400 - auc_roc: 0.9748
Epoch 59/80
1651/1651 [==============================] - 3s 2ms/step - loss: 0.0878 - acc: 0.9691 - auc_roc: 0.9748
Epoch 60/80
1651/1651 [==============================] - 3s 2ms/step - loss: 0.0588 - acc: 0.9812 - auc_roc: 0.9749
Epoch 61/80
1651/1651 [==============================] - 3s 2ms/step - loss: 0.0544 - acc: 0.9824 - auc_roc: 0.9750
Epoch 62/80
1651/1651 [==============================] - 3s 2ms/step - loss: 0.0522 - acc: 0.9806 - auc_roc: 0.9750
Epoch 63/80
1651/1651 [==============================] - 3s 2ms/step - loss: 0.1444 - acc: 0.9382 - auc_roc: 0.9751
Epoch 64/80
1651/1651 [==============================] - 3s 2ms/step - loss: 0.0680 - acc: 0.9746 - auc_roc: 0.9752
Epoch 65/80
1651/1651 [==============================] - 3s 2ms/step - loss: 0.0437 - acc: 0.9873 - auc_roc: 0.9752
Epoch 66/80
1651/1651 [==============================] - 3s 2ms/step - loss: 0.0374 - acc: 0.9867 - auc_roc: 0.9753
Epoch 67/80
1651/1651 [==============================] - 3s 2ms/step - loss: 0.0304 - acc: 0.9909 - auc_roc: 0.9754
Epoch 68/80
1651/1651 [==============================] - 3s 2ms/step - loss: 0.0251 - acc: 0.9927 - auc_roc: 0.9754
Epoch 69/80
1651/1651 [==============================] - 3s 2ms/step - loss: 0.0220 - acc: 0.9939 - auc_roc: 0.9755
Epoch 70/80
1651/1651 [==============================] - 3s 2ms/step - loss: 0.0219 - acc: 0.9939 - auc_roc: 0.9756
Epoch 71/80
1651/1651 [==============================] - 3s 2ms/step - loss: 0.0210 - acc: 0.9915 - auc_roc: 0.9757
Epoch 72/80
1651/1651 [==============================] - 3s 2ms/step - loss: 0.0230 - acc: 0.9933 - auc_roc: 0.9757
Epoch 73/80
1651/1651 [==============================] - 3s 2ms/step - loss: 0.0313 - acc: 0.9879 - auc_roc: 0.9758
Epoch 74/80
1651/1651 [==============================] - 3s 2ms/step - loss: 0.0413 - acc: 0.9867 - auc_roc: 0.9759
Epoch 75/80
1651/1651 [==============================] - 3s 2ms/step - loss: 0.0523 - acc: 0.9843 - auc_roc: 0.9759
Epoch 76/80
1651/1651 [==============================] - 3s 2ms/step - loss: 0.0246 - acc: 0.9945 - auc_roc: 0.9760
Epoch 77/80
1651/1651 [==============================] - 3s 2ms/step - loss: 0.0154 - acc: 0.9970 - auc_roc: 0.9761
Epoch 78/80
1651/1651 [==============================] - 3s 2ms/step - loss: 0.0205 - acc: 0.9964 - auc_roc: 0.9761
Epoch 79/80
1651/1651 [==============================] - 3s 2ms/step - loss: 0.1040 - acc: 0.9576 - auc_roc: 0.9762
Epoch 80/80
1651/1651 [==============================] - 3s 2ms/step - loss: 0.0444 - acc: 0.9861 - auc_roc: 0.9763
... history of metrics comprising: ['acc', 'loss', 'auc_roc']
... model fitting complete > starting model evaluation
modelEvaluate> scores:
[('loss', 2.2331960917527987), ('acc', 0.56981664320141368), ('auc_roc', 0.97622064878305026)]

info> infer classifier name from class name ...
runROCMulticlass> find 6 unique labels:
CKD Stage 1, CKD Stage 2, CKD Stage 3, CKD Stage 4, CKD Stage 5, Others

info> given pre-trained model ...
diagnosis> dim(y_score):(709, 6)
>>> test_auc_cv_metrics >>>
  + dimension test 
  + len(roc_auc):8 =?= n_classes (+{micro, macro}):6+2
  + class name: CKD Stage 1, mean_auc: 0.915789
  + ROC curve of class CKD Stage 1 (area = 0.92)
  + class name: CKD Stage 2, mean_auc: 0.757651
  + ROC curve of class CKD Stage 2 (area = 0.76)
  + class name: CKD Stage 3, mean_auc: 0.728472
  + ROC curve of class CKD Stage 3 (area = 0.73)
  + class name: CKD Stage 4, mean_auc: 0.743324
  + ROC curve of class CKD Stage 4 (area = 0.74)
  + class name: CKD Stage 5, mean_auc: 0.960361
  + ROC curve of class CKD Stage 5 (area = 0.96)
  + class name: Others, mean_auc: 0.819548
  + ROC curve of class Others (area = 0.82)
test_auc_cv_metrics> summary of AUCs vs classes ...
  + min | class=CKD Stage 3, auc=0.728472
  + max | class=CKD Stage 5, auc=0.960361
  + micro auc=0.867727 | macro auc=0.821802
  + Ranked AUC scores: 
    + class=CKD Stage 3, auc=0.728472
    + class=CKD Stage 4, auc=0.743324
    + class=CKD Stage 2, auc=0.757651
    + class=Others, auc=0.819548
    + class=CKD Stage 1, auc=0.915789
    + class=CKD Stage 5, auc=0.960361
  => [('CKD Stage 3', 0.72847169524965849), ('CKD Stage 4', 0.74332372718539863), ('CKD Stage 2', 0.75765056648777585), ('Others', 0.81954817412832681), ('CKD Stage 1', 0.91578947368421049), ('CKD Stage 5', 0.96036125987110843)]
output> saving performance to:
/Users/pleiades/Documents/work/tpheno/seqmaker/data/CKD/plot/roc-multiclass-Sequential-CKD-pv-dm2-regular-smallCKD.tif

runROCMulticlass> test set ratio: 0.300000
modelEvaluate> dim(X_train):(1651, 50, 100), dim(X_test): (709, 50, 100)
  + lookup:
{'Others': 5, 'CKD Stage 5': 4, 'CKD Stage 4': 3, 'CKD Stage 3': 2, 'CKD Stage 2': 1, 'CKD Stage 1': 0}

... class weights:
{0: 6.344086021505376, 1: 0.74494949494949492, 2: 1.1238095238095238, 3: 7.0238095238095237, 4: 0.51890941072999119, 5: 0.64906490649064907}

====================================================================================================
... early stopping>
       + patience: 20, model='max'
... model training>
       + batch_size: 32, epochs: 80, shuffle? True, metric: auc_roc
====================================================================================================
Epoch 1/80
1651/1651 [==============================] - 3s 2ms/step - loss: 1.7463 - acc: 0.2392 - auc_roc: 0.9761
Epoch 2/80
1651/1651 [==============================] - 3s 2ms/step - loss: 1.6315 - acc: 0.3640 - auc_roc: 0.9759
Epoch 3/80
1651/1651 [==============================] - 3s 2ms/step - loss: 1.4392 - acc: 0.4700 - auc_roc: 0.9757
Epoch 4/80
1651/1651 [==============================] - 3s 2ms/step - loss: 1.2872 - acc: 0.4894 - auc_roc: 0.9756
Epoch 5/80
1651/1651 [==============================] - 3s 2ms/step - loss: 1.1670 - acc: 0.5300 - auc_roc: 0.9755
Epoch 6/80
1651/1651 [==============================] - 3s 2ms/step - loss: 1.1263 - acc: 0.5294 - auc_roc: 0.9754
Epoch 7/80
1651/1651 [==============================] - 3s 2ms/step - loss: 1.0236 - acc: 0.5766 - auc_roc: 0.9753
Epoch 8/80
1651/1651 [==============================] - 3s 2ms/step - loss: 0.9463 - acc: 0.6069 - auc_roc: 0.9752
Epoch 9/80
1651/1651 [==============================] - 3s 2ms/step - loss: 0.9099 - acc: 0.5966 - auc_roc: 0.9751
Epoch 10/80
1651/1651 [==============================] - 3s 2ms/step - loss: 0.8911 - acc: 0.6039 - auc_roc: 0.9750
Epoch 11/80
1651/1651 [==============================] - 3s 2ms/step - loss: 0.8340 - acc: 0.6342 - auc_roc: 0.9750
Epoch 12/80
1651/1651 [==============================] - 3s 2ms/step - loss: 0.7421 - acc: 0.6657 - auc_roc: 0.9749
Epoch 13/80
1651/1651 [==============================] - 3s 2ms/step - loss: 0.7571 - acc: 0.6499 - auc_roc: 0.9749
Epoch 14/80
1651/1651 [==============================] - 3s 2ms/step - loss: 0.6985 - acc: 0.6687 - auc_roc: 0.9748
Epoch 15/80
1651/1651 [==============================] - 3s 2ms/step - loss: 0.6432 - acc: 0.6893 - auc_roc: 0.9748
Epoch 16/80
1651/1651 [==============================] - 3s 2ms/step - loss: 0.6223 - acc: 0.7044 - auc_roc: 0.9747
Epoch 17/80
1651/1651 [==============================] - 3s 2ms/step - loss: 0.5893 - acc: 0.7068 - auc_roc: 0.9747
Epoch 18/80
1651/1651 [==============================] - 3s 2ms/step - loss: 0.5737 - acc: 0.7286 - auc_roc: 0.9747
Epoch 19/80
1651/1651 [==============================] - 3s 2ms/step - loss: 0.5507 - acc: 0.7353 - auc_roc: 0.9746
Epoch 20/80
1651/1651 [==============================] - 3s 2ms/step - loss: 0.5028 - acc: 0.7547 - auc_roc: 0.9746
Epoch 21/80
1651/1651 [==============================] - 3s 2ms/step - loss: 0.5099 - acc: 0.7547 - auc_roc: 0.9746
Epoch 22/80
1651/1651 [==============================] - 3s 2ms/step - loss: 0.5835 - acc: 0.6972 - auc_roc: 0.9746
Epoch 23/80
1651/1651 [==============================] - 3s 2ms/step - loss: 0.4529 - acc: 0.7589 - auc_roc: 0.9745
Epoch 24/80
1651/1651 [==============================] - 3s 2ms/step - loss: 0.4221 - acc: 0.7904 - auc_roc: 0.9745
Epoch 25/80
1651/1651 [==============================] - 3s 2ms/step - loss: 0.4003 - acc: 0.7977 - auc_roc: 0.9745
Epoch 26/80
1651/1651 [==============================] - 3s 2ms/step - loss: 0.4099 - acc: 0.8038 - auc_roc: 0.9745
Epoch 27/80
1651/1651 [==============================] - 3s 2ms/step - loss: 0.3836 - acc: 0.8007 - auc_roc: 0.9745
Epoch 28/80
1651/1651 [==============================] - 3s 2ms/step - loss: 0.4884 - acc: 0.8038 - auc_roc: 0.9745
Epoch 29/80
1651/1651 [==============================] - 3s 2ms/step - loss: 0.4863 - acc: 0.7886 - auc_roc: 0.9745
Epoch 30/80
1651/1651 [==============================] - 3s 2ms/step - loss: 0.4096 - acc: 0.8141 - auc_roc: 0.9745
Epoch 31/80
1651/1651 [==============================] - 3s 2ms/step - loss: 0.3263 - acc: 0.8498 - auc_roc: 0.9745
Epoch 32/80
1651/1651 [==============================] - 3s 2ms/step - loss: 0.2873 - acc: 0.8637 - auc_roc: 0.9745
Epoch 33/80
1651/1651 [==============================] - 3s 2ms/step - loss: 0.2911 - acc: 0.8601 - auc_roc: 0.9746
Epoch 34/80
1651/1651 [==============================] - 3s 2ms/step - loss: 0.2565 - acc: 0.8879 - auc_roc: 0.9746
Epoch 35/80
1651/1651 [==============================] - 3s 2ms/step - loss: 0.2151 - acc: 0.8988 - auc_roc: 0.9746
Epoch 36/80
1651/1651 [==============================] - 3s 2ms/step - loss: 0.2005 - acc: 0.9079 - auc_roc: 0.9746
Epoch 37/80
1651/1651 [==============================] - 3s 2ms/step - loss: 0.1674 - acc: 0.9213 - auc_roc: 0.9747
Epoch 38/80
1651/1651 [==============================] - 3s 2ms/step - loss: 0.1526 - acc: 0.9340 - auc_roc: 0.9747
Epoch 39/80
1651/1651 [==============================] - 3s 2ms/step - loss: 0.1473 - acc: 0.9328 - auc_roc: 0.9748
Epoch 40/80
1651/1651 [==============================] - 3s 2ms/step - loss: 0.1486 - acc: 0.9328 - auc_roc: 0.9748
Epoch 41/80
1651/1651 [==============================] - 3s 2ms/step - loss: 0.1563 - acc: 0.9340 - auc_roc: 0.9749
Epoch 42/80
1651/1651 [==============================] - 3s 2ms/step - loss: 0.2300 - acc: 0.9055 - auc_roc: 0.9749
Epoch 43/80
1651/1651 [==============================] - 3s 2ms/step - loss: 0.2080 - acc: 0.9122 - auc_roc: 0.9749
Epoch 44/80
1651/1651 [==============================] - 3s 2ms/step - loss: 0.1993 - acc: 0.9213 - auc_roc: 0.9750
Epoch 45/80
1651/1651 [==============================] - 3s 2ms/step - loss: 0.1098 - acc: 0.9540 - auc_roc: 0.9750
Epoch 46/80
1651/1651 [==============================] - 3s 2ms/step - loss: 0.0907 - acc: 0.9649 - auc_roc: 0.9751
Epoch 47/80
1651/1651 [==============================] - 3s 2ms/step - loss: 0.1788 - acc: 0.9394 - auc_roc: 0.9751
Epoch 48/80
1651/1651 [==============================] - 3s 2ms/step - loss: 0.1265 - acc: 0.9552 - auc_roc: 0.9751
Epoch 49/80
1651/1651 [==============================] - 3s 2ms/step - loss: 0.1847 - acc: 0.9219 - auc_roc: 0.9752
Epoch 50/80
1651/1651 [==============================] - 3s 2ms/step - loss: 0.1345 - acc: 0.9485 - auc_roc: 0.9752
Epoch 51/80
1651/1651 [==============================] - 3s 2ms/step - loss: 0.0863 - acc: 0.9697 - auc_roc: 0.9753
Epoch 52/80
1651/1651 [==============================] - 3s 2ms/step - loss: 0.0715 - acc: 0.9733 - auc_roc: 0.9753
Epoch 53/80
1651/1651 [==============================] - 3s 2ms/step - loss: 0.0706 - acc: 0.9782 - auc_roc: 0.9754
Epoch 54/80
1651/1651 [==============================] - 3s 2ms/step - loss: 0.0591 - acc: 0.9800 - auc_roc: 0.9755
Epoch 55/80
1651/1651 [==============================] - 3s 2ms/step - loss: 0.0501 - acc: 0.9849 - auc_roc: 0.9755
Epoch 56/80
1651/1651 [==============================] - 3s 2ms/step - loss: 0.0390 - acc: 0.9909 - auc_roc: 0.9756
Epoch 57/80
1651/1651 [==============================] - 3s 2ms/step - loss: 0.0397 - acc: 0.9897 - auc_roc: 0.9756
Epoch 58/80
1651/1651 [==============================] - 3s 2ms/step - loss: 0.0397 - acc: 0.9867 - auc_roc: 0.9757
Epoch 59/80
1651/1651 [==============================] - 3s 2ms/step - loss: 0.0693 - acc: 0.9776 - auc_roc: 0.9758
Epoch 60/80
1651/1651 [==============================] - 3s 2ms/step - loss: 0.1461 - acc: 0.9485 - auc_roc: 0.9758
Epoch 61/80
1651/1651 [==============================] - 3s 2ms/step - loss: 0.2386 - acc: 0.9001 - auc_roc: 0.9758
Epoch 62/80
1651/1651 [==============================] - 3s 2ms/step - loss: 0.1094 - acc: 0.9552 - auc_roc: 0.9759
Epoch 63/80
1651/1651 [==============================] - 3s 2ms/step - loss: 0.1346 - acc: 0.9479 - auc_roc: 0.9759
Epoch 64/80
1651/1651 [==============================] - 3s 2ms/step - loss: 0.1303 - acc: 0.9455 - auc_roc: 0.9760
Epoch 65/80
1651/1651 [==============================] - 3s 2ms/step - loss: 0.0880 - acc: 0.9697 - auc_roc: 0.9760
Epoch 66/80
1651/1651 [==============================] - 3s 2ms/step - loss: 0.0751 - acc: 0.9733 - auc_roc: 0.9761
Epoch 67/80
1651/1651 [==============================] - 3s 2ms/step - loss: 0.0618 - acc: 0.9746 - auc_roc: 0.9761
Epoch 68/80
1651/1651 [==============================] - 3s 2ms/step - loss: 0.0659 - acc: 0.9721 - auc_roc: 0.9762
Epoch 69/80
1651/1651 [==============================] - 3s 2ms/step - loss: 0.0291 - acc: 0.9915 - auc_roc: 0.9762
Epoch 70/80
1651/1651 [==============================] - 3s 2ms/step - loss: 0.0255 - acc: 0.9945 - auc_roc: 0.9763
Epoch 71/80
1651/1651 [==============================] - 3s 2ms/step - loss: 0.0199 - acc: 0.9958 - auc_roc: 0.9764
Epoch 72/80
1651/1651 [==============================] - 3s 2ms/step - loss: 0.0347 - acc: 0.9885 - auc_roc: 0.9764
Epoch 73/80
1651/1651 [==============================] - 3s 2ms/step - loss: 0.0228 - acc: 0.9945 - auc_roc: 0.9765
Epoch 74/80
1651/1651 [==============================] - 3s 2ms/step - loss: 0.0207 - acc: 0.9952 - auc_roc: 0.9765
Epoch 75/80
1651/1651 [==============================] - 3s 2ms/step - loss: 0.0179 - acc: 0.9976 - auc_roc: 0.9766
Epoch 76/80
1651/1651 [==============================] - 3s 2ms/step - loss: 0.0155 - acc: 0.9970 - auc_roc: 0.9767
Epoch 77/80
1651/1651 [==============================] - 3s 2ms/step - loss: 0.0167 - acc: 0.9976 - auc_roc: 0.9767
Epoch 78/80
1651/1651 [==============================] - 3s 2ms/step - loss: 0.0157 - acc: 0.9952 - auc_roc: 0.9768
Epoch 79/80
1651/1651 [==============================] - 3s 2ms/step - loss: 0.0104 - acc: 0.9988 - auc_roc: 0.9768
Epoch 80/80
1651/1651 [==============================] - 3s 2ms/step - loss: 0.0127 - acc: 0.9988 - auc_roc: 0.9769
... history of metrics comprising: ['acc', 'loss', 'auc_roc']
... model fitting complete > starting model evaluation
modelEvaluate> scores:
[('loss', 2.7678330225856222), ('acc', 0.58956276445698164), ('auc_roc', 0.97687193654656246)]

info> infer classifier name from class name ...
runROCMulticlass> find 6 unique labels:
CKD Stage 1, CKD Stage 2, CKD Stage 3, CKD Stage 4, CKD Stage 5, Others

info> given pre-trained model ...
diagnosis> dim(y_score):(709, 6)
>>> test_auc_cv_metrics >>>
  + dimension test 
  + len(roc_auc):8 =?= n_classes (+{micro, macro}):6+2
  + class name: CKD Stage 1, mean_auc: 0.844746
  + ROC curve of class CKD Stage 1 (area = 0.84)
  + class name: CKD Stage 2, mean_auc: 0.767000
  + ROC curve of class CKD Stage 2 (area = 0.77)
  + class name: CKD Stage 3, mean_auc: 0.722381
  + ROC curve of class CKD Stage 3 (area = 0.72)
  + class name: CKD Stage 4, mean_auc: 0.676641
  + ROC curve of class CKD Stage 4 (area = 0.68)
  + class name: CKD Stage 5, mean_auc: 0.945396
  + ROC curve of class CKD Stage 5 (area = 0.95)
  + class name: Others, mean_auc: 0.809577
  + ROC curve of class Others (area = 0.81)
test_auc_cv_metrics> summary of AUCs vs classes ...
  + min | class=CKD Stage 4, auc=0.676641
  + max | class=CKD Stage 5, auc=0.945396
  + micro auc=0.857500 | macro auc=0.795697
  + Ranked AUC scores: 
    + class=CKD Stage 4, auc=0.676641
    + class=CKD Stage 3, auc=0.722381
    + class=CKD Stage 2, auc=0.767000
    + class=Others, auc=0.809577
    + class=CKD Stage 1, auc=0.844746
    + class=CKD Stage 5, auc=0.945396
  => [('CKD Stage 4', 0.67664059843590607), ('CKD Stage 3', 0.72238129757158387), ('CKD Stage 2', 0.76699967773122779), ('Others', 0.80957690837262652), ('CKD Stage 1', 0.8447460299583287), ('CKD Stage 5', 0.94539566499935879)]
output> saving performance to:
/Users/pleiades/Documents/work/tpheno/seqmaker/data/CKD/plot/roc-multiclass-Sequential-CKD-pv-dm2-regular-smallCKD.tif

runROCMulticlass> test set ratio: 0.300000
modelEvaluate> dim(X_train):(1651, 50, 100), dim(X_test): (709, 50, 100)
  + lookup:
{'Others': 5, 'CKD Stage 5': 4, 'CKD Stage 4': 3, 'CKD Stage 3': 2, 'CKD Stage 2': 1, 'CKD Stage 1': 0}

... class weights:
{0: 6.344086021505376, 1: 0.74494949494949492, 2: 1.1238095238095238, 3: 7.0238095238095237, 4: 0.51890941072999119, 5: 0.64906490649064907}

====================================================================================================
... early stopping>
       + patience: 20, model='max'
... model training>
       + batch_size: 32, epochs: 80, shuffle? True, metric: auc_roc
====================================================================================================
Epoch 1/80
1651/1651 [==============================] - 3s 2ms/step - loss: 1.7725 - acc: 0.1853 - auc_roc: 0.9767
Epoch 2/80
1651/1651 [==============================] - 3s 2ms/step - loss: 1.6439 - acc: 0.3773 - auc_roc: 0.9765
Epoch 3/80
1651/1651 [==============================] - 3s 2ms/step - loss: 1.4557 - acc: 0.4512 - auc_roc: 0.9764
Epoch 4/80
1651/1651 [==============================] - 3s 2ms/step - loss: 1.2815 - acc: 0.4779 - auc_roc: 0.9763
Epoch 5/80
1651/1651 [==============================] - 3s 2ms/step - loss: 1.2244 - acc: 0.5233 - auc_roc: 0.9762
Epoch 6/80
1651/1651 [==============================] - 3s 2ms/step - loss: 1.0629 - acc: 0.5857 - auc_roc: 0.9761
Epoch 7/80
1651/1651 [==============================] - 3s 2ms/step - loss: 0.9702 - acc: 0.5899 - auc_roc: 0.9760
Epoch 8/80
1651/1651 [==============================] - 3s 2ms/step - loss: 0.9539 - acc: 0.6008 - auc_roc: 0.9759
Epoch 9/80
1651/1651 [==============================] - 3s 2ms/step - loss: 0.9103 - acc: 0.5936 - auc_roc: 0.9759
Epoch 10/80
1651/1651 [==============================] - 3s 2ms/step - loss: 0.8679 - acc: 0.6081 - auc_roc: 0.9758
Epoch 11/80
1651/1651 [==============================] - 3s 2ms/step - loss: 0.7439 - acc: 0.6548 - auc_roc: 0.9757
Epoch 12/80
1651/1651 [==============================] - 3s 2ms/step - loss: 0.7406 - acc: 0.6766 - auc_roc: 0.9757
Epoch 13/80
1651/1651 [==============================] - 3s 2ms/step - loss: 0.7096 - acc: 0.6747 - auc_roc: 0.9756
Epoch 14/80
1651/1651 [==============================] - 3s 2ms/step - loss: 0.6989 - acc: 0.6875 - auc_roc: 0.9756
Epoch 15/80
1651/1651 [==============================] - 3s 2ms/step - loss: 0.6255 - acc: 0.6941 - auc_roc: 0.9755
Epoch 16/80
1651/1651 [==============================] - 3s 2ms/step - loss: 0.5723 - acc: 0.7196 - auc_roc: 0.9755
Epoch 17/80
1651/1651 [==============================] - 3s 2ms/step - loss: 0.5560 - acc: 0.7305 - auc_roc: 0.9755
Epoch 18/80
1651/1651 [==============================] - 3s 2ms/step - loss: 0.5516 - acc: 0.7408 - auc_roc: 0.9755
Epoch 19/80
1651/1651 [==============================] - 3s 2ms/step - loss: 0.5029 - acc: 0.7420 - auc_roc: 0.9754
Epoch 20/80
1651/1651 [==============================] - 3s 2ms/step - loss: 0.4725 - acc: 0.7559 - auc_roc: 0.9754
Epoch 21/80
1651/1651 [==============================] - 3s 2ms/step - loss: 0.4526 - acc: 0.7723 - auc_roc: 0.9754
Epoch 22/80
1651/1651 [==============================] - 3s 2ms/step - loss: 0.4588 - acc: 0.7741 - auc_roc: 0.9754
Epoch 23/80
1651/1651 [==============================] - 3s 2ms/step - loss: 0.5852 - acc: 0.7359 - auc_roc: 0.9754
Epoch 24/80
1651/1651 [==============================] - 3s 2ms/step - loss: 0.5268 - acc: 0.7498 - auc_roc: 0.9754
Epoch 25/80
1651/1651 [==============================] - 3s 2ms/step - loss: 0.4593 - acc: 0.7838 - auc_roc: 0.9754
Epoch 26/80
1651/1651 [==============================] - 3s 2ms/step - loss: 0.4387 - acc: 0.7710 - auc_roc: 0.9753
Epoch 27/80
1651/1651 [==============================] - 3s 2ms/step - loss: 0.3690 - acc: 0.8177 - auc_roc: 0.9753
Epoch 28/80
1651/1651 [==============================] - 3s 2ms/step - loss: 0.3493 - acc: 0.8262 - auc_roc: 0.9753
Epoch 29/80
1651/1651 [==============================] - 3s 2ms/step - loss: 0.3234 - acc: 0.8413 - auc_roc: 0.9753
Epoch 30/80
1651/1651 [==============================] - 3s 2ms/step - loss: 0.3681 - acc: 0.8304 - auc_roc: 0.9754
Epoch 31/80
1651/1651 [==============================] - 3s 2ms/step - loss: 0.5802 - acc: 0.7414 - auc_roc: 0.9754
Epoch 32/80
1651/1651 [==============================] - 3s 2ms/step - loss: 0.5429 - acc: 0.7498 - auc_roc: 0.9753
Epoch 33/80
1651/1651 [==============================] - 3s 2ms/step - loss: 0.4642 - acc: 0.7929 - auc_roc: 0.9753
Epoch 34/80
1651/1651 [==============================] - 3s 2ms/step - loss: 0.3626 - acc: 0.8201 - auc_roc: 0.9753
Epoch 35/80
1651/1651 [==============================] - 3s 2ms/step - loss: 0.2958 - acc: 0.8540 - auc_roc: 0.9753
Epoch 36/80
1651/1651 [==============================] - 3s 2ms/step - loss: 0.2694 - acc: 0.8667 - auc_roc: 0.9753
Epoch 37/80
1651/1651 [==============================] - 3s 2ms/step - loss: 0.2766 - acc: 0.8710 - auc_roc: 0.9754
Epoch 38/80
1651/1651 [==============================] - 3s 2ms/step - loss: 0.2597 - acc: 0.8764 - auc_roc: 0.9754
Epoch 39/80
1651/1651 [==============================] - 3s 2ms/step - loss: 0.2103 - acc: 0.9019 - auc_roc: 0.9754
Epoch 40/80
1651/1651 [==============================] - 3s 2ms/step - loss: 0.2042 - acc: 0.9019 - auc_roc: 0.9754
Epoch 41/80
1651/1651 [==============================] - 3s 2ms/step - loss: 0.1863 - acc: 0.9128 - auc_roc: 0.9755
Epoch 42/80
1651/1651 [==============================] - 3s 2ms/step - loss: 0.1953 - acc: 0.9152 - auc_roc: 0.9755
Epoch 43/80
1651/1651 [==============================] - 3s 2ms/step - loss: 0.1522 - acc: 0.9297 - auc_roc: 0.9755
Epoch 44/80
1651/1651 [==============================] - 3s 2ms/step - loss: 0.1399 - acc: 0.9340 - auc_roc: 0.9756
Epoch 45/80
1651/1651 [==============================] - 3s 2ms/step - loss: 0.1285 - acc: 0.9443 - auc_roc: 0.9756
Epoch 46/80
1651/1651 [==============================] - 3s 2ms/step - loss: 0.1202 - acc: 0.9461 - auc_roc: 0.9756
Epoch 47/80
1651/1651 [==============================] - 3s 2ms/step - loss: 0.2574 - acc: 0.8740 - auc_roc: 0.9757
Epoch 48/80
1651/1651 [==============================] - 3s 2ms/step - loss: 0.1566 - acc: 0.9316 - auc_roc: 0.9757
Epoch 49/80
1651/1651 [==============================] - 3s 2ms/step - loss: 0.1102 - acc: 0.9485 - auc_roc: 0.9757
Epoch 50/80
1651/1651 [==============================] - 3s 2ms/step - loss: 0.0993 - acc: 0.9552 - auc_roc: 0.9758
Epoch 51/80
1651/1651 [==============================] - 3s 2ms/step - loss: 0.0784 - acc: 0.9649 - auc_roc: 0.9758
Epoch 52/80
1651/1651 [==============================] - 3s 2ms/step - loss: 0.2787 - acc: 0.8861 - auc_roc: 0.9759
Epoch 53/80
1651/1651 [==============================] - 3s 2ms/step - loss: 0.3805 - acc: 0.8516 - auc_roc: 0.9759
Epoch 54/80
1651/1651 [==============================] - 3s 2ms/step - loss: 0.1847 - acc: 0.9243 - auc_roc: 0.9759
Epoch 55/80
1651/1651 [==============================] - 3s 2ms/step - loss: 0.1284 - acc: 0.9431 - auc_roc: 0.9759
Epoch 56/80
1651/1651 [==============================] - 3s 2ms/step - loss: 0.0894 - acc: 0.9631 - auc_roc: 0.9760
Epoch 57/80
1651/1651 [==============================] - 3s 2ms/step - loss: 0.0763 - acc: 0.9697 - auc_roc: 0.9760
Epoch 58/80
1651/1651 [==============================] - 3s 2ms/step - loss: 0.0849 - acc: 0.9679 - auc_roc: 0.9761
Epoch 59/80
1651/1651 [==============================] - 3s 2ms/step - loss: 0.0731 - acc: 0.9746 - auc_roc: 0.9761
Epoch 60/80
1651/1651 [==============================] - 3s 2ms/step - loss: 0.0577 - acc: 0.9752 - auc_roc: 0.9762
Epoch 61/80
1651/1651 [==============================] - 3s 2ms/step - loss: 0.0493 - acc: 0.9867 - auc_roc: 0.9762
Epoch 62/80
1651/1651 [==============================] - 3s 2ms/step - loss: 0.0503 - acc: 0.9843 - auc_roc: 0.9763
Epoch 63/80
1651/1651 [==============================] - 3s 2ms/step - loss: 0.0713 - acc: 0.9727 - auc_roc: 0.9763
Epoch 64/80
1651/1651 [==============================] - 3s 2ms/step - loss: 0.0531 - acc: 0.9824 - auc_roc: 0.9764
Epoch 65/80
1651/1651 [==============================] - 3s 2ms/step - loss: 0.0393 - acc: 0.9885 - auc_roc: 0.9764
Epoch 66/80
1651/1651 [==============================] - 3s 2ms/step - loss: 0.0549 - acc: 0.9836 - auc_roc: 0.9765
Epoch 67/80
1651/1651 [==============================] - 3s 2ms/step - loss: 0.0344 - acc: 0.9891 - auc_roc: 0.9765
Epoch 68/80
1651/1651 [==============================] - 3s 2ms/step - loss: 0.0188 - acc: 0.9982 - auc_roc: 0.9766
Epoch 69/80
1651/1651 [==============================] - 3s 2ms/step - loss: 0.0208 - acc: 0.9933 - auc_roc: 0.9766
Epoch 70/80
1651/1651 [==============================] - 3s 2ms/step - loss: 0.1471 - acc: 0.9455 - auc_roc: 0.9767
Epoch 71/80
1651/1651 [==============================] - 3s 2ms/step - loss: 0.0903 - acc: 0.9576 - auc_roc: 0.9767
Epoch 72/80
1651/1651 [==============================] - 3s 2ms/step - loss: 0.0457 - acc: 0.9855 - auc_roc: 0.9768
Epoch 73/80
1651/1651 [==============================] - 3s 2ms/step - loss: 0.0270 - acc: 0.9964 - auc_roc: 0.9768
Epoch 74/80
1651/1651 [==============================] - 3s 2ms/step - loss: 0.0202 - acc: 0.9958 - auc_roc: 0.9769
Epoch 75/80
1651/1651 [==============================] - 3s 2ms/step - loss: 0.0222 - acc: 0.9933 - auc_roc: 0.9769
Epoch 76/80
1651/1651 [==============================] - 3s 2ms/step - loss: 0.0206 - acc: 0.9939 - auc_roc: 0.9770
Epoch 77/80
1651/1651 [==============================] - 3s 2ms/step - loss: 0.0159 - acc: 0.9964 - auc_roc: 0.9770
Epoch 78/80
1651/1651 [==============================] - 3s 2ms/step - loss: 0.0132 - acc: 0.9988 - auc_roc: 0.9771
Epoch 79/80
1651/1651 [==============================] - 3s 2ms/step - loss: 0.0127 - acc: 0.9970 - auc_roc: 0.9771
Epoch 80/80
1651/1651 [==============================] - 3s 2ms/step - loss: 0.0128 - acc: 0.9982 - auc_roc: 0.9772
... history of metrics comprising: ['acc', 'loss', 'auc_roc']
... model fitting complete > starting model evaluation
modelEvaluate> scores:
[('loss', 2.7673042792359261), ('acc', 0.57968970389224916), ('auc_roc', 0.977156751330716)]

info> infer classifier name from class name ...
runROCMulticlass> find 6 unique labels:
CKD Stage 1, CKD Stage 2, CKD Stage 3, CKD Stage 4, CKD Stage 5, Others

info> given pre-trained model ...
diagnosis> dim(y_score):(709, 6)
>>> test_auc_cv_metrics >>>
  + dimension test 
  + len(roc_auc):8 =?= n_classes (+{micro, macro}):6+2
  + class name: CKD Stage 1, mean_auc: 0.854462
  + ROC curve of class CKD Stage 1 (area = 0.85)
  + class name: CKD Stage 2, mean_auc: 0.740793
  + ROC curve of class CKD Stage 2 (area = 0.74)
  + class name: CKD Stage 3, mean_auc: 0.761361
  + ROC curve of class CKD Stage 3 (area = 0.76)
  + class name: CKD Stage 4, mean_auc: 0.743326
  + ROC curve of class CKD Stage 4 (area = 0.74)
  + class name: CKD Stage 5, mean_auc: 0.952343
  + ROC curve of class CKD Stage 5 (area = 0.95)
  + class name: Others, mean_auc: 0.836037
  + ROC curve of class Others (area = 0.84)
test_auc_cv_metrics> summary of AUCs vs classes ...
  + min | class=CKD Stage 2, auc=0.740793
  + max | class=CKD Stage 5, auc=0.952343
  + micro auc=0.864011 | macro auc=0.815634
  + Ranked AUC scores: 
    + class=CKD Stage 2, auc=0.740793
    + class=CKD Stage 4, auc=0.743326
    + class=CKD Stage 3, auc=0.761361
    + class=Others, auc=0.836037
    + class=CKD Stage 1, auc=0.854462
    + class=CKD Stage 5, auc=0.952343
  => [('CKD Stage 2', 0.74079327811474172), ('CKD Stage 4', 0.74332611832611839), ('CKD Stage 3', 0.76136106395019798), ('Others', 0.83603703272388497), ('CKD Stage 1', 0.85446224256292902), ('CKD Stage 5', 0.95234252471094571)]
output> saving performance to:
/Users/pleiades/Documents/work/tpheno/seqmaker/data/CKD/plot/roc-multiclass-Sequential-CKD-pv-dm2-regular-smallCKD.tif

analyze_perf> min => 
Counter({'CKD Stage 4': 6, 'CKD Stage 3': 3, 'CKD Stage 2': 1})

analyze_perf> max => 
Counter({'CKD Stage 5': 10})

result> min(label: CKD Stage 4, score: 0.695957), err: (0.62799389778794812, 0.74714285714285711)
        max(label: CKD Stage 5, score: 0.951754), err: (0.9412979613638387, 0.96163785090165455)
result> other performance metrics ...
    + metric=micro => 0.864231 (err: (0.85177955800995053, 0.87767132634812139))
    + metric=macro => 0.808338 (err: (0.78820236319878934, 0.82296970213688814))
    + metric=loss => 2.368048 (err: (1.9026417594366249, 2.8642688389389406))
    + metric=acc => 0.582623 (err: (0.55007052202991435, 0.60225669966093742))
    + metric=auc_roc => 0.976080 (err: (0.9742259369750621, 0.98063528705887459))
pleiades@~/Documents/work/tpheno/seqmaker\:) [A
  [Restored Jul 8, 2018, 10:29:15 PM]
Last login: Sun Jul  8 22:29:11 on ttys000
/usr/bin/python: No module named virtualenvwrapper
virtualenvwrapper.sh: There was a problem running the initialization hooks. 

If Python could not import the module virtualenvwrapper.hook_loader,
check that virtualenvwrapper has been installed for
VIRTUALENVWRAPPER_PYTHON=/usr/bin/python and that PATH is
set properly.
pleiades@~/Documents/work/tpheno/seqmaker\:) cd data
pleiades@~/Documents/work/tpheno/seqmaker/data\:) ls
CKD/  CKD0/  PTSD/  SpA/  cluster_analysis/  cluster_stats-max_vote-Tbinary-Ckmeans-Sregular-D2Vtfidfavg.csv  code_measure_specimen.csv  diabetes/
pleiades@~/Documents/work/tpheno/seqmaker/data\:) ls CKD0/
pleiades@~/Documents/work/tpheno/seqmaker/data\:) ls CKD/
combined/			    eMerge_NKF_Stage_20170818.csv*	  lcs_local-df-diag-iso-LCKDStage2.csv	lcs_local-df-diag-iso-LCKDStage4.csv  lcs_local-df-diag-iso-LOthers.csv  nns_model/  plot/
condition_drug_labeled_seq-CKD.csv  lcs_local-df-diag-iso-LCKDStage1.csv  lcs_local-df-diag-iso-LCKDStage3.csv	lcs_local-df-diag-iso-LCKDStage5.csv  model/				 pathway/    test/
pleiades@~/Documents/work/tpheno/seqmaker/data\:) cd CKD0/
pleiades@~/Documents/work/tpheno/seqmaker/data/CKD0\:) ln -s ~/Documents/work/tpheno/seqmaker/data/CKD/condition_drug_labeled_seq-CKD.csv ~/Documents/work/tpheno/seqmaker/data/CKD0/condition_drug_labeled_seq-CKD.csv
pleiades@~/Documents/work/tpheno/seqmaker/data/CKD0\:) ls
condition_drug_labeled_seq-CKD.csv@
pleiades@~/Documents/work/tpheno/seqmaker/data/CKD0\:) ls -al condition_drug_labeled_seq-CKD.csv@
ls: cannot access 'condition_drug_labeled_seq-CKD.csv@': No such file or directory
pleiades@~/Documents/work/tpheno/seqmaker/data/CKD0\:) ls -al condition_drug_labeled_seq-CKD.csv
lrwxr-xr-x 1 pleiades 90 Jul 12 19:29 condition_drug_labeled_seq-CKD.csv -> /Users/pleiades/Documents/work/tpheno/seqmaker/data/CKD/condition_drug_labeled_seq-CKD.csv
pleiades@~/Documents/work/tpheno/seqmaker/data/CKD0\:) cdtp
pleiades@~/Documents/work/tpheno\:) source set_env.sh 
pleiades@~/Documents/work/tpheno\:) cd seqmaker/
pleiades@~/Documents/work/tpheno/seqmaker\:) ls
Wnns-ep100b32.h5    d2v			graph.py	   pathAnalyzer-FsRF.py   plot_compare_manifolds.py	 seqClassify-PostSGD.py        seqClassify.py		     seqGen.py	       seqTransform.pyc  tp_parser.py
__init__.py	    data/		graph.pyc	   pathAnalyzer-GB10K.py  query.py			 seqClassify-PriorGB.py        seqClassify.pyc		     seqMaker.py       seqUtils.py	 tset.py
__init__.pyc	    deep_utils.py	hc.py		   pathAnalyzer-RF10K.py  roc-multiclass-l1log-iris.tif  seqClassify-PriorRF.py        seqClassify0.py		     seqMaker2.py      seqUtils.pyc	 tset.pyc
algorithms.py	    density_est.py	init_weights.h5    pathAnalyzer.py	  select_cohort.py		 seqClassify-PriorSGD.py       seqClassifyTest-GB.py	     seqMaker2.pyc     seqparams.py	 tsne_test.py
algorithms.pyc	    dnn_demo.py		labeling.py	   pathAnalyzerApp.py	  seq2seq.py			 seqClassify-RegGB.py	       seqClassifyTest1.py	     seqMaker3.py      seqparams.pyc	 vector.py
analyzer.py	    dnn_utils.py	labeling.pyc	   pathAnalyzerTest.py	  seqAlgo.py			 seqClassify-RegRF.py	       seqClassifyTest2-SmallCKD.py  seqReader.py      similarity.log	 vector.pyc
analyzer.pyc	    doc/		lcs.py		   pathwayAnalyzer.py	  seqAlgo.pyc			 seqClassify-RegSGD.py	       seqClassifyTestT10V50.py      seqReader.pyc     star.py		 word2vec.py
archive/	    docProc.py		lcsApp.py	   pathwayAnalyzer0.py	  seqAnalyzer.py		 seqClassify-SparseGB.py       seqCluster.py		     seqReaderApp.py   targets.py
best		    docProc.pyc		learn_manifold.py  pathwayLabeler.py	  seqAnalyzer.pyc		 seqClassify-SparsePostGB.py   seqCluster.pyc		     seqReaderTest.py  targets.pyc
cohort.py	    draft.py		modelSelect.py	   plot/		  seqAnalyzerApp.py		 seqClassify-SparsePriorGB.py  seqCluster0.py		     seqSampling.py    tdoc.py
cohort.pyc	    embedding_utils.py	modelSelect.pyc    plotUtils.py		  seqAnalyzerTest.py		 seqClassify-SparseSGD.py      seqClusterTest.py	     seqSampling.pyc   tdoc.pyc
cohort_analyzer.py  evaluate.py		motif.py	   plotUtils.pyc	  seqClassify-PostGB.py		 seqClassify-VisitGB-Dev.py    seqConfig.py		     seqTest.py        test/
cohort_odhsi.py     evaluate.pyc	outlier.py	   plotUtils0.py	  seqClassify-PostRF.py		 seqClassify-VisitGB.py        seqConfig.pyc		     seqTransform.py   timing.py
pleiades@~/Documents/work/tpheno/seqmaker\:) python seqClassifyTest2-SmallCKD.py
========================================
0:00:03.533 - Start Program
========================================

Traceback (most recent call last):
  File "seqClassifyTest2-SmallCKD.py", line 4873, in <module>
    test()
  File "seqClassifyTest2-SmallCKD.py", line 4733, in test
    assert os.path.exists(ipath), "Invaid user input path:\n%s\n" % ipath
AssertionError: Invaid user input path:
/Users/pleiades/Documents/work/tpheno/data-exp/CKD0/condition_drug_labeled_seq-CKD.csv

========================================
0:00:03.536 - End Program
Elapsed time: 0:00:00.003
========================================

pleiades@~/Documents/work/tpheno/seqmaker\:) ls -l /Users/pleiades/Documents/work/tpheno/data-exp/CKD0/condition_drug_labeled_seq-CKD.csv
ls: cannot access '/Users/pleiades/Documents/work/tpheno/data-exp/CKD0/condition_drug_labeled_seq-CKD.csv': No such file or directory
pleiades@~/Documents/work/tpheno/seqmaker\:) cd data-exp
-bash: cd: data-exp: No such file or directory
pleiades@~/Documents/work/tpheno/seqmaker\:) cd ../data-exp
pleiades@~/Documents/work/tpheno/data-exp\:) ls
CKD/							condition_drug_multilabel.csv	    condition_drug_unilabel_diag.csv	fset_kmeans_1000_labeled_subset.csv			mini_test.d2v
PTSD/							condition_drug_multilabel_diag.csv  condition_occurrence-query_ids.csv	grouped_labs-PTSD.csv					plot/
condition-noncoded.csv					condition_drug_seq-CKD.dat	    condition_occurrence.csv		grouped_labs-Pconcept_hierarchy-Tbmeasurement-PTSD.csv	seqReader.pyc
condition_drug-PVDM_f200w7.d2v				condition_drug_seq-PTSD.csv	    configure.pyc			grouped_labs-Pge2-Tbmeasurement-PTSD.csv		similarity_diag.csv
condition_drug-PVDM_f200w7.d2v.docvecs.doctag_syn0.npy	condition_drug_seq.dat		    doc_mlabel_centroid_map.pkl		grouped_labs-Pge3-Tbmeasurement-PTSD.csv		similarity_drug.csv
condition_drug-PVDM_f200w7.d2v.wv.syn0.npy		condition_drug_test.doc2vec	    doc_sqr_centroid_map_file.pkl	grouped_labs-Pshallow-Tbmeasurement-PTSD.csv		token_lookup.csv
condition_drug-noncoded.csv				condition_drug_timed_seq-PTSD.dat   drug-noncoded.csv			grouped_labs-Pshallow2-Tbmeasurement-PTSD.csv
condition_drug_labeled_seq-CKD.csv			condition_drug_unilabel.csv	    fset_PVDM_432000_labeled.csv	kmeans_map-regular.csv
pleiades@~/Documents/work/tpheno/data-exp\:) mkdir CKD0
pleiades@~/Documents/work/tpheno/data-exp\:) ln -s ~/Documents/work/tpheno/seqmaker/data/CKD/condition_drug_labeled_seq-CKD.csv /Users/pleiades/Documents/work/tpheno/data-exp/CKD0/condition_drug_labeled_seq-CKD.csv
pleiades@~/Documents/work/tpheno/data-exp\:) ls -l /Users/pleiades/Documents/work/tpheno/data-exp/CKD0/condition_drug_labeled_seq-CKD.csv
lrwxr-xr-x 1 pleiades 90 Jul 12 19:31 /Users/pleiades/Documents/work/tpheno/data-exp/CKD0/condition_drug_labeled_seq-CKD.csv -> /Users/pleiades/Documents/work/tpheno/seqmaker/data/CKD/condition_drug_labeled_seq-CKD.csv
pleiades@~/Documents/work/tpheno/data-exp\:) cd ../seqmaker/
pleiades@~/Documents/work/tpheno/seqmaker\:) ls
Wnns-ep100b32.h5    d2v			graph.py	   pathAnalyzer-FsRF.py   plot_compare_manifolds.py	 seqClassify-PostSGD.py        seqClassify.py		     seqGen.py	       seqTransform.pyc  timing.pyc
__init__.py	    data/		graph.pyc	   pathAnalyzer-GB10K.py  query.py			 seqClassify-PriorGB.py        seqClassify.pyc		     seqMaker.py       seqUtils.py	 tp_parser.py
__init__.pyc	    deep_utils.py	hc.py		   pathAnalyzer-RF10K.py  roc-multiclass-l1log-iris.tif  seqClassify-PriorRF.py        seqClassify0.py		     seqMaker2.py      seqUtils.pyc	 tset.py
algorithms.py	    density_est.py	init_weights.h5    pathAnalyzer.py	  select_cohort.py		 seqClassify-PriorSGD.py       seqClassifyTest-GB.py	     seqMaker2.pyc     seqparams.py	 tset.pyc
algorithms.pyc	    dnn_demo.py		labeling.py	   pathAnalyzerApp.py	  seq2seq.py			 seqClassify-RegGB.py	       seqClassifyTest1.py	     seqMaker3.py      seqparams.pyc	 tsne_test.py
analyzer.py	    dnn_utils.py	labeling.pyc	   pathAnalyzerTest.py	  seqAlgo.py			 seqClassify-RegRF.py	       seqClassifyTest2-SmallCKD.py  seqReader.py      similarity.log	 vector.py
analyzer.pyc	    doc/		lcs.py		   pathwayAnalyzer.py	  seqAlgo.pyc			 seqClassify-RegSGD.py	       seqClassifyTestT10V50.py      seqReader.pyc     star.py		 vector.pyc
archive/	    docProc.py		lcsApp.py	   pathwayAnalyzer0.py	  seqAnalyzer.py		 seqClassify-SparseGB.py       seqCluster.py		     seqReaderApp.py   targets.py	 word2vec.py
best		    docProc.pyc		learn_manifold.py  pathwayLabeler.py	  seqAnalyzer.pyc		 seqClassify-SparsePostGB.py   seqCluster.pyc		     seqReaderTest.py  targets.pyc
cohort.py	    draft.py		modelSelect.py	   plot/		  seqAnalyzerApp.py		 seqClassify-SparsePriorGB.py  seqCluster0.py		     seqSampling.py    tdoc.py
cohort.pyc	    embedding_utils.py	modelSelect.pyc    plotUtils.py		  seqAnalyzerTest.py		 seqClassify-SparseSGD.py      seqClusterTest.py	     seqSampling.pyc   tdoc.pyc
cohort_analyzer.py  evaluate.py		motif.py	   plotUtils.pyc	  seqClassify-PostGB.py		 seqClassify-VisitGB-Dev.py    seqConfig.py		     seqTest.py        test/
cohort_odhsi.py     evaluate.pyc	outlier.py	   plotUtils0.py	  seqClassify-PostRF.py		 seqClassify-VisitGB.py        seqConfig.pyc		     seqTransform.py   timing.py
pleiades@~/Documents/work/tpheno/seqmaker\:) python seqClassifyTest2-SmallCKD.py
========================================
0:00:02.781 - Start Program
========================================

config> d2v: pv-dm2, user descriptor (model, tset, mcs): regular-dev-cohort
        cohort: CKD, ctype: regular
            + augmented? False, simplified? False dir_type=combined
================================================================================
t_model> cohort=CKD, d2v_method=pv-dm2, ctype=regular, descriptor=regular-dev-cohort, segment? n/a
================================================================================
t_model> predicate: None
         + max_features: unbounded, max_n_docs: None
================================================================================
1. Read temporal doc files ...
================================================================================
process_docs> inputs:
['/Users/pleiades/Documents/work/tpheno/data-exp/CKD0/condition_drug_labeled_seq-CKD.csv']

================================================================================
1. Read temporal doc files ...
================================================================================
loadDocuments> input files: []
readDocFromCSV> input files: []
read> reading from 1 source files:
['/Users/pleiades/Documents/work/tpheno/data-exp/CKD0/condition_drug_labeled_seq-CKD.csv']

read> processing header sequence ...
read> processing header timestamp ...
read> processing header label ...
    + labels (converted to single-label format, n=11): ['CKD G1-control' 'CKD G1A1-control' 'CKD Stage 1' 'CKD Stage 2'
 'CKD Stage 3a' 'CKD Stage 3b' 'CKD Stage 4' 'CKD Stage 5'
 'ESRD after transplant' 'ESRD on dialysis' 'Unknown']
seqReaderApp.load> nD: 2833, nT: 2833, nL: 2833
  + Stats: n_docs: 2833, n_classes:11 | cohort: CKD
processDocuments> Begin document transformation operations (e.g. simplify, diag-only, etc)
filterDocuments> Policy: Remove empty documents ...
transformDocuments> nD: 2833 (<- 2833), nT: 2833, nL: 2833
  + Stats: n_docs: 2833, n_classes:11
transformDocuments2> nD: 2360, nT: 2360, nL: 2360
  + Stats: n_docs: 2360, n_classes:11 | cohort: ?
    + (after transform) nDoc: 2833 -> 2360, size(D0): 16 -> 16
    + (after transform) nD: 2360, nT: 2360, nL: 2360
  + nD: 2360 | cohort=CKD, ctype=regular, labeled? True, simplified? False
segment_docs> policy: regular
segmentDocuments> Noop.
    + class labeling ...
    + unique labels (n=11):
['CKD G1-control' 'CKD G1A1-control' 'CKD Stage 1' 'CKD Stage 2'
 'CKD Stage 3a' 'CKD Stage 3b' 'CKD Stage 4' 'CKD Stage 5'
 'ESRD after transplant' 'ESRD on dialysis' 'Unknown']

    + class counts (all docs, n=2360 | value: 11
    + labels:
{'CKD Stage 3a': 215, 'Unknown': 411, 'CKD Stage 3b': 135, 'ESRD on dialysis': 41, 'CKD G1-control': 87, 'CKD G1A1-control': 108, 'CKD Stage 5': 31, 'CKD Stage 4': 56, 'ESRD after transplant': 686, 'CKD Stage 2': 528, 'CKD Stage 1': 62}

================================================================================
2. Compute document embedding (params: ) ...
================================================================================
makeTSetCombined> nDocTotal: 2360 =?= nDocEff: 2360 | doc stats: (m: 2.000000, med:2.000000, std:0.000000), window: 10
    + computing document vectors (nD:2360 + nDAug:0 -> nDTotal:2360) => nDEff: 2360 ...
makeTSetCombined> model dir: /Users/pleiades/Documents/work/tpheno/seqmaker/data/CKD/model
getDocVec> method: pv-dm2, model ID: regular-dev-cohort, segment_by_visit? False, load precomputed? False
getDocVec> labels (L) given for assessing similarity ...
getDocVecPV> prior to labelDocuments, already labeled? True, example: TaggedDocument(['813.42', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', 'V82.9', '367.9', '790.6', 'V70.0', '272.4'], ['CKD Stage 3a_0']), type: <class 'gensim.models.doc2vec.TaggedDocument'>
labelDocuments> input document is tagged
labelDocuments> Noop: input already tagged.
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
Doc2Vec Parameters
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
  + current d2v method: pv-dm2
  + number of features: 50
  + window size: 10
  + ignore tokens with total freq less than 2
  + number of epochs: 20
  + training method: negative sampling  + number of negative samples: 15  + use concatenation of context vectors? False

getDocVecPV> total: 2360
getDocVecPV> Params summary of d2v models (n_workers: 18, n_iter: 20) ...
  + n_features: 50, window: 10
  + negative sample? 15
  + min count: 2

  + Computing d2v model ((pv-dm followed by pv-dbow)) on training corpus (n=2360)
    + Building vocabulary for all coding sequences ...
   + (build_vocab) example doc: TaggedDocument(['813.42', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', 'V82.9', '367.9', '790.6', 'V70.0', '272.4'], ['CKD Stage 3a_0']) ~ type: <class 'gensim.models.doc2vec.TaggedDocument'>
     + pv-dm>   n_doc=2360, total_examples=2360, epochs=20=?=20
    + pv-dbow> n_doc=2360, total_examples=2360, epochs=20=?=20
  + .train_model> n_epochs=1, epochs(inner): 20
D2V.save> Info: saved model (method=dm):
/Users/pleiades/Documents/work/tpheno/seqmaker/data/CKD/model/Pf50w10i20-regular-dev-cohort.dm

D2V.save> Info: saved model (method=dbow):
/Users/pleiades/Documents/work/tpheno/seqmaker/data/CKD/model/Pf50w10i20-regular-dev-cohort.dbow

tsHandler> save document vectors (cv=0), sparse? False ...
tsHandler> training set dir: /Users/pleiades/Documents/work/tpheno/seqmaker/data/CKD/combined
prepareTrainingSet> n_classes: 11
TSet> Params: cohort: CKD, file id: regular-pv-dm2-regular-dev-cohort
TSet.saveDataFrame> tset params (cohort:CKD d2v:pv-dm2, ctype:regular, suffix=regular-dev-cohort)
TSet.saveDataFrame> Saving (cohort=CKD, d2v=pv-dm2, suffix=regular-dev-cohort) dataset to:
/Users/pleiades/Documents/work/tpheno/seqmaker/data/CKD/combined/tset-n0-IDregular-pv-dm2-regular-dev-cohort-GCKD.csv

status> Model computation complete (@nTrial=0)
tsHandler> save transformed documents parallel to tset (cv=0) ...
tsHandler> training set dir: /Users/pleiades/Documents/work/tpheno/seqmaker/data/CKD/combined
info> nD: 2360 (=?= nT: 2360), doctype: tset, n_labels: 2360
  + example D:
276.5,599.0,599.0,754.31,V20.2,599.0,787.91,583.0,782.3,276.1,277.89,unknown,593.9,MED:62010,MED:89125,MED:61458,MED:61915,582.2,582.2,582.2,582.0,581.9,582.0,582.0,582.0,582.0,582.2,582.0,582.0,582.0,582.0,582.0,581.9,791.0,791.0,791.0,791.0,791.0,791.0,791.0,791.0,791.0,791.0,791.0,V13.02,462,581.9,382.9,285.9,791.0,791.0,791.0,791.0,791.0,791.0,V71.09,758.0,309.0,309.0,995.53,995.53,753.9,753.9,585.3,315.9,585.3,585.3,585.3,581.9,585.3,585.3,580.9,585.4,585.4,585.4,585.4,585.4,588.81,583.9,585.5,NDC:00054465025,583.9,585.6,753.15,345.90,783.40,403.91,MED:63306,MED:62564,MED:157469,MED:157474,MED:63517,MED:106885,MED:63055,MED:62934,MED:61895,MED:62402,MED:66048,MED:61112,MED:61799,MED:60444,MED:62679,MED:61522,MED:61632,MED:61939,MED:62439,MED:63452,MED:126767,MED:133079,MED:63306,MED:63517,MED:63452,MED:106885,MED:61895,MED:63456,MED:62584,MED:66048,MED:61558,MED:61112,MED:60444,MED:61522,MED:61799,MED:62439,MED:61951,MED:60759,MED:61742,NDC:00143126701,NDC:58468002101,NDC:00054000713,NDC:00081063302,NDC:00536454010,NDC:16590013430,345.10,NDC:16590013430,345.10,NDC:50474059440

  + example T:
2005-02-20,2005-07-22,2005-09-13,2006-03-03,2006-03-31,2007-03-10,2007-03-10,2007-03-10,2007-03-10,2007-03-10,2007-03-10,2007-03-10,2007-03-10,2007-03-10,2007-03-12,2007-03-14,2007-03-16,2007-03-21,2007-04-02,2007-04-09,2007-04-16,2007-04-20,2007-04-23,2007-04-30,2007-05-01,2007-05-07,2007-05-14,2007-05-29,2007-06-28,2007-07-09,2007-07-23,2007-08-06,2007-09-10,2007-10-01,2007-10-29,2008-01-07,2008-01-09,2008-03-03,2008-03-04,2008-03-31,2008-05-05,2008-07-07,2008-09-15,2008-12-15,2009-02-14,2009-02-14,2009-02-14,2009-02-14,2009-02-14,2009-03-17,2009-06-17,2009-07-15,2009-07-16,2009-09-29,2010-02-03,2010-03-26,2010-03-26,2010-03-26,2010-04-05,2010-04-12,2010-04-26,2010-05-05,2010-08-24,2010-10-05,2010-11-16,2011-01-04,2011-04-06,2011-04-08,2011-08-03,2011-11-29,2011-12-15,2012-03-06,2012-04-10,2012-08-14,2012-11-20,2012-11-27,2013-05-09,2013-09-27,2013-09-27,2013-09-27,2013-09-27,2013-12-06,2013-12-06,2013-12-06,2013-12-06,2013-12-06,2013-12-06,2013-12-06,2013-12-06,2013-12-06,2013-12-06,2013-12-06,2013-12-06,2013-12-06,2013-12-06,2013-12-06,2013-12-06,2013-12-06,2013-12-06,2013-12-06,2013-12-06,2013-12-06,2013-12-06,2013-12-06,2013-12-06,2013-12-06,2013-12-06,2013-12-06,2013-12-06,2013-12-07,2013-12-07,2013-12-07,2013-12-07,2013-12-07,2013-12-07,2013-12-07,2013-12-07,2013-12-07,2013-12-07,2013-12-07,2013-12-07,2013-12-07,2013-12-07,2013-12-08,2013-12-08,2013-12-08,2013-12-09,2013-12-09,2013-12-09,2013-12-09,2013-12-09,2013-12-09,2013-12-18,2013-12-18,2014-03-26,2014-03-26

docToCSV> Warning: Input D is not a list of lists (class labels?) Example:
CKD Stage 2

  + example L:
ESRD on dialysis

docToCSV> Got (transformed) MCSs (size: 2360, doctype: tset, dim: (2360, 4))
TSet> Create a new directory (direcotry type=train): /Users/pleiades/Documents/work/tpheno/seqmaker/data/CKD/train
TSet> Params: cohort: CKD, file id: regular-pv-dm2-regular-dev-cohort
t_model> training set dimension: (2360, 100)
... t_model completed. X (dim: (2360, 100)), y: (n_classes: 11)
test> meta: regular-dev-cohort
t_classify> tset type dense, maxNPerClass: None, drop control? False
  + cohort: CKD, ctype: regular
  + d2v: pv-dm2, params: 
  + userFileID: regular-dev-cohort
  + using classifier: (GradientBoostingClassifier(criterion='friedman_mse', init=None,
              learning_rate=0.1, loss='deviance', max_depth=8,
              max_features='sqrt', max_leaf_nodes=None,
              min_impurity_decrease=0.0, min_impurity_split=None,
              min_samples_leaf=50, min_samples_split=250,
              min_weight_fraction_leaf=0.0, n_estimators=100,
              presort='auto', random_state=53, subsample=0.85, verbose=0,
              warm_start=False), {'n_estimators': [50, 100, 150, 200, 500], 'min_samples_split': [100, 200, 250, 300], 'min_samples_leaf': [100, 50, 25]})
TSet> Params: cohort: CKD, file id: regular-pv-dm2-regular-dev-cohort
TSet.load> loading training set (cohort=CKD, suffix=regular-dev-cohort) from:
/Users/pleiades/Documents/work/tpheno/seqmaker/data/CKD/combined/tset-n0-IDregular-pv-dm2-regular-dev-cohort-GCKD.csv

tsHandler.profile> Found 11 unique labels ...
  + label=CKD Stage 3a => N=215
  + label=Unknown => N=411
  + label=CKD Stage 3b => N=135
  + label=ESRD on dialysis => N=41
  + label=CKD G1-control => N=87
  + label=CKD G1A1-control => N=108
  + label=CKD Stage 5 => N=31
  + label=CKD Stage 4 => N=56
  + label=ESRD after transplant => N=686
  + label=CKD Stage 2 => N=528
  + label=CKD Stage 1 => N=62
loadTSetCombined> Modifying training data ...
> Prior to re-labeling ...
tsHandler.profile> Found 11 unique labels ...
  + label=CKD Stage 3a => N=215
  + label=Unknown => N=411
  + label=CKD Stage 3b => N=135
  + label=ESRD on dialysis => N=41
  + label=CKD G1-control => N=87
  + label=CKD G1A1-control => N=108
  + label=CKD Stage 5 => N=31
  + label=CKD Stage 4 => N=56
  + label=ESRD after transplant => N=686
  + label=CKD Stage 2 => N=528
  + label=CKD Stage 1 => N=62
  + (before) unique labels:
['ESRD after transplant' 'CKD Stage 3b' 'CKD Stage 2' 'CKD Stage 3a'
 'Unknown' 'CKD Stage 4' 'CKD G1A1-control' 'ESRD on dialysis'
 'CKD Stage 1' 'CKD G1-control' 'CKD Stage 5']

  + Control <- ['CKD G1-control', 'CKD G1A1-control', 'Unknown']
  + CKD Stage 5 <- ['ESRD after transplant', 'ESRD on dialysis']
  + CKD Stage 3 <- ['CKD Stage 3a', 'CKD Stage 3b']
merge> n_labels: 11 -> 6
  + (after) unique labels:
['CKD Stage 5' 'CKD Stage 3' 'CKD Stage 2' 'Control' 'CKD Stage 4'
 'CKD Stage 1']

> After re-labeling ...
tsHandler.profile> Found 6 unique labels ...
  + label=Control => N=606
  + label=CKD Stage 5 => N=758
  + label=CKD Stage 4 => N=56
  + label=CKD Stage 3 => N=350
  + label=CKD Stage 2 => N=528
  + label=CKD Stage 1 => N=62
loadTSet> number of classes: 6
t_classify> load training set of dim: (2360, 102)
  + label=Control => N=606
  + label=CKD Stage 5 => N=758
  + label=CKD Stage 4 => N=56
  + label=CKD Stage 3 => N=350
  + label=CKD Stage 2 => N=528
  + label=CKD Stage 1 => N=62
... cohort=CKD, ctype=regular, d2v=pv-dm2, meta=regular-dev-cohort
  + is_simplified? False, ... 
  + classification mode: multiclass
  + classifiers:
[GradientBoostingClassifier(criterion='friedman_mse', init=None,
              learning_rate=0.1, loss='deviance', max_depth=8,
              max_features='sqrt', max_leaf_nodes=None,
              min_impurity_decrease=0.0, min_impurity_split=None,
              min_samples_leaf=50, min_samples_split=250,
              min_weight_fraction_leaf=0.0, n_estimators=100,
              presort='auto', random_state=53, subsample=0.85, verbose=0,
              warm_start=False)]
  + training set type:dense
  + training set dim:2360
  + n classes:6

info> infer classifier name from class name ...
Traceback (most recent call last):
  File "seqClassifyTest2-SmallCKD.py", line 4873, in <module>
    test()
  File "seqClassifyTest2-SmallCKD.py", line 4836, in test
    clf_name='gradientboost') # don't use 'classifier_name'
  File "seqClassifyTest2-SmallCKD.py", line 3616, in t_classify
    meta=userFileID, identifier=None)  # use meta as one of the parameters to determine file ID
  File "seqClassifyTest2-SmallCKD.py", line 2698, in modelEvaluateBatch
    n_folds=n_folds, 
NameError: global name 'n_folds' is not defined
========================================
0:01:56.631 - End Program
Elapsed time: 0:01:53.850
========================================

pleiades@~/Documents/work/tpheno/seqmaker\:) python seqClassifyTest2-SmallCKD.py
========================================
0:00:02.861 - Start Program
========================================

config> d2v: pv-dm2, user descriptor (model, tset, mcs): regular-dev-cohort
        cohort: CKD, ctype: regular
            + augmented? False, simplified? False dir_type=combined
================================================================================
t_model> cohort=CKD, d2v_method=pv-dm2, ctype=regular, descriptor=regular-dev-cohort, segment? n/a
================================================================================
t_model> predicate: None
         + max_features: unbounded, max_n_docs: None
================================================================================
1. Read temporal doc files ...
================================================================================
process_docs> inputs:
['/Users/pleiades/Documents/work/tpheno/data-exp/CKD0/condition_drug_labeled_seq-CKD.csv']

================================================================================
1. Read temporal doc files ...
================================================================================
loadDocuments> input files: []
readDocFromCSV> input files: []
read> reading from 1 source files:
['/Users/pleiades/Documents/work/tpheno/data-exp/CKD0/condition_drug_labeled_seq-CKD.csv']

read> processing header sequence ...
read> processing header timestamp ...
read> processing header label ...
    + labels (converted to single-label format, n=11): ['CKD G1-control' 'CKD G1A1-control' 'CKD Stage 1' 'CKD Stage 2'
 'CKD Stage 3a' 'CKD Stage 3b' 'CKD Stage 4' 'CKD Stage 5'
 'ESRD after transplant' 'ESRD on dialysis' 'Unknown']
seqReaderApp.load> nD: 2833, nT: 2833, nL: 2833
  + Stats: n_docs: 2833, n_classes:11 | cohort: CKD
processDocuments> Begin document transformation operations (e.g. simplify, diag-only, etc)
filterDocuments> Policy: Remove empty documents ...
transformDocuments> nD: 2833 (<- 2833), nT: 2833, nL: 2833
  + Stats: n_docs: 2833, n_classes:11
transformDocuments2> nD: 2360, nT: 2360, nL: 2360
  + Stats: n_docs: 2360, n_classes:11 | cohort: ?
    + (after transform) nDoc: 2833 -> 2360, size(D0): 16 -> 16
    + (after transform) nD: 2360, nT: 2360, nL: 2360
  + nD: 2360 | cohort=CKD, ctype=regular, labeled? True, simplified? False
segment_docs> policy: regular
segmentDocuments> Noop.
    + class labeling ...
    + unique labels (n=11):
['CKD G1-control' 'CKD G1A1-control' 'CKD Stage 1' 'CKD Stage 2'
 'CKD Stage 3a' 'CKD Stage 3b' 'CKD Stage 4' 'CKD Stage 5'
 'ESRD after transplant' 'ESRD on dialysis' 'Unknown']

    + class counts (all docs, n=2360 | value: 11
    + labels:
{'CKD Stage 3a': 215, 'Unknown': 411, 'CKD Stage 3b': 135, 'ESRD on dialysis': 41, 'CKD G1-control': 87, 'CKD G1A1-control': 108, 'CKD Stage 5': 31, 'CKD Stage 4': 56, 'ESRD after transplant': 686, 'CKD Stage 2': 528, 'CKD Stage 1': 62}

================================================================================
2. Compute document embedding (params: ) ...
================================================================================
makeTSetCombined> nDocTotal: 2360 =?= nDocEff: 2360 | doc stats: (m: 2.000000, med:2.000000, std:0.000000), window: 10
    + computing document vectors (nD:2360 + nDAug:0 -> nDTotal:2360) => nDEff: 2360 ...
makeTSetCombined> model dir: /Users/pleiades/Documents/work/tpheno/seqmaker/data/CKD/model
getDocVec> method: pv-dm2, model ID: regular-dev-cohort, segment_by_visit? False, load precomputed? False
getDocVec> labels (L) given for assessing similarity ...
getDocVecPV> prior to labelDocuments, already labeled? True, example: TaggedDocument(['813.42', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', 'V82.9', '367.9', '790.6', 'V70.0', '272.4'], ['CKD Stage 3a_0']), type: <class 'gensim.models.doc2vec.TaggedDocument'>
labelDocuments> input document is tagged
labelDocuments> Noop: input already tagged.
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
Doc2Vec Parameters
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
  + current d2v method: pv-dm2
  + number of features: 50
  + window size: 10
  + ignore tokens with total freq less than 2
  + number of epochs: 20
  + training method: negative sampling  + number of negative samples: 15  + use concatenation of context vectors? False

getDocVecPV> total: 2360
getDocVecPV> Params summary of d2v models (n_workers: 18, n_iter: 20) ...
  + n_features: 50, window: 10
  + negative sample? 15
  + min count: 2

  + Computing d2v model ((pv-dm followed by pv-dbow)) on training corpus (n=2360)
    + Building vocabulary for all coding sequences ...
   + (build_vocab) example doc: TaggedDocument(['813.42', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', 'V82.9', '367.9', '790.6', 'V70.0', '272.4'], ['CKD Stage 3a_0']) ~ type: <class 'gensim.models.doc2vec.TaggedDocument'>
     + pv-dm>   n_doc=2360, total_examples=2360, epochs=20=?=20
    + pv-dbow> n_doc=2360, total_examples=2360, epochs=20=?=20
  + .train_model> n_epochs=1, epochs(inner): 20
D2V.save> Info: saved model (method=dm):
/Users/pleiades/Documents/work/tpheno/seqmaker/data/CKD/model/Pf50w10i20-regular-dev-cohort.dm

D2V.save> Info: saved model (method=dbow):
/Users/pleiades/Documents/work/tpheno/seqmaker/data/CKD/model/Pf50w10i20-regular-dev-cohort.dbow

tsHandler> save document vectors (cv=0), sparse? False ...
tsHandler> training set dir: /Users/pleiades/Documents/work/tpheno/seqmaker/data/CKD/combined
prepareTrainingSet> n_classes: 11
TSet> Params: cohort: CKD, file id: regular-pv-dm2-regular-dev-cohort
TSet.saveDataFrame> tset params (cohort:CKD d2v:pv-dm2, ctype:regular, suffix=regular-dev-cohort)
TSet.saveDataFrame> Saving (cohort=CKD, d2v=pv-dm2, suffix=regular-dev-cohort) dataset to:
/Users/pleiades/Documents/work/tpheno/seqmaker/data/CKD/combined/tset-n0-IDregular-pv-dm2-regular-dev-cohort-GCKD.csv

status> Model computation complete (@nTrial=0)
tsHandler> save transformed documents parallel to tset (cv=0) ...
tsHandler> training set dir: /Users/pleiades/Documents/work/tpheno/seqmaker/data/CKD/combined
info> nD: 2360 (=?= nT: 2360), doctype: tset, n_labels: 2360
  + example D:
710.0,710.0,710.0,V42.0,583.81,710.0,MED:87666,MED:62537,710.0,585.6,MED:62525,MED:61594,MED:61814,MED:60920,MED:62439,MED:61083,MED:61960,571.5,585.6,MED:62439,MED:63182,MED:61814,MED:61594,MED:60481,MED:61083,585.6,581.0,MED:62525,MED:62439,MED:63182,MED:61814,MED:61594,MED:60920,MED:61083,791.0,580.89,MED:62439,MED:61594,MED:62936,MED:62525,MED:61083,MED:60920,791.5,585.6,585.5,285.21,MED:87666,791.0,710.0,587,582.81,MED:87670,MED:62439,MED:61594,710.0,585.5,285.21,MED:87670,585.6,585.5,V56.0,585.6,585.5,285.21,V56.0,585.6,285.21,V56.0,585.6,285.21,V56.0,585.6,585.5,285.21,V56.0,585.6,285.21,V05.3,V56.0,585.6,588.0,280.9,285.21,V05.3,V56.0,585.6,588.0,280.9,285.21,V05.3,V56.0,585.6,588.0,280.9,285.21,V05.3,V56.0,585.6,588.0,280.9,285.21,V05.3,V56.0,585.6,588.0,280.9,285.21,V05.3,V56.0,585.6,588.0,280.9,285.21,V05.3,V56.0,585.6,588.0,280.9,285.21,V05.3,V56.0,585.6,588.0,280.9,285.21,V05.3,V56.0,585.6,588.0,280.9,285.21,V05.3,V56.0,585.6,588.0,280.9,285.21,V05.3,V56.0,585.6,588.0,280.9,285.21,V56.0,585.6,588.0,280.9,285.21,V56.0,585.6,588.0,280.9,285.21,V56.0,585.6,588.0,280.9,285.21,V56.0,585.6,588.0,280.9,285.21,V56.0,585.6,588.0,280.9,285.21,E878.0,V65.3,V85.0,585.6,710.0,782.3,288.50,E947.8,unknown,998.89,285.21,MED:62659,MED:69242,MED:61262,MED:62038,MED:61895,MED:72140,MED:62838,MED:61253,MED:60826,MED:62936,MED:62439,MED:63523,MED:60926,MED:60553,MED:101652,MED:62537,MED:60762,MED:69954,MED:71675,MED:62035,MED:61471,MED:62439,MED:62522,MED:60553,MED:62444,MED:63148,MED:63408,MED:69954,MED:62522,MED:62994,MED:61471,MED:69954,MED:62522,MED:99323,MED:62525,MED:63077,MED:61471,MED:60826,MED:62829,MED:61112,NDC:13310014501,MULTUM:453,MULTUM:8354,MULTUM:2475,NDC:00469061773,NDC:67618010160,NDC:58864003414,NDC:00078038666,NDC:68094059962,V42.0,V42.0,E878.0,583.81,584.9,996.81,710.0,276.7,593.9,MED:69242,MED:62659,MED:61262,MED:60926,MED:89117,MED:60826,MED:61471,MED:61460,MED:61895,MED:60635,MED:60762,MED:101652,MED:69954,MED:63349,MED:62525,MED:62439,MED:62936,MED:61471,MED:61460,MED:69954,MED:62439,MED:62936,MED:67464,MED:62525,MED:69954,MED:62525,MED:62522,MED:69954,MED:62525,MED:62522,NDC:68462010230,NDC:00004003822,NDC:00469061773,MED:62525,MED:62838,MED:61473,V42.0,V58.69,MED:62439,MED:62936,MED:69954,V42.0,V58.69,MED:62936,MED:62439,MED:69954,MED:62537,V42.0,V58.69,MED:69954,MED:62439,MED:62936,V58.69,710.0,V42.0,V58.69,599.0,V58.69,710.0,V42.0,V42.0,V42.0,V58.69,V42.0,V42.0,V42.0,V42.0,V42.0,V58.69,V42.0,V58.69,585.6,MED:61579,V42.0,V58.69,585.6,MED:61579,V42.0,V42.9,V58.69,585.6,MED:61579,V58.69,V42.0,V42.0,V42.0,V42.0,V42.0,V58.69,710.0,V42.0,V58.69,710.0,V58.69,V42.0,V58.69,710.0,V58.67,710.0,V42.0,V42.0,V42.0,V42.0,V42.0,710.0,V42.0,710.9,V42.0,710.0,V42.0,710.0,V42.0,710.9,V42.0,710.0,V42.0,710.0,V42.0,unknown

  + example T:
2007-09-07,2008-06-26,2008-06-27,2008-07-02,2008-07-02,2008-07-02,2008-07-03,2008-07-03,2008-08-01,2008-08-21,2008-08-21,2008-08-21,2008-08-21,2008-08-21,2008-08-21,2008-08-21,2008-08-21,2008-09-04,2008-09-04,2008-09-04,2008-09-04,2008-09-04,2008-09-04,2008-09-04,2008-09-04,2008-09-18,2008-09-18,2008-09-18,2008-09-18,2008-09-18,2008-09-18,2008-09-18,2008-09-18,2008-09-18,2008-10-27,2008-10-27,2008-10-27,2008-10-27,2008-10-27,2008-10-27,2008-10-27,2008-10-27,2008-11-03,2008-11-03,2008-11-03,2008-11-03,2008-11-04,2008-11-11,2008-11-11,2008-11-11,2008-11-11,2008-11-11,2008-11-11,2008-11-11,2008-11-21,2008-11-21,2008-11-21,2008-11-24,2008-12-08,2008-12-15,2008-12-19,2008-12-19,2008-12-19,2008-12-19,2008-12-21,2008-12-21,2008-12-21,2008-12-22,2008-12-22,2008-12-22,2008-12-29,2008-12-29,2008-12-29,2008-12-29,2008-12-31,2008-12-31,2008-12-31,2009-01-02,2009-01-02,2009-01-02,2009-01-02,2009-01-02,2009-01-02,2009-01-05,2009-01-05,2009-01-05,2009-01-05,2009-01-05,2009-01-05,2009-01-09,2009-01-09,2009-01-09,2009-01-09,2009-01-09,2009-01-09,2009-01-12,2009-01-12,2009-01-12,2009-01-12,2009-01-12,2009-01-12,2009-01-14,2009-01-14,2009-01-14,2009-01-14,2009-01-14,2009-01-14,2009-01-19,2009-01-19,2009-01-19,2009-01-19,2009-01-19,2009-01-19,2009-01-21,2009-01-21,2009-01-21,2009-01-21,2009-01-21,2009-01-21,2009-01-23,2009-01-23,2009-01-23,2009-01-23,2009-01-23,2009-01-23,2009-01-26,2009-01-26,2009-01-26,2009-01-26,2009-01-26,2009-01-26,2009-01-28,2009-01-28,2009-01-28,2009-01-28,2009-01-28,2009-01-28,2009-01-30,2009-01-30,2009-01-30,2009-01-30,2009-01-30,2009-01-30,2009-02-02,2009-02-02,2009-02-02,2009-02-02,2009-02-02,2009-02-04,2009-02-04,2009-02-04,2009-02-04,2009-02-04,2009-02-06,2009-02-06,2009-02-06,2009-02-06,2009-02-06,2009-02-09,2009-02-09,2009-02-09,2009-02-09,2009-02-09,2009-02-11,2009-02-11,2009-02-11,2009-02-11,2009-02-11,2009-02-12,2009-02-12,2009-02-12,2009-02-12,2009-02-12,2009-02-12,2009-02-12,2009-02-12,2009-02-12,2009-02-12,2009-02-12,2009-02-12,2009-02-12,2009-02-12,2009-02-12,2009-02-12,2009-02-12,2009-02-12,2009-02-12,2009-02-12,2009-02-12,2009-02-12,2009-02-12,2009-02-12,2009-02-12,2009-02-12,2009-02-12,2009-02-12,2009-02-13,2009-02-13,2009-02-13,2009-02-13,2009-02-13,2009-02-13,2009-02-13,2009-02-13,2009-02-13,2009-02-14,2009-02-14,2009-02-14,2009-02-14,2009-02-14,2009-02-15,2009-02-15,2009-02-16,2009-02-16,2009-02-16,2009-02-16,2009-02-16,2009-02-16,2009-02-16,2009-02-17,2009-02-17,2009-02-17,2009-02-17,2009-02-17,2009-02-17,2009-02-17,2009-02-17,2009-02-17,2009-02-20,2009-02-23,2009-02-23,2009-02-23,2009-02-23,2009-02-23,2009-02-23,2009-02-23,2009-02-23,2009-02-23,2009-02-24,2009-02-24,2009-02-24,2009-02-24,2009-02-24,2009-02-24,2009-02-24,2009-02-24,2009-02-24,2009-02-24,2009-02-24,2009-02-25,2009-02-25,2009-02-25,2009-02-25,2009-02-25,2009-02-25,2009-02-25,2009-02-26,2009-02-26,2009-02-26,2009-02-26,2009-02-26,2009-02-27,2009-02-27,2009-02-27,2009-02-28,2009-02-28,2009-02-28,2009-03-01,2009-03-01,2009-03-01,2009-03-01,2009-03-01,2009-03-01,2009-03-02,2009-03-02,2009-03-02,2009-03-02,2009-03-02,2009-03-03,2009-03-03,2009-03-03,2009-03-03,2009-03-03,2009-03-03,2009-03-04,2009-03-04,2009-03-04,2009-03-04,2009-03-04,2009-03-09,2009-03-09,2009-03-13,2009-03-13,2009-03-13,2009-03-18,2009-03-18,2009-04-02,2009-04-08,2009-04-17,2009-04-17,2009-04-28,2009-04-29,2009-05-01,2009-05-04,2009-05-06,2009-05-06,2009-05-07,2009-05-07,2009-05-07,2009-05-07,2009-05-08,2009-05-08,2009-05-08,2009-05-08,2009-05-11,2009-05-11,2009-05-11,2009-05-11,2009-05-13,2009-05-20,2009-05-20,2009-05-29,2009-06-04,2009-06-12,2009-06-19,2009-06-26,2009-06-26,2009-07-27,2009-09-03,2009-09-03,2009-09-10,2009-09-10,2009-10-12,2009-10-12,2010-05-24,2010-05-24,2010-06-02,2010-06-07,2010-06-14,2011-03-01,2011-11-11,2011-11-11,2012-04-02,2012-04-02,2012-12-13,2012-12-13,2012-12-31,2012-12-31,2013-07-12,2013-07-12,2013-11-08,2013-11-08,2014-03-06,2014-03-06,2015-01-05,2016-01-25

docToCSV> Warning: Input D is not a list of lists (class labels?) Example:
ESRD after transplant

  + example L:
ESRD after transplant

docToCSV> Got (transformed) MCSs (size: 2360, doctype: tset, dim: (2360, 4))
TSet> Params: cohort: CKD, file id: regular-pv-dm2-regular-dev-cohort
t_model> training set dimension: (2360, 100)
... t_model completed. X (dim: (2360, 100)), y: (n_classes: 11)
test> meta: regular-dev-cohort
t_classify> tset type dense, maxNPerClass: None, drop control? False
  + cohort: CKD, ctype: regular
  + d2v: pv-dm2, params: 
  + userFileID: regular-dev-cohort
  + using classifier: (GradientBoostingClassifier(criterion='friedman_mse', init=None,
              learning_rate=0.1, loss='deviance', max_depth=8,
              max_features='sqrt', max_leaf_nodes=None,
              min_impurity_decrease=0.0, min_impurity_split=None,
              min_samples_leaf=50, min_samples_split=250,
              min_weight_fraction_leaf=0.0, n_estimators=100,
              presort='auto', random_state=53, subsample=0.85, verbose=0,
              warm_start=False), {'n_estimators': [50, 100, 150, 200, 500], 'min_samples_split': [100, 200, 250, 300], 'min_samples_leaf': [100, 50, 25]})
TSet> Params: cohort: CKD, file id: regular-pv-dm2-regular-dev-cohort
TSet.load> loading training set (cohort=CKD, suffix=regular-dev-cohort) from:
/Users/pleiades/Documents/work/tpheno/seqmaker/data/CKD/combined/tset-n0-IDregular-pv-dm2-regular-dev-cohort-GCKD.csv

tsHandler.profile> Found 11 unique labels ...
  + label=CKD Stage 3a => N=215
  + label=Unknown => N=411
  + label=CKD Stage 3b => N=135
  + label=ESRD on dialysis => N=41
  + label=CKD G1-control => N=87
  + label=CKD G1A1-control => N=108
  + label=CKD Stage 5 => N=31
  + label=CKD Stage 4 => N=56
  + label=ESRD after transplant => N=686
  + label=CKD Stage 2 => N=528
  + label=CKD Stage 1 => N=62
loadTSetCombined> Modifying training data ...
> Prior to re-labeling ...
tsHandler.profile> Found 11 unique labels ...
  + label=CKD Stage 3a => N=215
  + label=Unknown => N=411
  + label=CKD Stage 3b => N=135
  + label=ESRD on dialysis => N=41
  + label=CKD G1-control => N=87
  + label=CKD G1A1-control => N=108
  + label=CKD Stage 5 => N=31
  + label=CKD Stage 4 => N=56
  + label=ESRD after transplant => N=686
  + label=CKD Stage 2 => N=528
  + label=CKD Stage 1 => N=62
  + (before) unique labels:
['CKD Stage 2' 'CKD G1-control' 'Unknown' 'ESRD after transplant'
 'ESRD on dialysis' 'CKD Stage 3b' 'CKD Stage 3a' 'CKD G1A1-control'
 'CKD Stage 1' 'CKD Stage 4' 'CKD Stage 5']

  + Control <- ['CKD G1-control', 'CKD G1A1-control', 'Unknown']
  + CKD Stage 5 <- ['ESRD after transplant', 'ESRD on dialysis']
  + CKD Stage 3 <- ['CKD Stage 3a', 'CKD Stage 3b']
merge> n_labels: 11 -> 6
  + (after) unique labels:
['CKD Stage 2' 'Control' 'CKD Stage 5' 'CKD Stage 3' 'CKD Stage 1'
 'CKD Stage 4']

> After re-labeling ...
tsHandler.profile> Found 6 unique labels ...
  + label=Control => N=606
  + label=CKD Stage 5 => N=758
  + label=CKD Stage 4 => N=56
  + label=CKD Stage 3 => N=350
  + label=CKD Stage 2 => N=528
  + label=CKD Stage 1 => N=62
loadTSet> number of classes: 6
t_classify> load training set of dim: (2360, 102)
  + label=Control => N=606
  + label=CKD Stage 5 => N=758
  + label=CKD Stage 4 => N=56
  + label=CKD Stage 3 => N=350
  + label=CKD Stage 2 => N=528
  + label=CKD Stage 1 => N=62
... cohort=CKD, ctype=regular, d2v=pv-dm2, meta=regular-dev-cohort
  + is_simplified? False, ... 
  + classification mode: multiclass
  + classifiers:
[GradientBoostingClassifier(criterion='friedman_mse', init=None,
              learning_rate=0.1, loss='deviance', max_depth=8,
              max_features='sqrt', max_leaf_nodes=None,
              min_impurity_decrease=0.0, min_impurity_split=None,
              min_samples_leaf=50, min_samples_split=250,
              min_weight_fraction_leaf=0.0, n_estimators=100,
              presort='auto', random_state=53, subsample=0.85, verbose=0,
              warm_start=False)]
  + training set type:dense
  + training set dim:2360
  + n classes:6

info> infer classifier name from class name ...
label_encoder> labels vs numeric labels ...
  + [1 0 0 0 0 0] ~> CKD Stage 1
  + [0 1 0 0 0 0] ~> CKD Stage 2
  + [0 0 1 0 0 0] ~> CKD Stage 3
  + [0 0 0 1 0 0] ~> CKD Stage 4
  + [0 0 0 0 1 0] ~> CKD Stage 5
  + [0 0 0 0 0 1] ~> Control
output> saving performance to:
/Users/pleiades/Documents/work/tpheno/seqmaker/roc-microAvg_std-GradientBoostingClassifier-CKD-pv-dm2-regular-regular-dev-cohort.tif

>>> test_auc_cv_metrics >>>
  + dimension test 
  + len(roc_auc):8 =?= n_classes (+{micro, macro}):6+2
  + roc_auc (classes+macro+micro):
{0: 0.90120435120435116, 1: 0.81544864639204262, 2: 0.79927849927849937, 3: 0.79470462197734926, 4: 0.97478893148987256, 5: 0.8623032930579333, 'macro': 0.85795472390000804, 'micro': 0.91384458374243449}

  + class name: CKD Stage 1, mean_auc: 0.901204
  + ROC curve of class CKD Stage 1 (area = 0.90)
  + class name: CKD Stage 2, mean_auc: 0.815449
  + ROC curve of class CKD Stage 2 (area = 0.82)
  + class name: CKD Stage 3, mean_auc: 0.799278
  + ROC curve of class CKD Stage 3 (area = 0.80)
  + class name: CKD Stage 4, mean_auc: 0.794705
  + ROC curve of class CKD Stage 4 (area = 0.79)
  + class name: CKD Stage 5, mean_auc: 0.974789
  + ROC curve of class CKD Stage 5 (area = 0.97)
  + class name: Control, mean_auc: 0.862303
  + ROC curve of class Control (area = 0.86)
test_auc_cv_metrics> summary of AUCs vs classes ...
  + min | class=CKD Stage 4, auc=0.794705
  + max | class=CKD Stage 5, auc=0.974789
  + Ranked AUC scores: 
    + class=CKD Stage 4, auc=0.794705
    + class=CKD Stage 3, auc=0.799278
    + class=CKD Stage 2, auc=0.815449
    + class=Control, auc=0.862303
    + class=CKD Stage 1, auc=0.901204
    + class=CKD Stage 5, auc=0.974789
  + micro vs macro? 0.913845: 0.857955 | use micro-averaging as the value for 'roc_auc'
Traceback (most recent call last):
  File "seqClassifyTest2-SmallCKD.py", line 4872, in <module>
    test()
  File "seqClassifyTest2-SmallCKD.py", line 4835, in test
    clf_name='gradientboost') # don't use 'classifier_name'
  File "seqClassifyTest2-SmallCKD.py", line 3615, in t_classify
    meta=userFileID, identifier=None)  # use meta as one of the parameters to determine file ID
  File "seqClassifyTest2-SmallCKD.py", line 2707, in modelEvaluateBatch
    identifier=userFileID) # use meta or identifier to distinguish different classificaiton tasks; set to None to use default
  File "/Users/pleiades/Documents/work/tpheno/seqmaker/modelSelect.py", line 1782, in modelEvaluateBatch
    res = modelEvaluate(X, y, **kargs)  # must provide either trained_model or model (untrained)
  File "/Users/pleiades/Documents/work/tpheno/seqmaker/modelSelect.py", line 991, in modelEvaluate
    res = modelEvaluateFunc(X, y, **kargs)  # classifier, model
  File "/Users/pleiades/Documents/work/tpheno/seqmaker/modelSelect.py", line 1341, in runCVROCMulticlass
    plot_selected_classes=kargs.get('plot_selected_classes', False)) 
  File "/Users/pleiades/Documents/work/tpheno/seqmaker/modelSelect.py", line 1559, in evalMulticlassROCCV
    saveFig(plt, fpath=os.path.join(prefix, fname))
  File "/Users/pleiades/Documents/work/tpheno/seqmaker/modelSelect.py", line 453, in saveFig
    assert os.path.exists(outputdir), "Invalid output path: %s" % outputdir
AssertionError: Invalid output path: prefix
========================================
0:02:08.098 - End Program
Elapsed time: 0:02:05.237
========================================

pleiades@~/Documents/work/tpheno/seqmaker\:) python seqClassifyTest2-SmallCKD.py
========================================
0:00:02.006 - Start Program
========================================

config> d2v: pv-dm2, user descriptor (model, tset, mcs): regular-dev-cohort
        cohort: CKD, ctype: regular
            + augmented? False, simplified? False dir_type=combined
================================================================================
t_model> cohort=CKD, d2v_method=pv-dm2, ctype=regular, descriptor=regular-dev-cohort, segment? n/a
================================================================================
t_model> predicate: None
         + max_features: unbounded, max_n_docs: None
================================================================================
1. Read temporal doc files ...
================================================================================
process_docs> inputs:
['/Users/pleiades/Documents/work/tpheno/data-exp/CKD0/condition_drug_labeled_seq-CKD.csv']

================================================================================
1. Read temporal doc files ...
================================================================================
loadDocuments> input files: []
readDocFromCSV> input files: []
read> reading from 1 source files:
['/Users/pleiades/Documents/work/tpheno/data-exp/CKD0/condition_drug_labeled_seq-CKD.csv']

read> processing header sequence ...
read> processing header timestamp ...
read> processing header label ...
    + labels (converted to single-label format, n=11): ['CKD G1-control' 'CKD G1A1-control' 'CKD Stage 1' 'CKD Stage 2'
 'CKD Stage 3a' 'CKD Stage 3b' 'CKD Stage 4' 'CKD Stage 5'
 'ESRD after transplant' 'ESRD on dialysis' 'Unknown']
seqReaderApp.load> nD: 2833, nT: 2833, nL: 2833
  + Stats: n_docs: 2833, n_classes:11 | cohort: CKD
processDocuments> Begin document transformation operations (e.g. simplify, diag-only, etc)
filterDocuments> Policy: Remove empty documents ...
transformDocuments> nD: 2833 (<- 2833), nT: 2833, nL: 2833
  + Stats: n_docs: 2833, n_classes:11
transformDocuments2> nD: 2360, nT: 2360, nL: 2360
  + Stats: n_docs: 2360, n_classes:11 | cohort: ?
    + (after transform) nDoc: 2833 -> 2360, size(D0): 16 -> 16
    + (after transform) nD: 2360, nT: 2360, nL: 2360
  + nD: 2360 | cohort=CKD, ctype=regular, labeled? True, simplified? False
segment_docs> policy: regular
segmentDocuments> Noop.
    + class labeling ...
    + unique labels (n=11):
['CKD G1-control' 'CKD G1A1-control' 'CKD Stage 1' 'CKD Stage 2'
 'CKD Stage 3a' 'CKD Stage 3b' 'CKD Stage 4' 'CKD Stage 5'
 'ESRD after transplant' 'ESRD on dialysis' 'Unknown']

    + class counts (all docs, n=2360 | value: 11
    + labels:
{'CKD Stage 3a': 215, 'Unknown': 411, 'CKD Stage 3b': 135, 'ESRD on dialysis': 41, 'CKD G1-control': 87, 'CKD G1A1-control': 108, 'CKD Stage 5': 31, 'CKD Stage 4': 56, 'ESRD after transplant': 686, 'CKD Stage 2': 528, 'CKD Stage 1': 62}

================================================================================
2. Compute document embedding (params: ) ...
================================================================================
makeTSetCombined> nDocTotal: 2360 =?= nDocEff: 2360 | doc stats: (m: 2.000000, med:2.000000, std:0.000000), window: 10
    + computing document vectors (nD:2360 + nDAug:0 -> nDTotal:2360) => nDEff: 2360 ...
makeTSetCombined> model dir: /Users/pleiades/Documents/work/tpheno/seqmaker/data/CKD/model
getDocVec> method: pv-dm2, model ID: regular-dev-cohort, segment_by_visit? False, load precomputed? False
getDocVec> labels (L) given for assessing similarity ...
getDocVecPV> prior to labelDocuments, already labeled? True, example: TaggedDocument(['813.42', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', 'V82.9', '367.9', '790.6', 'V70.0', '272.4'], ['CKD Stage 3a_0']), type: <class 'gensim.models.doc2vec.TaggedDocument'>
labelDocuments> input document is tagged
labelDocuments> Noop: input already tagged.
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
Doc2Vec Parameters
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
  + current d2v method: pv-dm2
  + number of features: 50
  + window size: 10
  + ignore tokens with total freq less than 2
  + number of epochs: 20
  + training method: negative sampling  + number of negative samples: 15  + use concatenation of context vectors? False

getDocVecPV> total: 2360
getDocVecPV> Params summary of d2v models (n_workers: 18, n_iter: 20) ...
  + n_features: 50, window: 10
  + negative sample? 15
  + min count: 2

  + Computing d2v model ((pv-dm followed by pv-dbow)) on training corpus (n=2360)
    + Building vocabulary for all coding sequences ...
   + (build_vocab) example doc: TaggedDocument(['813.42', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', 'V82.9', '367.9', '790.6', 'V70.0', '272.4'], ['CKD Stage 3a_0']) ~ type: <class 'gensim.models.doc2vec.TaggedDocument'>
     + pv-dm>   n_doc=2360, total_examples=2360, epochs=20=?=20
    + pv-dbow> n_doc=2360, total_examples=2360, epochs=20=?=20
  + .train_model> n_epochs=1, epochs(inner): 20
D2V.save> Info: saved model (method=dm):
/Users/pleiades/Documents/work/tpheno/seqmaker/data/CKD/model/Pf50w10i20-regular-dev-cohort.dm

D2V.save> Info: saved model (method=dbow):
/Users/pleiades/Documents/work/tpheno/seqmaker/data/CKD/model/Pf50w10i20-regular-dev-cohort.dbow

tsHandler> save document vectors (cv=0), sparse? False ...
tsHandler> training set dir: /Users/pleiades/Documents/work/tpheno/seqmaker/data/CKD/combined
prepareTrainingSet> n_classes: 11
TSet> Params: cohort: CKD, file id: regular-pv-dm2-regular-dev-cohort
TSet.saveDataFrame> tset params (cohort:CKD d2v:pv-dm2, ctype:regular, suffix=regular-dev-cohort)
TSet.saveDataFrame> Saving (cohort=CKD, d2v=pv-dm2, suffix=regular-dev-cohort) dataset to:
/Users/pleiades/Documents/work/tpheno/seqmaker/data/CKD/combined/tset-n0-IDregular-pv-dm2-regular-dev-cohort-GCKD.csv

status> Model computation complete (@nTrial=0)
tsHandler> save transformed documents parallel to tset (cv=0) ...
tsHandler> training set dir: /Users/pleiades/Documents/work/tpheno/seqmaker/data/CKD/combined
info> nD: 2360 (=?= nT: 2360), doctype: tset, n_labels: 2360
  + example D:
599.0,644.03,V22.2,V22.2,599.0,650,658.01,656.11,V27.0,664.21,MED:62810,MED:62006,MED:63257,MED:62624,MED:61829,MED:61382,MED:61895,MED:62439,MED:99142,MED:89274,MED:61736,V24.0

  + example T:
2006-09-22,2006-10-05,2006-10-16,2006-12-01,2006-12-01,2006-12-08,2006-12-08,2006-12-08,2006-12-08,2006-12-08,2006-12-08,2006-12-08,2006-12-09,2006-12-09,2006-12-09,2006-12-09,2006-12-09,2006-12-09,2006-12-09,2006-12-09,2006-12-10,2006-12-19

docToCSV> Warning: Input D is not a list of lists (class labels?) Example:
CKD Stage 2

  + example L:
Unknown

docToCSV> Got (transformed) MCSs (size: 2360, doctype: tset, dim: (2360, 4))
TSet> Params: cohort: CKD, file id: regular-pv-dm2-regular-dev-cohort
t_model> training set dimension: (2360, 100)
... t_model completed. X (dim: (2360, 100)), y: (n_classes: 11)
test> meta: regular-dev-cohort
t_classify> tset type dense, maxNPerClass: None, drop control? False
  + cohort: CKD, ctype: regular
  + d2v: pv-dm2, params: 
  + userFileID: regular-dev-cohort
  + using classifier: (GradientBoostingClassifier(criterion='friedman_mse', init=None,
              learning_rate=0.1, loss='deviance', max_depth=8,
              max_features='sqrt', max_leaf_nodes=None,
              min_impurity_decrease=0.0, min_impurity_split=None,
              min_samples_leaf=50, min_samples_split=250,
              min_weight_fraction_leaf=0.0, n_estimators=100,
              presort='auto', random_state=53, subsample=0.85, verbose=0,
              warm_start=False), {'n_estimators': [50, 100, 150, 200, 500], 'min_samples_split': [100, 200, 250, 300], 'min_samples_leaf': [100, 50, 25]})
TSet> Params: cohort: CKD, file id: regular-pv-dm2-regular-dev-cohort
TSet.load> loading training set (cohort=CKD, suffix=regular-dev-cohort) from:
/Users/pleiades/Documents/work/tpheno/seqmaker/data/CKD/combined/tset-n0-IDregular-pv-dm2-regular-dev-cohort-GCKD.csv

tsHandler.profile> Found 11 unique labels ...
  + label=CKD Stage 3a => N=215
  + label=Unknown => N=411
  + label=CKD Stage 3b => N=135
  + label=ESRD on dialysis => N=41
  + label=CKD G1-control => N=87
  + label=CKD G1A1-control => N=108
  + label=CKD Stage 5 => N=31
  + label=CKD Stage 4 => N=56
  + label=ESRD after transplant => N=686
  + label=CKD Stage 2 => N=528
  + label=CKD Stage 1 => N=62
loadTSetCombined> Modifying training data ...
> Prior to re-labeling ...
tsHandler.profile> Found 11 unique labels ...
  + label=CKD Stage 3a => N=215
  + label=Unknown => N=411
  + label=CKD Stage 3b => N=135
  + label=ESRD on dialysis => N=41
  + label=CKD G1-control => N=87
  + label=CKD G1A1-control => N=108
  + label=CKD Stage 5 => N=31
  + label=CKD Stage 4 => N=56
  + label=ESRD after transplant => N=686
  + label=CKD Stage 2 => N=528
  + label=CKD Stage 1 => N=62
  + (before) unique labels:
['CKD G1A1-control' 'ESRD after transplant' 'CKD Stage 3b' 'Unknown'
 'CKD Stage 3a' 'CKD Stage 4' 'CKD Stage 2' 'CKD Stage 1' 'CKD G1-control'
 'CKD Stage 5' 'ESRD on dialysis']

  + Control <- ['CKD G1-control', 'CKD G1A1-control', 'Unknown']
  + CKD Stage 5 <- ['ESRD after transplant', 'ESRD on dialysis']
  + CKD Stage 3 <- ['CKD Stage 3a', 'CKD Stage 3b']
merge> n_labels: 11 -> 6
  + (after) unique labels:
['Control' 'CKD Stage 5' 'CKD Stage 3' 'CKD Stage 4' 'CKD Stage 2'
 'CKD Stage 1']

> After re-labeling ...
tsHandler.profile> Found 6 unique labels ...
  + label=Control => N=606
  + label=CKD Stage 5 => N=758
  + label=CKD Stage 4 => N=56
  + label=CKD Stage 3 => N=350
  + label=CKD Stage 2 => N=528
  + label=CKD Stage 1 => N=62
loadTSet> number of classes: 6
t_classify> load training set of dim: (2360, 102)
  + label=Control => N=606
  + label=CKD Stage 5 => N=758
  + label=CKD Stage 4 => N=56
  + label=CKD Stage 3 => N=350
  + label=CKD Stage 2 => N=528
  + label=CKD Stage 1 => N=62
... cohort=CKD, ctype=regular, d2v=pv-dm2, meta=regular-dev-cohort
  + is_simplified? False, ... 
  + classification mode: multiclass
  + classifiers:
[GradientBoostingClassifier(criterion='friedman_mse', init=None,
              learning_rate=0.1, loss='deviance', max_depth=8,
              max_features='sqrt', max_leaf_nodes=None,
              min_impurity_decrease=0.0, min_impurity_split=None,
              min_samples_leaf=50, min_samples_split=250,
              min_weight_fraction_leaf=0.0, n_estimators=100,
              presort='auto', random_state=53, subsample=0.85, verbose=0,
              warm_start=False)]
  + training set type:dense
  + training set dim:2360
  + n classes:6

info> infer classifier name from class name ...
label_encoder> labels vs numeric labels ...
  + [1 0 0 0 0 0] ~> CKD Stage 1
  + [0 1 0 0 0 0] ~> CKD Stage 2
  + [0 0 1 0 0 0] ~> CKD Stage 3
  + [0 0 0 1 0 0] ~> CKD Stage 4
  + [0 0 0 0 1 0] ~> CKD Stage 5
  + [0 0 0 0 0 1] ~> Control
output> saving performance to:
/Users/pleiades/Documents/work/tpheno/seqmaker/roc-microAvg_std-GradientBoostingClassifier-CKD-pv-dm2-regular-regular-dev-cohort.tif

>>> test_auc_cv_metrics >>>
  + dimension test 
  + len(roc_auc):8 =?= n_classes (+{micro, macro}):6+2
  + roc_auc (classes+macro+micro):
{0: 0.89755244755244745, 1: 0.81791100583553422, 2: 0.79578643578643571, 3: 0.78945515763697582, 4: 0.97416576007548483, 5: 0.86185647287124056, 'macro': 0.85612121329301982, 'micro': 0.91277945074602029}

  + class name: CKD Stage 1, mean_auc: 0.897552
  + ROC curve of class CKD Stage 1 (area = 0.90)
  + class name: CKD Stage 2, mean_auc: 0.817911
  + ROC curve of class CKD Stage 2 (area = 0.82)
  + class name: CKD Stage 3, mean_auc: 0.795786
  + ROC curve of class CKD Stage 3 (area = 0.80)
  + class name: CKD Stage 4, mean_auc: 0.789455
  + ROC curve of class CKD Stage 4 (area = 0.79)
  + class name: CKD Stage 5, mean_auc: 0.974166
  + ROC curve of class CKD Stage 5 (area = 0.97)
  + class name: Control, mean_auc: 0.861856
  + ROC curve of class Control (area = 0.86)
test_auc_cv_metrics> summary of AUCs vs classes ...
  + min | class=CKD Stage 4, auc=0.789455
  + max | class=CKD Stage 5, auc=0.974166
  + Ranked AUC scores: 
    + class=CKD Stage 4, auc=0.789455
    + class=CKD Stage 3, auc=0.795786
    + class=CKD Stage 2, auc=0.817911
    + class=Control, auc=0.861856
    + class=CKD Stage 1, auc=0.897552
    + class=CKD Stage 5, auc=0.974166
  + micro vs macro? 0.912779: 0.856121 | use micro-averaging as the value for 'roc_auc'
output> saving performance to:
/Users/pleiades/Documents/work/tpheno/seqmaker/roc-MacroAvgPerClass-GradientBoostingClassifier-CKD-pv-dm2-regular-regular-dev-cohort.tif

modelEvaluate> dim(X): (2360, 100), n_classes: 6
Traceback (most recent call last):
  File "seqClassifyTest2-SmallCKD.py", line 4872, in <module>
    test()
  File "seqClassifyTest2-SmallCKD.py", line 4835, in test
    clf_name='gradientboost') # don't use 'classifier_name'
  File "seqClassifyTest2-SmallCKD.py", line 3615, in t_classify
    meta=userFileID, identifier=None)  # use meta as one of the parameters to determine file ID
  File "seqClassifyTest2-SmallCKD.py", line 2707, in modelEvaluateBatch
    identifier=userFileID) # use meta or identifier to distinguish different classificaiton tasks; set to None to use default
  File "/Users/pleiades/Documents/work/tpheno/seqmaker/modelSelect.py", line 1782, in modelEvaluateBatch
    res = modelEvaluate(X, y, **kargs)  # must provide either trained_model or model (untrained)
  File "/Users/pleiades/Documents/work/tpheno/seqmaker/modelSelect.py", line 1001, in modelEvaluate
    res0 = runCVMulticlass(X, y, **kargs)  # metrics=kargs.get('metrics', default_metrics), n_folds=n_folds
  File "/Users/pleiades/Documents/work/tpheno/seqmaker/modelSelect.py", line 1056, in runCVMulticlass
    scores = cross_val_score(classifier, X, y, cv=myCV, scoring=metric)
NameError: global name 'classifier' is not defined
========================================
0:02:12.746 - End Program
Elapsed time: 0:02:10.739
========================================

pleiades@~/Documents/work/tpheno/seqmaker\:) python seqClassifyTest2-SmallCKD.py
========================================
0:00:02.177 - Start Program
========================================

config> d2v: pv-dm2, user descriptor (model, tset, mcs): regular-dev-cohort
        cohort: CKD, ctype: regular
            + augmented? False, simplified? False dir_type=combined
================================================================================
t_model> cohort=CKD, d2v_method=pv-dm2, ctype=regular, descriptor=regular-dev-cohort, segment? n/a
================================================================================
t_model> predicate: None
         + max_features: unbounded, max_n_docs: None
================================================================================
1. Read temporal doc files ...
================================================================================
process_docs> inputs:
['/Users/pleiades/Documents/work/tpheno/data-exp/CKD0/condition_drug_labeled_seq-CKD.csv']

================================================================================
1. Read temporal doc files ...
================================================================================
loadDocuments> input files: []
readDocFromCSV> input files: []
read> reading from 1 source files:
['/Users/pleiades/Documents/work/tpheno/data-exp/CKD0/condition_drug_labeled_seq-CKD.csv']

read> processing header sequence ...
read> processing header timestamp ...
read> processing header label ...
    + labels (converted to single-label format, n=11): ['CKD G1-control' 'CKD G1A1-control' 'CKD Stage 1' 'CKD Stage 2'
 'CKD Stage 3a' 'CKD Stage 3b' 'CKD Stage 4' 'CKD Stage 5'
 'ESRD after transplant' 'ESRD on dialysis' 'Unknown']
seqReaderApp.load> nD: 2833, nT: 2833, nL: 2833
  + Stats: n_docs: 2833, n_classes:11 | cohort: CKD
processDocuments> Begin document transformation operations (e.g. simplify, diag-only, etc)
filterDocuments> Policy: Remove empty documents ...
transformDocuments> nD: 2833 (<- 2833), nT: 2833, nL: 2833
  + Stats: n_docs: 2833, n_classes:11
transformDocuments2> nD: 2360, nT: 2360, nL: 2360
  + Stats: n_docs: 2360, n_classes:11 | cohort: ?
    + (after transform) nDoc: 2833 -> 2360, size(D0): 16 -> 16
    + (after transform) nD: 2360, nT: 2360, nL: 2360
  + nD: 2360 | cohort=CKD, ctype=regular, labeled? True, simplified? False
segment_docs> policy: regular
segmentDocuments> Noop.
    + class labeling ...
    + unique labels (n=11):
['CKD G1-control' 'CKD G1A1-control' 'CKD Stage 1' 'CKD Stage 2'
 'CKD Stage 3a' 'CKD Stage 3b' 'CKD Stage 4' 'CKD Stage 5'
 'ESRD after transplant' 'ESRD on dialysis' 'Unknown']

    + class counts (all docs, n=2360 | value: 11
    + labels:
{'CKD Stage 3a': 215, 'Unknown': 411, 'CKD Stage 3b': 135, 'ESRD on dialysis': 41, 'CKD G1-control': 87, 'CKD G1A1-control': 108, 'CKD Stage 5': 31, 'CKD Stage 4': 56, 'ESRD after transplant': 686, 'CKD Stage 2': 528, 'CKD Stage 1': 62}

================================================================================
2. Compute document embedding (params: ) ...
================================================================================
makeTSetCombined> nDocTotal: 2360 =?= nDocEff: 2360 | doc stats: (m: 2.000000, med:2.000000, std:0.000000), window: 10
    + computing document vectors (nD:2360 + nDAug:0 -> nDTotal:2360) => nDEff: 2360 ...
makeTSetCombined> model dir: /Users/pleiades/Documents/work/tpheno/seqmaker/data/CKD/model
getDocVec> method: pv-dm2, model ID: regular-dev-cohort, segment_by_visit? False, load precomputed? False
getDocVec> labels (L) given for assessing similarity ...
getDocVecPV> prior to labelDocuments, already labeled? True, example: TaggedDocument(['813.42', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', 'V82.9', '367.9', '790.6', 'V70.0', '272.4'], ['CKD Stage 3a_0']), type: <class 'gensim.models.doc2vec.TaggedDocument'>
labelDocuments> input document is tagged
labelDocuments> Noop: input already tagged.
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
Doc2Vec Parameters
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
  + current d2v method: pv-dm2
  + number of features: 50
  + window size: 10
  + ignore tokens with total freq less than 2
  + number of epochs: 20
  + training method: negative sampling  + number of negative samples: 15  + use concatenation of context vectors? False

getDocVecPV> total: 2360
getDocVecPV> Params summary of d2v models (n_workers: 18, n_iter: 20) ...
  + n_features: 50, window: 10
  + negative sample? 15
  + min count: 2

  + Computing d2v model ((pv-dm followed by pv-dbow)) on training corpus (n=2360)
    + Building vocabulary for all coding sequences ...
   + (build_vocab) example doc: TaggedDocument(['813.42', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', 'V82.9', '367.9', '790.6', 'V70.0', '272.4'], ['CKD Stage 3a_0']) ~ type: <class 'gensim.models.doc2vec.TaggedDocument'>
     + pv-dm>   n_doc=2360, total_examples=2360, epochs=20=?=20
    + pv-dbow> n_doc=2360, total_examples=2360, epochs=20=?=20
  + .train_model> n_epochs=1, epochs(inner): 20
D2V.save> Info: saved model (method=dm):
/Users/pleiades/Documents/work/tpheno/seqmaker/data/CKD/model/Pf50w10i20-regular-dev-cohort.dm

D2V.save> Info: saved model (method=dbow):
/Users/pleiades/Documents/work/tpheno/seqmaker/data/CKD/model/Pf50w10i20-regular-dev-cohort.dbow

tsHandler> save document vectors (cv=0), sparse? False ...
tsHandler> training set dir: /Users/pleiades/Documents/work/tpheno/seqmaker/data/CKD/combined
prepareTrainingSet> n_classes: 11
TSet> Params: cohort: CKD, file id: regular-pv-dm2-regular-dev-cohort
TSet.saveDataFrame> tset params (cohort:CKD d2v:pv-dm2, ctype:regular, suffix=regular-dev-cohort)
TSet.saveDataFrame> Saving (cohort=CKD, d2v=pv-dm2, suffix=regular-dev-cohort) dataset to:
/Users/pleiades/Documents/work/tpheno/seqmaker/data/CKD/combined/tset-n0-IDregular-pv-dm2-regular-dev-cohort-GCKD.csv

status> Model computation complete (@nTrial=0)
tsHandler> save transformed documents parallel to tset (cv=0) ...
tsHandler> training set dir: /Users/pleiades/Documents/work/tpheno/seqmaker/data/CKD/combined
info> nD: 2360 (=?= nT: 2360), doctype: tset, n_labels: 2360
  + example D:
V34.01,765.23,V05.3,V29.0,779.89,759.3,550.92,751.4,770.2,769,478.30,746.89,770.84,747.0,428.0,362.23,742.1,776.6,747.11,770.18,041.85,605,772.11,742.3,765.14,753.29,774.2,745.12,771.82,779.34,MED:104248,MED:63060,MED:75961,MED:100053,MED:71151,MED:69247,MED:60486,MED:61243,MED:104245,MED:63060,MED:104245,MED:63060,MED:104245,MED:98284,MED:100054,MED:60486,MED:61243,MED:63185,MED:104245,MED:69247,MED:104245,MED:61343,MED:104245,MED:69247,MED:61343,MED:63060,MED:104245,MED:60486,MED:104245,MED:61093,MED:104245,MED:61243,MED:104245,MED:104245,MED:62773,MED:63185,MED:104245,MED:62773,MED:60486,MED:60420,MED:63185,MED:104245,MED:62773,MED:67465,MED:104245,MED:62773,MED:63185,MED:104245,MED:63182,MED:63060,MED:104245,MED:60486,MED:104245,MED:104245,MED:60486,MED:61055,MED:63185,MED:104245,MED:63185,MED:104245,MED:63185,MED:104245,MED:63185,MED:104245,MED:104245,MED:60486,MED:104245,MED:104245,MED:63224,MED:104245,MED:63185,MED:104245,MED:104245,MED:104245,MED:104245,MED:104245,MED:60486,MED:104245,MED:63081,MED:63185,MED:104245,MED:60486,MED:104245,MED:63224,MED:61619,MED:61253,MED:104245,MED:60420,MED:60486,MED:63185,MED:104245,MED:101088,MED:104245,MED:63181,MED:62124,MED:60480,MED:60486,MED:104245,MED:60486,MED:104245,MED:60486,MED:63185,MED:104245,MED:70466,MED:63185,MED:104245,MED:60468,MED:60473,MED:60486,MED:104245,MED:104245,MED:75023,MED:104245,MED:63185,MED:104245,MED:61243,MED:104245,MED:63081,MED:104245,MED:81379,MED:60468,MED:104245,MED:70466,MED:63185,MED:104245,MED:70466,MED:94350,MED:104245,MED:104245,MED:62124,MED:63181,MED:101088,MED:60480,MED:104245,MED:104245,MED:104245,MED:60468,MED:98289,MED:100055,MED:67465,MED:70466,MED:104245,MED:60468,MED:75023,MED:104245,MED:63181,MED:62124,MED:101088,MED:60480,MED:61243,MED:104245,MED:104245,MED:104245,MED:131573,MED:104245,MED:104245,MED:104245,MED:70466,MED:62124,MED:101088,MED:104245,MED:104245,MED:104245,MED:63185,MED:104245,MED:66091,MED:66167,MED:62649,MED:101088,MED:62124,MED:81313,MED:75860,MED:125839,MED:101088,MED:62124,MED:60472,MED:61865,MED:129532,MED:67465,MED:61865,MED:62649,MED:66091,MED:61865,MED:129532,MED:66091,MED:62649,MED:66091,MED:63181,MED:66091,MED:101088,MED:62124,MED:66053,MED:66091,MED:62649,MED:69247,MED:61511,MED:61167,MED:63181,MED:61865,MED:61511,MED:61511,MED:131573,MED:62124,MED:101088,MED:61865,MED:131573,MED:66091,MED:61865,MED:100055,MED:61248,MED:101088,MED:62124,MED:107357,MED:63185,MED:100055,MED:62564,MED:66091,MED:66105,MED:62886,MED:94352,MED:68346,MED:61911,MED:61511,MED:94352,MED:131573,MED:101088,MED:63181,MED:62124,MED:62544,MED:131573,MED:66091,MED:61865,MED:62679,MED:63543,MED:100056,MED:69247,MED:61972,MED:63185,MED:131573,MED:97380,MED:66053,MED:66091,MED:62649,MED:61865,MED:129532,MED:62544,MED:101088,MED:62124,MED:100055,NDC:00247165010,MED:63185,MED:81379,MED:63543,MED:104245,MED:61253,MED:61972,MED:61619,MED:89129,MED:81379,MED:104245,MED:61243,MED:81379,MED:62062,MED:63543,MED:104245,MED:61619,MED:98284,MED:69247,MED:61253,MED:94350,MED:60468,MED:61511,MED:62062,MED:63543,MED:104245,MED:81379,MED:94350,MED:62679,MED:60486,MED:62564,MED:63060,MED:72141,MED:62062,MED:104245,MED:69247,MED:61972,MED:81379,MED:94350,MED:60486,MED:62062,MED:104245,MED:62838,MED:81379,MED:62564,MED:62679,MED:61093,MED:61243,MED:81379,MED:104245,MED:62838,MED:60486,MED:81379,MED:104245,MED:81379,MED:104245,MED:81379,MED:104245,MED:62679,MED:81379,MED:104245,MED:70466,MED:104245,MED:60468,MED:61035,MED:61511,MED:62062,MED:69247,MED:104245,MED:81379,MED:60420,MED:61511,MED:63185,MED:66091,MED:61865,MED:61511,MED:81379,MED:62649,MED:66053,MED:101088,MED:62564,MED:62062,MED:62649,MED:102484,MED:61253,MED:60468,MED:61035,MED:131573,MED:63543,MED:62564,MED:94350,MED:62649,MED:62564,MED:63185,MED:81379,MED:86686,MED:100056,MED:66053,MED:61253,MED:62564,MED:104889,MED:62704,MED:61253,MED:63182,MED:66091,MED:62704,MED:101088,MED:63181,MED:62124,MED:60480,MED:62649,MED:66053,MED:61865,MED:69840,MED:61633,MED:61633,MED:133123,MED:131573,MED:102484,MED:62021,MED:66091,MED:66053,MED:61865,MED:125839,NDC:00093416073,NDC:00054329446,NDC:65628008003,NDC:00551020201,NDC:00006323966

  + example T:
2011-12-13,2011-12-13,2011-12-13,2011-12-13,2011-12-13,2011-12-13,2011-12-13,2011-12-13,2011-12-13,2011-12-13,2011-12-13,2011-12-13,2011-12-13,2011-12-13,2011-12-13,2011-12-13,2011-12-13,2011-12-13,2011-12-13,2011-12-13,2011-12-13,2011-12-13,2011-12-13,2011-12-13,2011-12-13,2011-12-13,2011-12-13,2011-12-13,2011-12-13,2011-12-13,2011-12-13,2011-12-13,2011-12-13,2011-12-13,2011-12-13,2011-12-13,2011-12-13,2011-12-13,2011-12-14,2011-12-15,2011-12-15,2011-12-16,2011-12-16,2011-12-16,2011-12-16,2011-12-16,2011-12-16,2011-12-17,2011-12-17,2011-12-17,2011-12-18,2011-12-19,2011-12-19,2011-12-19,2011-12-20,2011-12-20,2011-12-20,2011-12-20,2011-12-21,2011-12-21,2011-12-22,2011-12-22,2011-12-23,2011-12-24,2011-12-24,2011-12-25,2011-12-25,2011-12-25,2011-12-25,2011-12-25,2011-12-26,2011-12-26,2011-12-26,2011-12-27,2011-12-27,2011-12-27,2011-12-28,2011-12-28,2011-12-28,2011-12-29,2011-12-29,2011-12-29,2011-12-30,2011-12-31,2011-12-31,2011-12-31,2012-01-01,2012-01-01,2012-01-02,2012-01-02,2012-01-03,2012-01-03,2012-01-04,2012-01-04,2012-01-05,2012-01-05,2012-01-06,2012-01-07,2012-01-08,2012-01-08,2012-01-09,2012-01-09,2012-01-10,2012-01-11,2012-01-12,2012-01-13,2012-01-13,2012-01-14,2012-01-14,2012-01-15,2012-01-15,2012-01-15,2012-01-16,2012-01-17,2012-01-17,2012-01-17,2012-01-17,2012-01-17,2012-01-17,2012-01-18,2012-01-18,2012-01-19,2012-01-19,2012-01-19,2012-01-19,2012-01-19,2012-01-19,2012-01-20,2012-01-20,2012-01-21,2012-01-21,2012-01-22,2012-01-22,2012-01-22,2012-01-23,2012-01-23,2012-01-23,2012-01-23,2012-01-23,2012-01-24,2012-01-25,2012-01-26,2012-01-26,2012-01-27,2012-01-27,2012-01-27,2012-01-28,2012-01-28,2012-01-29,2012-01-29,2012-01-29,2012-01-30,2012-01-30,2012-01-31,2012-01-31,2012-01-31,2012-01-31,2012-02-01,2012-02-02,2012-02-02,2012-02-02,2012-02-02,2012-02-02,2012-02-03,2012-02-04,2012-02-05,2012-02-05,2012-02-06,2012-02-06,2012-02-06,2012-02-06,2012-02-06,2012-02-06,2012-02-07,2012-02-07,2012-02-07,2012-02-07,2012-02-07,2012-02-07,2012-02-07,2012-02-08,2012-02-09,2012-02-10,2012-02-11,2012-02-11,2012-02-12,2012-02-13,2012-02-13,2012-02-14,2012-02-14,2012-02-14,2012-02-15,2012-02-16,2012-02-17,2012-02-17,2012-02-18,2012-02-19,2012-02-20,2012-02-21,2012-02-21,2012-02-21,2012-02-22,2012-02-23,2012-02-28,2012-02-28,2012-02-29,2012-02-29,2012-03-03,2012-03-03,2012-03-04,2012-03-05,2012-03-05,2012-03-07,2012-03-08,2012-03-09,2012-03-09,2012-03-11,2012-03-12,2012-03-12,2012-03-13,2012-03-13,2012-03-19,2012-03-19,2012-03-20,2012-03-20,2012-03-20,2012-03-20,2012-03-23,2012-03-23,2012-03-23,2012-03-25,2012-03-26,2012-03-27,2012-03-27,2012-03-29,2012-04-06,2012-04-06,2012-04-06,2012-04-09,2012-04-09,2012-04-10,2012-04-10,2012-04-10,2012-04-11,2012-04-11,2012-04-12,2012-04-13,2012-04-13,2012-04-13,2012-04-14,2012-04-14,2012-04-14,2012-04-14,2012-04-15,2012-04-16,2012-04-17,2012-04-17,2012-04-17,2012-04-17,2012-04-22,2012-04-22,2012-04-22,2012-04-22,2012-04-23,2012-04-23,2012-04-23,2012-04-23,2012-04-24,2012-04-24,2012-04-24,2012-04-24,2012-04-24,2012-04-24,2012-04-24,2012-04-25,2012-04-25,2012-05-01,2012-05-01,2012-05-03,2012-05-04,2012-05-04,2012-05-04,2012-05-04,2012-05-04,2012-05-04,2012-05-04,2012-05-04,2012-05-05,2012-05-05,2012-05-05,2012-05-05,2012-05-06,2012-05-06,2012-05-06,2012-05-06,2012-05-06,2012-05-06,2012-05-06,2012-05-06,2012-05-06,2012-05-06,2012-05-06,2012-05-07,2012-05-07,2012-05-07,2012-05-07,2012-05-07,2012-05-07,2012-05-07,2012-05-08,2012-05-08,2012-05-08,2012-05-08,2012-05-08,2012-05-08,2012-05-08,2012-05-08,2012-05-08,2012-05-08,2012-05-09,2012-05-09,2012-05-09,2012-05-09,2012-05-09,2012-05-09,2012-05-09,2012-05-09,2012-05-10,2012-05-10,2012-05-10,2012-05-10,2012-05-11,2012-05-11,2012-05-12,2012-05-12,2012-05-13,2012-05-13,2012-05-13,2012-05-14,2012-05-14,2012-05-15,2012-05-15,2012-05-15,2012-05-15,2012-05-15,2012-05-16,2012-05-16,2012-05-16,2012-05-16,2012-05-16,2012-05-16,2012-05-17,2012-05-18,2012-05-18,2012-05-18,2012-05-20,2012-05-20,2012-05-20,2012-05-21,2012-05-21,2012-05-21,2012-05-21,2012-05-21,2012-05-21,2012-05-21,2012-05-21,2012-05-22,2012-05-22,2012-05-22,2012-05-22,2012-05-23,2012-05-25,2012-05-25,2012-05-25,2012-05-25,2012-05-25,2012-05-25,2012-05-25,2012-05-26,2012-05-26,2012-05-26,2012-05-26,2012-05-27,2012-05-28,2012-05-28,2012-05-29,2012-05-29,2012-05-29,2012-05-29,2012-05-30,2012-05-31,2012-05-31,2012-06-01,2012-06-01,2012-06-02,2012-06-06,2012-06-06,2012-06-06,2012-06-07,2012-06-07,2012-06-07,2012-06-07,2012-06-08,2012-06-11,2012-06-11,2012-06-11,2012-06-11,2012-06-11

docToCSV> Warning: Input D is not a list of lists (class labels?) Example:
CKD G1A1-control

  + example L:
CKD Stage 3a

docToCSV> Got (transformed) MCSs (size: 2360, doctype: tset, dim: (2360, 4))
TSet> Params: cohort: CKD, file id: regular-pv-dm2-regular-dev-cohort
t_model> training set dimension: (2360, 100)
... t_model completed. X (dim: (2360, 100)), y: (n_classes: 11)
test> meta: regular-dev-cohort
t_classify> tset type dense, maxNPerClass: None, drop control? False
  + cohort: CKD, ctype: regular
  + d2v: pv-dm2, params: 
  + userFileID: regular-dev-cohort
  + using classifier: (GradientBoostingClassifier(criterion='friedman_mse', init=None,
              learning_rate=0.1, loss='deviance', max_depth=8,
              max_features='sqrt', max_leaf_nodes=None,
              min_impurity_decrease=0.0, min_impurity_split=None,
              min_samples_leaf=50, min_samples_split=250,
              min_weight_fraction_leaf=0.0, n_estimators=100,
              presort='auto', random_state=53, subsample=0.85, verbose=0,
              warm_start=False), {'n_estimators': [50, 100, 150, 200, 500], 'min_samples_split': [100, 200, 250, 300], 'min_samples_leaf': [100, 50, 25]})
TSet> Params: cohort: CKD, file id: regular-pv-dm2-regular-dev-cohort
TSet.load> loading training set (cohort=CKD, suffix=regular-dev-cohort) from:
/Users/pleiades/Documents/work/tpheno/seqmaker/data/CKD/combined/tset-n0-IDregular-pv-dm2-regular-dev-cohort-GCKD.csv

tsHandler.profile> Found 11 unique labels ...
  + label=CKD Stage 3a => N=215
  + label=Unknown => N=411
  + label=CKD Stage 3b => N=135
  + label=ESRD on dialysis => N=41
  + label=CKD G1-control => N=87
  + label=CKD G1A1-control => N=108
  + label=CKD Stage 5 => N=31
  + label=CKD Stage 4 => N=56
  + label=ESRD after transplant => N=686
  + label=CKD Stage 2 => N=528
  + label=CKD Stage 1 => N=62
loadTSetCombined> Modifying training data ...
> Prior to re-labeling ...
tsHandler.profile> Found 11 unique labels ...
  + label=CKD Stage 3a => N=215
  + label=Unknown => N=411
  + label=CKD Stage 3b => N=135
  + label=ESRD on dialysis => N=41
  + label=CKD G1-control => N=87
  + label=CKD G1A1-control => N=108
  + label=CKD Stage 5 => N=31
  + label=CKD Stage 4 => N=56
  + label=ESRD after transplant => N=686
  + label=CKD Stage 2 => N=528
  + label=CKD Stage 1 => N=62
  + (before) unique labels:
['CKD Stage 2' 'CKD Stage 4' 'ESRD after transplant' 'CKD G1A1-control'
 'CKD G1-control' 'Unknown' 'CKD Stage 5' 'CKD Stage 3a' 'CKD Stage 3b'
 'CKD Stage 1' 'ESRD on dialysis']

  + Control <- ['CKD G1-control', 'CKD G1A1-control', 'Unknown']
  + CKD Stage 5 <- ['ESRD after transplant', 'ESRD on dialysis']
  + CKD Stage 3 <- ['CKD Stage 3a', 'CKD Stage 3b']
merge> n_labels: 11 -> 6
  + (after) unique labels:
['CKD Stage 2' 'CKD Stage 4' 'CKD Stage 5' 'Control' 'CKD Stage 3'
 'CKD Stage 1']

> After re-labeling ...
tsHandler.profile> Found 6 unique labels ...
  + label=Control => N=606
  + label=CKD Stage 5 => N=758
  + label=CKD Stage 4 => N=56
  + label=CKD Stage 3 => N=350
  + label=CKD Stage 2 => N=528
  + label=CKD Stage 1 => N=62
loadTSet> number of classes: 6
t_classify> load training set of dim: (2360, 102)
  + label=Control => N=606
  + label=CKD Stage 5 => N=758
  + label=CKD Stage 4 => N=56
  + label=CKD Stage 3 => N=350
  + label=CKD Stage 2 => N=528
  + label=CKD Stage 1 => N=62
... cohort=CKD, ctype=regular, d2v=pv-dm2, meta=regular-dev-cohort
  + is_simplified? False, ... 
  + classification mode: multiclass
  + classifiers:
[GradientBoostingClassifier(criterion='friedman_mse', init=None,
              learning_rate=0.1, loss='deviance', max_depth=8,
              max_features='sqrt', max_leaf_nodes=None,
              min_impurity_decrease=0.0, min_impurity_split=None,
              min_samples_leaf=50, min_samples_split=250,
              min_weight_fraction_leaf=0.0, n_estimators=100,
              presort='auto', random_state=53, subsample=0.85, verbose=0,
              warm_start=False)]
  + training set type:dense
  + training set dim:2360
  + n classes:6

info> infer classifier name from class name ...
label_encoder> labels vs numeric labels ...
  + [1 0 0 0 0 0] ~> CKD Stage 1
  + [0 1 0 0 0 0] ~> CKD Stage 2
  + [0 0 1 0 0 0] ~> CKD Stage 3
  + [0 0 0 1 0 0] ~> CKD Stage 4
  + [0 0 0 0 1 0] ~> CKD Stage 5
  + [0 0 0 0 0 1] ~> Control
output> saving performance to:
/Users/pleiades/Documents/work/tpheno/seqmaker/roc-microAvg_std-GradientBoostingClassifier-CKD-pv-dm2-regular-regular-dev-cohort.tif

>>> test_auc_cv_metrics >>>
  + dimension test 
  + len(roc_auc):8 =?= n_classes (+{micro, macro}):6+2
  + roc_auc (classes+macro+micro):
{0: 0.85848225848225845, 1: 0.8293517384083422, 2: 0.80375180375180366, 3: 0.77520661157024795, 4: 0.97606652090792911, 5: 0.86015664024063976, 'macro': 0.85050259556020358, 'micro': 0.91527970503674405}

  + class name: CKD Stage 1, mean_auc: 0.858482
  + ROC curve of class CKD Stage 1 (area = 0.86)
  + class name: CKD Stage 2, mean_auc: 0.829352
  + ROC curve of class CKD Stage 2 (area = 0.83)
  + class name: CKD Stage 3, mean_auc: 0.803752
  + ROC curve of class CKD Stage 3 (area = 0.80)
  + class name: CKD Stage 4, mean_auc: 0.775207
  + ROC curve of class CKD Stage 4 (area = 0.78)
  + class name: CKD Stage 5, mean_auc: 0.976067
  + ROC curve of class CKD Stage 5 (area = 0.98)
  + class name: Control, mean_auc: 0.860157
  + ROC curve of class Control (area = 0.86)
test_auc_cv_metrics> summary of AUCs vs classes ...
  + min | class=CKD Stage 4, auc=0.775207
  + max | class=CKD Stage 5, auc=0.976067
  + Ranked AUC scores: 
    + class=CKD Stage 4, auc=0.775207
    + class=CKD Stage 3, auc=0.803752
    + class=CKD Stage 2, auc=0.829352
    + class=CKD Stage 1, auc=0.858482
    + class=Control, auc=0.860157
    + class=CKD Stage 5, auc=0.976067
  + micro vs macro? 0.915280: 0.850503 | use micro-averaging as the value for 'roc_auc'
output> saving performance to:
/Users/pleiades/Documents/work/tpheno/seqmaker/roc-MacroAvgPerClass-GradientBoostingClassifier-CKD-pv-dm2-regular-regular-dev-cohort.tif

modelEvaluate> dim(X): (2360, 100), n_classes: 6
modelEvaluate> under metric: neg_log_loss
 ... scores(n_folds=5):
[-0.94122718 -0.98970838 -0.88042764 -0.93856768 -0.89364506]

modelEvaluate> under metric: accuracy
 ... scores(n_folds=5):
[ 0.63578947  0.61522199  0.65254237  0.63829787  0.67021277]

modelEvaluate> under metric: f1_micro
 ... scores(n_folds=5):
[ 0.63578947  0.61522199  0.65254237  0.63829787  0.67021277]

/Users/pleiades/anaconda2/lib/python2.7/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning:

F-score is ill-defined and being set to 0.0 in labels with no predicted samples.

modelEvaluate> under metric: f1_macro
 ... scores(n_folds=5):
[ 0.4765811   0.38313815  0.41508327  0.43763254  0.44714571]

label_encoder> labels vs numeric labels ...
  + [1 0 0 0 0 0] ~> CKD Stage 1
  + [0 1 0 0 0 0] ~> CKD Stage 2
  + [0 0 1 0 0 0] ~> CKD Stage 3
  + [0 0 0 1 0 0] ~> CKD Stage 4
  + [0 0 0 0 1 0] ~> CKD Stage 5
  + [0 0 0 0 0 1] ~> Control
output> saving performance to:
/Users/pleiades/Documents/work/tpheno/seqmaker/roc-microAvg_std-GradientBoostingClassifier-CKD-pv-dm2-regular-regular-dev-cohort.tif

>>> test_auc_cv_metrics >>>
  + dimension test 
  + len(roc_auc):8 =?= n_classes (+{micro, macro}):6+2
  + roc_auc (classes+macro+micro):
{0: 0.85848225848225845, 1: 0.8293517384083422, 2: 0.80375180375180366, 3: 0.77520661157024795, 4: 0.97606652090792911, 5: 0.86015664024063976, 'macro': 0.85050259556020358, 'micro': 0.91527970503674405}

  + class name: CKD Stage 1, mean_auc: 0.858482
  + ROC curve of class CKD Stage 1 (area = 0.86)
  + class name: CKD Stage 2, mean_auc: 0.829352
  + ROC curve of class CKD Stage 2 (area = 0.83)
  + class name: CKD Stage 3, mean_auc: 0.803752
  + ROC curve of class CKD Stage 3 (area = 0.80)
  + class name: CKD Stage 4, mean_auc: 0.775207
  + ROC curve of class CKD Stage 4 (area = 0.78)
  + class name: CKD Stage 5, mean_auc: 0.976067
  + ROC curve of class CKD Stage 5 (area = 0.98)
  + class name: Control, mean_auc: 0.860157
  + ROC curve of class Control (area = 0.86)
test_auc_cv_metrics> summary of AUCs vs classes ...
  + min | class=CKD Stage 4, auc=0.775207
  + max | class=CKD Stage 5, auc=0.976067
  + Ranked AUC scores: 
    + class=CKD Stage 4, auc=0.775207
    + class=CKD Stage 3, auc=0.803752
    + class=CKD Stage 2, auc=0.829352
    + class=CKD Stage 1, auc=0.858482
    + class=Control, auc=0.860157
    + class=CKD Stage 5, auc=0.976067
  + micro vs macro? 0.915280: 0.850503 | use micro-averaging as the value for 'roc_auc'
output> saving performance to:
/Users/pleiades/Documents/work/tpheno/seqmaker/roc-MacroAvgPerClass-GradientBoostingClassifier-CKD-pv-dm2-regular-regular-dev-cohort.tif

modelEvaluate> dim(X): (2360, 100), n_classes: 6
modelEvaluate> under metric: neg_log_loss
 ... scores(n_folds=5):
[-0.94122718 -0.98970838 -0.88042764 -0.93856768 -0.89364506]

modelEvaluate> under metric: accuracy
 ... scores(n_folds=5):
[ 0.63578947  0.61522199  0.65254237  0.63829787  0.67021277]

modelEvaluate> under metric: f1_micro
 ... scores(n_folds=5):
[ 0.63578947  0.61522199  0.65254237  0.63829787  0.67021277]

modelEvaluate> under metric: f1_macro
 ... scores(n_folds=5):
[ 0.4765811   0.38313815  0.41508327  0.43763254  0.44714571]

label_encoder> labels vs numeric labels ...
  + [1 0 0 0 0 0] ~> CKD Stage 1
  + [0 1 0 0 0 0] ~> CKD Stage 2
  + [0 0 1 0 0 0] ~> CKD Stage 3
  + [0 0 0 1 0 0] ~> CKD Stage 4
  + [0 0 0 0 1 0] ~> CKD Stage 5
  + [0 0 0 0 0 1] ~> Control
output> saving performance to:
/Users/pleiades/Documents/work/tpheno/seqmaker/roc-microAvg_std-GradientBoostingClassifier-CKD-pv-dm2-regular-regular-dev-cohort.tif

>>> test_auc_cv_metrics >>>
  + dimension test 
  + len(roc_auc):8 =?= n_classes (+{micro, macro}):6+2
  + roc_auc (classes+macro+micro):
{0: 0.85848225848225845, 1: 0.8293517384083422, 2: 0.80375180375180366, 3: 0.77520661157024795, 4: 0.97606652090792911, 5: 0.86015664024063976, 'macro': 0.85050259556020358, 'micro': 0.91527970503674405}

  + class name: CKD Stage 1, mean_auc: 0.858482
  + ROC curve of class CKD Stage 1 (area = 0.86)
  + class name: CKD Stage 2, mean_auc: 0.829352
  + ROC curve of class CKD Stage 2 (area = 0.83)
  + class name: CKD Stage 3, mean_auc: 0.803752
  + ROC curve of class CKD Stage 3 (area = 0.80)
  + class name: CKD Stage 4, mean_auc: 0.775207
  + ROC curve of class CKD Stage 4 (area = 0.78)
  + class name: CKD Stage 5, mean_auc: 0.976067
  + ROC curve of class CKD Stage 5 (area = 0.98)
  + class name: Control, mean_auc: 0.860157
  + ROC curve of class Control (area = 0.86)
test_auc_cv_metrics> summary of AUCs vs classes ...
  + min | class=CKD Stage 4, auc=0.775207
  + max | class=CKD Stage 5, auc=0.976067
  + Ranked AUC scores: 
    + class=CKD Stage 4, auc=0.775207
    + class=CKD Stage 3, auc=0.803752
    + class=CKD Stage 2, auc=0.829352
    + class=CKD Stage 1, auc=0.858482
    + class=Control, auc=0.860157
    + class=CKD Stage 5, auc=0.976067
  + micro vs macro? 0.915280: 0.850503 | use micro-averaging as the value for 'roc_auc'
output> saving performance to:
/Users/pleiades/Documents/work/tpheno/seqmaker/roc-MacroAvgPerClass-GradientBoostingClassifier-CKD-pv-dm2-regular-regular-dev-cohort.tif

modelEvaluate> dim(X): (2360, 100), n_classes: 6
modelEvaluate> under metric: neg_log_loss
 ... scores(n_folds=5):
[-0.94122718 -0.98970838 -0.88042764 -0.93856768 -0.89364506]

modelEvaluate> under metric: accuracy
 ... scores(n_folds=5):
[ 0.63578947  0.61522199  0.65254237  0.63829787  0.67021277]

modelEvaluate> under metric: f1_micro
 ... scores(n_folds=5):
[ 0.63578947  0.61522199  0.65254237  0.63829787  0.67021277]

modelEvaluate> under metric: f1_macro
 ... scores(n_folds=5):
[ 0.4765811   0.38313815  0.41508327  0.43763254  0.44714571]

label_encoder> labels vs numeric labels ...
  + [1 0 0 0 0 0] ~> CKD Stage 1
  + [0 1 0 0 0 0] ~> CKD Stage 2
  + [0 0 1 0 0 0] ~> CKD Stage 3
  + [0 0 0 1 0 0] ~> CKD Stage 4
  + [0 0 0 0 1 0] ~> CKD Stage 5
  + [0 0 0 0 0 1] ~> Control
output> saving performance to:
/Users/pleiades/Documents/work/tpheno/seqmaker/roc-microAvg_std-GradientBoostingClassifier-CKD-pv-dm2-regular-regular-dev-cohort.tif

>>> test_auc_cv_metrics >>>
  + dimension test 
  + len(roc_auc):8 =?= n_classes (+{micro, macro}):6+2
  + roc_auc (classes+macro+micro):
{0: 0.85848225848225845, 1: 0.8293517384083422, 2: 0.80375180375180366, 3: 0.77520661157024795, 4: 0.97606652090792911, 5: 0.86015664024063976, 'macro': 0.85050259556020358, 'micro': 0.91527970503674405}

  + class name: CKD Stage 1, mean_auc: 0.858482
  + ROC curve of class CKD Stage 1 (area = 0.86)
  + class name: CKD Stage 2, mean_auc: 0.829352
  + ROC curve of class CKD Stage 2 (area = 0.83)
  + class name: CKD Stage 3, mean_auc: 0.803752
  + ROC curve of class CKD Stage 3 (area = 0.80)
  + class name: CKD Stage 4, mean_auc: 0.775207
  + ROC curve of class CKD Stage 4 (area = 0.78)
  + class name: CKD Stage 5, mean_auc: 0.976067
  + ROC curve of class CKD Stage 5 (area = 0.98)
  + class name: Control, mean_auc: 0.860157
  + ROC curve of class Control (area = 0.86)
test_auc_cv_metrics> summary of AUCs vs classes ...
  + min | class=CKD Stage 4, auc=0.775207
  + max | class=CKD Stage 5, auc=0.976067
  + Ranked AUC scores: 
    + class=CKD Stage 4, auc=0.775207
    + class=CKD Stage 3, auc=0.803752
    + class=CKD Stage 2, auc=0.829352
    + class=CKD Stage 1, auc=0.858482
    + class=Control, auc=0.860157
    + class=CKD Stage 5, auc=0.976067
  + micro vs macro? 0.915280: 0.850503 | use micro-averaging as the value for 'roc_auc'
output> saving performance to:
/Users/pleiades/Documents/work/tpheno/seqmaker/roc-MacroAvgPerClass-GradientBoostingClassifier-CKD-pv-dm2-regular-regular-dev-cohort.tif

modelEvaluate> dim(X): (2360, 100), n_classes: 6
modelEvaluate> under metric: neg_log_loss
 ... scores(n_folds=5):
[-0.94122718 -0.98970838 -0.88042764 -0.93856768 -0.89364506]

modelEvaluate> under metric: accuracy
 ... scores(n_folds=5):
[ 0.63578947  0.61522199  0.65254237  0.63829787  0.67021277]

modelEvaluate> under metric: f1_micro
 ... scores(n_folds=5):
[ 0.63578947  0.61522199  0.65254237  0.63829787  0.67021277]

modelEvaluate> under metric: f1_macro
 ... scores(n_folds=5):
[ 0.4765811   0.38313815  0.41508327  0.43763254  0.44714571]

label_encoder> labels vs numeric labels ...
  + [1 0 0 0 0 0] ~> CKD Stage 1
  + [0 1 0 0 0 0] ~> CKD Stage 2
  + [0 0 1 0 0 0] ~> CKD Stage 3
  + [0 0 0 1 0 0] ~> CKD Stage 4
  + [0 0 0 0 1 0] ~> CKD Stage 5
  + [0 0 0 0 0 1] ~> Control
output> saving performance to:
/Users/pleiades/Documents/work/tpheno/seqmaker/roc-microAvg_std-GradientBoostingClassifier-CKD-pv-dm2-regular-regular-dev-cohort.tif

>>> test_auc_cv_metrics >>>
  + dimension test 
  + len(roc_auc):8 =?= n_classes (+{micro, macro}):6+2
  + roc_auc (classes+macro+micro):
{0: 0.85848225848225845, 1: 0.8293517384083422, 2: 0.80375180375180366, 3: 0.77520661157024795, 4: 0.97606652090792911, 5: 0.86015664024063976, 'macro': 0.85050259556020358, 'micro': 0.91527970503674405}

  + class name: CKD Stage 1, mean_auc: 0.858482
  + ROC curve of class CKD Stage 1 (area = 0.86)
  + class name: CKD Stage 2, mean_auc: 0.829352
  + ROC curve of class CKD Stage 2 (area = 0.83)
  + class name: CKD Stage 3, mean_auc: 0.803752
  + ROC curve of class CKD Stage 3 (area = 0.80)
  + class name: CKD Stage 4, mean_auc: 0.775207
  + ROC curve of class CKD Stage 4 (area = 0.78)
  + class name: CKD Stage 5, mean_auc: 0.976067
  + ROC curve of class CKD Stage 5 (area = 0.98)
  + class name: Control, mean_auc: 0.860157
  + ROC curve of class Control (area = 0.86)
test_auc_cv_metrics> summary of AUCs vs classes ...
  + min | class=CKD Stage 4, auc=0.775207
  + max | class=CKD Stage 5, auc=0.976067
  + Ranked AUC scores: 
    + class=CKD Stage 4, auc=0.775207
    + class=CKD Stage 3, auc=0.803752
    + class=CKD Stage 2, auc=0.829352
    + class=CKD Stage 1, auc=0.858482
    + class=Control, auc=0.860157
    + class=CKD Stage 5, auc=0.976067
  + micro vs macro? 0.915280: 0.850503 | use micro-averaging as the value for 'roc_auc'
output> saving performance to:
/Users/pleiades/Documents/work/tpheno/seqmaker/roc-MacroAvgPerClass-GradientBoostingClassifier-CKD-pv-dm2-regular-regular-dev-cohort.tif

modelEvaluate> dim(X): (2360, 100), n_classes: 6
modelEvaluate> under metric: neg_log_loss
 ... scores(n_folds=5):
[-0.94122718 -0.98970838 -0.88042764 -0.93856768 -0.89364506]

modelEvaluate> under metric: accuracy
 ... scores(n_folds=5):
[ 0.63578947  0.61522199  0.65254237  0.63829787  0.67021277]

modelEvaluate> under metric: f1_micro
 ... scores(n_folds=5):
[ 0.63578947  0.61522199  0.65254237  0.63829787  0.67021277]

modelEvaluate> under metric: f1_macro
 ... scores(n_folds=5):
[ 0.4765811   0.38313815  0.41508327  0.43763254  0.44714571]

analyze_perf> min => 
Counter({'CKD Stage 4': 5})

analyze_perf> max => 
Counter({'CKD Stage 5': 5})

result> min(label: CKD Stage 4, score: 0.775207), err: (0.77520661157024795, 0.77520661157024795)
        max(label: CKD Stage 5, score: 0.976067), err: (0.97606652090792911, 0.97606652090792911)
result> other performance metrics ...
    + metric=micro => 0.915280 (err: (0.91527970503674405, 0.91527970503674405))
    + metric=macro => 0.850503 (err: (0.85050259556020358, 0.85050259556020358))
    + metric=loss => -0.928715 (err: (-0.92871518769192762, -0.92871518769192762))
    + metric=acc => 0.642413 (err: (0.64241289443568994, 0.64241289443568994))
    + metric=auc_roc => 0.915280 (err: (0.91527970503674405, 0.91527970503674405))
========================================
0:06:30.775 - End Program
Elapsed time: 0:06:28.598
========================================

pleiades@~/Documents/work/tpheno/seqmaker\:) python seqClassifyTest2-SmallCKD.py
