Last login: Mon Mar 26 21:59:04 on ttys001
/usr/bin/python: No module named virtualenvwrapper
virtualenvwrapper.sh: There was a problem running the initialization hooks. 

... 

pleiades@~/Documents/work/tpheno/seqmaker\:) python dnn_utils.py 
Using TensorFlow backend.
config> d2v: pv-dm2, user descriptor (model, tset, mcs): smallCKD
        cohort: CKD, ctype: regular
            + augmented? False, simplified? False dir_type=combined
check> sysConfig complete ... meta? smallCKD
load_data> inputs:
['/Users/pleiades/Documents/work/tpheno/seqmaker/data/CKD/condition_drug_labeled_seq-CKD.csv']

================================================================================
1. Read temporal doc files ...
================================================================================
loadDocuments> input files: ['/Users/pleiades/Documents/work/tpheno/seqmaker/data/CKD/condition_drug_labeled_seq-CKD.csv']
readDocFromCSV> input files: ['/Users/pleiades/Documents/work/tpheno/seqmaker/data/CKD/condition_drug_labeled_seq-CKD.csv']
read> reading from 1 source files:
['/Users/pleiades/Documents/work/tpheno/seqmaker/data/CKD/condition_drug_labeled_seq-CKD.csv']

read> processing header sequence ...
read> processing header timestamp ...
read> processing header label ...
    + labels (converted to single-label format, n=11): ['CKD G1-control' 'CKD G1A1-control' 'CKD Stage 1' 'CKD Stage 2'
 'CKD Stage 3a' 'CKD Stage 3b' 'CKD Stage 4' 'CKD Stage 5'
 'ESRD after transplant' 'ESRD on dialysis' 'Unknown']
seqReaderApp.load> nD: 2833, nT: 2833, nL: 2833
  + Stats: n_docs: 2833, n_classes:11 | cohort: CKD
processDocuments> Begin document transformation operations (e.g. simplify, diag-only, etc)
filterDocuments> Policy: Remove empty documents ...
transformDocuments> nD: 2833 (<- 2833), nT: 2833, nL: 2833
  + Stats: n_docs: 2833, n_classes:11
transformDocuments2> nD: 2360, nT: 2360, nL: 2360
  + Stats: n_docs: 2360, n_classes:11 | cohort: ?
    + (after transform) nDoc: 2833 -> 2360, size(D0): 16 -> 16
    + (after transform) nD: 2360, nT: 2360, nL: 2360
  + nD: 2360 | cohort=CKD, ctype=regular, labeled? True, simplified? False
  + doc(last 150 chars):
['954.9', 'NDC:00093715510', 'NDC:00182845389', 'NDC:00093078701', 'NDC:00186504031', 'MULTUM:11007', 'NDC:00067014182', '401.9', 'NDC:00113040378', 'E000.9', 'E849.8', 'E885.9', '922.1', '920', '401.9', '272.4', '786.52', 'MED:61253', 'NDC:00054465025', 'MED:62439', '530.81', '530.81', '203.00', '401.9', 'V76.12', '203.00', '729.1', '203.00', '719.46', '401.9', '719.41', '719.41', '726.19', '719.41', '726.19', '719.41', '726.19', '203.00', 'V58.11', '714.0', '203.00', 'MED:60998', '203.00', '203.00', '203.00', '719.45', '530.81', '401.9', '272.4', '203.00', '733.14', '338.3', 'MED:61078', 'MED:62439', 'MED:61895', 'MED:63114', 'MED:60926', '203.00', 'MED:62453', 'MED:89117', 'MED:63114', 'MED:122364', 'MED:61522', 'MED:69488', 'MED:102225', 'MED:102225', 'MULTUM:7129', 'MULTUM:471', 'NDC:00093078701', 'NDC:49999058730', 'NDC:00574041202', 'NDC:00247157010', 'NDC:00093715410', 'MULTUM:8313', '578.9', '455.8', 'MED:60972', 'MED:62899', 'V58.11', '719.45', '714.0', '203.00', 'MED:62899', '199.1', '203.00', '203.00', '203.00', '203.00', '203.00', '203.00', '203.00', '203.00', '203.00', 'V58.11', '714.0', '203.00', 'MED:60998', '203.00', '203.00', 'V58.69', '714.0', '425.11', '401.9', '784.0', '272.4', '203.00', 'MED:60926', 'NDC:49999058730', 'NDC:00054055125', '203.00', '203.00', '203.00', '203.00', '203.00', '203.00', '780.2', 'E849.0', 'E885.9', 'V15.88', 'V49.86', 'V66.7', '805.01', '714.0', '707.20', '426.12', '424.1', '530.81', '401.9', '805.02', '203.00', '799.02', '338.3', '707.03', 'MED:61253', 'MED:62439', 'MED:60826', 'MED:158045', 'MED:62934', 'MED:62439', 'MED:62453', 'MED:63182', 'MED:89117', 'MED:61863', 'MED:61895', 'MED:61522', 'MED:60926', 'MED:60492', 'MED:61939', 'MED:61078', 'NDC:00186504031']

  + vdoc
    + ['NDC:49999058730', 'NDC:00054055125']
    + ['203.00']
    + ['203.00']
    + ['203.00']
    + ['203.00']
    + ['203.00']
    + ['203.00']
    + ['780.2', 'E849.0', 'E885.9', 'V15.88', 'V49.86', 'V66.7', '805.01', '714.0', '707.20', '426.12', '424.1', '530.81', '401.9', '805.02', '203.00', '799.02', '338.3', '707.03', 'MED:61253', 'MED:62439', 'MED:60826']
    + ['MED:158045', 'MED:62934', 'MED:62439', 'MED:62453', 'MED:63182', 'MED:89117', 'MED:61863', 'MED:61895', 'MED:61522', 'MED:60926', 'MED:60492', 'MED:61939', 'MED:61078']
    + ['NDC:00186504031']
  + doc(last 150 chars):
['MED:63089', 'MED:63156', 'MED:81152', 'MED:122364', '331.0', '432.1', '290.40', 'NDC:00456320560', 'NDC:00088221905', '290.40', '250.00', '401.9', '272.4', '724.2', 'NDC:00113018771', 'NDC:00067014182', '600.00', '250.00', '414.00', '401.9', '331.0', '272.4', '780.4', 'MED:61703', 'NDC:00049211066', 'MED:63523', 'MED:62934', 'MULTUM:353', '401.9', '437.9', '780.4', 'V12.09', 'NDC:00087607111', 'NDC:00113019402', 'NDC:00088221905', 'NDC:00143125601', 'NDC:00093733801', 'NDC:00113018771', 'NDC:00247212130', 'NDC:00310075139', 'NDC:00067014182', '250.00', '412', '414.8', '437.0', '427.89', '428.0', '290.41', '272.4', '276.8', '600.01', '428.21', '414.01', 'V15.82', 'V58.67', '788.30', 'MED:60920', 'MED:63156', 'MED:61968', 'MED:61785', 'MED:60798', 'MED:61504', 'MED:62094', 'MED:63182', 'MED:73041', 'MED:70402', 'MED:62453', 'MED:167651', 'MED:81152', 'MED:103014', 'MED:60884', 'MED:61331', 'MED:60794', 'MED:73041', 'MED:71158', 'MED:61066', 'MED:60884', 'MED:97607', 'MED:136371', 'MED:81159', 'MED:132302', 'MED:86673', 'MED:81159', 'MED:60490', 'MED:63089', 'MED:69860', 'NDC:00087607111', 'NDC:00006001954', 'NDC:00028005101', 'NDC:00113018771', 'NDC:00113019402', 'NDC:00039006013', 'NDC:00054022020', 'NDC:00247212130', 'NDC:00310075139', 'NDC:00093733801', 'NDC:00067014182', '331.0', 'NDC:00054022020', 'NDC:00028005101', 'NDC:00087607111', 'NDC:00006001954', 'NDC:00247212130', 'NDC:00039006013', 'NDC:00113019402', 'NDC:00067014182', 'NDC:00093733801', 'NDC:00054022020', 'NDC:00310075139', '296.20', 'NDC:00054022020', 'G30.9', '331.0', '290.40', 'F01.50', 'NDC:00310075139', 'NDC:00054022020', 'NDC:00028005101', 'NDC:00113018771', 'NDC:00113019402', 'NDC:00039006013', 'NDC:00093733801', 'NDC:00087607111', 'NDC:00067014182', 'NDC:00247212130', 'I50.9', '428.0', 'NDC:00054429925', 'I50.9', '428.0', 'NDC:00054429925', 'I50.9', '428.0', 'NDC:00054429925', 'NDC:00143126601', 'NDC:00186109205', '250.00', 'I50.9', '428.0', 'G30.9', '331.0', 'E11.9', 'V04.81', 'Z23', '290.40', 'F01.50', 'MED:63182', 'MED:136373', 'MED:63465', 'MED:62899']

  + vdoc
    + ['NDC:00028005101', 'NDC:00087607111', 'NDC:00006001954', 'NDC:00247212130', 'NDC:00039006013', 'NDC:00113019402', 'NDC:00067014182', 'NDC:00093733801', 'NDC:00054022020', 'NDC:00310075139']
    + ['296.20', 'NDC:00054022020']
    + ['G30.9', '331.0', '290.40', 'F01.50', 'NDC:00310075139', 'NDC:00054022020', 'NDC:00028005101', 'NDC:00113018771', 'NDC:00113019402', 'NDC:00039006013', 'NDC:00093733801', 'NDC:00087607111', 'NDC:00067014182', 'NDC:00247212130']
    + ['I50.9', '428.0', 'NDC:00054429925']
    + ['I50.9', '428.0', 'NDC:00054429925']
    + ['I50.9', '428.0', 'NDC:00054429925', 'NDC:00143126601', 'NDC:00186109205']
    + ['250.00', 'I50.9', '428.0', 'G30.9', '331.0', 'E11.9', 'V04.81', 'Z23']
    + ['290.40', 'F01.50']
    + ['MED:63182']
    + ['MED:136373', 'MED:63465', 'MED:62899']
  + doc(last 150 chars):
['MULTUM:12134', 'MULTUM:1228', 'V07.0', 'V49.86', '599.0', '401.9', '345.50', '348.5', '198.3', '276.1', '780.97', '041.49', '410.71', '162.9', 'MED:60468', 'MED:101653', 'MED:61558', 'MED:60468', 'MED:63465', 'MED:61112', 'MED:60798', 'MED:61939', 'MED:61522', 'MED:61895', 'MED:62439', 'MED:63456', 'MED:62714', 'MED:62453', 'MED:81159', 'MED:70402', 'MED:149830', 'MED:101650', 'MED:101653', 'MED:63517', 'MED:99323', 'MED:66048', 'MED:89117', 'MED:62899', 'MED:62552', 'MED:131579', 'MED:60917', 'MULTUM:7727', 'NDC:00169330312', 'NDC:00054418625', 'NDC:00186504031', 'NDC:00093749306', '345.10', '198.3']

  + vdoc
    + ['MULTUM:12134', 'MULTUM:1228']
    + ['V07.0', 'V49.86', '599.0', '401.9', '345.50', '348.5', '198.3', '276.1', '780.97', '041.49', '410.71', '162.9', 'MED:60468', 'MED:101653']
    + ['MED:61558', 'MED:60468', 'MED:63465', 'MED:61112', 'MED:60798', 'MED:61939', 'MED:61522', 'MED:61895', 'MED:62439', 'MED:63456', 'MED:62714', 'MED:62453', 'MED:81159', 'MED:70402', 'MED:149830', 'MED:101650', 'MED:101653', 'MED:63517', 'MED:99323']
    + ['MED:66048', 'MED:89117', 'MED:62899']
    + ['MED:62552']
    + ['MED:131579']
    + ['MED:60917', 'MULTUM:7727', 'NDC:00169330312', 'NDC:00054418625', 'NDC:00186504031', 'NDC:00093749306']
    + ['345.10', '198.3']
  + doc(last 150 chars):
['250.01', '401.9', 'MED:61685', 'MED:33336', 'MED:31650', 'MED:49229', 'MED:58474', '250.00', '401.9', '294.8', '784.0', '272.0', 'V68.1', 'MED:61685', '715.90', '290.0', '784.0', '250.02', '401.9', '272.0', 'E849.8', 'E885.9', '719.45', '719.46', '250.00', '401.9', '959.01', '784.0', 'V15.88', 'V43.64', '716.90', '719.49', '729.5', '584.9', '070.70', '486', '346.90', '401.9', '294.8', '250.60', '357.2', '272.4', '278.00', '276.52', '781.2', '296.90', 'MULTUM:9072', 'NDC:62856024690', 'NDC:64764045126', 'NDC:00169008183', 'NDC:79854051281', 'NDC:54868078802', 'NDC:54868565400', 'NDC:65597010490', 'MULTUM:2036', 'NDC:68387066390', 'NDC:66267001660', 'MED:61895', 'MED:62453', 'MED:63220', 'MULTUM:1822', 'MED:70402', 'MED:60822', 'MED:60607', 'MED:63110', 'MED:98510', 'MED:69488', 'MED:81151', 'MED:61703', 'MED:63156', 'MED:62439', 'MED:101650', 'MED:60887', 'MED:61112', 'MED:60798', 'MED:61685', 'MED:60896', 'MED:61504', 'MED:98511', 'MED:60946', 'MED:62899', 'MED:71158', 'MED:63523', 'MED:61775', 'MED:60946', 'MED:67452', 'MED:61124', 'Raised_Toilet_With_Safety_Frame', 'Semielectric_Hospital_Bed', 'Bedside_Commode', 'MED:62934', 'MED:62873', 'MED:62994', 'MED:61736', 'MED:62439', 'MED:62994', 'MED:62994', 'MED:62994', 'MED:62994', 'MED:63220', 'MULTUM:608', 'NDC:68115026360', '250.00', '401.9', 'V58.67', '070.70', '250.00', '346.90', '401.9', '272.4', '276.1', '294.20', 'V12.54', 'NDC:00006011228', 'NDC:00087607005', 'MED:63156', 'NDC:00310075239', 'MED:73041', 'MED:70402', 'MED:101650', 'MED:62934', 'MED:62899', 'MED:61939', 'MED:60798', 'NDC:00093834401', 'MED:62439', 'MED:63239', 'MED:67864', 'MED:122364', 'MED:68339', 'MED:60975', 'MED:101650', 'MED:101067', 'MED:63110', 'MED:62129', 'MED:60884', 'MED:62994', 'NDC:62856024690', 'NDC:00093834401', 'NDC:00310075239', 'NDC:79854051281', 'NDC:00087607111', 'NDC:00074306330', 'NDC:54868078802', 'MULTUM:1377', 'NDC:64764045126', 'MULTUM:6850', 'MULTUM:7054', 'NDC:00247192630', 'MED:101650']

  + vdoc
    + ['MED:61736', 'MED:62439', 'MED:62994']
    + ['MED:62994']
    + ['MED:62994']
    + ['MED:62994']
    + ['MED:63220']
    + ['MULTUM:608', 'NDC:68115026360']
    + ['250.00', '401.9']
    + ['V58.67', '070.70', '250.00', '346.90', '401.9', '272.4', '276.1', '294.20', 'V12.54', 'NDC:00006011228', 'NDC:00087607005', 'MED:63156', 'NDC:00310075239', 'MED:73041', 'MED:70402', 'MED:101650', 'MED:62934', 'MED:62899', 'MED:61939', 'MED:60798']
    + ['NDC:00093834401', 'MED:62439', 'MED:63239', 'MED:67864', 'MED:122364', 'MED:68339', 'MED:60975', 'MED:101650', 'MED:101067', 'MED:63110', 'MED:62129', 'MED:60884', 'MED:62994']
    + ['NDC:62856024690', 'NDC:00093834401', 'NDC:00310075239', 'NDC:79854051281', 'NDC:00087607111', 'NDC:00074306330', 'NDC:54868078802', 'MULTUM:1377', 'NDC:64764045126', 'MULTUM:6850', 'MULTUM:7054', 'NDC:00247192630', 'MED:101650']
  + doc(last 150 chars):
['V22.0', 'V22.2', 'V72.6', '642.91', '599.0', 'V72.3', 'V72.3', '789.00', '716.50', '883.0', 'V58.3', 'V72.3', 'V76.12', '787.2', '448.1', 'V01.1', 'V01.1', 'V76.12', 'V04.81', '465.9', 'V76.12', '756.15', 'V76.12', '465.9', 'V76.12', '793.80', '793.80', '564.00', '401.9', 'MED:28570', 'MED:30089', '793.89', '793.80', '272.4', '564.00', '793.80', 'V72.31', 'V70.0', 'V74.5', 'V73.81', '565.0', '789.00', '793.89', '786.2', '729.5', 'V76.12', '599.72', '586', '455.6', '455.3', '455.0', 'NDC:00074194912', 'NDC:00093715410', 'MULTUM:608', 'NDC:00093075301', '569.42', 'MED:60926', 'NDC:49999058730', '788.29', 'MED:61666', '585.9', '564.00', '599.0', '788.20', '578.9', '272.4', '280.9', '403.90', '041.49', '414.01', 'MED:62934', 'MED:62879', 'MED:61124', 'MED:61112', 'MED:61171', 'MED:61895', 'MED:61433', 'MED:61522', 'MED:61968', 'MED:62439', 'MED:61939', 'MED:63281', 'MED:61995', 'MED:106708', 'MED:133079', 'MED:122364', 'MED:62934', 'NDC:00093314701', 'NDC:00093733801', 'MED:61433', 'NDC:11523723402', 'MED:69488', 'MED:97778', 'NDC:00245010801', 'NDC:00093715410', '585.3', '791.0', '791.0', '585.3', '585.3', '583.9', '585.3', '585.3', '401.1', '401.1', '585.4', 'V76.12', '585.4', '585.4', 'V49.83', '285.21', 'MED:63518', '285.21', '285.21', '583.9', '285.21', 'MED:72161', 'MED:63518', '285.21', 'MED:63518', 'V72.31', 'V77.0', '627.2', '285.21', '285.21', 'MED:63518', '585.4', '285.21', 'MED:63518', '285.21', 'MED:63518', '285.21', 'MED:63518', 'NDC:00113040378', 'MED:167651', 'D63.1', 'MED:63518', 'D63.1', 'N18.4', 'R07.9', 'N18.4', 'N18.4', 'Z12.11', 'N18.6', 'Z23', 'Z76.82', 'N18.4']

  + vdoc
    + ['285.21', 'MED:63518']
    + ['NDC:00113040378', 'MED:167651']
    + ['D63.1', 'MED:63518']
    + ['D63.1']
    + ['N18.4']
    + ['R07.9', 'N18.4']
    + ['N18.4']
    + ['Z12.11']
    + ['N18.6', 'Z23', 'Z76.82']
    + ['N18.4']
  + doc(last 150 chars):
['309.4', '309.4', '309.4', '309.4', '366.9', '366.9', '366.8', '366.17', '366.17', 'V04.8', '401.9', '786.2', '573.9']

  + vdoc
    + ['309.4']
    + ['309.4']
    + ['366.9']
    + ['366.9']
    + ['366.8']
    + ['366.17']
    + ['366.17']
    + ['V04.8', '401.9']
    + ['786.2']
    + ['573.9']
  + doc(last 150 chars):
['MED:62679', 'MED:60671', 'MED:68180', 'MED:81318', 'MED:114640', 'MED:62968', 'MED:63089', 'MED:89117', 'MED:62834', 'MED:62453', 'MED:62439', 'MED:62616', 'MED:62685', 'MED:70402', 'MED:62987', 'MED:107078', 'MED:63118', 'MED:61895', 'MED:101650', 'MED:63606', 'MED:60920', 'MED:62879', 'MED:62679', 'MED:60946', 'MED:61211', 'MED:63129', 'MED:60612', 'MED:61112', 'MED:61522', 'MED:60465', 'MED:60798', 'MED:61513', 'MED:62679', 'MED:61118', 'MED:63448', 'MED:60843', 'MED:62987', 'MED:61473', 'MED:97890', 'MED:62679', 'MED:60612', 'MED:61361', 'MED:114640', 'MED:81318', 'MED:63408', 'MED:62184', 'MED:60583', 'MED:122364', 'MED:63285', 'MED:62742', 'MED:114640', 'MED:69488', 'MED:61513', 'MED:62679', 'MED:61558', 'MED:62934', 'MED:63596', 'MED:62899', 'MED:97890', 'MED:61361', 'MED:63274', 'MED:63594', 'MED:63408', 'MED:71459', 'MED:61513', 'MED:62184', 'MED:63183', 'MED:61460', 'MED:62679', 'MED:61118', 'MED:63272', 'MED:85037', 'MED:63274', 'MED:63408', 'MED:63590', 'MED:63055', 'MED:61321', 'MED:62127', 'MED:60920', 'MED:61473', 'MED:63272', 'MED:62557', 'MED:124575', 'MED:63413', 'MED:63590', 'MED:60920', 'MED:124575', 'MED:87663', 'MED:68349', 'MED:61473', 'MED:114640', 'MED:62934', 'MED:62659', 'MED:69143', 'MED:62834', 'MED:62800', 'MED:62664', 'MED:62899', 'MED:62184', 'MED:61264', 'MED:61558', 'MED:62899', 'NDC:00113040378', 'NDC:68258303101', 'NDC:00071041813', 'MED:101650', 'MED:61759', 'MED:97890', 'MED:69488', 'MED:62800', 'MED:63284', 'MED:97890', 'MED:61558', 'MED:60920', 'MED:101650', 'MED:62439', 'MED:68349', 'MED:61759', 'MED:62800', 'Nepro_Carb_Steady_Vanilla', 'MULTUM:7003', 'Nebulizer_Machine', 'NDC:00113040378', 'NDC:12843003520', 'NDC:00054001720', 'NDC:00085009101', 'MED:61513', 'MULTUM:3037', 'Diltiazem_Cd_180_Mg', 'NDC:63874060530', 'NDC:00182055589', 'Meplex_Dressing_Apply_To_Sacrum_Every_3_Days', 'NDC:11523723402', 'NDC:00088221905', 'NDC:00182864389', 'NDC:00172541310', 'NDC:00074380711', 'Diltiazem_Cd_180_Mg', 'Ipatropium_Mdi', 'aerochamber', 'NDC:68258303101', 'NDC:00182055589', 'NDC:00904545209', 'MULTUM:3037', 'MULTUM:12431', 'NDC:00085009101', 'NDC:00062535001', 'NDC:00093417773', 'MULTUM:12431', 'MULTUM:3755']

  + vdoc
    + ['MED:101650', 'MED:61759']
    + ['MED:97890']
    + ['MED:69488', 'MED:62800', 'MED:63284', 'MED:97890', 'MED:61558']
    + ['MED:60920']
    + ['MED:101650', 'MED:62439', 'MED:68349', 'MED:61759']
    + ['MED:62800', 'Nepro_Carb_Steady_Vanilla', 'MULTUM:7003', 'Nebulizer_Machine', 'NDC:00113040378', 'NDC:12843003520', 'NDC:00054001720', 'NDC:00085009101', 'MED:61513', 'MULTUM:3037', 'Diltiazem_Cd_180_Mg', 'NDC:63874060530', 'NDC:00182055589', 'Meplex_Dressing_Apply_To_Sacrum_Every_3_Days', 'NDC:11523723402', 'NDC:00088221905', 'NDC:00182864389', 'NDC:00172541310']
    + ['NDC:00074380711', 'Diltiazem_Cd_180_Mg', 'Ipatropium_Mdi', 'aerochamber', 'NDC:68258303101', 'NDC:00182055589', 'NDC:00904545209', 'MULTUM:3037', 'MULTUM:12431', 'NDC:00085009101']
    + ['NDC:00062535001', 'NDC:00093417773']
    + ['MULTUM:12431']
    + ['MULTUM:3755']
  + doc(last 150 chars):
['786.50', '786.50', 'V70.0', '427.9', '311', '401.9', '706.2', '727.41', '401.9', '727.41', '401.9', '401.9', 'V82.9', '401.9', '401.9', '727.3', '401.9', '401.9', '401.9', 'V70.0', '401.9', '401.9', '786.50', '578.1', '578.1', '211.3', '564.0', '401.9', '706.2', '706.2', '706.2', '401.9', '401.9', '789.00', '731.0', 'V14.9', '401.9', 'V62.81', 'V62.89', 'V62.81', 'V62.89', 'V62.81', 'V62.89', '401.9', '401.9', '706.2', '702.19', '706.2', '401.9', '701.9', '701.9', '701.9', '401.9', '530.81', '401.9', '731.0', 'MED:73190', '574.20', 'E928.9', '995.1', 'MED:29498', 'MED:33590', 'MED:28392', 'E928.9', '401.9', '995.1', 'MED:63435', 'MED:63517', 'MED:67867', 'MED:60926', 'MED:62439', 'MED:62038', 'MED:61812', 'MED:60826', 'MED:61895', 'MED:61836', 'MED:60582', 'MED:61112', 'MED:62994', 'MED:61836']

  + vdoc
    + ['701.9']
    + ['401.9']
    + ['530.81']
    + ['401.9']
    + ['731.0', 'MED:73190']
    + ['574.20']
    + ['E928.9', '995.1', 'MED:29498', 'MED:33590', 'MED:28392']
    + ['E928.9', '401.9', '995.1']
    + ['MED:63435', 'MED:63517', 'MED:67867', 'MED:60926', 'MED:62439', 'MED:62038', 'MED:61812', 'MED:60826', 'MED:61895', 'MED:61836', 'MED:60582', 'MED:61112', 'MED:62994']
    + ['MED:61836']
  + doc(last 150 chars):
['V82.9', '715.90', '401.9', '465.9', '250.00', '401.9', '401.9', '401.9', '571.9', '571.40', '401.9', '401.9', '789.00', '789.00', '454.1', '401.9', '454.1', '578.9', '719.41', '923.20', '401.9', '789.06', '455.0', '401.9', '472.0', '388.30', '573.3', '388.30', '571.40', 'V62.89', '465.9', '401.9', '401.9', 'V76.12', '401.9', '682.9', '709.9', '698.3', '719.40', '272.0', '078.10', '454.1', 'E849.8', 'E880.9', 'V14.0', '724.2', '401.9', '110.1', '401.9', '719.04', '401.9', '272.0', '272.0', '110.1', 'V76.12', '272.0', '703.8', '112.3', '112.3', '112.3', '112.3', '573.9', '571.40', '401.9', '784.0', '110.1', '719.41', '719.41', '719.41', '719.41', '719.41', '401.9', '719.41', '719.41', '719.41', '716.90', '786.2', '401.9', '388.70', '780.99', '478.1', 'V70.0', '465.9', '079.99', '486', '401.9', '110.1', '784.7', '401.9', '401.9', '110.1', '401.9', '311', '401.9', '692.9', '110.1', 'V76.12', '389.00']

  + vdoc
    + ['110.1']
    + ['784.7', '401.9']
    + ['401.9']
    + ['110.1']
    + ['401.9', '311']
    + ['401.9']
    + ['692.9']
    + ['110.1']
    + ['V76.12']
    + ['389.00']
  + doc(last 150 chars):
['V70.0', '788.1', '625.9', '788.39', '401.9', '616.0', '599.9', '692.9', '625.9', 'V72.3', 'V72.3', 'V70.0', '401.9', '455.6', '401.9', '451.9', '707.9', '401.9', '788.1', '401.9', '786.50', '786.59', '782.1', '411.1', '401.9', 'MED:63469', 'MED:62685', 'MED:62439', 'MED:63573', 'MED:61785', 'MED:61814', 'MED:61736', '401.9', '789.00', '401.9', '533.90', '401.9', '789.04', '401.9', '401.9', '724.2', '599.9', '401.9', '796.9', '692.9', '616.10', '401.9', '848.9', '401.9', '846.0', '784.7', '401.9', '401.9', '733.00', '401.9', '625.6', '401.9', 'V76.12', 'V68.1', '401.9', 'V67.9', '401.9', 'V76.12', '733.00', '724.2', '272.0', '424.90', 'NDC:11523723701', 'NDC:62037083301', 'NDC:58016653301', 'NDC:50383006104', 'NDC:64455014390', 'NDC:58016061304', '401.9', '272.0', 'NDC:60346059530', 'Vitamin_D_1000_Iu', 'NDC:49999035160', 'NDC:66105050503', '401.9', '272.0', 'NDC:62037083301', 'NDC:68115077730', 'V04.81', 'NDC:62037083301', 'NDC:60346059530', 'NDC:68115077730', '401.9', '272.0', 'V65.40', '401.9', '272.0', 'NDC:68387053730', '401.1', '272.2', 'MULTUM:2396', 'NDC:54868560700', 'NDC:68115077730', 'NDC:58016061304', 'NDC:49999035160', 'Vitamin_D_1000_Iu', 'V72.60', '401.1', '285.9', 'NDC:55887003812', '401.1', '285.9', 'MULTUM:608', 'V72.60', '401.9', '585.1', 'V72.60', '593.9', 'NDC:58864075930', 'MULTUM:8404', '401.1', '593.9', 'NDC:62037083301', 'NDC:55289087630', 'NDC:00245002414', 'V72.60', '709.9', '401.1', 'NDC:11523096307', 'NDC:66267059210', 'V04.81', '401.1', '272.2', 'MULTUM:16417', 'V72.60', '401.1', 'Blood_Pressure_Cuff', 'NDC:00378022201', '401.1', '401.1', 'NDC:00378021301', 'V76.12', '701.1', '401.1', 'MULTUM:1470', '401.9', '585.3']

  + vdoc
    + ['V72.60']
    + ['709.9', '401.1', 'NDC:11523096307', 'NDC:66267059210']
    + ['V04.81', '401.1', '272.2', 'MULTUM:16417']
    + ['V72.60']
    + ['401.1', 'Blood_Pressure_Cuff', 'NDC:00378022201']
    + ['401.1']
    + ['401.1', 'NDC:00378021301']
    + ['V76.12', '701.1', '401.1', 'MULTUM:1470']
    + ['401.9']
    + ['585.3']
  + doc(last 150 chars):
['747.11', 'V20.2', '434.11', '478.31', 'V20.2', '746.9', 'V12.54', 'V20.2', '796.2', 'V07.0', 'V12.49', 'V13.65', 'V15.1', '564.00', '746.81', '478.30', '518.0', '786.09', '747.69', '747.22', '348.89', '742.1', '287.5', '417.8', '747.11', '745.4', 'E878.1', '315.8', '263.0', '315.39', '996.09', '338.18', '079.89', '433.10', '438.20', 'MED:60998', 'MED:60481', 'MED:94350', 'MED:62511', 'MED:133116', 'MED:106366', 'MED:102484', 'MED:72705', 'MED:62062', 'MED:72705', 'MED:60998', 'MED:70466', 'MED:63540', 'MED:61253', 'MED:60998', 'MED:61348', 'MED:63518', 'MED:106366', 'MED:63540', 'MED:156852', 'MED:72705', 'MED:61348', 'MED:107357', 'MED:62343', 'MED:106366', 'MED:156852', 'MED:63518', 'MED:66023', 'MED:69488', 'MED:69488', 'MED:63122', 'MED:61627', 'MED:61229', 'MED:63081', 'MED:77728', 'MED:61995', 'MED:61974', 'NDC:00054329446', 'NDC:00054329446', '478.31', 'V67.59', '746.9', 'V12.54', '478.31', 'V12.49', '682.4', '746.9', 'NDC:00029152544', 'NDC:00009076004', '434.91', '434.91', '434.91', '787.21', '478.30', '436', '758.31', '478.31', 'V04.81', '746.9', '783.40', 'V12.54', '786.09', '784.42', '367.0', '367.20', '681.10', '746.9', 'V12.54', 'NDC:00093417773', 'V72.82', '478.31', 'V12.49', '746.9', '701.1', 'NDC:00245002414', 'V12.49', 'V67.59', '746.81', '786.09', '745.4', 'Albuterol_Spacer', 'NDC:00173068220', '780.39', '788.36', '746.9', '783.40', 'V12.54', 'V13.65', 'V45.01', '706.8', '780.39', '345.90', 'NDC:00064211003', 'NDC:00187065820', 'NDC:00054019959', '478.30', '345.41', 'V12.49', '788.36', '478.30', '783.40', 'diapers', 'V45.01', '348.89', '780.39', '345.90', '438.20', 'MED:61856', '327.23', 'J38.00', '478.30', 'G81.14', 'R26.9', '781.2', '342.12']

  + vdoc
    + ['788.36', '746.9', '783.40', 'V12.54']
    + ['V13.65', 'V45.01', '706.8', '780.39', '345.90', 'NDC:00064211003']
    + ['NDC:00187065820', 'NDC:00054019959']
    + ['478.30']
    + ['345.41']
    + ['V12.49', '788.36', '478.30', '783.40', 'diapers']
    + ['V45.01', '348.89', '780.39', '345.90', '438.20', 'MED:61856']
    + ['327.23']
    + ['J38.00', '478.30']
    + ['G81.14', 'R26.9', '781.2', '342.12']
  + doc(last 150 chars):
['070.54', '070.54', '070.54', '070.54', 'E849.0', 'E920.8', '892.0', 'MED:56017', '573.3', '070.54', '070.54']

  + vdoc
    + ['070.54']
    + ['070.54']
    + ['070.54']
    + ['070.54']
    + ['E849.0', 'E920.8', '892.0', 'MED:56017']
    + ['573.3']
    + ['070.54']
    + ['070.54']
  + doc(last 150 chars):
['585.6', '585.6', '403.91', '585.5', 'MED:101652', 'MED:60762', 'MED:66037', 'MED:60926', 'MED:69242', 'MED:62439', 'MED:61471', 'MED:62838', 'MED:61262', 'MED:61253', 'MED:63156', 'MED:62659', 'MED:62936', 'MED:89117', 'MED:60553', 'MED:61124', 'MED:62522', 'MED:62838', 'MED:71675', 'MED:62636', 'MED:61253', 'MED:61895', 'MED:69954', 'MED:62522', 'MED:69242', 'MED:62522', 'MED:63613', 'MED:69954', 'MED:62659', 'MED:81159', 'MED:60577', 'MED:60635', 'MED:61471', 'MED:61473', 'MED:69242', 'V42.0', 'V58.69', 'V42.0', 'V58.69', 'V42.0', 'V58.69', 'V42.0', 'V58.69', 'V42.0', 'V58.69', 'V42.0', 'V58.69', 'V42.0', 'V58.69', 'V42.0', 'V58.69', '599.0', '585.6', 'V42.0', 'V58.69', 'V42.0', 'V58.69', 'V42.0', 'V58.69', 'V42.0', 'V58.69', 'V58.69', 'V42.0', 'V42.0', 'V58.69', 'V58.69', 'V42.0', 'V42.0', 'V58.69', 'V42.0', 'V58.69', 'V42.0', 'V58.69', 'V04.81', 'V42.0', 'V58.69', 'MED:62511', 'V42.0', 'V58.69', 'V42.0', 'V58.69', 'V42.0', 'V58.69', 'V42.0', 'V58.69', 'V42.0', '794.8', 'V42.0', 'V58.69', '794.8', '793.4', 'V42.0', '782.4', '577.9', '751.69', '576.2', '793.4', 'V42.0', '577.9', '157.0', '230.9', 'V42.0', 'V58.69', 'V42.0', 'V58.69']

  + vdoc
    + ['V42.0', 'V58.69']
    + ['V42.0', 'V58.69']
    + ['V42.0', 'V58.69']
    + ['V42.0', '794.8']
    + ['V42.0', 'V58.69']
    + ['794.8', '793.4', 'V42.0', '782.4', '577.9', '751.69', '576.2']
    + ['793.4', 'V42.0', '577.9', '157.0']
    + ['230.9']
    + ['V42.0', 'V58.69']
    + ['V42.0', 'V58.69']
  + doc(last 150 chars):
['585.2', '585.1', '580.9', '585.2', '791.0', '585.3', '791.0', '585.2', '585.2', 'V42.0', '996.81', 'MED:60481', 'MED:62936', 'MED:62439', '581.1', 'MED:62936', 'MED:62871', 'MED:60481', 'MED:62439', '581.1', 'MED:62439', 'MED:62871', 'MED:60481', 'MED:62936', '581.1', '996.81', 'MED:62871', 'MED:60481', 'MED:62936', 'MED:62439']

  + vdoc
    + ['580.9']
    + ['585.2']
    + ['791.0', '585.3']
    + ['791.0']
    + ['585.2']
    + ['585.2']
    + ['V42.0', '996.81', 'MED:60481', 'MED:62936', 'MED:62439']
    + ['581.1', 'MED:62936', 'MED:62871', 'MED:60481', 'MED:62439']
    + ['581.1', 'MED:62439', 'MED:62871', 'MED:60481', 'MED:62936']
    + ['581.1', '996.81', 'MED:62871', 'MED:60481', 'MED:62936', 'MED:62439']
  + doc(last 150 chars):
['V22.2', 'V22.2', '250.00', '789.06', '649.13', '655.83', '648.03', '250.00', '642.03', '278.00', 'Prenatal_Vitamin', 'MED:62296', 'MED:70402', 'MED:62774', 'MED:60798', 'MED:62309', 'MED:63156', 'MED:61895', 'MED:106359', 'MED:62940', 'MED:62774', 'MULTUM:2741', 'MULTUM:6819', 'NDC:00002831501', '1cc_Syringes', 'Accucheck_Test_Strips', 'MULTUM:5208', 'MULTUM:6819', 'NDC:00002831501', 'MED:62774', '655.93', '655.93', 'V22.2', '644.21', '649.11', '655.81', 'V27.0', '642.71', '250.00', '401.9', '278.00', '648.93', '648.01', 'MED:62296', 'MED:70402', 'MED:106261', 'MED:73041', 'MED:61853', 'MED:62774', 'MED:60798', 'MED:63156', 'MED:61895', 'MED:62309', 'MED:62940', 'MED:101650', 'MED:73041', 'MED:62774', 'MED:61052', 'MED:61632', 'MED:63518', 'MED:73041', 'MED:61853', 'MED:61812', 'MED:73041', 'MED:62774', 'MED:62774', 'MED:62337', 'MED:63540', 'MED:99142', 'MED:103931', 'MED:70402', 'MED:131940', 'MED:106359', 'MED:107078', 'MED:63156', 'MED:60798', 'MED:62994', 'MED:60553', 'MED:61736', 'MED:61972', 'MED:61120', 'MED:62290', 'MED:63596', 'MED:61895', 'MED:60926', 'MED:61870', 'MED:62439', 'MED:73041', 'MED:62309', 'NDC:55111068301', 'MED:70402', 'NDC:00054465025', 'MED:73041', 'MED:69248', 'MED:60798', 'MED:63156', 'MED:70402', 'MED:63156', 'MED:60798', 'V23.9', 'V23.9', '654.23', '633.90', 'MED:60546', '633.01', '633.10', 'V70.0', 'V70.0', 'V70.0', 'V70.0', 'V23.9', 'V70.0', 'V70.0', '632', 'V70.0', '632']

  + vdoc
    + ['633.90', 'MED:60546']
    + ['633.01']
    + ['633.10']
    + ['V70.0']
    + ['V70.0']
    + ['V70.0']
    + ['V70.0', 'V23.9']
    + ['V70.0']
    + ['V70.0', '632']
    + ['V70.0', '632']
  + doc(last 150 chars):
['V22.1', '656.11', 'V02.51', 'V27.0', '664.11', '648.91', 'MED:61382', 'MED:61120', 'MED:60481', 'MED:62994', 'MED:61895', 'MED:62439', 'MED:60926', 'MED:62683', 'MED:61829', 'MED:61736', 'MED:99142', 'MED:63517', 'MED:106261', 'MED:63055', 'MED:62296', 'MED:61253', 'MULTUM:11732', 'MED:62624']

  + vdoc
    + ['V22.1', '656.11', 'V02.51', 'V27.0', '664.11', '648.91', 'MED:61382', 'MED:61120', 'MED:60481', 'MED:62994', 'MED:61895', 'MED:62439', 'MED:60926', 'MED:62683', 'MED:61829', 'MED:61736', 'MED:99142', 'MED:63517', 'MED:106261', 'MED:63055', 'MED:62296', 'MED:61253', 'MULTUM:11732', 'MED:62624']
  + doc(last 150 chars):
['655.83', 'V23.9', 'V67.9', '654.20', '655.83', 'V26.33', '655.83', 'V23.9', '655.83', 'V23.9', 'V67.9', '655.93', 'V23.9', 'V67.9', '796.2', '655.81', '659.41', 'V25.2', 'V27.0', '786.59', '642.31', '642.41', '493.90', '784.0', '648.91', '674.82', '654.21', 'MED:61895', 'MED:62439', 'MED:106359', 'MED:62296', 'MED:62587', 'MED:62290', 'MED:62994', 'MED:63596', 'MED:61895', 'MED:62439', 'MED:61870', 'MED:60926', 'MED:61120', 'MED:106359', 'MED:107078', 'MED:61594', 'MED:103931', 'MED:99142', 'NDC:54868051000', 'NDC:49999058730', 'NDC:00122301733', 'NDC:00904531346', 'MED:99018', 'MED:128621', 'V81.1', 'V72.31', '654.20']

  + vdoc
    + ['655.83', 'V23.9']
    + ['655.83', 'V23.9', 'V67.9']
    + ['655.93']
    + ['V23.9', 'V67.9']
    + ['796.2', '655.81', '659.41', 'V25.2', 'V27.0', '786.59', '642.31', '642.41', '493.90', '784.0', '648.91', '674.82', '654.21', 'MED:61895', 'MED:62439', 'MED:106359', 'MED:62296', 'MED:62587']
    + ['MED:62290', 'MED:62994', 'MED:63596', 'MED:61895', 'MED:62439', 'MED:61870', 'MED:60926', 'MED:61120', 'MED:106359', 'MED:107078', 'MED:61594', 'MED:103931', 'MED:99142']
    + ['NDC:54868051000', 'NDC:49999058730']
    + ['NDC:00122301733', 'NDC:00904531346', 'MED:99018', 'MED:128621']
    + ['V81.1']
    + ['V72.31', '654.20']
  + doc(last 150 chars):
['581.1', 'MED:62525', 'MED:77684', '581.1', 'MED:62525', 'MED:77684', 'MED:61814', 'MED:62439', '581.1', 'MED:62525', 'MED:77684', 'MED:61814', 'MED:62439', '581.1', 'MED:62525', 'MED:77684', 'MED:61814', 'MED:62439']

  + vdoc
    + ['581.1', 'MED:62525', 'MED:77684']
    + ['581.1', 'MED:62525', 'MED:77684', 'MED:61814', 'MED:62439']
    + ['581.1', 'MED:62525', 'MED:77684', 'MED:61814', 'MED:62439']
    + ['581.1', 'MED:62525', 'MED:77684', 'MED:61814', 'MED:62439']
  + doc(last 150 chars):
['MED:98005', 'MED:102484', 'MED:133116', 'MED:66167', 'MED:63122', 'MED:61972', 'MED:102419', 'MED:61911', 'MED:61511', 'MED:60936', 'MED:69155', 'MED:61309', 'MED:61911', 'MED:61511', 'MED:81379', 'MED:62649', 'MED:70786', 'MED:61836', 'MED:61511', 'MED:61309', 'MED:104889', 'MED:63182', 'MED:66136', 'MED:67465', 'MED:61511', 'MED:63465', 'MED:98005', 'MED:100184', 'MED:104889', 'MED:66125', 'MED:66068', 'MED:62666', 'MED:102484', 'MED:62649', 'MED:62274', 'MED:66136', 'MED:106366', 'MED:63540', 'MED:125227', 'MED:63122', 'MED:61836', 'MED:63096', 'MED:69148', 'MED:63433', 'MED:61678', 'MED:61704', 'MED:72705', 'MED:60481', 'MED:62701', 'MED:61309', 'MED:62402', 'MED:102419', 'MED:63465', 'MED:62343', 'MED:60835', 'MED:60755', 'MED:62402', 'MED:61865', 'MED:60481', 'MED:98005', 'MED:126011', 'MED:125229', 'MED:62659', 'MED:63055', 'MED:61836', 'MED:61865', 'MED:62343', 'MED:98005', 'MED:62666', 'MED:63055', 'MED:62899', 'MED:126011', 'MED:102484', 'MED:63182', 'MED:66136', 'MED:125229', 'MED:62402', 'MED:61471', 'MED:60481', 'MED:61216', 'MED:61309', 'MED:62659', 'MED:102419', 'MED:63465', 'MED:62343', 'MED:62829', 'MED:63540', 'MED:133116', 'MED:61865', 'MED:60481', 'MED:70786', 'MED:60481', 'MED:61704', 'MED:62829', 'MED:106366', 'MED:96730', 'MED:63433', 'MED:60984', 'MED:60650', 'MED:62659', 'MED:63182', 'MED:102218', 'MED:149979', 'MED:61704', 'MED:61759', 'MED:61865', 'MED:72705', 'MED:98005', 'MED:62659', 'MED:62666', 'MED:63055', 'MED:126011', 'MED:102484', 'MED:72705', 'MED:66136', 'MED:62934', 'MED:125229', 'MED:61865', 'MED:61759', 'MED:60481', 'MED:61309', 'MED:63433', 'MED:102419', 'MED:62829', 'MED:63465', 'MED:62035', 'MED:61471', 'MED:62829', 'MED:63055', 'MED:63518', 'MED:72705', 'MED:61253', 'MED:63540', 'MED:61836', 'MED:62402', 'MED:61348', 'MED:62829', 'MED:60553', 'MED:60556', 'MED:63055', 'MED:63518', 'MED:72705', 'MED:61253', 'MED:63540', 'MED:133116', 'MED:62934', 'MED:101186', 'MED:62871', 'MED:63414', 'MED:61216']

  + vdoc
    + ['MED:62659', 'MED:63055', 'MED:61836', 'MED:61865', 'MED:62343']
    + ['MED:98005', 'MED:62666', 'MED:63055', 'MED:62899', 'MED:126011', 'MED:102484', 'MED:63182', 'MED:66136', 'MED:125229', 'MED:62402', 'MED:61471', 'MED:60481', 'MED:61216', 'MED:61309', 'MED:62659', 'MED:102419', 'MED:63465', 'MED:62343', 'MED:62829']
    + ['MED:63540', 'MED:133116', 'MED:61865', 'MED:60481']
    + ['MED:70786', 'MED:60481', 'MED:61704', 'MED:62829']
    + ['MED:106366', 'MED:96730', 'MED:63433', 'MED:60984', 'MED:60650']
    + ['MED:62659', 'MED:63182', 'MED:102218', 'MED:149979', 'MED:61704', 'MED:61759', 'MED:61865', 'MED:72705']
    + ['MED:98005', 'MED:62659', 'MED:62666', 'MED:63055', 'MED:126011', 'MED:102484', 'MED:72705', 'MED:66136', 'MED:62934', 'MED:125229', 'MED:61865', 'MED:61759', 'MED:60481', 'MED:61309', 'MED:63433', 'MED:102419', 'MED:62829', 'MED:63465']
    + ['MED:62035', 'MED:61471', 'MED:62829']
    + ['MED:63055', 'MED:63518', 'MED:72705', 'MED:61253', 'MED:63540', 'MED:61836', 'MED:62402', 'MED:61348', 'MED:62829', 'MED:60553', 'MED:60556']
    + ['MED:63055', 'MED:63518', 'MED:72705', 'MED:61253', 'MED:63540', 'MED:133116', 'MED:62934', 'MED:101186', 'MED:62871', 'MED:63414', 'MED:61216']
  + doc(last 150 chars):
['582.9', '585.3', 'V58.65', '791.0', '584.5', '403.10', '588.81', '585.4', '582.9', 'V49.83', 'V49.83', 'V67.59', 'V03.82', '585.6', '585.4', 'MED:99018', '585.6', '585.6', '585.4', '585.3', 'N18.6', 'Z79.52', 'N18.6', 'N18.6', 'N18.4']

  + vdoc
    + ['585.4']
    + ['582.9']
    + ['V49.83']
    + ['V49.83', 'V67.59', 'V03.82', '585.6', '585.4', 'MED:99018']
    + ['585.6']
    + ['585.6', '585.4']
    + ['585.3']
    + ['N18.6']
    + ['Z79.52', 'N18.6']
    + ['N18.6', 'N18.4']
  + avgL: 3.401748, max n_tokens_in_visit: 71, min: 1, std: 4.775765
  + avgV: 90.685169, max n_visits_in_doc:   1082, min: 1, std: 114.666660
visitToDocment> size(V):2360 -> size(Dv):214017 (E[nVperDoc]=90.685169)
> D:
[['813.42', '813.42', '813.42', '813.42', '813.42', '813.42', '813.42', '813.42', '813.42', '813.42', '813.42', '813.42', '813.42', '813.42', '813.42', '813.42', '813.42', '813.42', '813.42', '813.42', '813.42', '813.42', '813.42', '813.42', '813.42', '813.42', '813.42', '813.42', '813.42', '813.42', '813.42', '813.42', '813.42', '813.42', '813.42', '813.42', '813.42', '813.42', '813.42', '813.42', '813.42', '813.42', '813.42', '813.42', '813.42', '813.42', '813.42', '813.42', '813.42', '813.42', '813.42', '813.42', '813.42', '813.42', '813.42', '813.42', '813.42', '813.42', '813.42', '813.42', '813.42', '813.42', '813.42', '813.42', '813.42', '813.42', '813.42', '813.42', '813.42', '813.42', '813.42'], ['813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41'], ['813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41'], ['813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41'], ['813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41'], ['813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41'], ['813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41'], ['813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41'], ['813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41'], ['813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41', '813.41']]

    + computing document vectors nD:2360 => nDEff: 214017 ...
makeTSetVisit> model dir: /Users/pleiades/Documents/work/tpheno/seqmaker/data/CKD/model
getDocVec> method: pv-dm2, model ID: smallCKD, segment_by_visit? True, load precomputed? True
getDocVecPV> prior to labelDocuments, already labeled? False, example: ['813.42', '813.42', '813.42', '813.42', '813.42', '813.42', '813.42', '813.42', '813.42', '813.42', '813.42', '813.42', '813.42', '813.42', '813.42', '813.42', '813.42', '813.42', '813.42', '813.42', '813.42', '813.42', '813.42', '813.42', '813.42', '813.42', '813.42', '813.42', '813.42', '813.42', '813.42', '813.42', '813.42', '813.42', '813.42', '813.42', '813.42', '813.42', '813.42', '813.42', '813.42', '813.42', '813.42', '813.42', '813.42', '813.42', '813.42', '813.42', '813.42', '813.42', '813.42', '813.42', '813.42', '813.42', '813.42', '813.42', '813.42', '813.42', '813.42', '813.42', '813.42', '813.42', '813.42', '813.42', '813.42', '813.42', '813.42', '813.42', '813.42', '813.42', '813.42'], type: <type 'list'>
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
Doc2Vec Parameters
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
  + current d2v method: pv-dm2
  + number of features: 50
  + window size: 10
  + ignore tokens with total freq less than 2
  + number of epochs: 20
  + training method: negative sampling  + number of negative samples: 15  + use concatenation of context vectors? False

getDocVecPV> total: 214017
getDocVecPV> Params summary of d2v models (n_workers: 18, n_iter: 20) ...
  + n_features: 50, window: 10
  + negative sample? 15
  + min count: 2

D2V.load> Info: model path:
/Users/pleiades/Documents/work/tpheno/seqmaker/data/CKD/model/Pf50w10i20-smallCKD.dm

D2V.load> Info: model path:
/Users/pleiades/Documents/work/tpheno/seqmaker/data/CKD/model/Pf50w10i20-smallCKD.dbow

check> input prior to consolidateVisits dim(X): (214017, 100), len(visitDocIDs): 214017
(check) contatenated vector dim: 5000 | lastN=50, indv fDim=100
(check) visit idx:
[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2]
(check) scope idx:
[0, 14, 97, 110, 112, 338, 429, 459, 503, 529, 606, 645, 712, 741, 951, 1075, 1198, 1212, 1372, 1508, 1715, 1794, 1844, 2002, 2011, 2389, 2561, 2958, 2986, 3087, 3103, 3162, 3459, 3530, 3619, 3625, 3778, 3841, 3990, 4012, 4070, 4123, 4223, 4226, 4665, 4813, 4932, 5178, 5549, 5676, 5688, 5716, 5805, 5921, 6438, 6445, 6463, 6562, 6641, 6751, 6825, 7009, 7053, 7074, 7079, 7175, 7245, 7326, 7590, 8072, 8132, 8135, 8147, 8186, 8241, 8587, 8595, 8709, 8737, 8831, 8847, 8968, 9000, 9059, 9167, 10166, 10315, 10501, 10553, 10577, 11085, 11192, 11221, 11887, 11969, 12067, 12116, 12120, 12461, 12569]

verify> mean dim: 9068.516949, median: 4900.000000, std: 11466.665963
(check) flatterned X, dim(Xp): (2360,)
tsHandler> save document vectors (cv=0), sparse? False ...
  + params: dim(X):(2360, 5000), index:0, n(docIDs):2360, d2v:pv-dm2, cohort:CKD, ctype:regular, shuffle? False, meta: smallCKD
tsHandler> training set dir: /Users/pleiades/Documents/work/tpheno/seqmaker/data/CKD/combined
prepareTrainingSet> n_classes: 11
TSet> Params: cohort: CKD, file id: regular-pv-dm2-smallCKD
TSet.saveDataFrame> tset params (cohort:CKD d2v:pv-dm2, ctype:regular, suffix=smallCKD)
TSet.saveDataFrame> Saving (cohort=CKD, d2v=pv-dm2, suffix=smallCKD) dataset to:
/Users/pleiades/Documents/work/tpheno/seqmaker/data/CKD/combined/tset-n0-IDregular-pv-dm2-smallCKD-GCKD.csv

status> Model computation complete (@nTrial=0)
info> each doc is repr by the last 50 visits
TSet> Params: cohort: CKD, file id: regular-pv-dm2-smallCKD
TSet.load> loading training set (cohort=CKD, suffix=smallCKD) from:
/Users/pleiades/Documents/work/tpheno/seqmaker/data/CKD/combined/tset-n0-IDregular-pv-dm2-smallCKD-GCKD.csv

tsHandler.profile> Found 11 unique labels ...
  + label=CKD Stage 3a => N=215
  + label=Unknown => N=411
  + label=CKD Stage 3b => N=135
  + label=ESRD on dialysis => N=41
  + label=CKD G1-control => N=87
  + label=CKD G1A1-control => N=108
  + label=CKD Stage 5 => N=31
  + label=CKD Stage 4 => N=56
  + label=ESRD after transplant => N=686
  + label=CKD Stage 2 => N=528
  + label=CKD Stage 1 => N=62
loadTSetCombined> Modifying training data ...
> Prior to re-labeling ...
tsHandler.profile> Found 11 unique labels ...
  + label=CKD Stage 3a => N=215
  + label=Unknown => N=411
  + label=CKD Stage 3b => N=135
  + label=ESRD on dialysis => N=41
  + label=CKD G1-control => N=87
  + label=CKD G1A1-control => N=108
  + label=CKD Stage 5 => N=31
  + label=CKD Stage 4 => N=56
  + label=ESRD after transplant => N=686
  + label=CKD Stage 2 => N=528
  + label=CKD Stage 1 => N=62
  + (before) unique labels:
['CKD Stage 3a' 'CKD Stage 2' 'Unknown' 'CKD Stage 3b' 'CKD Stage 4'
 'ESRD after transplant' 'ESRD on dialysis' 'CKD G1A1-control'
 'CKD Stage 1' 'CKD G1-control' 'CKD Stage 5']

  + CKD Stage 5 <- ['ESRD after transplant', 'ESRD on dialysis']
  + CKD Stage 3 <- ['CKD Stage 3a', 'CKD Stage 3b']
  + Others <- ['CKD G1-control', 'CKD G1A1-control', 'Unknown']
merge> n_labels: 11 -> 6
  + (after) unique labels:
['CKD Stage 3' 'CKD Stage 2' 'Others' 'CKD Stage 4' 'CKD Stage 5'
 'CKD Stage 1']

> After re-labeling ...
tsHandler.profile> Found 6 unique labels ...
  + label=Others => N=606
  + label=CKD Stage 5 => N=758
  + label=CKD Stage 4 => N=56
  + label=CKD Stage 3 => N=350
  + label=CKD Stage 2 => N=528
  + label=CKD Stage 1 => N=62
loadTSet> number of classes: 6
... cohort=CKD, ctype=regular, d2v=pv-dm2, meta=smallCKD
  + is_simplified? False, ... 
  + classification mode: multiclass
  + classifiers:
[]
  + training set type:dense
  + training set dim:2360
  + n classes:6

d_classify> dim(ts): (2360, 5002) > n_timesteps: 50, n_features: 100
  + dim(X <- ts): (2360, 5000)
d_classify> reshaped X: (2360, 50, 100) | n_classes=6

<<< Experimental Settings >>>

   + tset type dense, maxNPerClass: None, drop control? False
  + cohort: CKD, ctype: regular

  + D2V: pv-dm2, params> window: 10, n_features: 50
       + n_iter: 20, min_count: 2

  + userFileID: smallCKD

... data: 

... params (model selection): 

model_selection> trying {'n_units': 50, 'dropout_rate': 0.2} ...

make_lstm> n_units=50, r_dropout=0.200000, n_layers=1, n_classes=6
WARNING:tensorflow:From dnn_utils.py:157: streaming_auc (from tensorflow.contrib.metrics.python.ops.metric_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Please switch to tf.metrics.auc. Note that the order of the labels and predictions arguments has been switched.
  + lookup:
{'Others': 5, 'CKD Stage 5': 4, 'CKD Stage 4': 3, 'CKD Stage 3': 2, 'CKD Stage 2': 1, 'CKD Stage 1': 0}

... class weights:
{0: 6.344086021505376, 1: 0.74494949494949492, 2: 1.1238095238095238, 3: 7.0238095238095237, 4: 0.51890941072999119, 5: 0.64906490649064907}

====================================================================================================
... early stopping>
       + patience: 20, model='max'
... model training>
       + batch_size: 32, epochs: 60, shuffle? True, metric: auc_roc
====================================================================================================
Train on 1652 samples, validate on 708 samples
Epoch 1/60
2018-07-01 17:20:03.088307: I tensorflow/core/platform/cpu_feature_guard.cc:140] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA
1652/1652 [==============================] - 4s 2ms/step - loss: 1.6895 - acc: 0.2554 - auc_roc: 0.6217 - val_loss: 1.8713 - val_acc: 0.0904 - val_auc_roc: 0.6412
Epoch 2/60
1652/1652 [==============================] - 3s 2ms/step - loss: 1.5426 - acc: 0.3571 - auc_roc: 0.6460 - val_loss: 1.6664 - val_acc: 0.3715 - val_auc_roc: 0.6750
Epoch 3/60
1652/1652 [==============================] - 3s 2ms/step - loss: 1.3309 - acc: 0.4607 - auc_roc: 0.6979 - val_loss: 1.4207 - val_acc: 0.5749 - val_auc_roc: 0.7257
Epoch 4/60
1652/1652 [==============================] - 3s 2ms/step - loss: 1.2505 - acc: 0.4806 - auc_roc: 0.7449 - val_loss: 1.5239 - val_acc: 0.5749 - val_auc_roc: 0.7601
Epoch 5/60
1652/1652 [==============================] - 3s 2ms/step - loss: 1.1660 - acc: 0.5000 - auc_roc: 0.7713 - val_loss: 1.6423 - val_acc: 0.5268 - val_auc_roc: 0.7782
Epoch 6/60
1652/1652 [==============================] - 3s 2ms/step - loss: 1.1020 - acc: 0.5048 - auc_roc: 0.7837 - val_loss: 1.5058 - val_acc: 0.6568 - val_auc_roc: 0.7923
Epoch 7/60
1652/1652 [==============================] - 3s 2ms/step - loss: 1.0101 - acc: 0.5508 - auc_roc: 0.7999 - val_loss: 1.5720 - val_acc: 0.6243 - val_auc_roc: 0.8063
Epoch 8/60
1652/1652 [==============================] - 3s 2ms/step - loss: 0.9640 - acc: 0.5617 - auc_roc: 0.8112 - val_loss: 1.7574 - val_acc: 0.6497 - val_auc_roc: 0.8169
Epoch 9/60
1652/1652 [==============================] - 3s 2ms/step - loss: 0.9129 - acc: 0.6077 - auc_roc: 0.8215 - val_loss: 1.7435 - val_acc: 0.6483 - val_auc_roc: 0.8264
Epoch 10/60
1652/1652 [==============================] - 3s 2ms/step - loss: 0.9131 - acc: 0.5745 - auc_roc: 0.8297 - val_loss: 1.6594 - val_acc: 0.6511 - val_auc_roc: 0.8330
Epoch 11/60
1652/1652 [==============================] - 3s 2ms/step - loss: 0.8606 - acc: 0.5902 - auc_roc: 0.8359 - val_loss: 1.6962 - val_acc: 0.6836 - val_auc_roc: 0.8397
Epoch 12/60
1652/1652 [==============================] - 3s 2ms/step - loss: 0.7790 - acc: 0.6205 - auc_roc: 0.8433 - val_loss: 1.7852 - val_acc: 0.6766 - val_auc_roc: 0.8463
Epoch 13/60
1652/1652 [==============================] - 3s 2ms/step - loss: 0.7318 - acc: 0.6471 - auc_roc: 0.8490 - val_loss: 1.9969 - val_acc: 0.6921 - val_auc_roc: 0.8524
Epoch 14/60
1652/1652 [==============================] - 3s 2ms/step - loss: 0.7343 - acc: 0.6465 - auc_roc: 0.8549 - val_loss: 1.7996 - val_acc: 0.6949 - val_auc_roc: 0.8576
Epoch 15/60
1652/1652 [==============================] - 3s 2ms/step - loss: 0.6817 - acc: 0.6659 - auc_roc: 0.8602 - val_loss: 1.8959 - val_acc: 0.7062 - val_auc_roc: 0.8629
Epoch 16/60
1652/1652 [==============================] - 3s 2ms/step - loss: 0.7736 - acc: 0.6301 - auc_roc: 0.8643 - val_loss: 1.7888 - val_acc: 0.6751 - val_auc_roc: 0.8661
Epoch 17/60
1652/1652 [==============================] - 3s 2ms/step - loss: 0.6856 - acc: 0.6586 - auc_roc: 0.8678 - val_loss: 1.9996 - val_acc: 0.6836 - val_auc_roc: 0.8698
Epoch 18/60
1652/1652 [==============================] - 3s 2ms/step - loss: 0.6299 - acc: 0.6810 - auc_roc: 0.8716 - val_loss: 1.9281 - val_acc: 0.7076 - val_auc_roc: 0.8735
Epoch 19/60
1652/1652 [==============================] - 3s 2ms/step - loss: 0.5954 - acc: 0.6967 - auc_roc: 0.8752 - val_loss: 2.2416 - val_acc: 0.6907 - val_auc_roc: 0.8771
Epoch 20/60
1652/1652 [==============================] - 3s 2ms/step - loss: 0.5653 - acc: 0.7119 - auc_roc: 0.8787 - val_loss: 2.0354 - val_acc: 0.6780 - val_auc_roc: 0.8805
Epoch 21/60
1652/1652 [==============================] - 3s 2ms/step - loss: 0.5492 - acc: 0.7258 - auc_roc: 0.8818 - val_loss: 2.3445 - val_acc: 0.6610 - val_auc_roc: 0.8834
Epoch 22/60
1652/1652 [==============================] - 3s 2ms/step - loss: 0.5301 - acc: 0.7294 - auc_roc: 0.8844 - val_loss: 2.4274 - val_acc: 0.6638 - val_auc_roc: 0.8859
Epoch 23/60
1652/1652 [==============================] - 3s 2ms/step - loss: 0.5239 - acc: 0.7337 - auc_roc: 0.8871 - val_loss: 2.1858 - val_acc: 0.5734 - val_auc_roc: 0.8879
Epoch 00023: early stopping
... history of metrics comprising: ['acc', 'loss', 'val_auc_roc', 'auc_roc', 'val_acc', 'val_loss']
... ... metric (acc): [0.64648910440486507, 0.66585956402032775, 0.6301452787390055, 0.65859564179081032, 0.68099273636612423, 0.69673123515547042, 0.71186440692398223, 0.72578692493946728, 0.729418886054226, 0.73365617418981921] (n=23)
output> saving performance to:
/Users/pleiades/Documents/work/tpheno/seqmaker/data/CKD/plot/model_evalation-ep200b16.tif

... ... metric (loss): [0.73427880315457361, 0.68165362891504322, 0.77358232543197147, 0.68559723038938947, 0.62992783594362378, 0.59536843380685578, 0.56529396072426952, 0.5492072175403484, 0.53007583771144506, 0.52390399019596945] (n=23)
output> saving performance to:
/Users/pleiades/Documents/work/tpheno/seqmaker/data/CKD/plot/model_evalation-ep200b16.tif


model_selection> trying {'n_units': 100, 'dropout_rate': 0.2} ...

make_lstm> n_units=100, r_dropout=0.200000, n_layers=1, n_classes=6
  + lookup:
{'Others': 5, 'CKD Stage 5': 4, 'CKD Stage 4': 3, 'CKD Stage 3': 2, 'CKD Stage 2': 1, 'CKD Stage 1': 0}

... class weights:
{0: 6.344086021505376, 1: 0.74494949494949492, 2: 1.1238095238095238, 3: 7.0238095238095237, 4: 0.51890941072999119, 5: 0.64906490649064907}

====================================================================================================
... early stopping>
       + patience: 20, model='max'
... model training>
       + batch_size: 32, epochs: 60, shuffle? True, metric: auc_roc
====================================================================================================
Train on 1652 samples, validate on 708 samples
Epoch 1/60
1652/1652 [==============================] - 4s 2ms/step - loss: 1.6620 - acc: 0.3008 - auc_roc: 0.6369 - val_loss: 1.8311 - val_acc: 0.5028 - val_auc_roc: 0.6920
Epoch 2/60
1652/1652 [==============================] - 3s 2ms/step - loss: 1.4214 - acc: 0.4631 - auc_roc: 0.7169 - val_loss: 1.5476 - val_acc: 0.4802 - val_auc_roc: 0.7385
Epoch 3/60
1652/1652 [==============================] - 3s 2ms/step - loss: 1.2530 - acc: 0.4885 - auc_roc: 0.7523 - val_loss: 1.5695 - val_acc: 0.5226 - val_auc_roc: 0.7648
Epoch 4/60
1652/1652 [==============================] - 3s 2ms/step - loss: 1.1490 - acc: 0.5042 - auc_roc: 0.7752 - val_loss: 1.5368 - val_acc: 0.5523 - val_auc_roc: 0.7832
Epoch 5/60
1652/1652 [==============================] - 3s 2ms/step - loss: 1.0711 - acc: 0.5242 - auc_roc: 0.7902 - val_loss: 1.6002 - val_acc: 0.5904 - val_auc_roc: 0.7990
Epoch 6/60
1652/1652 [==============================] - 3s 2ms/step - loss: 0.9927 - acc: 0.5714 - auc_roc: 0.8060 - val_loss: 1.5609 - val_acc: 0.5989 - val_auc_roc: 0.8129
Epoch 7/60
1652/1652 [==============================] - 3s 2ms/step - loss: 0.9461 - acc: 0.5781 - auc_roc: 0.8182 - val_loss: 1.7321 - val_acc: 0.7020 - val_auc_roc: 0.8253
Epoch 8/60
1652/1652 [==============================] - 3s 2ms/step - loss: 0.8308 - acc: 0.6283 - auc_roc: 0.8312 - val_loss: 1.8082 - val_acc: 0.6780 - val_auc_roc: 0.8368
Epoch 9/60
1652/1652 [==============================] - 3s 2ms/step - loss: 0.7748 - acc: 0.6423 - auc_roc: 0.8416 - val_loss: 1.6266 - val_acc: 0.6808 - val_auc_roc: 0.8467
Epoch 10/60
1652/1652 [==============================] - 3s 2ms/step - loss: 0.7474 - acc: 0.6622 - auc_roc: 0.8509 - val_loss: 1.9997 - val_acc: 0.7034 - val_auc_roc: 0.8551
Epoch 11/60
1652/1652 [==============================] - 3s 2ms/step - loss: 0.6860 - acc: 0.6640 - auc_roc: 0.8591 - val_loss: 1.7916 - val_acc: 0.7218 - val_auc_roc: 0.8629
Epoch 12/60
1652/1652 [==============================] - 3s 2ms/step - loss: 0.6537 - acc: 0.6852 - auc_roc: 0.8662 - val_loss: 2.0739 - val_acc: 0.6794 - val_auc_roc: 0.8689
Epoch 13/60
1652/1652 [==============================] - 3s 2ms/step - loss: 0.6602 - acc: 0.6707 - auc_roc: 0.8712 - val_loss: 1.7123 - val_acc: 0.7034 - val_auc_roc: 0.8737
Epoch 14/60
1652/1652 [==============================] - 4s 2ms/step - loss: 0.5903 - acc: 0.7113 - auc_roc: 0.8760 - val_loss: 2.0729 - val_acc: 0.7345 - val_auc_roc: 0.8790
Epoch 15/60
1652/1652 [==============================] - 3s 2ms/step - loss: 0.5305 - acc: 0.7439 - auc_roc: 0.8815 - val_loss: 2.0607 - val_acc: 0.6370 - val_auc_roc: 0.8835
Epoch 16/60
1652/1652 [==============================] - 3s 2ms/step - loss: 0.5022 - acc: 0.7536 - auc_roc: 0.8853 - val_loss: 1.7833 - val_acc: 0.7105 - val_auc_roc: 0.8878
Epoch 17/60
1652/1652 [==============================] - 4s 2ms/step - loss: 0.4594 - acc: 0.7778 - auc_roc: 0.8899 - val_loss: 2.0825 - val_acc: 0.7316 - val_auc_roc: 0.8923
Epoch 18/60
1652/1652 [==============================] - 3s 2ms/step - loss: 0.4096 - acc: 0.8039 - auc_roc: 0.8944 - val_loss: 2.2028 - val_acc: 0.7331 - val_auc_roc: 0.8966
Epoch 19/60
1652/1652 [==============================] - 3s 2ms/step - loss: 0.3728 - acc: 0.8172 - auc_roc: 0.8985 - val_loss: 2.1312 - val_acc: 0.7062 - val_auc_roc: 0.9006
Epoch 20/60
1652/1652 [==============================] - 3s 2ms/step - loss: 0.3588 - acc: 0.8269 - auc_roc: 0.9023 - val_loss: 2.4780 - val_acc: 0.7316 - val_auc_roc: 0.9044
Epoch 21/60
1652/1652 [==============================] - 3s 2ms/step - loss: 0.3171 - acc: 0.8565 - auc_roc: 0.9061 - val_loss: 2.1419 - val_acc: 0.7048 - val_auc_roc: 0.9081
Epoch 22/60
1652/1652 [==============================] - 3s 2ms/step - loss: 0.3420 - acc: 0.8462 - auc_roc: 0.9095 - val_loss: 2.5983 - val_acc: 0.7345 - val_auc_roc: 0.9112
Epoch 23/60
1652/1652 [==============================] - 3s 2ms/step - loss: 0.2808 - acc: 0.8723 - auc_roc: 0.9125 - val_loss: 2.5218 - val_acc: 0.7288 - val_auc_roc: 0.9142
Epoch 24/60
1652/1652 [==============================] - 3s 2ms/step - loss: 0.3300 - acc: 0.8462 - auc_roc: 0.9154 - val_loss: 2.1856 - val_acc: 0.7161 - val_auc_roc: 0.9167
Epoch 00024: early stopping
... history of metrics comprising: ['acc', 'loss', 'val_auc_roc', 'auc_roc', 'val_acc', 'val_loss']
... ... metric (acc): [0.74394673152350921, 0.75363196154772227, 0.77784503603097022, 0.80387409172104285, 0.81719128329297819, 0.82687651302854892, 0.8565375299777015, 0.84624697336561738, 0.87227602876704768, 0.84624697365425983] (n=24)
output> saving performance to:
/Users/pleiades/Documents/work/tpheno/seqmaker/data/CKD/plot/model_evalation-ep200b16.tif

... ... metric (loss): [0.53050223909336491, 0.50219691420294177, 0.45935421186267028, 0.40964168396758111, 0.37284217049654111, 0.35878158308403257, 0.31708825045867345, 0.34203282105071203, 0.28077165923164776, 0.3299676959220203] (n=24)
output> saving performance to:
/Users/pleiades/Documents/work/tpheno/seqmaker/data/CKD/plot/model_evalation-ep200b16.tif


model_selection> trying {'n_units': 200, 'dropout_rate': 0.2} ...

make_lstm> n_units=200, r_dropout=0.200000, n_layers=1, n_classes=6
  + lookup:
{'Others': 5, 'CKD Stage 5': 4, 'CKD Stage 4': 3, 'CKD Stage 3': 2, 'CKD Stage 2': 1, 'CKD Stage 1': 0}

... class weights:
{0: 6.344086021505376, 1: 0.74494949494949492, 2: 1.1238095238095238, 3: 7.0238095238095237, 4: 0.51890941072999119, 5: 0.64906490649064907}

====================================================================================================
... early stopping>
       + patience: 20, model='max'
... model training>
       + batch_size: 32, epochs: 60, shuffle? True, metric: auc_roc
====================================================================================================
Train on 1652 samples, validate on 708 samples
Epoch 1/60
1652/1652 [==============================] - 5s 3ms/step - loss: 1.6451 - acc: 0.2815 - auc_roc: 0.5660 - val_loss: 1.6215 - val_acc: 0.5212 - val_auc_roc: 0.6916
Epoch 2/60
1652/1652 [==============================] - 4s 2ms/step - loss: 1.4358 - acc: 0.4358 - auc_roc: 0.7228 - val_loss: 1.4208 - val_acc: 0.5847 - val_auc_roc: 0.7475
Epoch 3/60
1652/1652 [==============================] - 4s 2ms/step - loss: 1.2449 - acc: 0.4776 - auc_roc: 0.7650 - val_loss: 1.7287 - val_acc: 0.4929 - val_auc_roc: 0.7740
Epoch 4/60
1652/1652 [==============================] - 4s 2ms/step - loss: 1.1727 - acc: 0.4818 - auc_roc: 0.7814 - val_loss: 1.8972 - val_acc: 0.2599 - val_auc_roc: 0.7771
Epoch 5/60
1652/1652 [==============================] - 4s 2ms/step - loss: 1.0993 - acc: 0.5194 - auc_roc: 0.7781 - val_loss: 1.6305 - val_acc: 0.6144 - val_auc_roc: 0.7871
Epoch 6/60
1652/1652 [==============================] - 4s 2ms/step - loss: 0.9569 - acc: 0.5672 - auc_roc: 0.7964 - val_loss: 1.8639 - val_acc: 0.4633 - val_auc_roc: 0.8015
Epoch 7/60
1652/1652 [==============================] - 4s 2ms/step - loss: 0.8684 - acc: 0.6035 - auc_roc: 0.8069 - val_loss: 1.8373 - val_acc: 0.6554 - val_auc_roc: 0.8148
Epoch 8/60
1652/1652 [==============================] - 4s 2ms/step - loss: 0.8780 - acc: 0.5920 - auc_roc: 0.8198 - val_loss: 1.6862 - val_acc: 0.4746 - val_auc_roc: 0.8230
Epoch 9/60
1652/1652 [==============================] - 5s 3ms/step - loss: 0.7697 - acc: 0.6356 - auc_roc: 0.8264 - val_loss: 1.8553 - val_acc: 0.6554 - val_auc_roc: 0.8321
Epoch 10/60
1652/1652 [==============================] - 4s 2ms/step - loss: 0.6763 - acc: 0.6610 - auc_roc: 0.8370 - val_loss: 1.9022 - val_acc: 0.6766 - val_auc_roc: 0.8427
Epoch 11/60
1652/1652 [==============================] - 4s 2ms/step - loss: 0.6225 - acc: 0.6864 - auc_roc: 0.8473 - val_loss: 2.1508 - val_acc: 0.6864 - val_auc_roc: 0.8521
Epoch 12/60
1652/1652 [==============================] - 4s 2ms/step - loss: 0.5813 - acc: 0.7076 - auc_roc: 0.8564 - val_loss: 1.8999 - val_acc: 0.6709 - val_auc_roc: 0.8606
Epoch 13/60
1652/1652 [==============================] - 4s 2ms/step - loss: 0.5797 - acc: 0.7197 - auc_roc: 0.8641 - val_loss: 2.4130 - val_acc: 0.7090 - val_auc_roc: 0.8679
Epoch 14/60
1652/1652 [==============================] - 4s 2ms/step - loss: 0.6322 - acc: 0.7046 - auc_roc: 0.8704 - val_loss: 2.0541 - val_acc: 0.6935 - val_auc_roc: 0.8733
Epoch 15/60
1652/1652 [==============================] - 4s 2ms/step - loss: 0.5582 - acc: 0.7331 - auc_roc: 0.8759 - val_loss: 1.9080 - val_acc: 0.6992 - val_auc_roc: 0.8788
Epoch 16/60
1652/1652 [==============================] - 4s 2ms/step - loss: 0.4942 - acc: 0.7621 - auc_roc: 0.8814 - val_loss: 2.3868 - val_acc: 0.7034 - val_auc_roc: 0.8840
Epoch 17/60
1652/1652 [==============================] - 4s 2ms/step - loss: 0.4187 - acc: 0.7978 - auc_roc: 0.8865 - val_loss: 2.2869 - val_acc: 0.6427 - val_auc_roc: 0.8889
Epoch 18/60
1652/1652 [==============================] - 4s 2ms/step - loss: 0.4329 - acc: 0.7863 - auc_roc: 0.8906 - val_loss: 2.3955 - val_acc: 0.6992 - val_auc_roc: 0.8930
Epoch 19/60
1652/1652 [==============================] - 4s 2ms/step - loss: 0.3370 - acc: 0.8378 - auc_roc: 0.8952 - val_loss: 2.3566 - val_acc: 0.6921 - val_auc_roc: 0.8977
Epoch 20/60
1652/1652 [==============================] - 4s 2ms/step - loss: 0.2995 - acc: 0.8571 - auc_roc: 0.8997 - val_loss: 2.6734 - val_acc: 0.6921 - val_auc_roc: 0.9019
Epoch 21/60
1652/1652 [==============================] - 4s 2ms/step - loss: 0.2784 - acc: 0.8801 - auc_roc: 0.9037 - val_loss: 2.4764 - val_acc: 0.7302 - val_auc_roc: 0.9060
Epoch 22/60
1652/1652 [==============================] - 4s 2ms/step - loss: 0.2528 - acc: 0.8892 - auc_roc: 0.9079 - val_loss: 2.4244 - val_acc: 0.6017 - val_auc_roc: 0.9096
Epoch 00022: early stopping
... history of metrics comprising: ['acc', 'loss', 'val_auc_roc', 'auc_roc', 'val_acc', 'val_loss']
... ... metric (acc): [0.71973365603001294, 0.70460048440582235, 0.7330508477462695, 0.76210653753026636, 0.79782082353319439, 0.78631961230215663, 0.83777239723875219, 0.85714285728717832, 0.88014527830604206, 0.8892251818867053] (n=22)
output> saving performance to:
/Users/pleiades/Documents/work/tpheno/seqmaker/data/CKD/plot/model_evalation-ep200b16.tif

... ... metric (loss): [0.57968986402412304, 0.63219522737128975, 0.55820385682380802, 0.49423318942580324, 0.41869250899654326, 0.43286128309679378, 0.33697384083530807, 0.29950942066622127, 0.27842469163437444, 0.25276843738036353] (n=22)
output> saving performance to:
/Users/pleiades/Documents/work/tpheno/seqmaker/data/CKD/plot/model_evalation-ep200b16.tif


model_selection> trying {'n_units': 300, 'dropout_rate': 0.2} ...

make_lstm> n_units=300, r_dropout=0.200000, n_layers=1, n_classes=6
  + lookup:
{'Others': 5, 'CKD Stage 5': 4, 'CKD Stage 4': 3, 'CKD Stage 3': 2, 'CKD Stage 2': 1, 'CKD Stage 1': 0}

... class weights:
{0: 6.344086021505376, 1: 0.74494949494949492, 2: 1.1238095238095238, 3: 7.0238095238095237, 4: 0.51890941072999119, 5: 0.64906490649064907}

====================================================================================================
... early stopping>
       + patience: 20, model='max'
... model training>
       + batch_size: 32, epochs: 60, shuffle? True, metric: auc_roc
====================================================================================================
Train on 1652 samples, validate on 708 samples
Epoch 1/60
1652/1652 [==============================] - 7s 4ms/step - loss: 1.6736 - acc: 0.2912 - auc_roc: 0.5741 - val_loss: 1.5850 - val_acc: 0.5763 - val_auc_roc: 0.6945
Epoch 2/60
1652/1652 [==============================] - 6s 4ms/step - loss: 1.3527 - acc: 0.4631 - auc_roc: 0.7350 - val_loss: 2.0138 - val_acc: 0.2458 - val_auc_roc: 0.7239
Epoch 3/60
1652/1652 [==============================] - 7s 4ms/step - loss: 1.2987 - acc: 0.4316 - auc_roc: 0.7172 - val_loss: 1.6524 - val_acc: 0.2966 - val_auc_roc: 0.7244
Epoch 4/60
1652/1652 [==============================] - 6s 4ms/step - loss: 1.1458 - acc: 0.5000 - auc_roc: 0.7366 - val_loss: 1.4620 - val_acc: 0.5918 - val_auc_roc: 0.7538
Epoch 5/60
1652/1652 [==============================] - 7s 4ms/step - loss: 1.0332 - acc: 0.5448 - auc_roc: 0.7682 - val_loss: 1.7593 - val_acc: 0.5085 - val_auc_roc: 0.7780
Epoch 6/60
1652/1652 [==============================] - 6s 4ms/step - loss: 0.9740 - acc: 0.5684 - auc_roc: 0.7861 - val_loss: 1.8467 - val_acc: 0.3658 - val_auc_roc: 0.7894
Epoch 7/60
1652/1652 [==============================] - 6s 4ms/step - loss: 0.9280 - acc: 0.5654 - auc_roc: 0.7931 - val_loss: 1.8105 - val_acc: 0.4915 - val_auc_roc: 0.7979
Epoch 8/60
1652/1652 [==============================] - 7s 4ms/step - loss: 0.8513 - acc: 0.6108 - auc_roc: 0.8037 - val_loss: 1.7867 - val_acc: 0.5819 - val_auc_roc: 0.8105
Epoch 9/60
1652/1652 [==============================] - 6s 4ms/step - loss: 0.8210 - acc: 0.6471 - auc_roc: 0.8162 - val_loss: 1.6042 - val_acc: 0.6709 - val_auc_roc: 0.8228
Epoch 10/60
1652/1652 [==============================] - 6s 4ms/step - loss: 0.6976 - acc: 0.6653 - auc_roc: 0.8286 - val_loss: 1.7877 - val_acc: 0.6780 - val_auc_roc: 0.8348
Epoch 11/60
1652/1652 [==============================] - 6s 4ms/step - loss: 0.7050 - acc: 0.6634 - auc_roc: 0.8392 - val_loss: 1.6852 - val_acc: 0.5946 - val_auc_roc: 0.8438
Epoch 12/60
1652/1652 [==============================] - 6s 4ms/step - loss: 0.6421 - acc: 0.6913 - auc_roc: 0.8472 - val_loss: 2.1127 - val_acc: 0.5452 - val_auc_roc: 0.8505
Epoch 13/60
1652/1652 [==============================] - 6s 4ms/step - loss: 0.6999 - acc: 0.6774 - auc_roc: 0.8522 - val_loss: 1.8793 - val_acc: 0.5099 - val_auc_roc: 0.8544
Epoch 14/60
1652/1652 [==============================] - 6s 4ms/step - loss: 0.5771 - acc: 0.7288 - auc_roc: 0.8568 - val_loss: 1.9376 - val_acc: 0.6766 - val_auc_roc: 0.8605
Epoch 15/60
1652/1652 [==============================] - 6s 4ms/step - loss: 0.6152 - acc: 0.7167 - auc_roc: 0.8633 - val_loss: 1.8519 - val_acc: 0.6667 - val_auc_roc: 0.8664
Epoch 16/60
1652/1652 [==============================] - 6s 4ms/step - loss: 0.5596 - acc: 0.7228 - auc_roc: 0.8689 - val_loss: 1.9820 - val_acc: 0.4901 - val_auc_roc: 0.8705
Epoch 17/60
1652/1652 [==============================] - 6s 4ms/step - loss: 0.4290 - acc: 0.7851 - auc_roc: 0.8723 - val_loss: 2.2959 - val_acc: 0.7048 - val_auc_roc: 0.8756
Epoch 18/60
1652/1652 [==============================] - 6s 4ms/step - loss: 0.3566 - acc: 0.8142 - auc_roc: 0.8785 - val_loss: 2.2717 - val_acc: 0.7048 - val_auc_roc: 0.8817
Epoch 19/60
1652/1652 [==============================] - 6s 4ms/step - loss: 0.3019 - acc: 0.8620 - auc_roc: 0.8845 - val_loss: 2.3682 - val_acc: 0.7006 - val_auc_roc: 0.8875
Epoch 20/60
1652/1652 [==============================] - 6s 4ms/step - loss: 0.2898 - acc: 0.8795 - auc_roc: 0.8900 - val_loss: 2.7177 - val_acc: 0.5819 - val_auc_roc: 0.8921
Epoch 21/60
1652/1652 [==============================] - 7s 4ms/step - loss: 0.3044 - acc: 0.8668 - auc_roc: 0.8938 - val_loss: 2.0672 - val_acc: 0.6949 - val_auc_roc: 0.8962
Epoch 22/60
1652/1652 [==============================] - 6s 4ms/step - loss: 0.2385 - acc: 0.8898 - auc_roc: 0.8983 - val_loss: 1.9806 - val_acc: 0.6794 - val_auc_roc: 0.9007
Epoch 23/60
1652/1652 [==============================] - 6s 4ms/step - loss: 0.2188 - acc: 0.9044 - auc_roc: 0.9025 - val_loss: 2.3261 - val_acc: 0.6977 - val_auc_roc: 0.9047
Epoch 24/60
1652/1652 [==============================] - 6s 4ms/step - loss: 0.1605 - acc: 0.9304 - auc_roc: 0.9065 - val_loss: 2.7075 - val_acc: 0.6907 - val_auc_roc: 0.9086
Epoch 00024: early stopping
... history of metrics comprising: ['acc', 'loss', 'val_auc_roc', 'auc_roc', 'val_acc', 'val_loss']
... ... metric (acc): [0.71670702208040993, 0.7227602904125795, 0.78510895912641476, 0.81416464862176929, 0.8619854722992849, 0.87953995128520757, 0.86682808731139138, 0.8898305081859339, 0.90435835379953822, 0.9303874090566473] (n=24)
output> saving performance to:
/Users/pleiades/Documents/work/tpheno/seqmaker/data/CKD/plot/model_evalation-ep200b16.tif

... ... metric (loss): [0.61517285203818262, 0.55955127956792172, 0.42901165166432287, 0.35659021600972651, 0.30194050593179883, 0.28981121393150627, 0.30436470166534257, 0.23848418620827699, 0.21877292116098196, 0.16047124766697318] (n=24)
output> saving performance to:
/Users/pleiades/Documents/work/tpheno/seqmaker/data/CKD/plot/model_evalation-ep200b16.tif


model_selection> trying {'n_units': 400, 'dropout_rate': 0.2} ...

make_lstm> n_units=400, r_dropout=0.200000, n_layers=1, n_classes=6
  + lookup:
{'Others': 5, 'CKD Stage 5': 4, 'CKD Stage 4': 3, 'CKD Stage 3': 2, 'CKD Stage 2': 1, 'CKD Stage 1': 0}

... class weights:
{0: 6.344086021505376, 1: 0.74494949494949492, 2: 1.1238095238095238, 3: 7.0238095238095237, 4: 0.51890941072999119, 5: 0.64906490649064907}

====================================================================================================
... early stopping>
       + patience: 20, model='max'
... model training>
       + batch_size: 32, epochs: 60, shuffle? True, metric: auc_roc
====================================================================================================
Train on 1652 samples, validate on 708 samples
Epoch 1/60
1652/1652 [==============================] - 10s 6ms/step - loss: 1.5922 - acc: 0.3565 - auc_roc: 0.6431 - val_loss: 1.5435 - val_acc: 0.5466 - val_auc_roc: 0.7404
Epoch 2/60
1652/1652 [==============================] - 9s 6ms/step - loss: 1.3391 - acc: 0.4546 - auc_roc: 0.7679 - val_loss: 1.3340 - val_acc: 0.5777 - val_auc_roc: 0.7862
Epoch 3/60
1652/1652 [==============================] - 10s 6ms/step - loss: 1.3890 - acc: 0.4146 - auc_roc: 0.7959 - val_loss: 1.6659 - val_acc: 0.2797 - val_auc_roc: 0.7811
Epoch 4/60
1652/1652 [==============================] - 9s 6ms/step - loss: 1.2826 - acc: 0.4219 - auc_roc: 0.7758 - val_loss: 1.8651 - val_acc: 0.3291 - val_auc_roc: 0.7730
Epoch 5/60
1652/1652 [==============================] - 9s 6ms/step - loss: 1.1898 - acc: 0.4824 - auc_roc: 0.7731 - val_loss: 1.8387 - val_acc: 0.5014 - val_auc_roc: 0.7768
Epoch 6/60
1652/1652 [==============================] - 9s 6ms/step - loss: 1.0532 - acc: 0.5563 - auc_roc: 0.7827 - val_loss: 1.6927 - val_acc: 0.5042 - val_auc_roc: 0.7893
Epoch 7/60
1652/1652 [==============================] - 9s 6ms/step - loss: 0.9594 - acc: 0.5702 - auc_roc: 0.7949 - val_loss: 1.5802 - val_acc: 0.6554 - val_auc_roc: 0.8030
Epoch 8/60
1652/1652 [==============================] - 10s 6ms/step - loss: 0.9275 - acc: 0.5884 - auc_roc: 0.8098 - val_loss: 2.1255 - val_acc: 0.4266 - val_auc_roc: 0.8122
Epoch 9/60
1652/1652 [==============================] - 10s 6ms/step - loss: 0.8911 - acc: 0.6053 - auc_roc: 0.8147 - val_loss: 1.7472 - val_acc: 0.6356 - val_auc_roc: 0.8202
Epoch 10/60
1652/1652 [==============================] - 10s 6ms/step - loss: 0.8069 - acc: 0.6199 - auc_roc: 0.8247 - val_loss: 1.6367 - val_acc: 0.6723 - val_auc_roc: 0.8301
Epoch 11/60
1652/1652 [==============================] - 10s 6ms/step - loss: 0.7201 - acc: 0.6598 - auc_roc: 0.8351 - val_loss: 1.7808 - val_acc: 0.6653 - val_auc_roc: 0.8399
Epoch 12/60
1652/1652 [==============================] - 10s 6ms/step - loss: 0.6827 - acc: 0.6677 - auc_roc: 0.8437 - val_loss: 1.8801 - val_acc: 0.6879 - val_auc_roc: 0.8480
Epoch 13/60
1652/1652 [==============================] - 10s 6ms/step - loss: 0.6259 - acc: 0.6931 - auc_roc: 0.8520 - val_loss: 1.9256 - val_acc: 0.6031 - val_auc_roc: 0.8552
Epoch 14/60
1652/1652 [==============================] - 9s 6ms/step - loss: 0.6078 - acc: 0.7100 - auc_roc: 0.8580 - val_loss: 2.4465 - val_acc: 0.4223 - val_auc_roc: 0.8594
Epoch 15/60
1652/1652 [==============================] - 10s 6ms/step - loss: 0.5988 - acc: 0.6961 - auc_roc: 0.8604 - val_loss: 2.1830 - val_acc: 0.5975 - val_auc_roc: 0.8630
Epoch 16/60
1652/1652 [==============================] - 10s 6ms/step - loss: 0.5639 - acc: 0.7179 - auc_roc: 0.8653 - val_loss: 2.1125 - val_acc: 0.6751 - val_auc_roc: 0.8682
Epoch 17/60
1652/1652 [==============================] - 10s 6ms/step - loss: 0.6105 - acc: 0.7318 - auc_roc: 0.8704 - val_loss: 2.0496 - val_acc: 0.6667 - val_auc_roc: 0.8728
Epoch 18/60
1652/1652 [==============================] - 10s 6ms/step - loss: 0.7059 - acc: 0.7167 - auc_roc: 0.8742 - val_loss: 1.7885 - val_acc: 0.6963 - val_auc_roc: 0.8763
Epoch 19/60
1652/1652 [==============================] - 11s 7ms/step - loss: 0.5061 - acc: 0.7615 - auc_roc: 0.8785 - val_loss: 2.5231 - val_acc: 0.4025 - val_auc_roc: 0.8797
Epoch 20/60
1652/1652 [==============================] - 10s 6ms/step - loss: 0.4845 - acc: 0.7785 - auc_roc: 0.8805 - val_loss: 2.3443 - val_acc: 0.7105 - val_auc_roc: 0.8828
Epoch 21/60
1652/1652 [==============================] - 10s 6ms/step - loss: 0.3583 - acc: 0.8263 - auc_roc: 0.8851 - val_loss: 2.2676 - val_acc: 0.7105 - val_auc_roc: 0.8877
Epoch 22/60
1652/1652 [==============================] - 10s 6ms/step - loss: 0.3048 - acc: 0.8517 - auc_roc: 0.8899 - val_loss: 2.4071 - val_acc: 0.6850 - val_auc_roc: 0.8923
Epoch 00022: early stopping
... history of metrics comprising: ['acc', 'loss', 'val_auc_roc', 'auc_roc', 'val_acc', 'val_loss']
... ... metric (acc): [0.69309927346342703, 0.71004842586147876, 0.6961259078459936, 0.71791767583343657, 0.73184019370460052, 0.71670702208040993, 0.76150121050943187, 0.77845036348476826, 0.8262711865849991, 0.85169491539855846] (n=22)
output> saving performance to:
/Users/pleiades/Documents/work/tpheno/seqmaker/data/CKD/plot/model_evalation-ep200b16.tif

... ... metric (loss): [0.62588060190833505, 0.60776548033476452, 0.5987942487217901, 0.56394230244234744, 0.61045660825387615, 0.70587743151274485, 0.50610817921940987, 0.48447692726195291, 0.35834932320054447, 0.30475732532598204] (n=22)
output> saving performance to:
/Users/pleiades/Documents/work/tpheno/seqmaker/data/CKD/plot/model_evalation-ep200b16.tif


model_selection> trying {'n_units': 500, 'dropout_rate': 0.2} ...

make_lstm> n_units=500, r_dropout=0.200000, n_layers=1, n_classes=6
  + lookup:
{'Others': 5, 'CKD Stage 5': 4, 'CKD Stage 4': 3, 'CKD Stage 3': 2, 'CKD Stage 2': 1, 'CKD Stage 1': 0}

... class weights:
{0: 6.344086021505376, 1: 0.74494949494949492, 2: 1.1238095238095238, 3: 7.0238095238095237, 4: 0.51890941072999119, 5: 0.64906490649064907}

====================================================================================================
... early stopping>
       + patience: 20, model='max'
... model training>
       + batch_size: 32, epochs: 60, shuffle? True, metric: auc_roc
====================================================================================================
Train on 1652 samples, validate on 708 samples
Epoch 1/60
1652/1652 [==============================] - 15s 9ms/step - loss: 1.6099 - acc: 0.3354 - auc_roc: 0.6958 - val_loss: 1.6314 - val_acc: 0.5099 - val_auc_roc: 0.7544
Epoch 2/60
1652/1652 [==============================] - 15s 9ms/step - loss: 1.4246 - acc: 0.4346 - auc_roc: 0.7635 - val_loss: 1.5656 - val_acc: 0.5862 - val_auc_roc: 0.7779
Epoch 3/60
1652/1652 [==============================] - 15s 9ms/step - loss: 1.2856 - acc: 0.4728 - auc_roc: 0.7892 - val_loss: 1.3990 - val_acc: 0.6144 - val_auc_roc: 0.7986
Epoch 4/60
1652/1652 [==============================] - 14s 9ms/step - loss: 1.1766 - acc: 0.5018 - auc_roc: 0.8050 - val_loss: 1.6010 - val_acc: 0.6441 - val_auc_roc: 0.8134
Epoch 5/60
1652/1652 [==============================] - 16s 9ms/step - loss: 1.1871 - acc: 0.4631 - auc_roc: 0.8164 - val_loss: 2.0959 - val_acc: 0.1808 - val_auc_roc: 0.8090
Epoch 6/60
1652/1652 [==============================] - 16s 10ms/step - loss: 1.1280 - acc: 0.5182 - auc_roc: 0.8041 - val_loss: 1.9126 - val_acc: 0.4915 - val_auc_roc: 0.8077
Epoch 7/60
1652/1652 [==============================] - 16s 9ms/step - loss: 0.9723 - acc: 0.5581 - auc_roc: 0.8114 - val_loss: 1.6348 - val_acc: 0.6554 - val_auc_roc: 0.8177
Epoch 8/60
1652/1652 [==============================] - 16s 10ms/step - loss: 0.8675 - acc: 0.6041 - auc_roc: 0.8233 - val_loss: 2.0929 - val_acc: 0.4153 - val_auc_roc: 0.8256
Epoch 9/60
1652/1652 [==============================] - 16s 10ms/step - loss: 0.7870 - acc: 0.6277 - auc_roc: 0.8278 - val_loss: 2.2083 - val_acc: 0.6554 - val_auc_roc: 0.8332
Epoch 10/60
1652/1652 [==============================] - 14s 9ms/step - loss: 0.7478 - acc: 0.6235 - auc_roc: 0.8375 - val_loss: 1.6631 - val_acc: 0.6511 - val_auc_roc: 0.8421
Epoch 11/60
1652/1652 [==============================] - 15s 9ms/step - loss: 0.6912 - acc: 0.6749 - auc_roc: 0.8463 - val_loss: 1.7495 - val_acc: 0.6582 - val_auc_roc: 0.8510
Epoch 12/60
1652/1652 [==============================] - 16s 10ms/step - loss: 0.6571 - acc: 0.6816 - auc_roc: 0.8544 - val_loss: 1.8315 - val_acc: 0.6497 - val_auc_roc: 0.8579
Epoch 13/60
1652/1652 [==============================] - 15s 9ms/step - loss: 0.5906 - acc: 0.7191 - auc_roc: 0.8613 - val_loss: 1.9700 - val_acc: 0.6935 - val_auc_roc: 0.8651
Epoch 14/60
1652/1652 [==============================] - 16s 9ms/step - loss: 0.5186 - acc: 0.7421 - auc_roc: 0.8685 - val_loss: 2.0733 - val_acc: 0.6596 - val_auc_roc: 0.8720
Epoch 15/60
1652/1652 [==============================] - 15s 9ms/step - loss: 0.4539 - acc: 0.7875 - auc_roc: 0.8749 - val_loss: 2.3773 - val_acc: 0.7020 - val_auc_roc: 0.8786
Epoch 16/60
1652/1652 [==============================] - 15s 9ms/step - loss: 0.4020 - acc: 0.8130 - auc_roc: 0.8817 - val_loss: 2.8028 - val_acc: 0.5212 - val_auc_roc: 0.8835
Epoch 17/60
1652/1652 [==============================] - 15s 9ms/step - loss: 0.6856 - acc: 0.7161 - auc_roc: 0.8838 - val_loss: 1.8322 - val_acc: 0.6638 - val_auc_roc: 0.8855
Epoch 18/60
1652/1652 [==============================] - 16s 9ms/step - loss: 0.4428 - acc: 0.7906 - auc_roc: 0.8876 - val_loss: 2.1811 - val_acc: 0.6992 - val_auc_roc: 0.8901
Epoch 19/60
1652/1652 [==============================] - 15s 9ms/step - loss: 0.3451 - acc: 0.8450 - auc_roc: 0.8926 - val_loss: 2.3316 - val_acc: 0.6116 - val_auc_roc: 0.8948
Epoch 20/60
1652/1652 [==============================] - 15s 9ms/step - loss: 0.2809 - acc: 0.8644 - auc_roc: 0.8967 - val_loss: 2.3137 - val_acc: 0.7189 - val_auc_roc: 0.8993
Epoch 21/60
1652/1652 [==============================] - 14s 9ms/step - loss: 0.2098 - acc: 0.9062 - auc_roc: 0.9016 - val_loss: 2.7101 - val_acc: 0.6893 - val_auc_roc: 0.9041
Epoch 22/60
1652/1652 [==============================] - 14s 9ms/step - loss: 0.1887 - acc: 0.9153 - auc_roc: 0.9061 - val_loss: 2.6987 - val_acc: 0.6977 - val_auc_roc: 0.9084
Epoch 23/60
1652/1652 [==============================] - 14s 9ms/step - loss: 0.2324 - acc: 0.9195 - auc_roc: 0.9102 - val_loss: 2.4724 - val_acc: 0.6836 - val_auc_roc: 0.9121
Epoch 00023: early stopping
... history of metrics comprising: ['acc', 'loss', 'val_auc_roc', 'auc_roc', 'val_acc', 'val_loss']
... ... metric (acc): [0.74213075031668452, 0.78753026663246806, 0.81295399515738498, 0.71610169477093311, 0.79055690072639229, 0.84503631946826963, 0.86440677951669576, 0.90617433399611469, 0.91525423699949326, 0.91949152527940758] (n=23)
output> saving performance to:
/Users/pleiades/Documents/work/tpheno/seqmaker/data/CKD/plot/model_evalation-ep200b16.tif

... ... metric (loss): [0.5186039347914172, 0.45388489355475214, 0.40197286940660082, 0.68561878244755636, 0.44275394089285458, 0.34507219273299339, 0.28094787235410101, 0.2097802983357889, 0.18868544697761536, 0.23242710786927986] (n=23)
output> saving performance to:
/Users/pleiades/Documents/work/tpheno/seqmaker/data/CKD/plot/model_evalation-ep200b16.tif


model_selection> trying {'n_units': 50, 'dropout_rate': 0.3} ...

make_lstm> n_units=50, r_dropout=0.300000, n_layers=1, n_classes=6
  + lookup:
{'Others': 5, 'CKD Stage 5': 4, 'CKD Stage 4': 3, 'CKD Stage 3': 2, 'CKD Stage 2': 1, 'CKD Stage 1': 0}

... class weights:
{0: 6.344086021505376, 1: 0.74494949494949492, 2: 1.1238095238095238, 3: 7.0238095238095237, 4: 0.51890941072999119, 5: 0.64906490649064907}

====================================================================================================
... early stopping>
       + patience: 20, model='max'
... model training>
       + batch_size: 32, epochs: 60, shuffle? True, metric: auc_roc
====================================================================================================
Train on 1652 samples, validate on 708 samples
Epoch 1/60
1652/1652 [==============================] - 4s 3ms/step - loss: 1.7352 - acc: 0.2246 - auc_roc: 0.6186 - val_loss: 1.9807 - val_acc: 0.1257 - val_auc_roc: 0.5902
Epoch 2/60
1652/1652 [==============================] - 3s 2ms/step - loss: 1.5706 - acc: 0.3638 - auc_roc: 0.6134 - val_loss: 1.7498 - val_acc: 0.5381 - val_auc_roc: 0.6633
Epoch 3/60
1652/1652 [==============================] - 3s 2ms/step - loss: 1.3827 - acc: 0.4340 - auc_roc: 0.6941 - val_loss: 1.6382 - val_acc: 0.5890 - val_auc_roc: 0.7204
Epoch 4/60
1652/1652 [==============================] - 3s 2ms/step - loss: 1.2795 - acc: 0.4824 - auc_roc: 0.7384 - val_loss: 1.4416 - val_acc: 0.6977 - val_auc_roc: 0.7570
Epoch 5/60
1652/1652 [==============================] - 3s 2ms/step - loss: 1.1742 - acc: 0.4879 - auc_roc: 0.7699 - val_loss: 1.5130 - val_acc: 0.5706 - val_auc_roc: 0.7780
Epoch 6/60
1652/1652 [==============================] - 3s 2ms/step - loss: 1.1030 - acc: 0.5272 - auc_roc: 0.7857 - val_loss: 1.4404 - val_acc: 0.6638 - val_auc_roc: 0.7938
Epoch 7/60
1652/1652 [==============================] - 3s 2ms/step - loss: 1.0514 - acc: 0.5418 - auc_roc: 0.8012 - val_loss: 1.4904 - val_acc: 0.6469 - val_auc_roc: 0.8072
Epoch 8/60
1652/1652 [==============================] - 3s 2ms/step - loss: 0.9732 - acc: 0.5623 - auc_roc: 0.8130 - val_loss: 1.6729 - val_acc: 0.7090 - val_auc_roc: 0.8192
Epoch 9/60
1652/1652 [==============================] - 3s 2ms/step - loss: 0.9121 - acc: 0.5944 - auc_roc: 0.8246 - val_loss: 1.5501 - val_acc: 0.6794 - val_auc_roc: 0.8295
Epoch 10/60
1652/1652 [==============================] - 3s 2ms/step - loss: 0.9100 - acc: 0.5811 - auc_roc: 0.8336 - val_loss: 1.4214 - val_acc: 0.5932 - val_auc_roc: 0.8363
Epoch 11/60
1652/1652 [==============================] - 3s 2ms/step - loss: 0.9539 - acc: 0.5642 - auc_roc: 0.8378 - val_loss: 1.7069 - val_acc: 0.6540 - val_auc_roc: 0.8396
Epoch 12/60
1652/1652 [==============================] - 3s 2ms/step - loss: 0.8801 - acc: 0.5835 - auc_roc: 0.8422 - val_loss: 1.7346 - val_acc: 0.6314 - val_auc_roc: 0.8439
Epoch 13/60
1652/1652 [==============================] - 3s 2ms/step - loss: 0.7838 - acc: 0.6326 - auc_roc: 0.8462 - val_loss: 1.8857 - val_acc: 0.7105 - val_auc_roc: 0.8495
Epoch 14/60
1652/1652 [==============================] - 3s 2ms/step - loss: 0.7748 - acc: 0.6186 - auc_roc: 0.8520 - val_loss: 1.7945 - val_acc: 0.6893 - val_auc_roc: 0.8547
Epoch 15/60
1652/1652 [==============================] - 3s 2ms/step - loss: 0.7555 - acc: 0.6344 - auc_roc: 0.8570 - val_loss: 1.8384 - val_acc: 0.6794 - val_auc_roc: 0.8591
Epoch 16/60
1652/1652 [==============================] - 3s 2ms/step - loss: 0.7503 - acc: 0.6229 - auc_roc: 0.8608 - val_loss: 1.9044 - val_acc: 0.6596 - val_auc_roc: 0.8624
Epoch 17/60
1652/1652 [==============================] - 3s 2ms/step - loss: 0.6904 - acc: 0.6762 - auc_roc: 0.8641 - val_loss: 2.0214 - val_acc: 0.7006 - val_auc_roc: 0.8664
Epoch 18/60
1652/1652 [==============================] - 3s 2ms/step - loss: 0.6722 - acc: 0.6586 - auc_roc: 0.8681 - val_loss: 2.1884 - val_acc: 0.6822 - val_auc_roc: 0.8699
Epoch 19/60
1652/1652 [==============================] - 3s 2ms/step - loss: 0.7400 - acc: 0.6671 - auc_roc: 0.8713 - val_loss: 1.6220 - val_acc: 0.7599 - val_auc_roc: 0.8729
Epoch 20/60
1652/1652 [==============================] - 3s 2ms/step - loss: 1.1124 - acc: 0.4982 - auc_roc: 0.8722 - val_loss: 1.7689 - val_acc: 0.4605 - val_auc_roc: 0.8708
Epoch 21/60
1652/1652 [==============================] - 3s 2ms/step - loss: 0.8283 - acc: 0.5926 - auc_roc: 0.8704 - val_loss: 1.9026 - val_acc: 0.5890 - val_auc_roc: 0.8705
Epoch 22/60
1652/1652 [==============================] - 3s 2ms/step - loss: 0.7125 - acc: 0.6441 - auc_roc: 0.8710 - val_loss: 1.8054 - val_acc: 0.6667 - val_auc_roc: 0.8721
Epoch 23/60
1652/1652 [==============================] - 3s 2ms/step - loss: 0.6619 - acc: 0.6810 - auc_roc: 0.8730 - val_loss: 2.0998 - val_acc: 0.6737 - val_auc_roc: 0.8741
Epoch 24/60
1652/1652 [==============================] - 3s 2ms/step - loss: 0.6439 - acc: 0.6749 - auc_roc: 0.8750 - val_loss: 2.1087 - val_acc: 0.7090 - val_auc_roc: 0.8762
Epoch 25/60
1652/1652 [==============================] - 3s 2ms/step - loss: 0.6102 - acc: 0.6889 - auc_roc: 0.8772 - val_loss: 1.9940 - val_acc: 0.6963 - val_auc_roc: 0.8785
Epoch 26/60
1652/1652 [==============================] - 4s 2ms/step - loss: 0.6121 - acc: 0.7010 - auc_roc: 0.8795 - val_loss: 1.9064 - val_acc: 0.7034 - val_auc_roc: 0.8807
Epoch 27/60
1652/1652 [==============================] - 3s 2ms/step - loss: 0.5755 - acc: 0.7149 - auc_roc: 0.8817 - val_loss: 2.2887 - val_acc: 0.6271 - val_auc_roc: 0.8825
Epoch 28/60
1652/1652 [==============================] - 3s 2ms/step - loss: 0.5556 - acc: 0.7209 - auc_roc: 0.8832 - val_loss: 2.2922 - val_acc: 0.7189 - val_auc_roc: 0.8844
Epoch 29/60
1652/1652 [==============================] - 3s 2ms/step - loss: 0.5232 - acc: 0.7331 - auc_roc: 0.8854 - val_loss: 2.2756 - val_acc: 0.7090 - val_auc_roc: 0.8866
Epoch 30/60
1652/1652 [==============================] - 3s 2ms/step - loss: 0.5067 - acc: 0.7506 - auc_roc: 0.8876 - val_loss: 2.3241 - val_acc: 0.7161 - val_auc_roc: 0.8887
Epoch 00030: early stopping
... history of metrics comprising: ['acc', 'loss', 'val_auc_roc', 'auc_roc', 'val_acc', 'val_loss']
... ... metric (acc): [0.59261501239517989, 0.64406779646584833, 0.68099273622180301, 0.67493946760099099, 0.68886198547215494, 0.70096852329106363, 0.71489104130654879, 0.7209443099273608, 0.73305084745762716, 0.75060532687651327] (n=30)
output> saving performance to:
/Users/pleiades/Documents/work/tpheno/seqmaker/data/CKD/plot/model_evalation-ep200b16.tif

... ... metric (loss): [0.82829186731620219, 0.71246264907407419, 0.66193116043150857, 0.64394382169113895, 0.61022160416942528, 0.61209087524806616, 0.57552801429792411, 0.55562653336628876, 0.52319549273059096, 0.50671999867256845] (n=30)
output> saving performance to:
/Users/pleiades/Documents/work/tpheno/seqmaker/data/CKD/plot/model_evalation-ep200b16.tif


model_selection> trying {'n_units': 100, 'dropout_rate': 0.3} ...

make_lstm> n_units=100, r_dropout=0.300000, n_layers=1, n_classes=6
  + lookup:
{'Others': 5, 'CKD Stage 5': 4, 'CKD Stage 4': 3, 'CKD Stage 3': 2, 'CKD Stage 2': 1, 'CKD Stage 1': 0}

... class weights:
{0: 6.344086021505376, 1: 0.74494949494949492, 2: 1.1238095238095238, 3: 7.0238095238095237, 4: 0.51890941072999119, 5: 0.64906490649064907}

====================================================================================================
... early stopping>
       + patience: 20, model='max'
... model training>
       + batch_size: 32, epochs: 60, shuffle? True, metric: auc_roc
====================================================================================================
Train on 1652 samples, validate on 708 samples
Epoch 1/60
1652/1652 [==============================] - 4s 3ms/step - loss: 1.7056 - acc: 0.2161 - auc_roc: 0.5421 - val_loss: 1.8678 - val_acc: 0.3446 - val_auc_roc: 0.6253
Epoch 2/60
1652/1652 [==============================] - 3s 2ms/step - loss: 1.5051 - acc: 0.3965 - auc_roc: 0.6637 - val_loss: 1.7871 - val_acc: 0.4336 - val_auc_roc: 0.6915
Epoch 3/60
1652/1652 [==============================] - 3s 2ms/step - loss: 1.3321 - acc: 0.4582 - auc_roc: 0.7086 - val_loss: 1.5778 - val_acc: 0.7274 - val_auc_roc: 0.7396
Epoch 4/60
1652/1652 [==============================] - 3s 2ms/step - loss: 1.2198 - acc: 0.5000 - auc_roc: 0.7603 - val_loss: 1.5506 - val_acc: 0.6907 - val_auc_roc: 0.7757
Epoch 5/60
1652/1652 [==============================] - 4s 2ms/step - loss: 1.1466 - acc: 0.5061 - auc_roc: 0.7866 - val_loss: 1.4513 - val_acc: 0.6356 - val_auc_roc: 0.7945
Epoch 6/60
1652/1652 [==============================] - 3s 2ms/step - loss: 1.0421 - acc: 0.5533 - auc_roc: 0.8021 - val_loss: 1.5138 - val_acc: 0.6992 - val_auc_roc: 0.8105
Epoch 7/60
1652/1652 [==============================] - 3s 2ms/step - loss: 1.0014 - acc: 0.5515 - auc_roc: 0.8166 - val_loss: 1.6419 - val_acc: 0.6483 - val_auc_roc: 0.8214
Epoch 8/60
1652/1652 [==============================] - 3s 2ms/step - loss: 0.9052 - acc: 0.5884 - auc_roc: 0.8255 - val_loss: 1.6903 - val_acc: 0.6949 - val_auc_roc: 0.8311
Epoch 9/60
1652/1652 [==============================] - 3s 2ms/step - loss: 0.8476 - acc: 0.6108 - auc_roc: 0.8360 - val_loss: 1.4992 - val_acc: 0.7048 - val_auc_roc: 0.8408
Epoch 10/60
1652/1652 [==============================] - 3s 2ms/step - loss: 0.8337 - acc: 0.5938 - auc_roc: 0.8447 - val_loss: 1.7837 - val_acc: 0.6695 - val_auc_roc: 0.8478
Epoch 11/60
1652/1652 [==============================] - 3s 2ms/step - loss: 0.7596 - acc: 0.6459 - auc_roc: 0.8511 - val_loss: 1.7636 - val_acc: 0.7048 - val_auc_roc: 0.8548
Epoch 12/60
1652/1652 [==============================] - 3s 2ms/step - loss: 0.7180 - acc: 0.6501 - auc_roc: 0.8577 - val_loss: 2.0799 - val_acc: 0.6243 - val_auc_roc: 0.8602
Epoch 13/60
1652/1652 [==============================] - 3s 2ms/step - loss: 0.7816 - acc: 0.6374 - auc_roc: 0.8620 - val_loss: 1.9907 - val_acc: 0.6130 - val_auc_roc: 0.8634
Epoch 14/60
1652/1652 [==============================] - 3s 2ms/step - loss: 0.7243 - acc: 0.6507 - auc_roc: 0.8648 - val_loss: 1.8626 - val_acc: 0.7189 - val_auc_roc: 0.8676
Epoch 15/60
1652/1652 [==============================] - 3s 2ms/step - loss: 0.6283 - acc: 0.6967 - auc_roc: 0.8700 - val_loss: 2.1020 - val_acc: 0.6667 - val_auc_roc: 0.8723
Epoch 16/60
1652/1652 [==============================] - 3s 2ms/step - loss: 0.5711 - acc: 0.7137 - auc_roc: 0.8744 - val_loss: 2.0951 - val_acc: 0.6935 - val_auc_roc: 0.8768
Epoch 17/60
1652/1652 [==============================] - 3s 2ms/step - loss: 0.5334 - acc: 0.7318 - auc_roc: 0.8790 - val_loss: 2.0352 - val_acc: 0.7218 - val_auc_roc: 0.8814
Epoch 18/60
1652/1652 [==============================] - 3s 2ms/step - loss: 0.4779 - acc: 0.7609 - auc_roc: 0.8836 - val_loss: 2.3064 - val_acc: 0.7006 - val_auc_roc: 0.8859
Epoch 19/60
1652/1652 [==============================] - 3s 2ms/step - loss: 0.4841 - acc: 0.7700 - auc_roc: 0.8876 - val_loss: 2.2909 - val_acc: 0.7260 - val_auc_roc: 0.8898
Epoch 20/60
1652/1652 [==============================] - 3s 2ms/step - loss: 0.4179 - acc: 0.8021 - auc_roc: 0.8917 - val_loss: 2.4257 - val_acc: 0.7175 - val_auc_roc: 0.8938
Epoch 21/60
1652/1652 [==============================] - 3s 2ms/step - loss: 0.4839 - acc: 0.7591 - auc_roc: 0.8952 - val_loss: 2.4199 - val_acc: 0.6695 - val_auc_roc: 0.8965
Epoch 22/60
1652/1652 [==============================] - 4s 2ms/step - loss: 0.4351 - acc: 0.7984 - auc_roc: 0.8980 - val_loss: 2.1293 - val_acc: 0.5763 - val_auc_roc: 0.8993
Epoch 23/60
1652/1652 [==============================] - 3s 2ms/step - loss: 0.4331 - acc: 0.7924 - auc_roc: 0.9002 - val_loss: 2.1946 - val_acc: 0.6582 - val_auc_roc: 0.9016
Epoch 24/60
1652/1652 [==============================] - 3s 2ms/step - loss: 0.3429 - acc: 0.8335 - auc_roc: 0.9030 - val_loss: 2.2698 - val_acc: 0.7006 - val_auc_roc: 0.9046
Epoch 25/60
1652/1652 [==============================] - 3s 2ms/step - loss: 0.3138 - acc: 0.8590 - auc_roc: 0.9059 - val_loss: 2.3599 - val_acc: 0.6935 - val_auc_roc: 0.9075
Epoch 00025: early stopping
... history of metrics comprising: ['acc', 'loss', 'val_auc_roc', 'auc_roc', 'val_acc', 'val_loss']
... ... metric (acc): [0.71368038769784337, 0.7318401935602793, 0.76089588377723971, 0.76997578678061829, 0.80205811138014527, 0.7590799031476998, 0.79842614983242299, 0.79237288121161098, 0.83353510867019542, 0.85895883777239712] (n=25)
output> saving performance to:
/Users/pleiades/Documents/work/tpheno/seqmaker/data/CKD/plot/model_evalation-ep200b16.tif

... ... metric (loss): [0.57113183771438225, 0.53339825314413258, 0.47792292961774091, 0.48413937598394713, 0.41788875955646321, 0.48394023325772317, 0.43505988845525007, 0.43312362074563349, 0.34285936632687475, 0.31382550519257424] (n=25)
output> saving performance to:
/Users/pleiades/Documents/work/tpheno/seqmaker/data/CKD/plot/model_evalation-ep200b16.tif


model_selection> trying {'n_units': 200, 'dropout_rate': 0.3} ...

make_lstm> n_units=200, r_dropout=0.300000, n_layers=1, n_classes=6
  + lookup:
{'Others': 5, 'CKD Stage 5': 4, 'CKD Stage 4': 3, 'CKD Stage 3': 2, 'CKD Stage 2': 1, 'CKD Stage 1': 0}

... class weights:
{0: 6.344086021505376, 1: 0.74494949494949492, 2: 1.1238095238095238, 3: 7.0238095238095237, 4: 0.51890941072999119, 5: 0.64906490649064907}

====================================================================================================
... early stopping>
       + patience: 20, model='max'
... model training>
       + batch_size: 32, epochs: 60, shuffle? True, metric: auc_roc
====================================================================================================
Train on 1652 samples, validate on 708 samples
Epoch 1/60
1652/1652 [==============================] - 5s 3ms/step - loss: 1.6466 - acc: 0.3238 - auc_roc: 0.6340 - val_loss: 1.5939 - val_acc: 0.6497 - val_auc_roc: 0.7332
Epoch 2/60
1652/1652 [==============================] - 4s 3ms/step - loss: 1.4092 - acc: 0.4661 - auc_roc: 0.7685 - val_loss: 1.5084 - val_acc: 0.5692 - val_auc_roc: 0.7850
Epoch 3/60
1652/1652 [==============================] - 4s 3ms/step - loss: 1.2215 - acc: 0.5194 - auc_roc: 0.7987 - val_loss: 1.5708 - val_acc: 0.6158 - val_auc_roc: 0.8078
Epoch 4/60
1652/1652 [==============================] - 4s 3ms/step - loss: 1.1916 - acc: 0.5381 - auc_roc: 0.8143 - val_loss: 1.3928 - val_acc: 0.6342 - val_auc_roc: 0.8205
Epoch 5/60
1652/1652 [==============================] - 4s 3ms/step - loss: 1.0776 - acc: 0.5266 - auc_roc: 0.8233 - val_loss: 1.5745 - val_acc: 0.6582 - val_auc_roc: 0.8297
Epoch 6/60
1652/1652 [==============================] - 4s 3ms/step - loss: 0.9956 - acc: 0.5539 - auc_roc: 0.8348 - val_loss: 1.7124 - val_acc: 0.5297 - val_auc_roc: 0.8358
Epoch 7/60
1652/1652 [==============================] - 4s 3ms/step - loss: 0.9945 - acc: 0.5726 - auc_roc: 0.8374 - val_loss: 1.4214 - val_acc: 0.6723 - val_auc_roc: 0.8419
Epoch 8/60
1652/1652 [==============================] - 4s 2ms/step - loss: 0.8423 - acc: 0.6150 - auc_roc: 0.8462 - val_loss: 1.7491 - val_acc: 0.5184 - val_auc_roc: 0.8484
Epoch 9/60
1652/1652 [==============================] - 4s 3ms/step - loss: 0.7992 - acc: 0.6253 - auc_roc: 0.8502 - val_loss: 1.7083 - val_acc: 0.6780 - val_auc_roc: 0.8543
Epoch 10/60
1652/1652 [==============================] - 4s 2ms/step - loss: 0.7294 - acc: 0.6477 - auc_roc: 0.8579 - val_loss: 1.8843 - val_acc: 0.7076 - val_auc_roc: 0.8619
Epoch 11/60
1652/1652 [==============================] - 4s 3ms/step - loss: 0.6863 - acc: 0.6689 - auc_roc: 0.8649 - val_loss: 1.9053 - val_acc: 0.6864 - val_auc_roc: 0.8681
Epoch 12/60
1652/1652 [==============================] - 4s 3ms/step - loss: 0.6425 - acc: 0.6737 - auc_roc: 0.8708 - val_loss: 1.9555 - val_acc: 0.7161 - val_auc_roc: 0.8738
Epoch 13/60
1652/1652 [==============================] - 4s 3ms/step - loss: 0.6231 - acc: 0.6907 - auc_roc: 0.8764 - val_loss: 1.9453 - val_acc: 0.6907 - val_auc_roc: 0.8790
Epoch 14/60
1652/1652 [==============================] - 4s 3ms/step - loss: 0.5409 - acc: 0.7228 - auc_roc: 0.8812 - val_loss: 2.1599 - val_acc: 0.7175 - val_auc_roc: 0.8840
Epoch 15/60
1652/1652 [==============================] - 5s 3ms/step - loss: 0.5248 - acc: 0.7288 - auc_roc: 0.8861 - val_loss: 1.8921 - val_acc: 0.7218 - val_auc_roc: 0.8885
Epoch 16/60
1652/1652 [==============================] - 4s 3ms/step - loss: 0.5236 - acc: 0.7458 - auc_roc: 0.8905 - val_loss: 2.1064 - val_acc: 0.7090 - val_auc_roc: 0.8924
Epoch 17/60
1652/1652 [==============================] - 4s 3ms/step - loss: 0.4718 - acc: 0.7833 - auc_roc: 0.8942 - val_loss: 2.1001 - val_acc: 0.7387 - val_auc_roc: 0.8965
Epoch 18/60
1652/1652 [==============================] - 4s 3ms/step - loss: 0.4405 - acc: 0.7990 - auc_roc: 0.8983 - val_loss: 2.2569 - val_acc: 0.7331 - val_auc_roc: 0.9006
Epoch 19/60
1652/1652 [==============================] - 4s 3ms/step - loss: 0.3560 - acc: 0.8251 - auc_roc: 0.9024 - val_loss: 2.5459 - val_acc: 0.6893 - val_auc_roc: 0.9044
Epoch 20/60
1652/1652 [==============================] - 5s 3ms/step - loss: 0.3547 - acc: 0.8378 - auc_roc: 0.9059 - val_loss: 2.3789 - val_acc: 0.6850 - val_auc_roc: 0.9077
Epoch 21/60
1652/1652 [==============================] - 4s 3ms/step - loss: 0.3310 - acc: 0.8529 - auc_roc: 0.9089 - val_loss: 2.3557 - val_acc: 0.6949 - val_auc_roc: 0.9107
Epoch 22/60
1652/1652 [==============================] - 5s 3ms/step - loss: 0.2632 - acc: 0.8771 - auc_roc: 0.9121 - val_loss: 2.7591 - val_acc: 0.6836 - val_auc_roc: 0.9137
Epoch 23/60
1652/1652 [==============================] - 5s 3ms/step - loss: 0.2390 - acc: 0.8971 - auc_roc: 0.9150 - val_loss: 2.7055 - val_acc: 0.7218 - val_auc_roc: 0.9167
Epoch 24/60
1652/1652 [==============================] - 4s 3ms/step - loss: 0.2019 - acc: 0.9122 - auc_roc: 0.9180 - val_loss: 2.4327 - val_acc: 0.7316 - val_auc_roc: 0.9197
Epoch 00024: early stopping
... history of metrics comprising: ['acc', 'loss', 'val_auc_roc', 'auc_roc', 'val_acc', 'val_loss']
... ... metric (acc): [0.72881355917771273, 0.7457627120087279, 0.78329297849687485, 0.7990314769975787, 0.82506053268765134, 0.8377723973830733, 0.85290556900726389, 0.87711864377915427, 0.89709443113705722, 0.9122276026169267] (n=24)
output> saving performance to:
/Users/pleiades/Documents/work/tpheno/seqmaker/data/CKD/plot/model_evalation-ep200b16.tif

... ... metric (loss): [0.52475638150014259, 0.52363669193974416, 0.4718370345256519, 0.44052730706355764, 0.35601972025474105, 0.35467095142703947, 0.33097377686465912, 0.2632080251599051, 0.23903234804513668, 0.20186780097265219] (n=24)
output> saving performance to:
/Users/pleiades/Documents/work/tpheno/seqmaker/data/CKD/plot/model_evalation-ep200b16.tif


model_selection> trying {'n_units': 300, 'dropout_rate': 0.3} ...

make_lstm> n_units=300, r_dropout=0.300000, n_layers=1, n_classes=6
  + lookup:
{'Others': 5, 'CKD Stage 5': 4, 'CKD Stage 4': 3, 'CKD Stage 3': 2, 'CKD Stage 2': 1, 'CKD Stage 1': 0}

... class weights:
{0: 6.344086021505376, 1: 0.74494949494949492, 2: 1.1238095238095238, 3: 7.0238095238095237, 4: 0.51890941072999119, 5: 0.64906490649064907}

====================================================================================================
... early stopping>
       + patience: 20, model='max'
... model training>
       + batch_size: 32, epochs: 60, shuffle? True, metric: auc_roc
====================================================================================================
Train on 1652 samples, validate on 708 samples
Epoch 1/60
1652/1652 [==============================] - 9s 5ms/step - loss: 1.6283 - acc: 0.3323 - auc_roc: 0.6301 - val_loss: 1.5382 - val_acc: 0.5763 - val_auc_roc: 0.7393
Epoch 2/60
1652/1652 [==============================] - 8s 5ms/step - loss: 1.4545 - acc: 0.4056 - auc_roc: 0.7625 - val_loss: 1.8156 - val_acc: 0.3870 - val_auc_roc: 0.7562
Epoch 3/60
1652/1652 [==============================] - 15s 9ms/step - loss: 1.2789 - acc: 0.4921 - auc_roc: 0.7640 - val_loss: 1.3724 - val_acc: 0.5240 - val_auc_roc: 0.7761
Epoch 4/60
1652/1652 [==============================] - 10s 6ms/step - loss: 1.1393 - acc: 0.5079 - auc_roc: 0.7842 - val_loss: 1.5711 - val_acc: 0.6116 - val_auc_roc: 0.7943
Epoch 5/60
1652/1652 [==============================] - 8s 5ms/step - loss: 1.0545 - acc: 0.5654 - auc_roc: 0.8046 - val_loss: 1.5981 - val_acc: 0.5579 - val_auc_roc: 0.8100
Epoch 6/60
1652/1652 [==============================] - 8s 5ms/step - loss: 0.9740 - acc: 0.5757 - auc_roc: 0.8163 - val_loss: 1.6696 - val_acc: 0.6610 - val_auc_roc: 0.8225
Epoch 7/60
1652/1652 [==============================] - 8s 5ms/step - loss: 0.8571 - acc: 0.6005 - auc_roc: 0.8286 - val_loss: 1.9582 - val_acc: 0.6850 - val_auc_roc: 0.8351
Epoch 8/60
1652/1652 [==============================] - 8s 5ms/step - loss: 0.7966 - acc: 0.6199 - auc_roc: 0.8402 - val_loss: 1.6352 - val_acc: 0.6059 - val_auc_roc: 0.8445
Epoch 9/60
1652/1652 [==============================] - 7s 4ms/step - loss: 0.7470 - acc: 0.6368 - auc_roc: 0.8481 - val_loss: 1.8269 - val_acc: 0.6681 - val_auc_roc: 0.8524
Epoch 10/60
1652/1652 [==============================] - 7s 4ms/step - loss: 0.6607 - acc: 0.6610 - auc_roc: 0.8564 - val_loss: 2.0121 - val_acc: 0.5890 - val_auc_roc: 0.8597
Epoch 11/60
1652/1652 [==============================] - 7s 4ms/step - loss: 0.6899 - acc: 0.6731 - auc_roc: 0.8626 - val_loss: 1.7767 - val_acc: 0.6059 - val_auc_roc: 0.8649
Epoch 12/60
1652/1652 [==============================] - 7s 4ms/step - loss: 0.7106 - acc: 0.6786 - auc_roc: 0.8670 - val_loss: 1.6422 - val_acc: 0.6624 - val_auc_roc: 0.8699
Epoch 13/60
1652/1652 [==============================] - 7s 4ms/step - loss: 0.6656 - acc: 0.6834 - auc_roc: 0.8719 - val_loss: 1.9839 - val_acc: 0.5452 - val_auc_roc: 0.8736
Epoch 14/60
1652/1652 [==============================] - 6s 4ms/step - loss: 0.5786 - acc: 0.7209 - auc_roc: 0.8753 - val_loss: 2.8107 - val_acc: 0.3277 - val_auc_roc: 0.8754
Epoch 15/60
1652/1652 [==============================] - 7s 4ms/step - loss: 0.6728 - acc: 0.6665 - auc_roc: 0.8750 - val_loss: 2.4116 - val_acc: 0.2726 - val_auc_roc: 0.8744
Epoch 16/60
1652/1652 [==============================] - 6s 4ms/step - loss: 0.6175 - acc: 0.6816 - auc_roc: 0.8742 - val_loss: 2.2875 - val_acc: 0.6455 - val_auc_roc: 0.8764
Epoch 17/60
1652/1652 [==============================] - 7s 4ms/step - loss: 0.4642 - acc: 0.7669 - auc_roc: 0.8786 - val_loss: 2.3790 - val_acc: 0.6525 - val_auc_roc: 0.8812
Epoch 18/60
1652/1652 [==============================] - 7s 4ms/step - loss: 0.4274 - acc: 0.7851 - auc_roc: 0.8834 - val_loss: 2.3881 - val_acc: 0.7034 - val_auc_roc: 0.8860
Epoch 19/60
1652/1652 [==============================] - 7s 4ms/step - loss: 0.4221 - acc: 0.8160 - auc_roc: 0.8883 - val_loss: 2.3973 - val_acc: 0.7105 - val_auc_roc: 0.8907
Epoch 20/60
1652/1652 [==============================] - 7s 4ms/step - loss: 0.3681 - acc: 0.8172 - auc_roc: 0.8929 - val_loss: 2.3969 - val_acc: 0.6511 - val_auc_roc: 0.8950
Epoch 21/60
1652/1652 [==============================] - 7s 4ms/step - loss: 0.3037 - acc: 0.8590 - auc_roc: 0.8969 - val_loss: 2.6345 - val_acc: 0.6879 - val_auc_roc: 0.8992
Epoch 22/60
1652/1652 [==============================] - 7s 4ms/step - loss: 0.2447 - acc: 0.8838 - auc_roc: 0.9011 - val_loss: 2.8535 - val_acc: 0.6582 - val_auc_roc: 0.9032
Epoch 23/60
1652/1652 [==============================] - 7s 4ms/step - loss: 0.2062 - acc: 0.9007 - auc_roc: 0.9048 - val_loss: 2.7991 - val_acc: 0.6822 - val_auc_roc: 0.9070
Epoch 00023: early stopping
... history of metrics comprising: ['acc', 'loss', 'val_auc_roc', 'auc_roc', 'val_acc', 'val_loss']
... ... metric (acc): [0.72094430963871847, 0.66646489089684102, 0.68159806295399517, 0.76694915239805173, 0.78510895912641476, 0.81598062953995154, 0.81719128300433586, 0.8589588376280759, 0.88377723970944311, 0.90072639196317361] (n=23)
output> saving performance to:
/Users/pleiades/Documents/work/tpheno/seqmaker/data/CKD/plot/model_evalation-ep200b16.tif

... ... metric (loss): [0.57859018120292316, 0.67282451671203169, 0.61751858576158059, 0.4642445663707308, 0.4273671360627791, 0.42205385499370013, 0.36808493087568817, 0.30368415098502044, 0.24467341930179273, 0.20620890852902762] (n=23)
output> saving performance to:
/Users/pleiades/Documents/work/tpheno/seqmaker/data/CKD/plot/model_evalation-ep200b16.tif


model_selection> trying {'n_units': 400, 'dropout_rate': 0.3} ...

make_lstm> n_units=400, r_dropout=0.300000, n_layers=1, n_classes=6
  + lookup:
{'Others': 5, 'CKD Stage 5': 4, 'CKD Stage 4': 3, 'CKD Stage 3': 2, 'CKD Stage 2': 1, 'CKD Stage 1': 0}

... class weights:
{0: 6.344086021505376, 1: 0.74494949494949492, 2: 1.1238095238095238, 3: 7.0238095238095237, 4: 0.51890941072999119, 5: 0.64906490649064907}

====================================================================================================
... early stopping>
       + patience: 20, model='max'
... model training>
       + batch_size: 32, epochs: 60, shuffle? True, metric: auc_roc
====================================================================================================
Train on 1652 samples, validate on 708 samples
Epoch 1/60
1652/1652 [==============================] - 10s 6ms/step - loss: 1.6035 - acc: 0.3311 - auc_roc: 0.6788 - val_loss: 1.6336 - val_acc: 0.6130 - val_auc_roc: 0.7425
Epoch 2/60
1652/1652 [==============================] - 10s 6ms/step - loss: 1.4412 - acc: 0.4219 - auc_roc: 0.7608 - val_loss: 2.1688 - val_acc: 0.0720 - val_auc_roc: 0.7352
Epoch 3/60
1652/1652 [==============================] - 10s 6ms/step - loss: 1.3633 - acc: 0.4346 - auc_roc: 0.7221 - val_loss: 1.9054 - val_acc: 0.5127 - val_auc_roc: 0.7408
Epoch 4/60
1652/1652 [==============================] - 12s 8ms/step - loss: 1.1598 - acc: 0.4861 - auc_roc: 0.7560 - val_loss: 1.6313 - val_acc: 0.6003 - val_auc_roc: 0.7719
Epoch 5/60
1652/1652 [==============================] - 13s 8ms/step - loss: 1.1304 - acc: 0.5109 - auc_roc: 0.7829 - val_loss: 1.7250 - val_acc: 0.5523 - val_auc_roc: 0.7894
Epoch 6/60
1652/1652 [==============================] - 14s 8ms/step - loss: 1.0187 - acc: 0.5587 - auc_roc: 0.7960 - val_loss: 1.7286 - val_acc: 0.6144 - val_auc_roc: 0.8045
Epoch 7/60
1652/1652 [==============================] - 12s 7ms/step - loss: 0.9571 - acc: 0.5581 - auc_roc: 0.8098 - val_loss: 1.8313 - val_acc: 0.4958 - val_auc_roc: 0.8138
Epoch 8/60
1652/1652 [==============================] - 11s 7ms/step - loss: 0.8786 - acc: 0.5956 - auc_roc: 0.8181 - val_loss: 1.9284 - val_acc: 0.5551 - val_auc_roc: 0.8226
Epoch 9/60
1652/1652 [==============================] - 10s 6ms/step - loss: 0.9326 - acc: 0.5502 - auc_roc: 0.8250 - val_loss: 1.7772 - val_acc: 0.6582 - val_auc_roc: 0.8294
Epoch 10/60
1652/1652 [==============================] - 10s 6ms/step - loss: 0.8375 - acc: 0.6332 - auc_roc: 0.8334 - val_loss: 1.9455 - val_acc: 0.6144 - val_auc_roc: 0.8373
Epoch 11/60
1652/1652 [==============================] - 10s 6ms/step - loss: 0.7847 - acc: 0.6059 - auc_roc: 0.8395 - val_loss: 1.8965 - val_acc: 0.6328 - val_auc_roc: 0.8433
Epoch 12/60
1652/1652 [==============================] - 10s 6ms/step - loss: 0.7036 - acc: 0.6695 - auc_roc: 0.8467 - val_loss: 2.1336 - val_acc: 0.5720 - val_auc_roc: 0.8498
Epoch 13/60
1652/1652 [==============================] - 10s 6ms/step - loss: 0.6917 - acc: 0.6695 - auc_roc: 0.8522 - val_loss: 1.7659 - val_acc: 0.5904 - val_auc_roc: 0.8550
Epoch 14/60
1652/1652 [==============================] - 10s 6ms/step - loss: 0.5823 - acc: 0.7203 - auc_roc: 0.8579 - val_loss: 2.3904 - val_acc: 0.6483 - val_auc_roc: 0.8611
Epoch 15/60
1652/1652 [==============================] - 9s 6ms/step - loss: 0.5274 - acc: 0.7482 - auc_roc: 0.8640 - val_loss: 2.3509 - val_acc: 0.6836 - val_auc_roc: 0.8674
Epoch 16/60
1652/1652 [==============================] - 9s 6ms/step - loss: 0.4667 - acc: 0.7633 - auc_roc: 0.8702 - val_loss: 2.3768 - val_acc: 0.6737 - val_auc_roc: 0.8737
Epoch 17/60
1652/1652 [==============================] - 10s 6ms/step - loss: 0.4341 - acc: 0.8057 - auc_roc: 0.8766 - val_loss: 1.9659 - val_acc: 0.6582 - val_auc_roc: 0.8796
Epoch 18/60
1652/1652 [==============================] - 10s 6ms/step - loss: 0.3586 - acc: 0.8172 - auc_roc: 0.8823 - val_loss: 2.2938 - val_acc: 0.6949 - val_auc_roc: 0.8852
Epoch 19/60
1652/1652 [==============================] - 11s 6ms/step - loss: 0.3196 - acc: 0.8529 - auc_roc: 0.8880 - val_loss: 2.3784 - val_acc: 0.7090 - val_auc_roc: 0.8908
Epoch 20/60
1652/1652 [==============================] - 10s 6ms/step - loss: 0.3450 - acc: 0.8535 - auc_roc: 0.8931 - val_loss: 2.4528 - val_acc: 0.7105 - val_auc_roc: 0.8954
Epoch 21/60
1652/1652 [==============================] - 10s 6ms/step - loss: 0.2851 - acc: 0.8674 - auc_roc: 0.8974 - val_loss: 2.6132 - val_acc: 0.6073 - val_auc_roc: 0.8994
Epoch 22/60
1652/1652 [==============================] - 10s 6ms/step - loss: 0.3266 - acc: 0.8608 - auc_roc: 0.9009 - val_loss: 2.3205 - val_acc: 0.6596 - val_auc_roc: 0.9028
Epoch 23/60
1652/1652 [==============================] - 11s 6ms/step - loss: 0.2991 - acc: 0.8662 - auc_roc: 0.9043 - val_loss: 2.6240 - val_acc: 0.6766 - val_auc_roc: 0.9061
Epoch 24/60
1652/1652 [==============================] - 10s 6ms/step - loss: 0.2066 - acc: 0.9128 - auc_roc: 0.9078 - val_loss: 2.5406 - val_acc: 0.6992 - val_auc_roc: 0.9099
Epoch 00024: early stopping
... history of metrics comprising: ['acc', 'loss', 'val_auc_roc', 'auc_roc', 'val_acc', 'val_loss']
... ... metric (acc): [0.7481840195147812, 0.76331719157193534, 0.80569007249490399, 0.81719128329297819, 0.85290556900726389, 0.8535108961724196, 0.86743341375494121, 0.8607748181132947, 0.86622276057919922, 0.9128329297820823] (n=24)
output> saving performance to:
/Users/pleiades/Documents/work/tpheno/seqmaker/data/CKD/plot/model_evalation-ep200b16.tif

... ... metric (loss): [0.52742013010505329, 0.46668814212877585, 0.43412628517312518, 0.35863324906000504, 0.31959694667243493, 0.34501847660859042, 0.28511528263080493, 0.32662740991998818, 0.29914756339341042, 0.20657153429404876] (n=24)
output> saving performance to:
/Users/pleiades/Documents/work/tpheno/seqmaker/data/CKD/plot/model_evalation-ep200b16.tif


model_selection> trying {'n_units': 500, 'dropout_rate': 0.3} ...

make_lstm> n_units=500, r_dropout=0.300000, n_layers=1, n_classes=6
  + lookup:
{'Others': 5, 'CKD Stage 5': 4, 'CKD Stage 4': 3, 'CKD Stage 3': 2, 'CKD Stage 2': 1, 'CKD Stage 1': 0}

... class weights:
{0: 6.344086021505376, 1: 0.74494949494949492, 2: 1.1238095238095238, 3: 7.0238095238095237, 4: 0.51890941072999119, 5: 0.64906490649064907}

====================================================================================================
... early stopping>
       + patience: 20, model='max'
... model training>
       + batch_size: 32, epochs: 60, shuffle? True, metric: auc_roc
====================================================================================================
Train on 1652 samples, validate on 708 samples
Epoch 1/60
1652/1652 [==============================] - 15s 9ms/step - loss: 1.6372 - acc: 0.3202 - auc_roc: 0.6406 - val_loss: 1.6173 - val_acc: 0.2359 - val_auc_roc: 0.6820
Epoch 2/60
1652/1652 [==============================] - 14s 9ms/step - loss: 1.3872 - acc: 0.4691 - auc_roc: 0.7044 - val_loss: 1.4792 - val_acc: 0.5395 - val_auc_roc: 0.7369
Epoch 3/60
1652/1652 [==============================] - 15s 9ms/step - loss: 1.3282 - acc: 0.4050 - auc_roc: 0.7499 - val_loss: 1.6610 - val_acc: 0.4421 - val_auc_roc: 0.7519
Epoch 4/60
1652/1652 [==============================] - 14s 9ms/step - loss: 1.2113 - acc: 0.4885 - auc_roc: 0.7594 - val_loss: 1.4531 - val_acc: 0.6441 - val_auc_roc: 0.7758
Epoch 5/60
1652/1652 [==============================] - 14s 9ms/step - loss: 1.1237 - acc: 0.5079 - auc_roc: 0.7858 - val_loss: 1.7500 - val_acc: 0.5593 - val_auc_roc: 0.7918
Epoch 6/60
1652/1652 [==============================] - 16s 10ms/step - loss: 1.0510 - acc: 0.5369 - auc_roc: 0.7964 - val_loss: 1.8684 - val_acc: 0.6257 - val_auc_roc: 0.8041
Epoch 7/60
1652/1652 [==============================] - 15s 9ms/step - loss: 0.9769 - acc: 0.5630 - auc_roc: 0.8110 - val_loss: 1.5749 - val_acc: 0.5523 - val_auc_roc: 0.8150
Epoch 8/60
1652/1652 [==============================] - 15s 9ms/step - loss: 0.8826 - acc: 0.5920 - auc_roc: 0.8193 - val_loss: 1.5014 - val_acc: 0.6638 - val_auc_roc: 0.8253
Epoch 9/60
1652/1652 [==============================] - 15s 9ms/step - loss: 0.8317 - acc: 0.6120 - auc_roc: 0.8302 - val_loss: 1.7906 - val_acc: 0.6427 - val_auc_roc: 0.8351
Epoch 10/60
1652/1652 [==============================] - 14s 9ms/step - loss: 0.7396 - acc: 0.6416 - auc_roc: 0.8390 - val_loss: 2.0043 - val_acc: 0.6469 - val_auc_roc: 0.8438
Epoch 11/60
1652/1652 [==============================] - 14s 8ms/step - loss: 0.7164 - acc: 0.6538 - auc_roc: 0.8475 - val_loss: 1.9182 - val_acc: 0.6427 - val_auc_roc: 0.8515
Epoch 12/60
1652/1652 [==============================] - 21s 13ms/step - loss: 0.6892 - acc: 0.6768 - auc_roc: 0.8543 - val_loss: 2.1475 - val_acc: 0.4223 - val_auc_roc: 0.8556
Epoch 13/60
1652/1652 [==============================] - 17s 10ms/step - loss: 0.6781 - acc: 0.6519 - auc_roc: 0.8565 - val_loss: 2.7790 - val_acc: 0.2994 - val_auc_roc: 0.8564
Epoch 14/60
1652/1652 [==============================] - 16s 9ms/step - loss: 0.6815 - acc: 0.6646 - auc_roc: 0.8564 - val_loss: 1.9192 - val_acc: 0.6582 - val_auc_roc: 0.8595
Epoch 15/60
1652/1652 [==============================] - 16s 10ms/step - loss: 0.8095 - acc: 0.6320 - auc_roc: 0.8607 - val_loss: 2.0203 - val_acc: 0.5805 - val_auc_roc: 0.8619
Epoch 16/60
1652/1652 [==============================] - 16s 10ms/step - loss: 0.5471 - acc: 0.7209 - auc_roc: 0.8641 - val_loss: 2.2331 - val_acc: 0.6610 - val_auc_roc: 0.8671
Epoch 17/60
1652/1652 [==============================] - 16s 10ms/step - loss: 0.5022 - acc: 0.7585 - auc_roc: 0.8698 - val_loss: 2.3550 - val_acc: 0.6427 - val_auc_roc: 0.8724
Epoch 18/60
1652/1652 [==============================] - 17s 10ms/step - loss: 0.4142 - acc: 0.7912 - auc_roc: 0.8750 - val_loss: 2.4060 - val_acc: 0.6822 - val_auc_roc: 0.8781
Epoch 19/60
1652/1652 [==============================] - 17s 10ms/step - loss: 0.3827 - acc: 0.8154 - auc_roc: 0.8806 - val_loss: 2.7427 - val_acc: 0.6780 - val_auc_roc: 0.8834
Epoch 20/60
1652/1652 [==============================] - 17s 10ms/step - loss: 0.3210 - acc: 0.8414 - auc_roc: 0.8859 - val_loss: 2.6019 - val_acc: 0.5932 - val_auc_roc: 0.8882
Epoch 21/60
1652/1652 [==============================] - 17s 10ms/step - loss: 0.3349 - acc: 0.8396 - auc_roc: 0.8900 - val_loss: 2.6492 - val_acc: 0.6963 - val_auc_roc: 0.8925
Epoch 22/60
1652/1652 [==============================] - 17s 10ms/step - loss: 0.4100 - acc: 0.8208 - auc_roc: 0.8942 - val_loss: 2.3723 - val_acc: 0.6935 - val_auc_roc: 0.8962
Epoch 23/60
1652/1652 [==============================] - 17s 10ms/step - loss: 0.2790 - acc: 0.8638 - auc_roc: 0.8980 - val_loss: 2.7628 - val_acc: 0.7161 - val_auc_roc: 0.9003
Epoch 24/60
1652/1652 [==============================] - 15s 9ms/step - loss: 0.2176 - acc: 0.8989 - auc_roc: 0.9022 - val_loss: 2.4786 - val_acc: 0.7034 - val_auc_roc: 0.9043
Epoch 00024: early stopping
... history of metrics comprising: ['acc', 'loss', 'val_auc_roc', 'auc_roc', 'val_acc', 'val_loss']
... ... metric (acc): [0.63196125907990319, 0.72094431021600314, 0.75847457598254409, 0.79116222760290555, 0.81537530266343827, 0.84140435849783202, 0.8395883778682921, 0.8208232442634158, 0.86380145292882482, 0.8989104113336337] (n=24)
output> saving performance to:
/Users/pleiades/Documents/work/tpheno/seqmaker/data/CKD/plot/model_evalation-ep200b16.tif

... ... metric (loss): [0.80948471359132856, 0.54708207144286958, 0.50224454827227838, 0.4141596928780073, 0.38270204725334778, 0.32104251495862413, 0.33490283155845385, 0.40996979187822224, 0.27898090002611819, 0.21758790678608503] (n=24)
output> saving performance to:
/Users/pleiades/Documents/work/tpheno/seqmaker/data/CKD/plot/model_evalation-ep200b16.tif


model_selection> trying {'n_units': 50, 'dropout_rate': 0.5} ...

make_lstm> n_units=50, r_dropout=0.500000, n_layers=1, n_classes=6
  + lookup:
{'Others': 5, 'CKD Stage 5': 4, 'CKD Stage 4': 3, 'CKD Stage 3': 2, 'CKD Stage 2': 1, 'CKD Stage 1': 0}

... class weights:
{0: 6.344086021505376, 1: 0.74494949494949492, 2: 1.1238095238095238, 3: 7.0238095238095237, 4: 0.51890941072999119, 5: 0.64906490649064907}

====================================================================================================
... early stopping>
       + patience: 20, model='max'
... model training>
       + batch_size: 32, epochs: 60, shuffle? True, metric: auc_roc
====================================================================================================
Train on 1652 samples, validate on 708 samples
Epoch 1/60
1652/1652 [==============================] - 7s 4ms/step - loss: 1.7369 - acc: 0.2161 - auc_roc: 0.5164 - val_loss: 2.0662 - val_acc: 0.0339 - val_auc_roc: 0.5258
Epoch 2/60
1652/1652 [==============================] - 4s 3ms/step - loss: 1.6708 - acc: 0.2403 - auc_roc: 0.5334 - val_loss: 1.9647 - val_acc: 0.0523 - val_auc_roc: 0.5497
Epoch 3/60
1652/1652 [==============================] - 4s 2ms/step - loss: 1.5529 - acc: 0.3565 - auc_roc: 0.5681 - val_loss: 1.9591 - val_acc: 0.3446 - val_auc_roc: 0.5994
Epoch 4/60
1652/1652 [==============================] - 3s 2ms/step - loss: 1.4320 - acc: 0.4262 - auc_roc: 0.6247 - val_loss: 1.6323 - val_acc: 0.4675 - val_auc_roc: 0.6524
Epoch 5/60
1652/1652 [==============================] - 3s 2ms/step - loss: 1.2583 - acc: 0.4728 - auc_roc: 0.6753 - val_loss: 1.7151 - val_acc: 0.3672 - val_auc_roc: 0.6895
Epoch 6/60
1652/1652 [==============================] - 3s 2ms/step - loss: 1.2423 - acc: 0.4849 - auc_roc: 0.7000 - val_loss: 1.3329 - val_acc: 0.6483 - val_auc_roc: 0.7166
Epoch 7/60
1652/1652 [==============================] - 3s 2ms/step - loss: 1.1356 - acc: 0.5200 - auc_roc: 0.7302 - val_loss: 1.4278 - val_acc: 0.6610 - val_auc_roc: 0.7430
Epoch 8/60
1652/1652 [==============================] - 3s 2ms/step - loss: 1.0700 - acc: 0.5297 - auc_roc: 0.7532 - val_loss: 1.4552 - val_acc: 0.6921 - val_auc_roc: 0.7634
Epoch 9/60
1652/1652 [==============================] - 3s 2ms/step - loss: 1.0453 - acc: 0.5291 - auc_roc: 0.7717 - val_loss: 1.5863 - val_acc: 0.6723 - val_auc_roc: 0.7790
Epoch 10/60
1652/1652 [==============================] - 3s 2ms/step - loss: 1.0410 - acc: 0.5351 - auc_roc: 0.7850 - val_loss: 1.6425 - val_acc: 0.6370 - val_auc_roc: 0.7900
Epoch 11/60
1652/1652 [==============================] - 3s 2ms/step - loss: 0.9717 - acc: 0.5678 - auc_roc: 0.7948 - val_loss: 1.4576 - val_acc: 0.7175 - val_auc_roc: 0.8007
Epoch 12/60
1652/1652 [==============================] - 3s 2ms/step - loss: 0.9210 - acc: 0.5805 - auc_roc: 0.8059 - val_loss: 1.5168 - val_acc: 0.6921 - val_auc_roc: 0.8103
Epoch 13/60
1652/1652 [==============================] - 3s 2ms/step - loss: 0.9063 - acc: 0.5914 - auc_roc: 0.8145 - val_loss: 1.7394 - val_acc: 0.6610 - val_auc_roc: 0.8182
Epoch 14/60
1652/1652 [==============================] - 4s 2ms/step - loss: 0.8629 - acc: 0.6096 - auc_roc: 0.8214 - val_loss: 1.7392 - val_acc: 0.6695 - val_auc_roc: 0.8250
Epoch 15/60
1652/1652 [==============================] - 4s 2ms/step - loss: 0.8354 - acc: 0.5914 - auc_roc: 0.8277 - val_loss: 1.6395 - val_acc: 0.7105 - val_auc_roc: 0.8310
Epoch 16/60
1652/1652 [==============================] - 4s 3ms/step - loss: 0.7912 - acc: 0.6205 - auc_roc: 0.8342 - val_loss: 1.6640 - val_acc: 0.6992 - val_auc_roc: 0.8374
Epoch 17/60
1652/1652 [==============================] - 4s 2ms/step - loss: 0.7753 - acc: 0.6253 - auc_roc: 0.8399 - val_loss: 1.7529 - val_acc: 0.7105 - val_auc_roc: 0.8427
Epoch 18/60
1652/1652 [==============================] - 3s 2ms/step - loss: 0.7489 - acc: 0.6301 - auc_roc: 0.8452 - val_loss: 1.7633 - val_acc: 0.7119 - val_auc_roc: 0.8478
Epoch 19/60
1652/1652 [==============================] - 4s 2ms/step - loss: 0.7019 - acc: 0.6538 - auc_roc: 0.8502 - val_loss: 1.9355 - val_acc: 0.7246 - val_auc_roc: 0.8527
Epoch 20/60
1652/1652 [==============================] - 4s 2ms/step - loss: 0.7136 - acc: 0.6640 - auc_roc: 0.8549 - val_loss: 2.0333 - val_acc: 0.7119 - val_auc_roc: 0.8571
Epoch 21/60
1652/1652 [==============================] - 3s 2ms/step - loss: 0.6729 - acc: 0.6646 - auc_roc: 0.8589 - val_loss: 2.0335 - val_acc: 0.7105 - val_auc_roc: 0.8608
Epoch 22/60
1652/1652 [==============================] - 3s 2ms/step - loss: 0.6442 - acc: 0.6810 - auc_roc: 0.8625 - val_loss: 1.9672 - val_acc: 0.7401 - val_auc_roc: 0.8646
Epoch 23/60
1652/1652 [==============================] - 3s 2ms/step - loss: 0.7244 - acc: 0.6356 - auc_roc: 0.8660 - val_loss: 2.0433 - val_acc: 0.6822 - val_auc_roc: 0.8674
Epoch 24/60
1652/1652 [==============================] - 3s 2ms/step - loss: 0.6915 - acc: 0.6580 - auc_roc: 0.8685 - val_loss: 2.1570 - val_acc: 0.6766 - val_auc_roc: 0.8698
Epoch 25/60
1652/1652 [==============================] - 4s 2ms/step - loss: 0.7348 - acc: 0.6223 - auc_roc: 0.8709 - val_loss: 2.5702 - val_acc: 0.2952 - val_auc_roc: 0.8695
Epoch 26/60
1652/1652 [==============================] - 3s 2ms/step - loss: 0.7745 - acc: 0.5950 - auc_roc: 0.8684 - val_loss: 2.1030 - val_acc: 0.6412 - val_auc_roc: 0.8691
Epoch 00026: early stopping
... history of metrics comprising: ['acc', 'loss', 'val_auc_roc', 'auc_roc', 'val_acc', 'val_loss']
... ... metric (acc): [0.62530266329393547, 0.63014527830604206, 0.65375302677870373, 0.66404358367943017, 0.66464891070026466, 0.68099273593316068, 0.63559322048330424, 0.65799031476997583, 0.62227602920001124, 0.59503631975691196] (n=26)
output> saving performance to:
/Users/pleiades/Documents/work/tpheno/seqmaker/data/CKD/plot/model_evalation-ep200b16.tif

... ... metric (loss): [0.77533080560531797, 0.74893713040732879, 0.70185444112551409, 0.71358969757112412, 0.67287788826963224, 0.64421114664678136, 0.72443177018846783, 0.69149125877939188, 0.73476410532690417, 0.77454028233488881] (n=26)
output> saving performance to:
/Users/pleiades/Documents/work/tpheno/seqmaker/data/CKD/plot/model_evalation-ep200b16.tif


model_selection> trying {'n_units': 100, 'dropout_rate': 0.5} ...

make_lstm> n_units=100, r_dropout=0.500000, n_layers=1, n_classes=6
  + lookup:
{'Others': 5, 'CKD Stage 5': 4, 'CKD Stage 4': 3, 'CKD Stage 3': 2, 'CKD Stage 2': 1, 'CKD Stage 1': 0}

... class weights:
{0: 6.344086021505376, 1: 0.74494949494949492, 2: 1.1238095238095238, 3: 7.0238095238095237, 4: 0.51890941072999119, 5: 0.64906490649064907}

====================================================================================================
... early stopping>
       + patience: 20, model='max'
... model training>
       + batch_size: 32, epochs: 60, shuffle? True, metric: auc_roc
====================================================================================================
Train on 1652 samples, validate on 708 samples
Epoch 1/60
1652/1652 [==============================] - 5s 3ms/step - loss: 1.7497 - acc: 0.2082 - auc_roc: 0.5049 - val_loss: 1.9540 - val_acc: 0.0593 - val_auc_roc: 0.5703
Epoch 2/60
1652/1652 [==============================] - 3s 2ms/step - loss: 1.5701 - acc: 0.3596 - auc_roc: 0.6017 - val_loss: 1.7594 - val_acc: 0.5042 - val_auc_roc: 0.6592
Epoch 3/60
1652/1652 [==============================] - 4s 2ms/step - loss: 1.4161 - acc: 0.4159 - auc_roc: 0.6934 - val_loss: 1.4532 - val_acc: 0.4816 - val_auc_roc: 0.7107
Epoch 4/60
1652/1652 [==============================] - 3s 2ms/step - loss: 1.2619 - acc: 0.4764 - auc_roc: 0.7255 - val_loss: 1.7217 - val_acc: 0.5184 - val_auc_roc: 0.7406
Epoch 5/60
1652/1652 [==============================] - 3s 2ms/step - loss: 1.1850 - acc: 0.5163 - auc_roc: 0.7525 - val_loss: 1.3006 - val_acc: 0.6667 - val_auc_roc: 0.7660
Epoch 6/60
1652/1652 [==============================] - 4s 2ms/step - loss: 1.1362 - acc: 0.5103 - auc_roc: 0.7770 - val_loss: 1.5944 - val_acc: 0.4718 - val_auc_roc: 0.7810
Epoch 7/60
1652/1652 [==============================] - 3s 2ms/step - loss: 1.1211 - acc: 0.5182 - auc_roc: 0.7843 - val_loss: 1.4096 - val_acc: 0.6328 - val_auc_roc: 0.7913
Epoch 8/60
1652/1652 [==============================] - 4s 2ms/step - loss: 1.0000 - acc: 0.5533 - auc_roc: 0.7978 - val_loss: 1.5472 - val_acc: 0.6455 - val_auc_roc: 0.8042
Epoch 9/60
1652/1652 [==============================] - 3s 2ms/step - loss: 0.9338 - acc: 0.5654 - auc_roc: 0.8096 - val_loss: 1.4876 - val_acc: 0.6808 - val_auc_roc: 0.8153
Epoch 10/60
1652/1652 [==============================] - 3s 2ms/step - loss: 0.8865 - acc: 0.6047 - auc_roc: 0.8205 - val_loss: 1.5945 - val_acc: 0.6850 - val_auc_roc: 0.8261
Epoch 11/60
1652/1652 [==============================] - 4s 2ms/step - loss: 0.8605 - acc: 0.6108 - auc_roc: 0.8302 - val_loss: 1.5384 - val_acc: 0.6766 - val_auc_roc: 0.8341
Epoch 12/60
1652/1652 [==============================] - 3s 2ms/step - loss: 0.8743 - acc: 0.5630 - auc_roc: 0.8364 - val_loss: 1.6866 - val_acc: 0.6596 - val_auc_roc: 0.8390
Epoch 13/60
1652/1652 [==============================] - 4s 2ms/step - loss: 0.7920 - acc: 0.6199 - auc_roc: 0.8419 - val_loss: 1.6463 - val_acc: 0.6836 - val_auc_roc: 0.8450
Epoch 14/60
1652/1652 [==============================] - 4s 2ms/step - loss: 0.7334 - acc: 0.6441 - auc_roc: 0.8479 - val_loss: 1.7985 - val_acc: 0.6977 - val_auc_roc: 0.8509
Epoch 15/60
1652/1652 [==============================] - 4s 2ms/step - loss: 0.7183 - acc: 0.6380 - auc_roc: 0.8534 - val_loss: 1.7496 - val_acc: 0.6667 - val_auc_roc: 0.8559
Epoch 16/60
1652/1652 [==============================] - 4s 2ms/step - loss: 0.6961 - acc: 0.6586 - auc_roc: 0.8579 - val_loss: 2.1006 - val_acc: 0.7006 - val_auc_roc: 0.8604
Epoch 17/60
1652/1652 [==============================] - 4s 2ms/step - loss: 0.6413 - acc: 0.6798 - auc_roc: 0.8627 - val_loss: 1.8828 - val_acc: 0.7147 - val_auc_roc: 0.8652
Epoch 18/60
1652/1652 [==============================] - 4s 2ms/step - loss: 0.8298 - acc: 0.6162 - auc_roc: 0.8665 - val_loss: 1.4502 - val_acc: 0.6469 - val_auc_roc: 0.8678
Epoch 19/60
1652/1652 [==============================] - 3s 2ms/step - loss: 0.8150 - acc: 0.5708 - auc_roc: 0.8687 - val_loss: 1.8897 - val_acc: 0.4647 - val_auc_roc: 0.8681
Epoch 20/60
1652/1652 [==============================] - 3s 2ms/step - loss: 0.7391 - acc: 0.6320 - auc_roc: 0.8685 - val_loss: 1.7761 - val_acc: 0.5989 - val_auc_roc: 0.8691
Epoch 21/60
1652/1652 [==============================] - 3s 2ms/step - loss: 0.6494 - acc: 0.6792 - auc_roc: 0.8703 - val_loss: 1.9214 - val_acc: 0.7119 - val_auc_roc: 0.8721
Epoch 22/60
1652/1652 [==============================] - 3s 2ms/step - loss: 0.5865 - acc: 0.6895 - auc_roc: 0.8736 - val_loss: 1.9758 - val_acc: 0.6935 - val_auc_roc: 0.8753
Epoch 23/60
1652/1652 [==============================] - 3s 2ms/step - loss: 0.5408 - acc: 0.7240 - auc_roc: 0.8768 - val_loss: 2.0114 - val_acc: 0.7232 - val_auc_roc: 0.8787
Epoch 24/60
1652/1652 [==============================] - 3s 2ms/step - loss: 0.5462 - acc: 0.7264 - auc_roc: 0.8802 - val_loss: 1.9363 - val_acc: 0.7133 - val_auc_roc: 0.8818
Epoch 25/60
1652/1652 [==============================] - 4s 2ms/step - loss: 0.5110 - acc: 0.7355 - auc_roc: 0.8832 - val_loss: 2.1053 - val_acc: 0.6949 - val_auc_roc: 0.8847
Epoch 00025: early stopping
... history of metrics comprising: ['acc', 'loss', 'val_auc_roc', 'auc_roc', 'val_acc', 'val_loss']
... ... metric (acc): [0.65859564135784676, 0.67978208218013403, 0.61622276043487811, 0.57082324484070046, 0.6319612592242243, 0.67917675530362076, 0.68946731234866832, 0.72397094430992737, 0.72639225196030177, 0.73547215496368035] (n=25)
output> saving performance to:
/Users/pleiades/Documents/work/tpheno/seqmaker/data/CKD/plot/model_evalation-ep200b16.tif

... ... metric (loss): [0.69610204412342558, 0.64125170517198682, 0.8298377150773425, 0.81497162912428811, 0.73906014661234742, 0.64938731386932858, 0.58647994989344343, 0.54080013588034792, 0.54619896339735163, 0.51097154299802983] (n=25)
output> saving performance to:
/Users/pleiades/Documents/work/tpheno/seqmaker/data/CKD/plot/model_evalation-ep200b16.tif


model_selection> trying {'n_units': 200, 'dropout_rate': 0.5} ...

make_lstm> n_units=200, r_dropout=0.500000, n_layers=1, n_classes=6
  + lookup:
{'Others': 5, 'CKD Stage 5': 4, 'CKD Stage 4': 3, 'CKD Stage 3': 2, 'CKD Stage 2': 1, 'CKD Stage 1': 0}

... class weights:
{0: 6.344086021505376, 1: 0.74494949494949492, 2: 1.1238095238095238, 3: 7.0238095238095237, 4: 0.51890941072999119, 5: 0.64906490649064907}

====================================================================================================
... early stopping>
       + patience: 20, model='max'
... model training>
       + batch_size: 32, epochs: 60, shuffle? True, metric: auc_roc
====================================================================================================
Train on 1652 samples, validate on 708 samples
Epoch 1/60
1652/1652 [==============================] - 6s 4ms/step - loss: 1.6574 - acc: 0.3335 - auc_roc: 0.6774 - val_loss: 1.8029 - val_acc: 0.4251 - val_auc_roc: 0.7077
Epoch 2/60
1652/1652 [==============================] - 4s 3ms/step - loss: 1.4125 - acc: 0.4679 - auc_roc: 0.7230 - val_loss: 1.5984 - val_acc: 0.5169 - val_auc_roc: 0.7436
Epoch 3/60
1652/1652 [==============================] - 4s 3ms/step - loss: 1.2934 - acc: 0.4861 - auc_roc: 0.7590 - val_loss: 1.4121 - val_acc: 0.6342 - val_auc_roc: 0.7745
Epoch 4/60
1652/1652 [==============================] - 4s 3ms/step - loss: 1.2157 - acc: 0.4843 - auc_roc: 0.7858 - val_loss: 1.7188 - val_acc: 0.5862 - val_auc_roc: 0.7909
Epoch 5/60
1652/1652 [==============================] - 4s 3ms/step - loss: 1.0996 - acc: 0.5430 - auc_roc: 0.7982 - val_loss: 1.6161 - val_acc: 0.6342 - val_auc_roc: 0.8065
Epoch 6/60
1652/1652 [==============================] - 4s 3ms/step - loss: 1.0612 - acc: 0.5321 - auc_roc: 0.8119 - val_loss: 1.5792 - val_acc: 0.5198 - val_auc_roc: 0.8150
Epoch 7/60
1652/1652 [==============================] - 4s 3ms/step - loss: 1.0243 - acc: 0.5400 - auc_roc: 0.8182 - val_loss: 1.5498 - val_acc: 0.6511 - val_auc_roc: 0.8228
Epoch 8/60
1652/1652 [==============================] - 4s 3ms/step - loss: 0.9223 - acc: 0.5745 - auc_roc: 0.8273 - val_loss: 1.6194 - val_acc: 0.6780 - val_auc_roc: 0.8318
Epoch 9/60
1652/1652 [==============================] - 5s 3ms/step - loss: 0.8894 - acc: 0.5902 - auc_roc: 0.8359 - val_loss: 1.8168 - val_acc: 0.6681 - val_auc_roc: 0.8394
Epoch 10/60
1652/1652 [==============================] - 5s 3ms/step - loss: 0.8138 - acc: 0.6144 - auc_roc: 0.8431 - val_loss: 1.9441 - val_acc: 0.7105 - val_auc_roc: 0.8470
Epoch 11/60
1652/1652 [==============================] - 4s 3ms/step - loss: 0.8879 - acc: 0.5896 - auc_roc: 0.8495 - val_loss: 1.5115 - val_acc: 0.6427 - val_auc_roc: 0.8522
Epoch 12/60
1652/1652 [==============================] - 4s 3ms/step - loss: 0.7538 - acc: 0.6368 - auc_roc: 0.8546 - val_loss: 1.8616 - val_acc: 0.7119 - val_auc_roc: 0.8578
Epoch 13/60
1652/1652 [==============================] - 4s 2ms/step - loss: 0.7442 - acc: 0.6604 - auc_roc: 0.8607 - val_loss: 1.7564 - val_acc: 0.7161 - val_auc_roc: 0.8635
Epoch 14/60
1652/1652 [==============================] - 4s 3ms/step - loss: 0.6587 - acc: 0.6610 - auc_roc: 0.8661 - val_loss: 1.9962 - val_acc: 0.7133 - val_auc_roc: 0.8687
Epoch 15/60
1652/1652 [==============================] - 4s 2ms/step - loss: 0.6072 - acc: 0.6949 - auc_roc: 0.8714 - val_loss: 1.7518 - val_acc: 0.7105 - val_auc_roc: 0.8741
Epoch 16/60
1652/1652 [==============================] - 4s 3ms/step - loss: 0.5679 - acc: 0.7167 - auc_roc: 0.8764 - val_loss: 1.9443 - val_acc: 0.7020 - val_auc_roc: 0.8789
Epoch 17/60
1652/1652 [==============================] - 4s 2ms/step - loss: 0.5106 - acc: 0.7439 - auc_roc: 0.8812 - val_loss: 1.9776 - val_acc: 0.7147 - val_auc_roc: 0.8836
Epoch 18/60
1652/1652 [==============================] - 4s 3ms/step - loss: 0.5302 - acc: 0.7476 - auc_roc: 0.8855 - val_loss: 2.0648 - val_acc: 0.7048 - val_auc_roc: 0.8876
Epoch 19/60
1652/1652 [==============================] - 4s 2ms/step - loss: 0.4651 - acc: 0.7748 - auc_roc: 0.8895 - val_loss: 2.1713 - val_acc: 0.6963 - val_auc_roc: 0.8915
Epoch 20/60
1652/1652 [==============================] - 4s 3ms/step - loss: 0.4473 - acc: 0.7845 - auc_roc: 0.8931 - val_loss: 2.3149 - val_acc: 0.7359 - val_auc_roc: 0.8951
Epoch 21/60
1652/1652 [==============================] - 4s 3ms/step - loss: 0.4030 - acc: 0.8039 - auc_roc: 0.8969 - val_loss: 2.3405 - val_acc: 0.7175 - val_auc_roc: 0.8988
Epoch 22/60
1652/1652 [==============================] - 4s 3ms/step - loss: 0.4181 - acc: 0.8057 - auc_roc: 0.9004 - val_loss: 2.1423 - val_acc: 0.6935 - val_auc_roc: 0.9019
Epoch 23/60
1652/1652 [==============================] - 4s 3ms/step - loss: 0.4350 - acc: 0.8075 - auc_roc: 0.9032 - val_loss: 2.4919 - val_acc: 0.7246 - val_auc_roc: 0.9046
Epoch 00023: early stopping
... history of metrics comprising: ['acc', 'loss', 'val_auc_roc', 'auc_roc', 'val_acc', 'val_loss']
... ... metric (acc): [0.66101694900822117, 0.69491525394864584, 0.71670702193608871, 0.74394673137918799, 0.74757869263826793, 0.77481840164840365, 0.78450363210558027, 0.80387409200968518, 0.80569007292786754, 0.80750605341308634] (n=23)
output> saving performance to:
/Users/pleiades/Documents/work/tpheno/seqmaker/data/CKD/plot/model_evalation-ep200b16.tif

... ... metric (loss): [0.65865668921436005, 0.60717969858617526, 0.56794449030342753, 0.51064654268306331, 0.53015795155241185, 0.46512470147222928, 0.44727631097267095, 0.40296331011931485, 0.4181145711037495, 0.43500577400440743] (n=23)
output> saving performance to:
/Users/pleiades/Documents/work/tpheno/seqmaker/data/CKD/plot/model_evalation-ep200b16.tif


model_selection> trying {'n_units': 300, 'dropout_rate': 0.5} ...

make_lstm> n_units=300, r_dropout=0.500000, n_layers=1, n_classes=6
  + lookup:
{'Others': 5, 'CKD Stage 5': 4, 'CKD Stage 4': 3, 'CKD Stage 3': 2, 'CKD Stage 2': 1, 'CKD Stage 1': 0}

... class weights:
{0: 6.344086021505376, 1: 0.74494949494949492, 2: 1.1238095238095238, 3: 7.0238095238095237, 4: 0.51890941072999119, 5: 0.64906490649064907}

====================================================================================================
... early stopping>
       + patience: 20, model='max'
... model training>
       + batch_size: 32, epochs: 60, shuffle? True, metric: auc_roc
====================================================================================================
Train on 1652 samples, validate on 708 samples
Epoch 1/60
1652/1652 [==============================] - 9s 5ms/step - loss: 1.6592 - acc: 0.2984 - auc_roc: 0.5658 - val_loss: 1.7036 - val_acc: 0.2542 - val_auc_roc: 0.6546
Epoch 2/60
1652/1652 [==============================] - 6s 4ms/step - loss: 1.4556 - acc: 0.4237 - auc_roc: 0.6771 - val_loss: 1.7253 - val_acc: 0.1949 - val_auc_roc: 0.6837
Epoch 3/60
1652/1652 [==============================] - 6s 4ms/step - loss: 1.3261 - acc: 0.4407 - auc_roc: 0.6892 - val_loss: 1.6381 - val_acc: 0.4816 - val_auc_roc: 0.7115
Epoch 4/60
1652/1652 [==============================] - 7s 4ms/step - loss: 1.1897 - acc: 0.5012 - auc_roc: 0.7291 - val_loss: 1.6114 - val_acc: 0.5551 - val_auc_roc: 0.7451
Epoch 5/60
1652/1652 [==============================] - 6s 4ms/step - loss: 1.1097 - acc: 0.4933 - auc_roc: 0.7553 - val_loss: 2.1624 - val_acc: 0.3234 - val_auc_roc: 0.7590
Epoch 6/60
1652/1652 [==============================] - 7s 4ms/step - loss: 1.0775 - acc: 0.5400 - auc_roc: 0.7634 - val_loss: 1.6894 - val_acc: 0.5749 - val_auc_roc: 0.7737
Epoch 7/60
1652/1652 [==============================] - 6s 4ms/step - loss: 0.9864 - acc: 0.5781 - auc_roc: 0.7823 - val_loss: 1.8433 - val_acc: 0.5339 - val_auc_roc: 0.7879
Epoch 8/60
1652/1652 [==============================] - 7s 4ms/step - loss: 0.8783 - acc: 0.5902 - auc_roc: 0.7937 - val_loss: 1.7950 - val_acc: 0.6497 - val_auc_roc: 0.8019
Epoch 9/60
1652/1652 [==============================] - 7s 4ms/step - loss: 0.7877 - acc: 0.6320 - auc_roc: 0.8088 - val_loss: 1.8124 - val_acc: 0.6808 - val_auc_roc: 0.8165
Epoch 10/60
1652/1652 [==============================] - 7s 4ms/step - loss: 0.7858 - acc: 0.6398 - auc_roc: 0.8226 - val_loss: 1.6855 - val_acc: 0.6751 - val_auc_roc: 0.8281
Epoch 11/60
1652/1652 [==============================] - 7s 4ms/step - loss: 0.7277 - acc: 0.6513 - auc_roc: 0.8334 - val_loss: 1.8168 - val_acc: 0.5960 - val_auc_roc: 0.8376
Epoch 12/60
1652/1652 [==============================] - 8s 5ms/step - loss: 0.7688 - acc: 0.6217 - auc_roc: 0.8407 - val_loss: 1.7431 - val_acc: 0.6102 - val_auc_roc: 0.8436
Epoch 13/60
1652/1652 [==============================] - 8s 5ms/step - loss: 0.7347 - acc: 0.6616 - auc_roc: 0.8459 - val_loss: 1.8331 - val_acc: 0.6356 - val_auc_roc: 0.8495
Epoch 14/60
1652/1652 [==============================] - 8s 5ms/step - loss: 0.6337 - acc: 0.6973 - auc_roc: 0.8524 - val_loss: 2.0998 - val_acc: 0.7076 - val_auc_roc: 0.8562
Epoch 15/60
1652/1652 [==============================] - 9s 5ms/step - loss: 0.5602 - acc: 0.7191 - auc_roc: 0.8596 - val_loss: 2.1538 - val_acc: 0.6822 - val_auc_roc: 0.8630
Epoch 16/60
1652/1652 [==============================] - 14s 8ms/step - loss: 0.5360 - acc: 0.7331 - auc_roc: 0.8658 - val_loss: 1.9788 - val_acc: 0.6836 - val_auc_roc: 0.8691
Epoch 17/60
1652/1652 [==============================] - 8s 5ms/step - loss: 0.5244 - acc: 0.7355 - auc_roc: 0.8716 - val_loss: 2.1019 - val_acc: 0.6921 - val_auc_roc: 0.8743
Epoch 18/60
1652/1652 [==============================] - 8s 5ms/step - loss: 0.4424 - acc: 0.7778 - auc_roc: 0.8769 - val_loss: 1.9737 - val_acc: 0.7090 - val_auc_roc: 0.8798
Epoch 19/60
1652/1652 [==============================] - 8s 5ms/step - loss: 0.3659 - acc: 0.8172 - auc_roc: 0.8825 - val_loss: 2.1536 - val_acc: 0.6907 - val_auc_roc: 0.8852
Epoch 20/60
1652/1652 [==============================] - 7s 4ms/step - loss: 0.3498 - acc: 0.8311 - auc_roc: 0.8875 - val_loss: 2.3026 - val_acc: 0.6610 - val_auc_roc: 0.8900
Epoch 21/60
1652/1652 [==============================] - 7s 4ms/step - loss: 0.3398 - acc: 0.8366 - auc_roc: 0.8920 - val_loss: 2.4344 - val_acc: 0.6836 - val_auc_roc: 0.8943
Epoch 22/60
1652/1652 [==============================] - 7s 4ms/step - loss: 0.2897 - acc: 0.8602 - auc_roc: 0.8962 - val_loss: 2.9545 - val_acc: 0.6893 - val_auc_roc: 0.8985
Epoch 23/60
1652/1652 [==============================] - 7s 4ms/step - loss: 0.2371 - acc: 0.8898 - auc_roc: 0.9004 - val_loss: 2.3322 - val_acc: 0.6709 - val_auc_roc: 0.9025
Epoch 24/60
1652/1652 [==============================] - 7s 4ms/step - loss: 0.2362 - acc: 0.8850 - auc_roc: 0.9042 - val_loss: 2.6662 - val_acc: 0.6836 - val_auc_roc: 0.9061
Epoch 00024: early stopping
... history of metrics comprising: ['acc', 'loss', 'val_auc_roc', 'auc_roc', 'val_acc', 'val_loss']
... ... metric (acc): [0.71912832900917845, 0.73305084745762716, 0.73547215510800157, 0.77784503660825499, 0.81719128358162052, 0.83111380130846335, 0.83656174363004676, 0.86016949152542377, 0.88983050833025512, 0.88498789331814853] (n=24)
output> saving performance to:
/Users/pleiades/Documents/work/tpheno/seqmaker/data/CKD/plot/model_evalation-ep200b16.tif

... ... metric (loss): [0.56022225150761829, 0.53602751923531078, 0.52439237030597341, 0.44240318992813332, 0.36586865999219492, 0.34983896058206121, 0.33980494874730238, 0.28968457282311116, 0.23712113615098357, 0.23622498370833317] (n=24)
output> saving performance to:
/Users/pleiades/Documents/work/tpheno/seqmaker/data/CKD/plot/model_evalation-ep200b16.tif


model_selection> trying {'n_units': 400, 'dropout_rate': 0.5} ...

make_lstm> n_units=400, r_dropout=0.500000, n_layers=1, n_classes=6
  + lookup:
{'Others': 5, 'CKD Stage 5': 4, 'CKD Stage 4': 3, 'CKD Stage 3': 2, 'CKD Stage 2': 1, 'CKD Stage 1': 0}

... class weights:
{0: 6.344086021505376, 1: 0.74494949494949492, 2: 1.1238095238095238, 3: 7.0238095238095237, 4: 0.51890941072999119, 5: 0.64906490649064907}

====================================================================================================
... early stopping>
       + patience: 20, model='max'
... model training>
       + batch_size: 32, epochs: 60, shuffle? True, metric: auc_roc
====================================================================================================
Train on 1652 samples, validate on 708 samples
Epoch 1/60
1652/1652 [==============================] - 11s 7ms/step - loss: 1.6580 - acc: 0.3166 - auc_roc: 0.6115 - val_loss: 1.6529 - val_acc: 0.5537 - val_auc_roc: 0.7464
Epoch 2/60
1652/1652 [==============================] - 10s 6ms/step - loss: 1.4234 - acc: 0.4528 - auc_roc: 0.7680 - val_loss: 1.4432 - val_acc: 0.5932 - val_auc_roc: 0.7835
Epoch 3/60
1652/1652 [==============================] - 10s 6ms/step - loss: 1.2905 - acc: 0.4933 - auc_roc: 0.7924 - val_loss: 1.4098 - val_acc: 0.5763 - val_auc_roc: 0.8032
Epoch 4/60
1652/1652 [==============================] - 10s 6ms/step - loss: 1.1901 - acc: 0.5018 - auc_roc: 0.8091 - val_loss: 1.4827 - val_acc: 0.5311 - val_auc_roc: 0.8140
Epoch 5/60
1652/1652 [==============================] - 10s 6ms/step - loss: 1.2155 - acc: 0.4588 - auc_roc: 0.8129 - val_loss: 1.6658 - val_acc: 0.4534 - val_auc_roc: 0.8104
Epoch 6/60
1652/1652 [==============================] - 10s 6ms/step - loss: 1.0563 - acc: 0.5472 - auc_roc: 0.8128 - val_loss: 1.4716 - val_acc: 0.6257 - val_auc_roc: 0.8188
Epoch 7/60
1652/1652 [==============================] - 10s 6ms/step - loss: 1.0279 - acc: 0.5575 - auc_roc: 0.8236 - val_loss: 1.5937 - val_acc: 0.6893 - val_auc_roc: 0.8286
Epoch 8/60
1652/1652 [==============================] - 10s 6ms/step - loss: 0.9319 - acc: 0.5932 - auc_roc: 0.8336 - val_loss: 1.8060 - val_acc: 0.4986 - val_auc_roc: 0.8357
Epoch 9/60
1652/1652 [==============================] - 10s 6ms/step - loss: 0.8368 - acc: 0.6205 - auc_roc: 0.8382 - val_loss: 1.5588 - val_acc: 0.7105 - val_auc_roc: 0.8433
Epoch 10/60
1652/1652 [==============================] - 10s 6ms/step - loss: 0.8028 - acc: 0.6416 - auc_roc: 0.8478 - val_loss: 1.5730 - val_acc: 0.6638 - val_auc_roc: 0.8515
Epoch 11/60
1652/1652 [==============================] - 10s 6ms/step - loss: 0.7338 - acc: 0.6495 - auc_roc: 0.8548 - val_loss: 1.7682 - val_acc: 0.6511 - val_auc_roc: 0.8583
Epoch 12/60
1652/1652 [==============================] - 10s 6ms/step - loss: 0.6647 - acc: 0.6707 - auc_roc: 0.8613 - val_loss: 1.8347 - val_acc: 0.6864 - val_auc_roc: 0.8647
Epoch 13/60
1652/1652 [==============================] - 11s 7ms/step - loss: 0.6657 - acc: 0.6774 - auc_roc: 0.8675 - val_loss: 1.9988 - val_acc: 0.7133 - val_auc_roc: 0.8706
Epoch 14/60
1652/1652 [==============================] - 11s 7ms/step - loss: 0.6081 - acc: 0.7125 - auc_roc: 0.8732 - val_loss: 2.1435 - val_acc: 0.6554 - val_auc_roc: 0.8757
Epoch 15/60
1652/1652 [==============================] - 11s 7ms/step - loss: 0.5508 - acc: 0.7337 - auc_roc: 0.8780 - val_loss: 2.0302 - val_acc: 0.6864 - val_auc_roc: 0.8804
Epoch 16/60
1652/1652 [==============================] - 11s 6ms/step - loss: 0.5806 - acc: 0.7228 - auc_roc: 0.8823 - val_loss: 1.7195 - val_acc: 0.6554 - val_auc_roc: 0.8845
Epoch 17/60
1652/1652 [==============================] - 11s 6ms/step - loss: 0.5975 - acc: 0.7197 - auc_roc: 0.8861 - val_loss: 2.1456 - val_acc: 0.5805 - val_auc_roc: 0.8873
Epoch 18/60
1652/1652 [==============================] - 11s 7ms/step - loss: 0.5133 - acc: 0.7524 - auc_roc: 0.8885 - val_loss: 2.0747 - val_acc: 0.7316 - val_auc_roc: 0.8908
Epoch 19/60
1652/1652 [==============================] - 11s 7ms/step - loss: 0.4534 - acc: 0.7948 - auc_roc: 0.8929 - val_loss: 2.0148 - val_acc: 0.6497 - val_auc_roc: 0.8950
Epoch 20/60
1652/1652 [==============================] - 10s 6ms/step - loss: 0.4572 - acc: 0.7887 - auc_roc: 0.8965 - val_loss: 2.0559 - val_acc: 0.6977 - val_auc_roc: 0.8985
Epoch 21/60
1652/1652 [==============================] - 10s 6ms/step - loss: 0.3561 - acc: 0.8341 - auc_roc: 0.9003 - val_loss: 2.2067 - val_acc: 0.7203 - val_auc_roc: 0.9025
Epoch 22/60
1652/1652 [==============================] - 11s 6ms/step - loss: 0.3144 - acc: 0.8499 - auc_roc: 0.9041 - val_loss: 2.3083 - val_acc: 0.6808 - val_auc_roc: 0.9061
Epoch 23/60
1652/1652 [==============================] - 10s 6ms/step - loss: 0.3027 - acc: 0.8499 - auc_roc: 0.9076 - val_loss: 2.2942 - val_acc: 0.5763 - val_auc_roc: 0.9091
Epoch 00023: early stopping
... history of metrics comprising: ['acc', 'loss', 'val_auc_roc', 'auc_roc', 'val_acc', 'val_loss']
... ... metric (acc): [0.71246973351185316, 0.73365617447846165, 0.72276029026825839, 0.71973365588569183, 0.75242130750605329, 0.7947941888619855, 0.78874092038549459, 0.83414043597967225, 0.84987893448037621, 0.84987893491333966] (n=23)
output> saving performance to:
/Users/pleiades/Documents/work/tpheno/seqmaker/data/CKD/plot/model_evalation-ep200b16.tif

... ... metric (loss): [0.60808473089416726, 0.55082075907589445, 0.58061093294014365, 0.5974562673245446, 0.5133186900586828, 0.45339909073226964, 0.45722636125855526, 0.35611081051191462, 0.31442855684578275, 0.30274277377070874] (n=23)
output> saving performance to:
/Users/pleiades/Documents/work/tpheno/seqmaker/data/CKD/plot/model_evalation-ep200b16.tif


model_selection> trying {'n_units': 500, 'dropout_rate': 0.5} ...

make_lstm> n_units=500, r_dropout=0.500000, n_layers=1, n_classes=6
  + lookup:
{'Others': 5, 'CKD Stage 5': 4, 'CKD Stage 4': 3, 'CKD Stage 3': 2, 'CKD Stage 2': 1, 'CKD Stage 1': 0}

... class weights:
{0: 6.344086021505376, 1: 0.74494949494949492, 2: 1.1238095238095238, 3: 7.0238095238095237, 4: 0.51890941072999119, 5: 0.64906490649064907}

====================================================================================================
... early stopping>
       + patience: 20, model='max'
... model training>
       + batch_size: 32, epochs: 60, shuffle? True, metric: auc_roc
====================================================================================================
Train on 1652 samples, validate on 708 samples
Epoch 1/60
1652/1652 [==============================] - 17s 10ms/step - loss: 1.6551 - acc: 0.3269 - auc_roc: 0.6377 - val_loss: 1.7706 - val_acc: 0.3912 - val_auc_roc: 0.6967
Epoch 2/60
1652/1652 [==============================] - 15s 9ms/step - loss: 1.4152 - acc: 0.4522 - auc_roc: 0.7229 - val_loss: 1.4432 - val_acc: 0.6398 - val_auc_roc: 0.7566
Epoch 3/60
1652/1652 [==============================] - 15s 9ms/step - loss: 1.2683 - acc: 0.4764 - auc_roc: 0.7758 - val_loss: 1.4811 - val_acc: 0.6045 - val_auc_roc: 0.7843
Epoch 4/60
1652/1652 [==============================] - 16s 9ms/step - loss: 1.2446 - acc: 0.5387 - auc_roc: 0.7948 - val_loss: 1.8749 - val_acc: 0.4449 - val_auc_roc: 0.7972
Epoch 5/60
1652/1652 [==============================] - 16s 10ms/step - loss: 1.1579 - acc: 0.5188 - auc_roc: 0.7975 - val_loss: 1.6282 - val_acc: 0.5904 - val_auc_roc: 0.8058
Epoch 6/60
1652/1652 [==============================] - 16s 10ms/step - loss: 1.0465 - acc: 0.5460 - auc_roc: 0.8130 - val_loss: 1.6681 - val_acc: 0.5946 - val_auc_roc: 0.8184
Epoch 7/60
1652/1652 [==============================] - 15s 9ms/step - loss: 1.0501 - acc: 0.5169 - auc_roc: 0.8220 - val_loss: 1.8966 - val_acc: 0.4195 - val_auc_roc: 0.8212
Epoch 8/60
1652/1652 [==============================] - 16s 9ms/step - loss: 0.9054 - acc: 0.5932 - auc_roc: 0.8228 - val_loss: 1.6713 - val_acc: 0.6455 - val_auc_roc: 0.8278
Epoch 9/60
1652/1652 [==============================] - 16s 10ms/step - loss: 0.8528 - acc: 0.6156 - auc_roc: 0.8323 - val_loss: 1.5886 - val_acc: 0.6638 - val_auc_roc: 0.8367
Epoch 10/60
1652/1652 [==============================] - 16s 10ms/step - loss: 0.8076 - acc: 0.6338 - auc_roc: 0.8408 - val_loss: 1.7698 - val_acc: 0.6469 - val_auc_roc: 0.8449
Epoch 11/60
1652/1652 [==============================] - 16s 10ms/step - loss: 0.7337 - acc: 0.6610 - auc_roc: 0.8487 - val_loss: 1.7072 - val_acc: 0.6907 - val_auc_roc: 0.8528
Epoch 12/60
1652/1652 [==============================] - 16s 9ms/step - loss: 0.6915 - acc: 0.6749 - auc_roc: 0.8561 - val_loss: 1.9094 - val_acc: 0.6455 - val_auc_roc: 0.8595
Epoch 13/60
1652/1652 [==============================] - 16s 9ms/step - loss: 0.5982 - acc: 0.7004 - auc_roc: 0.8624 - val_loss: 2.0653 - val_acc: 0.6822 - val_auc_roc: 0.8660
Epoch 14/60
1652/1652 [==============================] - 15s 9ms/step - loss: 0.6926 - acc: 0.6846 - auc_roc: 0.8683 - val_loss: 1.9929 - val_acc: 0.6766 - val_auc_roc: 0.8709
Epoch 15/60
1652/1652 [==============================] - 15s 9ms/step - loss: 0.5891 - acc: 0.7070 - auc_roc: 0.8731 - val_loss: 2.1284 - val_acc: 0.6299 - val_auc_roc: 0.8754
Epoch 16/60
1652/1652 [==============================] - 14s 9ms/step - loss: 0.5155 - acc: 0.7458 - auc_roc: 0.8776 - val_loss: 1.9055 - val_acc: 0.7274 - val_auc_roc: 0.8807
Epoch 17/60
1652/1652 [==============================] - 16s 9ms/step - loss: 0.5160 - acc: 0.7682 - auc_roc: 0.8831 - val_loss: 2.1341 - val_acc: 0.6977 - val_auc_roc: 0.8856
Epoch 18/60
1652/1652 [==============================] - 15s 9ms/step - loss: 0.4212 - acc: 0.7972 - auc_roc: 0.8880 - val_loss: 1.9385 - val_acc: 0.6921 - val_auc_roc: 0.8905
Epoch 19/60
1652/1652 [==============================] - 15s 9ms/step - loss: 0.3411 - acc: 0.8414 - auc_roc: 0.8927 - val_loss: 2.0863 - val_acc: 0.6949 - val_auc_roc: 0.8953
Epoch 20/60
1652/1652 [==============================] - 20s 12ms/step - loss: 0.2935 - acc: 0.8644 - auc_roc: 0.8975 - val_loss: 2.3461 - val_acc: 0.7119 - val_auc_roc: 0.9001
Epoch 21/60
1652/1652 [==============================] - 18s 11ms/step - loss: 0.5777 - acc: 0.7312 - auc_roc: 0.9009 - val_loss: 1.9201 - val_acc: 0.6893 - val_auc_roc: 0.9021
Epoch 22/60
1652/1652 [==============================] - 18s 11ms/step - loss: 0.3241 - acc: 0.8462 - auc_roc: 0.9037 - val_loss: 2.4730 - val_acc: 0.6921 - val_auc_roc: 0.9056
Epoch 00022: early stopping
... history of metrics comprising: ['acc', 'loss', 'val_auc_roc', 'auc_roc', 'val_acc', 'val_loss']
... ... metric (acc): [0.70036319612590803, 0.68462469704791939, 0.70702179205619686, 0.74576271172008557, 0.76815980615107837, 0.7972154965123599, 0.84140435849783202, 0.86440677980533809, 0.73123486711672947, 0.84624697307697505] (n=22)
output> saving performance to:
/Users/pleiades/Documents/work/tpheno/seqmaker/data/CKD/plot/model_evalation-ep200b16.tif

... ... metric (loss): [0.59817922721474859, 0.69257252989900597, 0.58908287664879899, 0.51552065838913075, 0.51602632326883491, 0.42121936579304803, 0.3410707255396947, 0.29354967447516417, 0.57770168665823574, 0.32409710020332011] (n=22)
output> saving performance to:
/Users/pleiades/Documents/work/tpheno/seqmaker/data/CKD/plot/model_evalation-ep200b16.tif


model_selection> trying {'n_units': 50, 'dropout_rate': 0.6} ...

make_lstm> n_units=50, r_dropout=0.600000, n_layers=1, n_classes=6
  + lookup:
{'Others': 5, 'CKD Stage 5': 4, 'CKD Stage 4': 3, 'CKD Stage 3': 2, 'CKD Stage 2': 1, 'CKD Stage 1': 0}

... class weights:
{0: 6.344086021505376, 1: 0.74494949494949492, 2: 1.1238095238095238, 3: 7.0238095238095237, 4: 0.51890941072999119, 5: 0.64906490649064907}

====================================================================================================
... early stopping>
       + patience: 20, model='max'
... model training>
       + batch_size: 32, epochs: 60, shuffle? True, metric: auc_roc
====================================================================================================
Train on 1652 samples, validate on 708 samples
Epoch 1/60
1652/1652 [==============================] - 6s 4ms/step - loss: 1.7351 - acc: 0.2070 - auc_roc: 0.5127 - val_loss: 1.9144 - val_acc: 0.1102 - val_auc_roc: 0.5624
Epoch 2/60
1652/1652 [==============================] - 4s 2ms/step - loss: 1.6466 - acc: 0.3081 - auc_roc: 0.5957 - val_loss: 1.6973 - val_acc: 0.4718 - val_auc_roc: 0.6350
Epoch 3/60
1652/1652 [==============================] - 4s 2ms/step - loss: 1.5061 - acc: 0.3904 - auc_roc: 0.6631 - val_loss: 1.5498 - val_acc: 0.5212 - val_auc_roc: 0.6867
Epoch 4/60
1652/1652 [==============================] - 3s 2ms/step - loss: 1.4088 - acc: 0.4274 - auc_roc: 0.7044 - val_loss: 1.5237 - val_acc: 0.4379 - val_auc_roc: 0.7160
Epoch 5/60
1652/1652 [==============================] - 3s 2ms/step - loss: 1.3289 - acc: 0.4528 - auc_roc: 0.7241 - val_loss: 1.4182 - val_acc: 0.5791 - val_auc_roc: 0.7369
Epoch 6/60
1652/1652 [==============================] - 3s 2ms/step - loss: 1.2725 - acc: 0.5012 - auc_roc: 0.7465 - val_loss: 1.3889 - val_acc: 0.5833 - val_auc_roc: 0.7561
Epoch 7/60
1652/1652 [==============================] - 3s 2ms/step - loss: 1.1834 - acc: 0.5206 - auc_roc: 0.7638 - val_loss: 1.5510 - val_acc: 0.5254 - val_auc_roc: 0.7698
Epoch 8/60
1652/1652 [==============================] - 3s 2ms/step - loss: 1.1056 - acc: 0.5097 - auc_roc: 0.7742 - val_loss: 1.4786 - val_acc: 0.5989 - val_auc_roc: 0.7797
Epoch 9/60
1652/1652 [==============================] - 3s 2ms/step - loss: 1.0593 - acc: 0.5315 - auc_roc: 0.7852 - val_loss: 1.4930 - val_acc: 0.6780 - val_auc_roc: 0.7908
Epoch 10/60
1652/1652 [==============================] - 3s 2ms/step - loss: 1.0246 - acc: 0.5666 - auc_roc: 0.7963 - val_loss: 1.6051 - val_acc: 0.5734 - val_auc_roc: 0.7999
Epoch 11/60
1652/1652 [==============================] - 3s 2ms/step - loss: 1.0201 - acc: 0.5375 - auc_roc: 0.8031 - val_loss: 1.7086 - val_acc: 0.3701 - val_auc_roc: 0.8018
Epoch 12/60
1652/1652 [==============================] - 3s 2ms/step - loss: 0.9637 - acc: 0.5448 - auc_roc: 0.8016 - val_loss: 1.4100 - val_acc: 0.7147 - val_auc_roc: 0.8065
Epoch 13/60
1652/1652 [==============================] - 3s 2ms/step - loss: 0.9002 - acc: 0.6084 - auc_roc: 0.8109 - val_loss: 1.4118 - val_acc: 0.6653 - val_auc_roc: 0.8149
Epoch 14/60
1652/1652 [==============================] - 3s 2ms/step - loss: 0.8468 - acc: 0.6253 - auc_roc: 0.8187 - val_loss: 1.5700 - val_acc: 0.7218 - val_auc_roc: 0.8229
Epoch 15/60
1652/1652 [==============================] - 3s 2ms/step - loss: 0.8602 - acc: 0.6029 - auc_roc: 0.8263 - val_loss: 1.6390 - val_acc: 0.6314 - val_auc_roc: 0.8293
Epoch 16/60
1652/1652 [==============================] - 3s 2ms/step - loss: 0.8650 - acc: 0.6053 - auc_roc: 0.8314 - val_loss: 1.4125 - val_acc: 0.6794 - val_auc_roc: 0.8341
Epoch 17/60
1652/1652 [==============================] - 3s 2ms/step - loss: 0.7837 - acc: 0.6435 - auc_roc: 0.8367 - val_loss: 1.5116 - val_acc: 0.7062 - val_auc_roc: 0.8396
Epoch 18/60
1652/1652 [==============================] - 3s 2ms/step - loss: 0.7309 - acc: 0.6610 - auc_roc: 0.8423 - val_loss: 1.6543 - val_acc: 0.6992 - val_auc_roc: 0.8451
Epoch 19/60
1652/1652 [==============================] - 3s 2ms/step - loss: 0.7252 - acc: 0.6501 - auc_roc: 0.8473 - val_loss: 1.5755 - val_acc: 0.7020 - val_auc_roc: 0.8496
Epoch 20/60
1652/1652 [==============================] - 3s 2ms/step - loss: 0.7671 - acc: 0.6156 - auc_roc: 0.8515 - val_loss: 1.5241 - val_acc: 0.6723 - val_auc_roc: 0.8530
Epoch 21/60
1652/1652 [==============================] - 3s 2ms/step - loss: 0.7285 - acc: 0.6477 - auc_roc: 0.8546 - val_loss: 1.5328 - val_acc: 0.7203 - val_auc_roc: 0.8567
Epoch 22/60
1652/1652 [==============================] - 3s 2ms/step - loss: 0.7450 - acc: 0.6441 - auc_roc: 0.8582 - val_loss: 1.7751 - val_acc: 0.6836 - val_auc_roc: 0.8598
Epoch 23/60
1652/1652 [==============================] - 3s 2ms/step - loss: 0.6735 - acc: 0.6713 - auc_roc: 0.8612 - val_loss: 1.7307 - val_acc: 0.6935 - val_auc_roc: 0.8630
Epoch 24/60
1652/1652 [==============================] - 3s 2ms/step - loss: 0.6454 - acc: 0.6840 - auc_roc: 0.8646 - val_loss: 1.7379 - val_acc: 0.6935 - val_auc_roc: 0.8663
Epoch 25/60
1652/1652 [==============================] - 3s 2ms/step - loss: 0.6176 - acc: 0.7046 - auc_roc: 0.8677 - val_loss: 1.9422 - val_acc: 0.7147 - val_auc_roc: 0.8694
Epoch 26/60
1652/1652 [==============================] - 4s 2ms/step - loss: 0.6318 - acc: 0.6937 - auc_roc: 0.8706 - val_loss: 1.6337 - val_acc: 0.6737 - val_auc_roc: 0.8718
Epoch 00026: early stopping
... history of metrics comprising: ['acc', 'loss', 'val_auc_roc', 'auc_roc', 'val_acc', 'val_loss']
... ... metric (acc): [0.6434624700222985, 0.6610169492968635, 0.65012106523098145, 0.61561743312540118, 0.64769975758060705, 0.64406779661016944, 0.67130750605326872, 0.68401937060436957, 0.70460048440582235, 0.69370460019561919] (n=26)
output> saving performance to:
/Users/pleiades/Documents/work/tpheno/seqmaker/data/CKD/plot/model_evalation-ep200b16.tif

... ... metric (loss): [0.78373485053134018, 0.7309360618164118, 0.72517703563768698, 0.76713363815450786, 0.7285412394105667, 0.74499647265196423, 0.67354429908295232, 0.64537909966115514, 0.61759907844280215, 0.63182356571169795] (n=26)
output> saving performance to:
/Users/pleiades/Documents/work/tpheno/seqmaker/data/CKD/plot/model_evalation-ep200b16.tif


model_selection> trying {'n_units': 100, 'dropout_rate': 0.6} ...

make_lstm> n_units=100, r_dropout=0.600000, n_layers=1, n_classes=6
  + lookup:
{'Others': 5, 'CKD Stage 5': 4, 'CKD Stage 4': 3, 'CKD Stage 3': 2, 'CKD Stage 2': 1, 'CKD Stage 1': 0}

... class weights:
{0: 6.344086021505376, 1: 0.74494949494949492, 2: 1.1238095238095238, 3: 7.0238095238095237, 4: 0.51890941072999119, 5: 0.64906490649064907}

====================================================================================================
... early stopping>
       + patience: 20, model='max'
... model training>
       + batch_size: 32, epochs: 60, shuffle? True, metric: auc_roc
====================================================================================================
Train on 1652 samples, validate on 708 samples
Epoch 1/60
1652/1652 [==============================] - 7s 4ms/step - loss: 1.7300 - acc: 0.2506 - auc_roc: 0.5771 - val_loss: 1.9246 - val_acc: 0.1893 - val_auc_roc: 0.6044
Epoch 2/60
1652/1652 [==============================] - 4s 2ms/step - loss: 1.5376 - acc: 0.3789 - auc_roc: 0.6321 - val_loss: 1.8397 - val_acc: 0.3573 - val_auc_roc: 0.6580
Epoch 3/60
1652/1652 [==============================] - 4s 3ms/step - loss: 1.4029 - acc: 0.4449 - auc_roc: 0.6807 - val_loss: 1.7971 - val_acc: 0.4520 - val_auc_roc: 0.7002
Epoch 4/60
1652/1652 [==============================] - 5s 3ms/step - loss: 1.2923 - acc: 0.5024 - auc_roc: 0.7175 - val_loss: 1.4720 - val_acc: 0.6158 - val_auc_roc: 0.7379
Epoch 5/60
1652/1652 [==============================] - 4s 2ms/step - loss: 1.2029 - acc: 0.5109 - auc_roc: 0.7524 - val_loss: 1.4229 - val_acc: 0.5960 - val_auc_roc: 0.7648
Epoch 6/60
1652/1652 [==============================] - 4s 2ms/step - loss: 1.1108 - acc: 0.5109 - auc_roc: 0.7734 - val_loss: 1.5395 - val_acc: 0.6031 - val_auc_roc: 0.7823
Epoch 7/60
1652/1652 [==============================] - 4s 2ms/step - loss: 1.0733 - acc: 0.5357 - auc_roc: 0.7884 - val_loss: 1.6167 - val_acc: 0.4732 - val_auc_roc: 0.7931
Epoch 8/60
1652/1652 [==============================] - 4s 2ms/step - loss: 1.0371 - acc: 0.5297 - auc_roc: 0.7971 - val_loss: 1.6884 - val_acc: 0.6201 - val_auc_roc: 0.8017
Epoch 9/60
1652/1652 [==============================] - 4s 2ms/step - loss: 1.0040 - acc: 0.5515 - auc_roc: 0.8065 - val_loss: 1.3946 - val_acc: 0.6653 - val_auc_roc: 0.8121
Epoch 10/60
1652/1652 [==============================] - 4s 2ms/step - loss: 0.9047 - acc: 0.5884 - auc_roc: 0.8166 - val_loss: 1.7242 - val_acc: 0.6638 - val_auc_roc: 0.8217
Epoch 11/60
1652/1652 [==============================] - 4s 2ms/step - loss: 0.8769 - acc: 0.6059 - auc_roc: 0.8257 - val_loss: 1.6935 - val_acc: 0.6370 - val_auc_roc: 0.8294
Epoch 12/60
1652/1652 [==============================] - 4s 2ms/step - loss: 0.8216 - acc: 0.6144 - auc_roc: 0.8330 - val_loss: 2.0089 - val_acc: 0.5212 - val_auc_roc: 0.8351
Epoch 13/60
1652/1652 [==============================] - 4s 2ms/step - loss: 0.7917 - acc: 0.6132 - auc_roc: 0.8373 - val_loss: 1.6720 - val_acc: 0.6257 - val_auc_roc: 0.8400
Epoch 14/60
1652/1652 [==============================] - 4s 2ms/step - loss: 0.7481 - acc: 0.6459 - auc_roc: 0.8427 - val_loss: 1.7952 - val_acc: 0.6144 - val_auc_roc: 0.8455
Epoch 15/60
1652/1652 [==============================] - 4s 2ms/step - loss: 0.7119 - acc: 0.6743 - auc_roc: 0.8480 - val_loss: 2.0911 - val_acc: 0.6059 - val_auc_roc: 0.8504
Epoch 16/60
1652/1652 [==============================] - 4s 2ms/step - loss: 0.7061 - acc: 0.6429 - auc_roc: 0.8526 - val_loss: 1.8650 - val_acc: 0.5593 - val_auc_roc: 0.8545
Epoch 17/60
1652/1652 [==============================] - 3s 2ms/step - loss: 0.7184 - acc: 0.6580 - auc_roc: 0.8559 - val_loss: 1.7186 - val_acc: 0.6921 - val_auc_roc: 0.8585
Epoch 18/60
1652/1652 [==============================] - 4s 2ms/step - loss: 0.6468 - acc: 0.6858 - auc_roc: 0.8608 - val_loss: 1.7494 - val_acc: 0.6638 - val_auc_roc: 0.8631
Epoch 19/60
1652/1652 [==============================] - 4s 2ms/step - loss: 0.7449 - acc: 0.6586 - auc_roc: 0.8646 - val_loss: 1.7753 - val_acc: 0.6144 - val_auc_roc: 0.8660
Epoch 20/60
1652/1652 [==============================] - 4s 2ms/step - loss: 0.6106 - acc: 0.6973 - auc_roc: 0.8675 - val_loss: 2.0238 - val_acc: 0.6751 - val_auc_roc: 0.8695
Epoch 21/60
1652/1652 [==============================] - 4s 2ms/step - loss: 0.5868 - acc: 0.7052 - auc_roc: 0.8710 - val_loss: 2.0690 - val_acc: 0.6766 - val_auc_roc: 0.8729
Epoch 22/60
1652/1652 [==============================] - 4s 2ms/step - loss: 0.5644 - acc: 0.7258 - auc_roc: 0.8744 - val_loss: 2.0901 - val_acc: 0.6582 - val_auc_roc: 0.8761
Epoch 23/60
1652/1652 [==============================] - 4s 2ms/step - loss: 0.5950 - acc: 0.7125 - auc_roc: 0.8774 - val_loss: 2.1699 - val_acc: 0.6554 - val_auc_roc: 0.8788
Epoch 24/60
1652/1652 [==============================] - 4s 2ms/step - loss: 0.6647 - acc: 0.6531 - auc_roc: 0.8794 - val_loss: 2.2931 - val_acc: 0.5551 - val_auc_roc: 0.8799
Epoch 25/60
1652/1652 [==============================] - 3s 2ms/step - loss: 0.5956 - acc: 0.7094 - auc_roc: 0.8805 - val_loss: 2.1028 - val_acc: 0.6511 - val_auc_roc: 0.8817
Epoch 26/60
1652/1652 [==============================] - 4s 2ms/step - loss: 0.4879 - acc: 0.7573 - auc_roc: 0.8829 - val_loss: 2.2006 - val_acc: 0.6935 - val_auc_roc: 0.8845
Epoch 27/60
1652/1652 [==============================] - 4s 2ms/step - loss: 0.4736 - acc: 0.7718 - auc_roc: 0.8858 - val_loss: 2.0951 - val_acc: 0.7020 - val_auc_roc: 0.8873
Epoch 28/60
1652/1652 [==============================] - 4s 2ms/step - loss: 0.4209 - acc: 0.7887 - auc_roc: 0.8886 - val_loss: 2.4130 - val_acc: 0.6398 - val_auc_roc: 0.8899
Epoch 29/60
1652/1652 [==============================] - 3s 2ms/step - loss: 0.4461 - acc: 0.7663 - auc_roc: 0.8909 - val_loss: 2.4156 - val_acc: 0.6808 - val_auc_roc: 0.8921
Epoch 00029: early stopping
... history of metrics comprising: ['acc', 'loss', 'val_auc_roc', 'auc_roc', 'val_acc', 'val_loss']
... ... metric (acc): [0.69733656188766258, 0.70520581099369339, 0.72578692465082495, 0.71246973336753194, 0.65314770004651157, 0.70944309956225005, 0.75726392222951744, 0.77179176769880065, 0.78874091980820993, 0.76634382581018079] (n=29)
output> saving performance to:
/Users/pleiades/Documents/work/tpheno/seqmaker/data/CKD/plot/model_evalation-ep200b16.tif

... ... metric (loss): [0.61059774512528797, 0.58682174399747689, 0.5643641203281089, 0.5949751148789616, 0.6647436895901585, 0.59562775860687145, 0.48789229823082469, 0.47361561692078524, 0.4208602870636356, 0.44609377069565631] (n=29)
output> saving performance to:
/Users/pleiades/Documents/work/tpheno/seqmaker/data/CKD/plot/model_evalation-ep200b16.tif


model_selection> trying {'n_units': 200, 'dropout_rate': 0.6} ...

make_lstm> n_units=200, r_dropout=0.600000, n_layers=1, n_classes=6
  + lookup:
{'Others': 5, 'CKD Stage 5': 4, 'CKD Stage 4': 3, 'CKD Stage 3': 2, 'CKD Stage 2': 1, 'CKD Stage 1': 0}

... class weights:
{0: 6.344086021505376, 1: 0.74494949494949492, 2: 1.1238095238095238, 3: 7.0238095238095237, 4: 0.51890941072999119, 5: 0.64906490649064907}

====================================================================================================
... early stopping>
       + patience: 20, model='max'
... model training>
       + batch_size: 32, epochs: 60, shuffle? True, metric: auc_roc
====================================================================================================
Train on 1652 samples, validate on 708 samples
Epoch 1/60
1652/1652 [==============================] - 7s 4ms/step - loss: 1.6853 - acc: 0.2809 - auc_roc: 0.6014 - val_loss: 1.7236 - val_acc: 0.5381 - val_auc_roc: 0.6899
Epoch 2/60
1652/1652 [==============================] - 5s 3ms/step - loss: 1.4818 - acc: 0.4352 - auc_roc: 0.7262 - val_loss: 1.9223 - val_acc: 0.2020 - val_auc_roc: 0.7098
Epoch 3/60
1652/1652 [==============================] - 5s 3ms/step - loss: 1.4008 - acc: 0.4171 - auc_roc: 0.6968 - val_loss: 1.4894 - val_acc: 0.6045 - val_auc_roc: 0.7218
Epoch 4/60
1652/1652 [==============================] - 5s 3ms/step - loss: 1.3554 - acc: 0.4594 - auc_roc: 0.7376 - val_loss: 1.4885 - val_acc: 0.5650 - val_auc_roc: 0.7443
Epoch 5/60
1652/1652 [==============================] - 5s 3ms/step - loss: 1.1585 - acc: 0.5012 - auc_roc: 0.7548 - val_loss: 1.3602 - val_acc: 0.6116 - val_auc_roc: 0.7669
Epoch 6/60
1652/1652 [==============================] - 5s 3ms/step - loss: 1.1554 - acc: 0.4909 - auc_roc: 0.7752 - val_loss: 1.4285 - val_acc: 0.6667 - val_auc_roc: 0.7853
Epoch 7/60
1652/1652 [==============================] - 5s 3ms/step - loss: 1.0535 - acc: 0.5454 - auc_roc: 0.7938 - val_loss: 1.6844 - val_acc: 0.6398 - val_auc_roc: 0.8003
Epoch 8/60
1652/1652 [==============================] - 5s 3ms/step - loss: 0.9830 - acc: 0.5714 - auc_roc: 0.8059 - val_loss: 1.6202 - val_acc: 0.6780 - val_auc_roc: 0.8123
Epoch 9/60
1652/1652 [==============================] - 4s 3ms/step - loss: 0.9105 - acc: 0.5781 - auc_roc: 0.8178 - val_loss: 1.7331 - val_acc: 0.6794 - val_auc_roc: 0.8230
Epoch 10/60
1652/1652 [==============================] - 5s 3ms/step - loss: 0.8653 - acc: 0.5944 - auc_roc: 0.8277 - val_loss: 1.4452 - val_acc: 0.6681 - val_auc_roc: 0.8323
Epoch 11/60
1652/1652 [==============================] - 4s 3ms/step - loss: 0.8374 - acc: 0.6186 - auc_roc: 0.8363 - val_loss: 1.5295 - val_acc: 0.7147 - val_auc_roc: 0.8405
Epoch 12/60
1652/1652 [==============================] - 5s 3ms/step - loss: 0.8528 - acc: 0.5950 - auc_roc: 0.8435 - val_loss: 1.9134 - val_acc: 0.5749 - val_auc_roc: 0.8456
Epoch 13/60
1652/1652 [==============================] - 5s 3ms/step - loss: 0.8023 - acc: 0.6168 - auc_roc: 0.8473 - val_loss: 1.7354 - val_acc: 0.6864 - val_auc_roc: 0.8502
Epoch 14/60
1652/1652 [==============================] - 4s 3ms/step - loss: 0.7359 - acc: 0.6483 - auc_roc: 0.8528 - val_loss: 1.6038 - val_acc: 0.6963 - val_auc_roc: 0.8559
Epoch 15/60
1652/1652 [==============================] - 4s 3ms/step - loss: 0.6730 - acc: 0.6755 - auc_roc: 0.8586 - val_loss: 1.9142 - val_acc: 0.7232 - val_auc_roc: 0.8617
Epoch 16/60
1652/1652 [==============================] - 5s 3ms/step - loss: 0.6372 - acc: 0.6846 - auc_roc: 0.8643 - val_loss: 2.2009 - val_acc: 0.6977 - val_auc_roc: 0.8668
Epoch 17/60
1652/1652 [==============================] - 5s 3ms/step - loss: 0.6099 - acc: 0.7016 - auc_roc: 0.8690 - val_loss: 2.0743 - val_acc: 0.7034 - val_auc_roc: 0.8714
Epoch 18/60
1652/1652 [==============================] - 5s 3ms/step - loss: 0.5486 - acc: 0.7343 - auc_roc: 0.8735 - val_loss: 2.1155 - val_acc: 0.7147 - val_auc_roc: 0.8760
Epoch 19/60
1652/1652 [==============================] - 5s 3ms/step - loss: 0.5582 - acc: 0.7264 - auc_roc: 0.8779 - val_loss: 2.2249 - val_acc: 0.6963 - val_auc_roc: 0.8800
Epoch 20/60
1652/1652 [==============================] - 5s 3ms/step - loss: 0.5238 - acc: 0.7403 - auc_roc: 0.8816 - val_loss: 2.3113 - val_acc: 0.7203 - val_auc_roc: 0.8836
Epoch 21/60
1652/1652 [==============================] - 4s 3ms/step - loss: 0.4666 - acc: 0.7688 - auc_roc: 0.8854 - val_loss: 2.5191 - val_acc: 0.7189 - val_auc_roc: 0.8874
Epoch 22/60
1652/1652 [==============================] - 5s 3ms/step - loss: 0.4338 - acc: 0.7990 - auc_roc: 0.8890 - val_loss: 2.1206 - val_acc: 0.7034 - val_auc_roc: 0.8909
Epoch 23/60
1652/1652 [==============================] - 4s 3ms/step - loss: 0.3930 - acc: 0.8063 - auc_roc: 0.8926 - val_loss: 2.4018 - val_acc: 0.7119 - val_auc_roc: 0.8945
Epoch 24/60
1652/1652 [==============================] - 4s 3ms/step - loss: 0.3685 - acc: 0.8299 - auc_roc: 0.8961 - val_loss: 2.3468 - val_acc: 0.6893 - val_auc_roc: 0.8978
Epoch 25/60
1652/1652 [==============================] - 4s 3ms/step - loss: 0.3893 - acc: 0.8027 - auc_roc: 0.8990 - val_loss: 2.5991 - val_acc: 0.7218 - val_auc_roc: 0.9006
Epoch 00025: early stopping
... history of metrics comprising: ['acc', 'loss', 'val_auc_roc', 'auc_roc', 'val_acc', 'val_loss']
... ... metric (acc): [0.68462469762520406, 0.70157384959029223, 0.73426150092201137, 0.72639225181598066, 0.74031477026442927, 0.76876513317191286, 0.79903147670893637, 0.8062953996600597, 0.82990314769975781, 0.8026634379680162] (n=25)
output> saving performance to:
/Users/pleiades/Documents/work/tpheno/seqmaker/data/CKD/plot/model_evalation-ep200b16.tif

... ... metric (loss): [0.6372374796982827, 0.60993677796232215, 0.54863012125647959, 0.55819434165665949, 0.52375886876127042, 0.466620949870449, 0.43382806076553199, 0.39298417110708667, 0.36850038322351747, 0.38926875944864953] (n=25)
output> saving performance to:
/Users/pleiades/Documents/work/tpheno/seqmaker/data/CKD/plot/model_evalation-ep200b16.tif


model_selection> trying {'n_units': 300, 'dropout_rate': 0.6} ...

make_lstm> n_units=300, r_dropout=0.600000, n_layers=1, n_classes=6
  + lookup:
{'Others': 5, 'CKD Stage 5': 4, 'CKD Stage 4': 3, 'CKD Stage 3': 2, 'CKD Stage 2': 1, 'CKD Stage 1': 0}

... class weights:
{0: 6.344086021505376, 1: 0.74494949494949492, 2: 1.1238095238095238, 3: 7.0238095238095237, 4: 0.51890941072999119, 5: 0.64906490649064907}

====================================================================================================
... early stopping>
       + patience: 20, model='max'
... model training>
       + batch_size: 32, epochs: 60, shuffle? True, metric: auc_roc
====================================================================================================
Train on 1652 samples, validate on 708 samples
Epoch 1/60
1652/1652 [==============================] - 9s 6ms/step - loss: 1.6666 - acc: 0.3172 - auc_roc: 0.6114 - val_loss: 1.7195 - val_acc: 0.3898 - val_auc_roc: 0.6838
Epoch 2/60
1652/1652 [==============================] - 7s 4ms/step - loss: 1.4234 - acc: 0.4340 - auc_roc: 0.7085 - val_loss: 1.8212 - val_acc: 0.3107 - val_auc_roc: 0.7186
Epoch 3/60
1652/1652 [==============================] - 7s 4ms/step - loss: 1.3749 - acc: 0.4340 - auc_roc: 0.7286 - val_loss: 1.5988 - val_acc: 0.2712 - val_auc_roc: 0.7292
Epoch 4/60
1652/1652 [==============================] - 7s 4ms/step - loss: 1.2719 - acc: 0.4824 - auc_roc: 0.7362 - val_loss: 1.7695 - val_acc: 0.4732 - val_auc_roc: 0.7465
Epoch 5/60
1652/1652 [==============================] - 7s 4ms/step - loss: 1.1022 - acc: 0.5212 - auc_roc: 0.7547 - val_loss: 1.3279 - val_acc: 0.6497 - val_auc_roc: 0.7696
Epoch 6/60
1652/1652 [==============================] - 7s 4ms/step - loss: 1.0936 - acc: 0.5315 - auc_roc: 0.7806 - val_loss: 1.3286 - val_acc: 0.5918 - val_auc_roc: 0.7889
Epoch 7/60
1652/1652 [==============================] - 7s 4ms/step - loss: 0.9985 - acc: 0.5581 - auc_roc: 0.7961 - val_loss: 1.5820 - val_acc: 0.6271 - val_auc_roc: 0.8027
Epoch 8/60
1652/1652 [==============================] - 7s 4ms/step - loss: 0.9272 - acc: 0.5944 - auc_roc: 0.8091 - val_loss: 1.9103 - val_acc: 0.6568 - val_auc_roc: 0.8156
Epoch 9/60
1652/1652 [==============================] - 7s 4ms/step - loss: 0.8504 - acc: 0.6011 - auc_roc: 0.8205 - val_loss: 2.1234 - val_acc: 0.6045 - val_auc_roc: 0.8252
Epoch 10/60
1652/1652 [==============================] - 7s 4ms/step - loss: 0.8544 - acc: 0.5932 - auc_roc: 0.8287 - val_loss: 1.5344 - val_acc: 0.6751 - val_auc_roc: 0.8332
Epoch 11/60
1652/1652 [==============================] - 8s 5ms/step - loss: 0.8207 - acc: 0.5993 - auc_roc: 0.8367 - val_loss: 2.3081 - val_acc: 0.6045 - val_auc_roc: 0.8394
Epoch 12/60
1652/1652 [==============================] - 7s 4ms/step - loss: 0.7458 - acc: 0.6441 - auc_roc: 0.8423 - val_loss: 1.8164 - val_acc: 0.6850 - val_auc_roc: 0.8463
Epoch 13/60
1652/1652 [==============================] - 7s 4ms/step - loss: 0.7113 - acc: 0.6513 - auc_roc: 0.8496 - val_loss: 1.8215 - val_acc: 0.6554 - val_auc_roc: 0.8527
Epoch 14/60
1652/1652 [==============================] - 7s 4ms/step - loss: 0.6477 - acc: 0.6731 - auc_roc: 0.8555 - val_loss: 1.9507 - val_acc: 0.6879 - val_auc_roc: 0.8588
Epoch 15/60
1652/1652 [==============================] - 7s 4ms/step - loss: 0.5983 - acc: 0.6949 - auc_roc: 0.8616 - val_loss: 1.8828 - val_acc: 0.6808 - val_auc_roc: 0.8644
Epoch 16/60
1652/1652 [==============================] - 7s 4ms/step - loss: 0.5809 - acc: 0.7125 - auc_roc: 0.8670 - val_loss: 2.3341 - val_acc: 0.6907 - val_auc_roc: 0.8695
Epoch 17/60
1652/1652 [==============================] - 8s 5ms/step - loss: 0.6181 - acc: 0.6943 - auc_roc: 0.8713 - val_loss: 1.7932 - val_acc: 0.6356 - val_auc_roc: 0.8734
Epoch 18/60
1652/1652 [==============================] - 9s 5ms/step - loss: 0.7104 - acc: 0.6689 - auc_roc: 0.8748 - val_loss: 1.7769 - val_acc: 0.6893 - val_auc_roc: 0.8766
Epoch 19/60
1652/1652 [==============================] - 8s 5ms/step - loss: 0.5541 - acc: 0.7324 - auc_roc: 0.8785 - val_loss: 1.9031 - val_acc: 0.6653 - val_auc_roc: 0.8806
Epoch 20/60
1652/1652 [==============================] - 7s 4ms/step - loss: 0.4827 - acc: 0.7700 - auc_roc: 0.8825 - val_loss: 2.1161 - val_acc: 0.6836 - val_auc_roc: 0.8847
Epoch 21/60
1652/1652 [==============================] - 6s 4ms/step - loss: 0.4162 - acc: 0.7948 - auc_roc: 0.8867 - val_loss: 2.3283 - val_acc: 0.6992 - val_auc_roc: 0.8889
Epoch 22/60
1652/1652 [==============================] - 6s 4ms/step - loss: 0.3542 - acc: 0.8214 - auc_roc: 0.8908 - val_loss: 2.3407 - val_acc: 0.7133 - val_auc_roc: 0.8930
Epoch 23/60
1652/1652 [==============================] - 6s 4ms/step - loss: 0.4454 - acc: 0.8008 - auc_roc: 0.8946 - val_loss: 2.4275 - val_acc: 0.7133 - val_auc_roc: 0.8965
Epoch 24/60
1652/1652 [==============================] - 6520s 4s/step - loss: 0.3839 - acc: 0.8257 - auc_roc: 0.8979 - val_loss: 2.2081 - val_acc: 0.7090 - val_auc_roc: 0.8998
Epoch 25/60
1652/1652 [==============================] - 6s 4ms/step - loss: 0.3174 - acc: 0.8692 - auc_roc: 0.9015 - val_loss: 2.4227 - val_acc: 0.6992 - val_auc_roc: 0.9032
Epoch 00025: early stopping
... history of metrics comprising: ['acc', 'loss', 'val_auc_roc', 'auc_roc', 'val_acc', 'val_loss']
... ... metric (acc): [0.71246973336753194, 0.69430992764941712, 0.66888619825857309, 0.73244552029247145, 0.76997578678061829, 0.7947941888619855, 0.82142857113992906, 0.80084745777143984, 0.8256658594198435, 0.86924939438448112] (n=25)
output> saving performance to:
/Users/pleiades/Documents/work/tpheno/seqmaker/data/CKD/plot/model_evalation-ep200b16.tif

... ... metric (loss): [0.58089322876410676, 0.61808679626293972, 0.71041708131102033, 0.55407612253043614, 0.48269974766862883, 0.41617245326319274, 0.35424675346864049, 0.44544317603977196, 0.3838569114196676, 0.31743195486992382] (n=25)
output> saving performance to:
/Users/pleiades/Documents/work/tpheno/seqmaker/data/CKD/plot/model_evalation-ep200b16.tif


model_selection> trying {'n_units': 400, 'dropout_rate': 0.6} ...

make_lstm> n_units=400, r_dropout=0.600000, n_layers=1, n_classes=6
  + lookup:
{'Others': 5, 'CKD Stage 5': 4, 'CKD Stage 4': 3, 'CKD Stage 3': 2, 'CKD Stage 2': 1, 'CKD Stage 1': 0}

... class weights:
{0: 6.344086021505376, 1: 0.74494949494949492, 2: 1.1238095238095238, 3: 7.0238095238095237, 4: 0.51890941072999119, 5: 0.64906490649064907}

====================================================================================================
... early stopping>
       + patience: 20, model='max'
... model training>
       + batch_size: 32, epochs: 60, shuffle? True, metric: auc_roc
====================================================================================================
Train on 1652 samples, validate on 708 samples
Epoch 1/60
1652/1652 [==============================] - 11s 7ms/step - loss: 1.6683 - acc: 0.2918 - auc_roc: 0.6166 - val_loss: 1.7488 - val_acc: 0.3785 - val_auc_roc: 0.6858
Epoch 2/60
1652/1652 [==============================] - 8s 5ms/step - loss: 1.4858 - acc: 0.3783 - auc_roc: 0.6930 - val_loss: 1.4536 - val_acc: 0.6045 - val_auc_roc: 0.7240
Epoch 3/60
1652/1652 [==============================] - 8s 5ms/step - loss: 1.4250 - acc: 0.4140 - auc_roc: 0.7434 - val_loss: 1.8202 - val_acc: 0.4859 - val_auc_roc: 0.7458
Epoch 4/60
1652/1652 [==============================] - 9s 6ms/step - loss: 1.3216 - acc: 0.4292 - auc_roc: 0.7531 - val_loss: 1.4064 - val_acc: 0.5678 - val_auc_roc: 0.7614
Epoch 5/60
1652/1652 [==============================] - 9s 5ms/step - loss: 1.1499 - acc: 0.4933 - auc_roc: 0.7717 - val_loss: 1.4519 - val_acc: 0.5212 - val_auc_roc: 0.7805
Epoch 6/60
1652/1652 [==============================] - 9s 6ms/step - loss: 1.0951 - acc: 0.5418 - auc_roc: 0.7876 - val_loss: 1.3949 - val_acc: 0.6186 - val_auc_roc: 0.7955
Epoch 7/60
1652/1652 [==============================] - 9s 5ms/step - loss: 1.0089 - acc: 0.5593 - auc_roc: 0.8021 - val_loss: 1.7697 - val_acc: 0.5664 - val_auc_roc: 0.8068
Epoch 8/60
1652/1652 [==============================] - 9s 5ms/step - loss: 0.9473 - acc: 0.5672 - auc_roc: 0.8118 - val_loss: 1.6960 - val_acc: 0.5777 - val_auc_roc: 0.8167
Epoch 9/60
1652/1652 [==============================] - 8s 5ms/step - loss: 0.9052 - acc: 0.5811 - auc_roc: 0.8211 - val_loss: 1.7926 - val_acc: 0.6285 - val_auc_roc: 0.8254
Epoch 10/60
1652/1652 [==============================] - 8s 5ms/step - loss: 0.8445 - acc: 0.6053 - auc_roc: 0.8295 - val_loss: 1.7635 - val_acc: 0.5127 - val_auc_roc: 0.8320
Epoch 11/60
1652/1652 [==============================] - 8s 5ms/step - loss: 0.8192 - acc: 0.5775 - auc_roc: 0.8338 - val_loss: 2.1668 - val_acc: 0.4011 - val_auc_roc: 0.8346
Epoch 12/60
1652/1652 [==============================] - 9s 5ms/step - loss: 0.8343 - acc: 0.6162 - auc_roc: 0.8353 - val_loss: 1.8770 - val_acc: 0.6653 - val_auc_roc: 0.8386
Epoch 13/60
1652/1652 [==============================] - 9s 5ms/step - loss: 0.7060 - acc: 0.6525 - auc_roc: 0.8421 - val_loss: 2.0557 - val_acc: 0.6695 - val_auc_roc: 0.8459
Epoch 14/60
1652/1652 [==============================] - 9s 5ms/step - loss: 0.6611 - acc: 0.6895 - auc_roc: 0.8492 - val_loss: 1.9522 - val_acc: 0.6441 - val_auc_roc: 0.8525
Epoch 15/60
1652/1652 [==============================] - 9s 6ms/step - loss: 0.6064 - acc: 0.7064 - auc_roc: 0.8553 - val_loss: 2.1695 - val_acc: 0.7006 - val_auc_roc: 0.8587
Epoch 16/60
1652/1652 [==============================] - 9s 5ms/step - loss: 0.5268 - acc: 0.7421 - auc_roc: 0.8617 - val_loss: 2.4905 - val_acc: 0.6441 - val_auc_roc: 0.8648
Epoch 17/60
1652/1652 [==============================] - 9s 5ms/step - loss: 0.5263 - acc: 0.7403 - auc_roc: 0.8671 - val_loss: 2.4252 - val_acc: 0.4661 - val_auc_roc: 0.8685
Epoch 18/60
1652/1652 [==============================] - 8s 5ms/step - loss: 0.6590 - acc: 0.6913 - auc_roc: 0.8690 - val_loss: 1.8128 - val_acc: 0.6751 - val_auc_roc: 0.8712
Epoch 19/60
1652/1652 [==============================] - 8s 5ms/step - loss: 0.5244 - acc: 0.7415 - auc_roc: 0.8732 - val_loss: 2.2238 - val_acc: 0.6780 - val_auc_roc: 0.8756
Epoch 20/60
1652/1652 [==============================] - 9s 5ms/step - loss: 0.4356 - acc: 0.7875 - auc_roc: 0.8780 - val_loss: 2.4907 - val_acc: 0.6695 - val_auc_roc: 0.8802
Epoch 21/60
1652/1652 [==============================] - 8s 5ms/step - loss: 0.3874 - acc: 0.8148 - auc_roc: 0.8821 - val_loss: 2.4703 - val_acc: 0.6794 - val_auc_roc: 0.8845
Epoch 22/60
1652/1652 [==============================] - 8s 5ms/step - loss: 0.5944 - acc: 0.7730 - auc_roc: 0.8862 - val_loss: 1.9267 - val_acc: 0.6624 - val_auc_roc: 0.8877
Epoch 23/60
1652/1652 [==============================] - 10s 6ms/step - loss: 0.4433 - acc: 0.8057 - auc_roc: 0.8894 - val_loss: 2.3381 - val_acc: 0.6638 - val_auc_roc: 0.8912
Epoch 24/60
1652/1652 [==============================] - 9s 5ms/step - loss: 0.3316 - acc: 0.8462 - auc_roc: 0.8929 - val_loss: 2.3135 - val_acc: 0.7076 - val_auc_roc: 0.8950
Epoch 25/60
1652/1652 [==============================] - 9s 5ms/step - loss: 0.3172 - acc: 0.8541 - auc_roc: 0.8966 - val_loss: 2.5772 - val_acc: 0.6836 - val_auc_roc: 0.8985
Epoch 26/60
1652/1652 [==============================] - 9s 5ms/step - loss: 0.2274 - acc: 0.8892 - auc_roc: 0.9002 - val_loss: 2.6340 - val_acc: 0.6921 - val_auc_roc: 0.9022
Epoch 00026: early stopping
... history of metrics comprising: ['acc', 'loss', 'val_auc_roc', 'auc_roc', 'val_acc', 'val_loss']
... ... metric (acc): [0.7403147696871446, 0.69128329297820823, 0.74152542401745591, 0.78753026663246806, 0.81476997564260378, 0.77300242130750607, 0.80569007249490399, 0.84624697322129627, 0.8541162224716482, 0.8892251818867053] (n=26)
output> saving performance to:
/Users/pleiades/Documents/work/tpheno/seqmaker/data/CKD/plot/model_evalation-ep200b16.tif

... ... metric (loss): [0.52627466810240298, 0.65899510100736458, 0.52444734397292425, 0.43555479065557945, 0.38736187567433777, 0.59442402779623038, 0.44332746602143847, 0.33163546931368387, 0.31716611281434215, 0.22737155526371325] (n=26)
output> saving performance to:
/Users/pleiades/Documents/work/tpheno/seqmaker/data/CKD/plot/model_evalation-ep200b16.tif


model_selection> trying {'n_units': 500, 'dropout_rate': 0.6} ...

make_lstm> n_units=500, r_dropout=0.600000, n_layers=1, n_classes=6
  + lookup:
{'Others': 5, 'CKD Stage 5': 4, 'CKD Stage 4': 3, 'CKD Stage 3': 2, 'CKD Stage 2': 1, 'CKD Stage 1': 0}

... class weights:
{0: 6.344086021505376, 1: 0.74494949494949492, 2: 1.1238095238095238, 3: 7.0238095238095237, 4: 0.51890941072999119, 5: 0.64906490649064907}

====================================================================================================
... early stopping>
       + patience: 20, model='max'
... model training>
       + batch_size: 32, epochs: 60, shuffle? True, metric: auc_roc
====================================================================================================
Train on 1652 samples, validate on 708 samples
Epoch 1/60
1652/1652 [==============================] - 16s 10ms/step - loss: 1.6467 - acc: 0.3015 - auc_roc: 0.6612 - val_loss: 1.7299 - val_acc: 0.2895 - val_auc_roc: 0.6857
Epoch 2/60
1652/1652 [==============================] - 14s 8ms/step - loss: 1.4198 - acc: 0.4510 - auc_roc: 0.7151 - val_loss: 1.2008 - val_acc: 0.6257 - val_auc_roc: 0.7499
Epoch 3/60
1652/1652 [==============================] - 13s 8ms/step - loss: 1.3238 - acc: 0.4576 - auc_roc: 0.7684 - val_loss: 1.4482 - val_acc: 0.6271 - val_auc_roc: 0.7823
Epoch 4/60
1652/1652 [==============================] - 12s 8ms/step - loss: 1.2469 - acc: 0.4921 - auc_roc: 0.7913 - val_loss: 1.6392 - val_acc: 0.4915 - val_auc_roc: 0.7971
Epoch 5/60
1652/1652 [==============================] - 12s 7ms/step - loss: 1.2476 - acc: 0.4437 - auc_roc: 0.7986 - val_loss: 1.7277 - val_acc: 0.4647 - val_auc_roc: 0.7988
Epoch 6/60
1652/1652 [==============================] - 13s 8ms/step - loss: 1.1434 - acc: 0.5121 - auc_roc: 0.8016 - val_loss: 1.6751 - val_acc: 0.4251 - val_auc_roc: 0.8028
Epoch 7/60
1652/1652 [==============================] - 13s 8ms/step - loss: 1.0623 - acc: 0.5109 - auc_roc: 0.8041 - val_loss: 1.5018 - val_acc: 0.4972 - val_auc_roc: 0.8074
Epoch 8/60
1652/1652 [==============================] - 13s 8ms/step - loss: 0.9835 - acc: 0.5648 - auc_roc: 0.8107 - val_loss: 1.7147 - val_acc: 0.5579 - val_auc_roc: 0.8144
Epoch 9/60
1652/1652 [==============================] - 13s 8ms/step - loss: 0.9192 - acc: 0.5962 - auc_roc: 0.8181 - val_loss: 1.9741 - val_acc: 0.5819 - val_auc_roc: 0.8223
Epoch 10/60
1652/1652 [==============================] - 13s 8ms/step - loss: 0.9589 - acc: 0.5533 - auc_roc: 0.8254 - val_loss: 1.5474 - val_acc: 0.5805 - val_auc_roc: 0.8286
Epoch 11/60
1652/1652 [==============================] - 13s 8ms/step - loss: 0.8585 - acc: 0.5696 - auc_roc: 0.8317 - val_loss: 1.7343 - val_acc: 0.6342 - val_auc_roc: 0.8354
Epoch 12/60
1652/1652 [==============================] - 13s 8ms/step - loss: 0.8334 - acc: 0.6017 - auc_roc: 0.8385 - val_loss: 1.9452 - val_acc: 0.6285 - val_auc_roc: 0.8413
Epoch 13/60
1652/1652 [==============================] - 14s 8ms/step - loss: 0.7299 - acc: 0.6386 - auc_roc: 0.8442 - val_loss: 2.1719 - val_acc: 0.4534 - val_auc_roc: 0.8460
Epoch 14/60
1652/1652 [==============================] - 14s 8ms/step - loss: 0.7045 - acc: 0.6598 - auc_roc: 0.8475 - val_loss: 1.9046 - val_acc: 0.6370 - val_auc_roc: 0.8507
Epoch 15/60
1652/1652 [==============================] - 14s 9ms/step - loss: 0.6371 - acc: 0.6695 - auc_roc: 0.8532 - val_loss: 2.2179 - val_acc: 0.6441 - val_auc_roc: 0.8565
Epoch 16/60
1652/1652 [==============================] - 14s 8ms/step - loss: 0.6230 - acc: 0.6931 - auc_roc: 0.8593 - val_loss: 2.4915 - val_acc: 0.4788 - val_auc_roc: 0.8604
Epoch 17/60
1652/1652 [==============================] - 14s 8ms/step - loss: 0.8093 - acc: 0.6320 - auc_roc: 0.8605 - val_loss: 1.8979 - val_acc: 0.6582 - val_auc_roc: 0.8623
Epoch 18/60
1652/1652 [==============================] - 15s 9ms/step - loss: 0.6106 - acc: 0.7052 - auc_roc: 0.8646 - val_loss: 2.2429 - val_acc: 0.6483 - val_auc_roc: 0.8669
Epoch 19/60
1652/1652 [==============================] - 15s 9ms/step - loss: 0.5419 - acc: 0.7264 - auc_roc: 0.8689 - val_loss: 2.3807 - val_acc: 0.6836 - val_auc_roc: 0.8715
Epoch 20/60
1652/1652 [==============================] - 15s 9ms/step - loss: 0.5065 - acc: 0.7548 - auc_roc: 0.8736 - val_loss: 2.0665 - val_acc: 0.6977 - val_auc_roc: 0.8761
Epoch 21/60
1652/1652 [==============================] - 15s 9ms/step - loss: 0.4439 - acc: 0.7821 - auc_roc: 0.8780 - val_loss: 2.5253 - val_acc: 0.6977 - val_auc_roc: 0.8806
Epoch 22/60
1652/1652 [==============================] - 15s 9ms/step - loss: 0.3789 - acc: 0.8021 - auc_roc: 0.8827 - val_loss: 2.2488 - val_acc: 0.7076 - val_auc_roc: 0.8851
Epoch 00022: early stopping
... history of metrics comprising: ['acc', 'loss', 'val_auc_roc', 'auc_roc', 'val_acc', 'val_loss']
... ... metric (acc): [0.63861985486587081, 0.65980629525519452, 0.66949152542372881, 0.69309927360774815, 0.63196125936854552, 0.70520581099369339, 0.72639225181598066, 0.75484261530074892, 0.78208232431088465, 0.80205811138014527] (n=22)
output> saving performance to:
/Users/pleiades/Documents/work/tpheno/seqmaker/data/CKD/plot/model_evalation-ep200b16.tif

... ... metric (loss): [0.7298637510211935, 0.70454403476622718, 0.63714182391293694, 0.62304345776324699, 0.80929660566205264, 0.6105618632734543, 0.54186032687203356, 0.50654800687228796, 0.44391700185240035, 0.37893515680950435] (n=22)
output> saving performance to:
/Users/pleiades/Documents/work/tpheno/seqmaker/data/CKD/plot/model_evalation-ep200b16.tif

result> performance scores ...

... performance ranking (n_models:24 -> 22):
[({'n_units': 100, 'dropout_rate': 0.5}, 0.65550611461478925, 1.2494593967031911), ({'n_units': 50, 'dropout_rate': 0.2}, 0.62688892638134885, 1.4377704664355233), ({'n_units': 50, 'dropout_rate': 0.3}, 0.62300120169977868, 1.4767646411501469), ({'n_units': 500, 'dropout_rate': 0.5}, 0.48690201680899825, 1.6121273147484967), ({'n_units': 200, 'dropout_rate': 0.5}, 0.504307004001181, 1.6152414379651936), ({'n_units': 500, 'dropout_rate': 0.6}, 0.59857120288053378, 1.6162240703587956), ({'n_units': 400, 'dropout_rate': 0.5}, 0.47341989734126644, 1.6259167576841613), ({'n_units': 100, 'dropout_rate': 0.6}, 0.54455921454377665, 1.6427382750218684), ({'n_units': 400, 'dropout_rate': 0.2}, 0.5366408428181747, 1.6681472163800755), ({'n_units': 300, 'dropout_rate': 0.6}, 0.48633242255983278, 1.6787487889101085), ({'n_units': 200, 'dropout_rate': 0.6}, 0.49289599137502488, 1.7985499846661066), ({'n_units': 100, 'dropout_rate': 0.3}, 0.44932897699947222, 1.8033458072466655), ({'n_units': 100, 'dropout_rate': 0.2}, 0.3903179229370185, 1.8282896406852354), ({'n_units': 400, 'dropout_rate': 0.6}, 0.44465584106220168, 1.8765761652620117), ({'n_units': 200, 'dropout_rate': 0.2}, 0.42835523202546294, 1.9091582352567624), ({'n_units': 300, 'dropout_rate': 0.2}, 0.34741707758450335, 1.9094790684698184), ({'n_units': 300, 'dropout_rate': 0.5}, 0.38815885929810218, 1.9170133194404326), ({'n_units': 200, 'dropout_rate': 0.3}, 0.37065300377532295, 1.9826960536539318), ({'n_units': 500, 'dropout_rate': 0.2}, 0.37597473393629594, 2.0033557432327092), ({'n_units': 400, 'dropout_rate': 0.3}, 0.35689450199862371, 2.0348097482589438), ({'n_units': 500, 'dropout_rate': 0.3}, 0.42181570186453354, 2.0403739003475097), ({'n_units': 300, 'dropout_rate': 0.3}, 0.43052502507952745, 2.1053003341524805)]

... under metric (loss), best score: 0.655506, gap: 1.249459
... model config: {'n_units': 100, 'dropout_rate': 0.5}

... performance ranking (n_models:24 -> 6):
[({'n_units': 100, 'dropout_rate': 0.2}, 0.81446731229093972, 0.10104923319489445), ({'n_units': 200, 'dropout_rate': 0.3}, 0.82590799032920204, 0.11503228411451272), ({'n_units': 300, 'dropout_rate': 0.5}, 0.80853510898770209, 0.12393058921369082), ({'n_units': 400, 'dropout_rate': 0.3}, 0.83480629542838014, 0.15754640842273038), ({'n_units': 500, 'dropout_rate': 0.2}, 0.82996368028638445, 0.16527441474966131), ({'n_units': 300, 'dropout_rate': 0.2}, 0.8371670702179177, 0.17600887812752231)]

... under metric (acc), best score: 0.814467, gap: 0.101049
... model config: {'n_units': 100, 'dropout_rate': 0.2}

... performance ranking (n_models:24 -> 24):
[({'n_units': 50, 'dropout_rate': 0.3}, 0.87841417938110045, 0.0010231211985954891), ({'n_units': 100, 'dropout_rate': 0.6}, 0.87982889246421059, 0.0014296662913300118), ({'n_units': 100, 'dropout_rate': 0.5}, 0.87083483792967731, 0.0014937509251179426), ({'n_units': 50, 'dropout_rate': 0.5}, 0.85855259521532867, 0.001597545274906742), ({'n_units': 300, 'dropout_rate': 0.3}, 0.88704702113788869, 0.0018009213356359188), ({'n_units': 50, 'dropout_rate': 0.2}, 0.87259735356808865, 0.0018702712821037082), ({'n_units': 100, 'dropout_rate': 0.3}, 0.89185923397108069, 0.0018756143935176883), ({'n_units': 200, 'dropout_rate': 0.3}, 0.90313338358812134, 0.0019444090065405817), ({'n_units': 50, 'dropout_rate': 0.6}, 0.8554551984582629, 0.001979843342467702), ({'n_units': 400, 'dropout_rate': 0.6}, 0.88347182653429424, 0.0019845864626552023), ({'n_units': 100, 'dropout_rate': 0.2}, 0.89954575239601786, 0.0019883770053670258), ({'n_units': 400, 'dropout_rate': 0.5}, 0.89095236738426631, 0.0020344237967591106), ({'n_units': 300, 'dropout_rate': 0.6}, 0.88456663196369756, 0.002057290481308649), ({'n_units': 200, 'dropout_rate': 0.6}, 0.88282993165979096, 0.0020784648172886833), ({'n_units': 200, 'dropout_rate': 0.5}, 0.88636900231278248, 0.0021141330304891293), ({'n_units': 400, 'dropout_rate': 0.2}, 0.87143393131491642, 0.0023071781101489108), ({'n_units': 500, 'dropout_rate': 0.6}, 0.86326294554347849, 0.0023438192404885427), ({'n_units': 500, 'dropout_rate': 0.3}, 0.88206357585027217, 0.0023795476452391773), ({'n_units': 500, 'dropout_rate': 0.2}, 0.89037119242527285, 0.0024652289997867394), ({'n_units': 500, 'dropout_rate': 0.5}, 0.88473400063722529, 0.0024800361116824599), ({'n_units': 300, 'dropout_rate': 0.2}, 0.88585208566367757, 0.0025656048235536133), ({'n_units': 200, 'dropout_rate': 0.2}, 0.88753603558274796, 0.0025766745847111139), ({'n_units': 400, 'dropout_rate': 0.3}, 0.88844752912082614, 0.0025781034653566959), ({'n_units': 300, 'dropout_rate': 0.5}, 0.88367983737811628, 0.0026058604295836618)]

... under metric (auc_roc), best score: 0.878414, gap: 0.001023
... model config: {'n_units': 50, 'dropout_rate': 0.3}

result> popular 10 model (out of 13 metric-neutral options with topN=5) ...
  + (n_selected=2) model: (('n_units', 100), ('dropout_rate', 0.5))
  + (n_selected=2) model: (('n_units', 50), ('dropout_rate', 0.3))
  + (n_selected=1) model: (('n_units', 100), ('dropout_rate', 0.2))
  + (n_selected=1) model: (('n_units', 300), ('dropout_rate', 0.3))
  + (n_selected=1) model: (('n_units', 200), ('dropout_rate', 0.5))
  + (n_selected=1) model: (('n_units', 300), ('dropout_rate', 0.5))
  + (n_selected=1) model: (('n_units', 200), ('dropout_rate', 0.3))
  + (n_selected=1) model: (('n_units', 500), ('dropout_rate', 0.2))
  + (n_selected=1) model: (('n_units', 50), ('dropout_rate', 0.5))
  + (n_selected=1) model: (('n_units', 50), ('dropout_rate', 0.2))
result> best configuration:
{'n_units': 100, 'dropout_rate': 0.5}

model_select> opt model:
{'n_units': 100, 'dropout_rate': 0.5}

make_lstm> n_units=100, r_dropout=0.500000, n_layers=1, n_classes=6
... classifier name: Sequential
runROCMulticlass> test set ratio: 0.300000
modelEvaluate> dim(X_train):(1651, 50, 100), dim(X_test): (709, 50, 100)
  + lookup:
{'Others': 5, 'CKD Stage 5': 4, 'CKD Stage 4': 3, 'CKD Stage 3': 2, 'CKD Stage 2': 1, 'CKD Stage 1': 0}

... class weights:
{0: 6.344086021505376, 1: 0.74494949494949492, 2: 1.1238095238095238, 3: 7.0238095238095237, 4: 0.51890941072999119, 5: 0.64906490649064907}

====================================================================================================
... early stopping>
       + patience: 20, model='max'
... model training>
       + batch_size: 32, epochs: 80, shuffle? True, metric: auc_roc
====================================================================================================
Epoch 1/80
1651/1651 [==============================] - 6s 3ms/step - loss: 1.7418 - acc: 0.2810 - auc_roc: 0.5874  
/Users/pleiades/anaconda2/lib/python2.7/site-packages/keras/callbacks.py:526: RuntimeWarning:

Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: acc,loss,auc_roc

Epoch 2/80
1651/1651 [==============================] - 3s 2ms/step - loss: 1.5078 - acc: 0.4288 - auc_roc: 0.6791
Epoch 3/80
1651/1651 [==============================] - 4s 2ms/step - loss: 1.3820 - acc: 0.4500 - auc_roc: 0.7069
Epoch 4/80
1651/1651 [==============================] - 4s 2ms/step - loss: 1.2644 - acc: 0.4870 - auc_roc: 0.7382
Epoch 5/80
1651/1651 [==============================] - 4s 2ms/step - loss: 1.1536 - acc: 0.5366 - auc_roc: 0.7607
Epoch 6/80
1651/1651 [==============================] - 3s 2ms/step - loss: 1.0791 - acc: 0.5572 - auc_roc: 0.7819
Epoch 7/80
1651/1651 [==============================] - 3s 2ms/step - loss: 1.0297 - acc: 0.5766 - auc_roc: 0.7980
Epoch 8/80
1651/1651 [==============================] - 3s 2ms/step - loss: 0.9407 - acc: 0.5887 - auc_roc: 0.8108
Epoch 9/80
1651/1651 [==============================] - 3s 2ms/step - loss: 0.9081 - acc: 0.6190 - auc_roc: 0.8225
Epoch 10/80
1651/1651 [==============================] - 4s 2ms/step - loss: 0.8341 - acc: 0.6227 - auc_roc: 0.8323
Epoch 11/80
1651/1651 [==============================] - 4s 2ms/step - loss: 0.8103 - acc: 0.6463 - auc_roc: 0.8412
Epoch 12/80
1651/1651 [==============================] - 3s 2ms/step - loss: 0.7591 - acc: 0.6451 - auc_roc: 0.8480
Epoch 13/80
1651/1651 [==============================] - 3s 2ms/step - loss: 0.7586 - acc: 0.6644 - auc_roc: 0.8548
Epoch 14/80
1651/1651 [==============================] - 3s 2ms/step - loss: 0.6695 - acc: 0.6753 - auc_roc: 0.8614
Epoch 15/80
1651/1651 [==============================] - 3s 2ms/step - loss: 0.6446 - acc: 0.6838 - auc_roc: 0.8672
Epoch 16/80
1651/1651 [==============================] - 3s 2ms/step - loss: 0.6270 - acc: 0.6984 - auc_roc: 0.8724
Epoch 17/80
1651/1651 [==============================] - 4s 2ms/step - loss: 0.6260 - acc: 0.7081 - auc_roc: 0.8776
Epoch 18/80
1651/1651 [==============================] - 4s 2ms/step - loss: 0.5836 - acc: 0.7365 - auc_roc: 0.8822
Epoch 19/80
1651/1651 [==============================] - 4s 2ms/step - loss: 0.5346 - acc: 0.7389 - auc_roc: 0.8870
Epoch 20/80
1651/1651 [==============================] - 4s 2ms/step - loss: 0.4920 - acc: 0.7583 - auc_roc: 0.8914
Epoch 21/80
1651/1651 [==============================] - 4s 2ms/step - loss: 0.4808 - acc: 0.7638 - auc_roc: 0.8959
Epoch 22/80
1651/1651 [==============================] - 4s 2ms/step - loss: 0.4630 - acc: 0.7741 - auc_roc: 0.8995
Epoch 23/80
1651/1651 [==============================] - 4s 2ms/step - loss: 0.4330 - acc: 0.7916 - auc_roc: 0.9034
Epoch 24/80
1651/1651 [==============================] - 4s 2ms/step - loss: 0.4225 - acc: 0.7916 - auc_roc: 0.9069
Epoch 25/80
1651/1651 [==============================] - 4s 2ms/step - loss: 0.3686 - acc: 0.8159 - auc_roc: 0.9104
Epoch 26/80
1651/1651 [==============================] - 3s 2ms/step - loss: 0.3750 - acc: 0.8141 - auc_roc: 0.9138
Epoch 27/80
1651/1651 [==============================] - 4s 2ms/step - loss: 0.3705 - acc: 0.8243 - auc_roc: 0.9170
Epoch 28/80
1651/1651 [==============================] - 3s 2ms/step - loss: 0.3203 - acc: 0.8455 - auc_roc: 0.9200
Epoch 29/80
1651/1651 [==============================] - 4s 2ms/step - loss: 0.2961 - acc: 0.8565 - auc_roc: 0.9232
Epoch 30/80
1651/1651 [==============================] - 4s 2ms/step - loss: 0.2673 - acc: 0.8795 - auc_roc: 0.9261
Epoch 31/80
1651/1651 [==============================] - 3s 2ms/step - loss: 0.2713 - acc: 0.8783 - auc_roc: 0.9290
Epoch 32/80
1651/1651 [==============================] - 4s 2ms/step - loss: 0.5662 - acc: 0.7680 - auc_roc: 0.9310
Epoch 33/80
1651/1651 [==============================] - 4s 2ms/step - loss: 0.3782 - acc: 0.8286 - auc_roc: 0.9325
Epoch 34/80
1651/1651 [==============================] - 4s 2ms/step - loss: 0.3829 - acc: 0.8328 - auc_roc: 0.9344
Epoch 35/80
1651/1651 [==============================] - 3s 2ms/step - loss: 0.3373 - acc: 0.8449 - auc_roc: 0.9360
Epoch 36/80
1651/1651 [==============================] - 4s 2ms/step - loss: 0.2281 - acc: 0.8928 - auc_roc: 0.9381
Epoch 37/80
1651/1651 [==============================] - 4s 2ms/step - loss: 0.1983 - acc: 0.9110 - auc_roc: 0.9402
Epoch 38/80
1651/1651 [==============================] - 4s 2ms/step - loss: 0.1964 - acc: 0.9140 - auc_roc: 0.9423
Epoch 39/80
1651/1651 [==============================] - 3s 2ms/step - loss: 0.2210 - acc: 0.9001 - auc_roc: 0.9443
Epoch 40/80
1651/1651 [==============================] - 3s 2ms/step - loss: 0.1567 - acc: 0.9297 - auc_roc: 0.9462
Epoch 41/80
1651/1651 [==============================] - 4s 2ms/step - loss: 0.1607 - acc: 0.9249 - auc_roc: 0.9481
Epoch 42/80
1651/1651 [==============================] - 4s 2ms/step - loss: 0.2232 - acc: 0.9013 - auc_roc: 0.9498
Epoch 43/80
1651/1651 [==============================] - 4s 2ms/step - loss: 0.2307 - acc: 0.9188 - auc_roc: 0.9512
Epoch 44/80
1651/1651 [==============================] - 3s 2ms/step - loss: 0.2239 - acc: 0.9055 - auc_roc: 0.9527
Epoch 45/80
1651/1651 [==============================] - 4s 2ms/step - loss: 0.1754 - acc: 0.9291 - auc_roc: 0.9540
Epoch 46/80
1651/1651 [==============================] - 4s 2ms/step - loss: 0.1134 - acc: 0.9570 - auc_roc: 0.9555
Epoch 47/80
1651/1651 [==============================] - 4s 2ms/step - loss: 0.1122 - acc: 0.9552 - auc_roc: 0.9569
Epoch 48/80
1651/1651 [==============================] - 4s 2ms/step - loss: 0.0846 - acc: 0.9727 - auc_roc: 0.9584
Epoch 49/80
1651/1651 [==============================] - 4s 2ms/step - loss: 0.3626 - acc: 0.8692 - auc_roc: 0.9594
Epoch 50/80
1651/1651 [==============================] - 4s 2ms/step - loss: 0.2106 - acc: 0.9152 - auc_roc: 0.9602
Epoch 51/80
1651/1651 [==============================] - 4s 2ms/step - loss: 0.1493 - acc: 0.9419 - auc_roc: 0.9612
Epoch 52/80
1651/1651 [==============================] - 4s 2ms/step - loss: 0.0980 - acc: 0.9649 - auc_roc: 0.9623
Epoch 53/80
1651/1651 [==============================] - 4s 2ms/step - loss: 0.0839 - acc: 0.9697 - auc_roc: 0.9635
Epoch 54/80
1651/1651 [==============================] - 3s 2ms/step - loss: 0.0787 - acc: 0.9727 - auc_roc: 0.9646
Epoch 55/80
1651/1651 [==============================] - 4s 2ms/step - loss: 0.0647 - acc: 0.9794 - auc_roc: 0.9657
Epoch 56/80
1651/1651 [==============================] - 4s 2ms/step - loss: 0.0506 - acc: 0.9836 - auc_roc: 0.9668
Epoch 57/80
1651/1651 [==============================] - 4s 2ms/step - loss: 0.0664 - acc: 0.9709 - auc_roc: 0.9678
Epoch 58/80
1651/1651 [==============================] - 4s 2ms/step - loss: 0.0932 - acc: 0.9715 - auc_roc: 0.9687
Epoch 59/80
1651/1651 [==============================] - 3s 2ms/step - loss: 0.1094 - acc: 0.9588 - auc_roc: 0.9695
Epoch 60/80
1651/1651 [==============================] - 4s 2ms/step - loss: 0.0640 - acc: 0.9764 - auc_roc: 0.9703
Epoch 61/80
1651/1651 [==============================] - 4s 2ms/step - loss: 0.0464 - acc: 0.9873 - auc_roc: 0.9712
Epoch 62/80
1651/1651 [==============================] - 4s 2ms/step - loss: 0.0320 - acc: 0.9903 - auc_roc: 0.9720
Epoch 63/80
1651/1651 [==============================] - 4s 2ms/step - loss: 0.0316 - acc: 0.9909 - auc_roc: 0.9728
Epoch 64/80
1651/1651 [==============================] - 4s 2ms/step - loss: 0.0699 - acc: 0.9782 - auc_roc: 0.9736
Epoch 65/80
1651/1651 [==============================] - 4s 2ms/step - loss: 0.0509 - acc: 0.9861 - auc_roc: 0.9743
Epoch 66/80
1651/1651 [==============================] - 4s 2ms/step - loss: 0.0357 - acc: 0.9903 - auc_roc: 0.9749
Epoch 67/80
1651/1651 [==============================] - 4s 2ms/step - loss: 0.0259 - acc: 0.9927 - auc_roc: 0.9756
Epoch 68/80
1651/1651 [==============================] - 4s 2ms/step - loss: 0.0222 - acc: 0.9927 - auc_roc: 0.9763
Epoch 69/80
1651/1651 [==============================] - 4s 2ms/step - loss: 0.0225 - acc: 0.9927 - auc_roc: 0.9769
Epoch 70/80
1651/1651 [==============================] - 4s 2ms/step - loss: 0.0677 - acc: 0.9788 - auc_roc: 0.9776
Epoch 71/80
1651/1651 [==============================] - 4s 2ms/step - loss: 0.1216 - acc: 0.9534 - auc_roc: 0.9780
Epoch 72/80
1651/1651 [==============================] - 4s 2ms/step - loss: 0.0836 - acc: 0.9758 - auc_roc: 0.9784
Epoch 73/80
1651/1651 [==============================] - 4s 3ms/step - loss: 0.1613 - acc: 0.9334 - auc_roc: 0.9788
Epoch 74/80
1651/1651 [==============================] - 4s 2ms/step - loss: 0.0976 - acc: 0.9661 - auc_roc: 0.9792
Epoch 75/80
1651/1651 [==============================] - 4s 2ms/step - loss: 0.1233 - acc: 0.9564 - auc_roc: 0.9795
Epoch 76/80
1651/1651 [==============================] - 4s 2ms/step - loss: 0.1186 - acc: 0.9655 - auc_roc: 0.9799
Epoch 77/80
1651/1651 [==============================] - 4s 2ms/step - loss: 0.3197 - acc: 0.8643 - auc_roc: 0.9801
Epoch 78/80
1651/1651 [==============================] - 4s 2ms/step - loss: 0.1508 - acc: 0.9346 - auc_roc: 0.9802
Epoch 79/80
1651/1651 [==============================] - 4s 2ms/step - loss: 0.1057 - acc: 0.9631 - auc_roc: 0.9805
Epoch 80/80
1651/1651 [==============================] - 4s 2ms/step - loss: 0.0817 - acc: 0.9703 - auc_roc: 0.9809
... history of metrics comprising: ['acc', 'loss', 'auc_roc']
... model fitting complete > starting model evaluation
modelEvaluate> scores:
[('loss', 1.943959528031235), ('acc', 0.60225669966093742), ('auc_roc', 0.98063528705887459)]

info> infer classifier name from class name ...
runROCMulticlass> find 6 unique labels:
CKD Stage 1, CKD Stage 2, CKD Stage 3, CKD Stage 4, CKD Stage 5, Others

info> given pre-trained model ...
diagnosis> dim(y_score):(709, 6)
>>> test_auc_cv_metrics >>>
  + dimension test 
  + len(roc_auc):8 =?= n_classes (+{micro, macro}):6+2
  + class name: CKD Stage 1, mean_auc: 0.833519
  + ROC curve of class CKD Stage 1 (area = 0.83)
  + class name: CKD Stage 2, mean_auc: 0.763158
  + ROC curve of class CKD Stage 2 (area = 0.76)
  + class name: CKD Stage 3, mean_auc: 0.755208
  + ROC curve of class CKD Stage 3 (area = 0.76)
  + class name: CKD Stage 4, mean_auc: 0.717360
  + ROC curve of class CKD Stage 4 (area = 0.72)
  + class name: CKD Stage 5, mean_auc: 0.951816
  + ROC curve of class CKD Stage 5 (area = 0.95)
  + class name: Others, mean_auc: 0.817881
  + ROC curve of class Others (area = 0.82)
test_auc_cv_metrics> summary of AUCs vs classes ...
  + min | class=CKD Stage 4, auc=0.717360
  + max | class=CKD Stage 5, auc=0.951816
  + micro auc=0.872955 | macro auc=0.807485
  + Ranked AUC scores: 
    + class=CKD Stage 4, auc=0.717360
    + class=CKD Stage 3, auc=0.755208
    + class=CKD Stage 2, auc=0.763158
    + class=Others, auc=0.817881
    + class=CKD Stage 1, auc=0.833519
    + class=CKD Stage 5, auc=0.951816
  => [('CKD Stage 4', 0.7173601147776183), ('CKD Stage 3', 0.75520781586355346), ('CKD Stage 2', 0.76315789473684215), ('Others', 0.81788125013224999), ('CKD Stage 1', 0.83351926977687629), ('CKD Stage 5', 0.95181591950084754)]
output> saving performance to:
/Users/pleiades/Documents/work/tpheno/seqmaker/data/CKD/plot/roc-multiclass-Sequential-CKD-pv-dm2-regular-smallCKD.tif

runROCMulticlass> test set ratio: 0.300000
modelEvaluate> dim(X_train):(1651, 50, 100), dim(X_test): (709, 50, 100)
  + lookup:
{'Others': 5, 'CKD Stage 5': 4, 'CKD Stage 4': 3, 'CKD Stage 3': 2, 'CKD Stage 2': 1, 'CKD Stage 1': 0}

... class weights:
{0: 6.344086021505376, 1: 0.74494949494949492, 2: 1.1238095238095238, 3: 7.0238095238095237, 4: 0.51890941072999119, 5: 0.64906490649064907}

====================================================================================================
... early stopping>
       + patience: 20, model='max'
... model training>
       + batch_size: 32, epochs: 80, shuffle? True, metric: auc_roc
====================================================================================================
Epoch 1/80
1651/1651 [==============================] - 3s 2ms/step - loss: 1.7830 - acc: 0.2392 - auc_roc: 0.9795
Epoch 2/80
1651/1651 [==============================] - 4s 2ms/step - loss: 1.6869 - acc: 0.3071 - auc_roc: 0.9780
Epoch 3/80
1651/1651 [==============================] - 4s 2ms/step - loss: 1.5650 - acc: 0.4228 - auc_roc: 0.9766
Epoch 4/80
1651/1651 [==============================] - 4s 2ms/step - loss: 1.4171 - acc: 0.4282 - auc_roc: 0.9755
Epoch 5/80
1651/1651 [==============================] - 4s 2ms/step - loss: 1.2746 - acc: 0.5009 - auc_roc: 0.9745
Epoch 6/80
1651/1651 [==============================] - 4s 2ms/step - loss: 1.2489 - acc: 0.5027 - auc_roc: 0.9736
Epoch 7/80
1651/1651 [==============================] - 4s 2ms/step - loss: 1.2167 - acc: 0.4870 - auc_roc: 0.9725
Epoch 8/80
1651/1651 [==============================] - 4s 2ms/step - loss: 1.0806 - acc: 0.5463 - auc_roc: 0.9717
Epoch 9/80
1651/1651 [==============================] - 4s 2ms/step - loss: 1.0043 - acc: 0.5863 - auc_roc: 0.9711
Epoch 10/80
1651/1651 [==============================] - 4s 2ms/step - loss: 0.9631 - acc: 0.5984 - auc_roc: 0.9704
Epoch 11/80
1651/1651 [==============================] - 4s 2ms/step - loss: 0.9463 - acc: 0.6002 - auc_roc: 0.9698
Epoch 12/80
1651/1651 [==============================] - 4s 2ms/step - loss: 0.9000 - acc: 0.6184 - auc_roc: 0.9693
Epoch 13/80
1651/1651 [==============================] - 4s 2ms/step - loss: 0.8445 - acc: 0.6323 - auc_roc: 0.9688
Epoch 14/80
1651/1651 [==============================] - 4s 2ms/step - loss: 0.7776 - acc: 0.6420 - auc_roc: 0.9683
Epoch 15/80
1651/1651 [==============================] - 4s 2ms/step - loss: 0.7620 - acc: 0.6505 - auc_roc: 0.9679
Epoch 16/80
1651/1651 [==============================] - 4s 3ms/step - loss: 0.7448 - acc: 0.6626 - auc_roc: 0.9676
Epoch 17/80
1651/1651 [==============================] - 4s 2ms/step - loss: 0.7766 - acc: 0.6475 - auc_roc: 0.9672
Epoch 18/80
1651/1651 [==============================] - 4s 3ms/step - loss: 0.6725 - acc: 0.6796 - auc_roc: 0.9669
Epoch 19/80
1651/1651 [==============================] - 4s 2ms/step - loss: 0.6315 - acc: 0.6947 - auc_roc: 0.9666
Epoch 20/80
1651/1651 [==============================] - 4s 2ms/step - loss: 0.5933 - acc: 0.7081 - auc_roc: 0.9665
Epoch 21/80
1651/1651 [==============================] - 4s 2ms/step - loss: 0.6248 - acc: 0.7044 - auc_roc: 0.9662
Epoch 22/80
1651/1651 [==============================] - 4s 2ms/step - loss: 0.5407 - acc: 0.7317 - auc_roc: 0.9661
Epoch 23/80
1651/1651 [==============================] - 4s 2ms/step - loss: 0.5491 - acc: 0.7311 - auc_roc: 0.9660
Epoch 24/80
1651/1651 [==============================] - 4s 2ms/step - loss: 0.5919 - acc: 0.7159 - auc_roc: 0.9659
Epoch 25/80
1651/1651 [==============================] - 4s 2ms/step - loss: 0.5507 - acc: 0.7371 - auc_roc: 0.9658
Epoch 26/80
1651/1651 [==============================] - 4s 2ms/step - loss: 0.5605 - acc: 0.7420 - auc_roc: 0.9656
Epoch 27/80
1651/1651 [==============================] - 4s 2ms/step - loss: 0.6011 - acc: 0.7268 - auc_roc: 0.9655
Epoch 28/80
1651/1651 [==============================] - 4s 2ms/step - loss: 0.5129 - acc: 0.7626 - auc_roc: 0.9654
Epoch 29/80
1651/1651 [==============================] - 4s 2ms/step - loss: 0.4754 - acc: 0.7620 - auc_roc: 0.9654
Epoch 30/80
1651/1651 [==============================] - 4s 2ms/step - loss: 0.4285 - acc: 0.7916 - auc_roc: 0.9654
Epoch 31/80
1651/1651 [==============================] - 4s 2ms/step - loss: 0.4035 - acc: 0.8086 - auc_roc: 0.9655
Epoch 32/80
1651/1651 [==============================] - 4s 2ms/step - loss: 0.4582 - acc: 0.7874 - auc_roc: 0.9656
Epoch 33/80
1651/1651 [==============================] - 4s 2ms/step - loss: 0.3760 - acc: 0.8128 - auc_roc: 0.9656
Epoch 34/80
1651/1651 [==============================] - 4s 2ms/step - loss: 0.3538 - acc: 0.8304 - auc_roc: 0.9657
Epoch 35/80
1651/1651 [==============================] - 4s 2ms/step - loss: 0.3267 - acc: 0.8389 - auc_roc: 0.9659
Epoch 36/80
1651/1651 [==============================] - 4s 2ms/step - loss: 0.3067 - acc: 0.8534 - auc_roc: 0.9661
Epoch 37/80
1651/1651 [==============================] - 4s 2ms/step - loss: 0.3090 - acc: 0.8516 - auc_roc: 0.9662
Epoch 38/80
1651/1651 [==============================] - 4s 2ms/step - loss: 0.3361 - acc: 0.8468 - auc_roc: 0.9664
Epoch 39/80
1651/1651 [==============================] - 4s 2ms/step - loss: 0.4431 - acc: 0.7904 - auc_roc: 0.9664
Epoch 40/80
1651/1651 [==============================] - 4s 2ms/step - loss: 0.2962 - acc: 0.8686 - auc_roc: 0.9665
Epoch 41/80
1651/1651 [==============================] - 4s 2ms/step - loss: 0.2588 - acc: 0.8795 - auc_roc: 0.9667
Epoch 42/80
1651/1651 [==============================] - 4s 2ms/step - loss: 0.2082 - acc: 0.9043 - auc_roc: 0.9670
Epoch 43/80
1651/1651 [==============================] - 4s 2ms/step - loss: 0.2070 - acc: 0.9110 - auc_roc: 0.9673
Epoch 44/80
1651/1651 [==============================] - 4s 2ms/step - loss: 0.3870 - acc: 0.8110 - auc_roc: 0.9674
Epoch 45/80
1651/1651 [==============================] - 4s 2ms/step - loss: 0.3041 - acc: 0.8625 - auc_roc: 0.9675
Epoch 46/80
1651/1651 [==============================] - 4s 2ms/step - loss: 0.2401 - acc: 0.8946 - auc_roc: 0.9677
Epoch 47/80
1651/1651 [==============================] - 4s 2ms/step - loss: 0.2462 - acc: 0.8892 - auc_roc: 0.9680
Epoch 48/80
1651/1651 [==============================] - 4s 2ms/step - loss: 0.2721 - acc: 0.8855 - auc_roc: 0.9681
Epoch 49/80
1651/1651 [==============================] - 4s 2ms/step - loss: 0.2289 - acc: 0.8982 - auc_roc: 0.9683
Epoch 50/80
1651/1651 [==============================] - 4s 2ms/step - loss: 0.2451 - acc: 0.9055 - auc_roc: 0.9686
Epoch 51/80
1651/1651 [==============================] - 4s 2ms/step - loss: 0.3233 - acc: 0.8607 - auc_roc: 0.9687
Epoch 52/80
1651/1651 [==============================] - 4s 2ms/step - loss: 0.2842 - acc: 0.8910 - auc_roc: 0.9689
Epoch 53/80
1651/1651 [==============================] - 4s 2ms/step - loss: 0.1765 - acc: 0.9267 - auc_roc: 0.9691
Epoch 54/80
1651/1651 [==============================] - 4s 2ms/step - loss: 0.1667 - acc: 0.9291 - auc_roc: 0.9694
Epoch 55/80
1651/1651 [==============================] - 4s 2ms/step - loss: 0.1280 - acc: 0.9503 - auc_roc: 0.9697
Epoch 56/80
1651/1651 [==============================] - 4s 2ms/step - loss: 0.1108 - acc: 0.9461 - auc_roc: 0.9700
Epoch 57/80
1651/1651 [==============================] - 4s 2ms/step - loss: 0.0920 - acc: 0.9679 - auc_roc: 0.9704
Epoch 58/80
1651/1651 [==============================] - 4s 2ms/step - loss: 0.0943 - acc: 0.9667 - auc_roc: 0.9707
Epoch 59/80
1651/1651 [==============================] - 4s 2ms/step - loss: 0.0849 - acc: 0.9612 - auc_roc: 0.9710
Epoch 60/80
1651/1651 [==============================] - 4s 2ms/step - loss: 0.0711 - acc: 0.9643 - auc_roc: 0.9713
Epoch 61/80
1651/1651 [==============================] - 4s 2ms/step - loss: 0.1917 - acc: 0.9279 - auc_roc: 0.9716
Epoch 62/80
1651/1651 [==============================] - 4s 2ms/step - loss: 0.4356 - acc: 0.8480 - auc_roc: 0.9717
Epoch 63/80
1651/1651 [==============================] - 4s 2ms/step - loss: 0.2247 - acc: 0.9061 - auc_roc: 0.9718
Epoch 64/80
1651/1651 [==============================] - 4s 2ms/step - loss: 0.1472 - acc: 0.9400 - auc_roc: 0.9721
Epoch 65/80
1651/1651 [==============================] - 4s 2ms/step - loss: 0.1112 - acc: 0.9546 - auc_roc: 0.9723
Epoch 66/80
1651/1651 [==============================] - 4s 2ms/step - loss: 0.0937 - acc: 0.9655 - auc_roc: 0.9726
Epoch 67/80
1651/1651 [==============================] - 4s 2ms/step - loss: 0.0779 - acc: 0.9709 - auc_roc: 0.9729
Epoch 68/80
1651/1651 [==============================] - 4s 2ms/step - loss: 0.0615 - acc: 0.9843 - auc_roc: 0.9732
Epoch 69/80
1651/1651 [==============================] - 4s 2ms/step - loss: 0.0554 - acc: 0.9824 - auc_roc: 0.9735
Epoch 70/80
1651/1651 [==============================] - 4s 2ms/step - loss: 0.0418 - acc: 0.9873 - auc_roc: 0.9738
Epoch 71/80
1651/1651 [==============================] - 4s 2ms/step - loss: 0.0674 - acc: 0.9740 - auc_roc: 0.9741
Epoch 72/80
1651/1651 [==============================] - 4s 2ms/step - loss: 0.0567 - acc: 0.9788 - auc_roc: 0.9744
Epoch 73/80
1651/1651 [==============================] - 4s 2ms/step - loss: 0.0654 - acc: 0.9752 - auc_roc: 0.9747
Epoch 74/80
1651/1651 [==============================] - 4s 2ms/step - loss: 0.0640 - acc: 0.9764 - auc_roc: 0.9749
Epoch 75/80
1651/1651 [==============================] - 4s 2ms/step - loss: 0.0610 - acc: 0.9800 - auc_roc: 0.9752
Epoch 76/80
1651/1651 [==============================] - 4s 2ms/step - loss: 0.2396 - acc: 0.8928 - auc_roc: 0.9754
Epoch 77/80
1651/1651 [==============================] - 4s 2ms/step - loss: 0.1528 - acc: 0.9279 - auc_roc: 0.9755
Epoch 78/80
1651/1651 [==============================] - 4s 2ms/step - loss: 0.0924 - acc: 0.9631 - auc_roc: 0.9757
Epoch 79/80
1651/1651 [==============================] - 4s 2ms/step - loss: 0.0578 - acc: 0.9758 - auc_roc: 0.9760
Epoch 80/80
1651/1651 [==============================] - 4s 2ms/step - loss: 0.0415 - acc: 0.9879 - auc_roc: 0.9762
... history of metrics comprising: ['acc', 'loss', 'auc_roc']
... model fitting complete > starting model evaluation
modelEvaluate> scores:
[('loss', 2.3512535767763727), ('acc', 0.588152327263473), ('auc_roc', 0.97609508903473829)]

info> infer classifier name from class name ...
runROCMulticlass> find 6 unique labels:
CKD Stage 1, CKD Stage 2, CKD Stage 3, CKD Stage 4, CKD Stage 5, Others

info> given pre-trained model ...
diagnosis> dim(y_score):(709, 6)
>>> test_auc_cv_metrics >>>
  + dimension test 
  + len(roc_auc):8 =?= n_classes (+{micro, macro}):6+2
  + class name: CKD Stage 1, mean_auc: 0.894469
  + ROC curve of class CKD Stage 1 (area = 0.89)
  + class name: CKD Stage 2, mean_auc: 0.763859
  + ROC curve of class CKD Stage 2 (area = 0.76)
  + class name: CKD Stage 3, mean_auc: 0.700719
  + ROC curve of class CKD Stage 3 (area = 0.70)
  + class name: CKD Stage 4, mean_auc: 0.699232
  + ROC curve of class CKD Stage 4 (area = 0.70)
  + class name: CKD Stage 5, mean_auc: 0.944577
  + ROC curve of class CKD Stage 5 (area = 0.94)
  + class name: Others, mean_auc: 0.819797
  + ROC curve of class Others (area = 0.82)
test_auc_cv_metrics> summary of AUCs vs classes ...
  + min | class=CKD Stage 4, auc=0.699232
  + max | class=CKD Stage 5, auc=0.944577
  + micro auc=0.859212 | macro auc=0.804865
  + Ranked AUC scores: 
    + class=CKD Stage 4, auc=0.699232
    + class=CKD Stage 3, auc=0.700719
    + class=CKD Stage 2, auc=0.763859
    + class=Others, auc=0.819797
    + class=CKD Stage 1, auc=0.894469
    + class=CKD Stage 5, auc=0.944577
  => [('CKD Stage 4', 0.69923150816522572), ('CKD Stage 3', 0.70071865443425074), ('CKD Stage 2', 0.76385857704059368), ('Others', 0.81979679611045309), ('CKD Stage 1', 0.89446870451237259), ('CKD Stage 5', 0.94457702055237991)]
output> saving performance to:
/Users/pleiades/Documents/work/tpheno/seqmaker/data/CKD/plot/roc-multiclass-Sequential-CKD-pv-dm2-regular-smallCKD.tif

runROCMulticlass> test set ratio: 0.300000
modelEvaluate> dim(X_train):(1651, 50, 100), dim(X_test): (709, 50, 100)
  + lookup:
{'Others': 5, 'CKD Stage 5': 4, 'CKD Stage 4': 3, 'CKD Stage 3': 2, 'CKD Stage 2': 1, 'CKD Stage 1': 0}

... class weights:
{0: 6.344086021505376, 1: 0.74494949494949492, 2: 1.1238095238095238, 3: 7.0238095238095237, 4: 0.51890941072999119, 5: 0.64906490649064907}

====================================================================================================
... early stopping>
       + patience: 20, model='max'
... model training>
       + batch_size: 32, epochs: 80, shuffle? True, metric: auc_roc
====================================================================================================
Epoch 1/80
1651/1651 [==============================] - 4s 2ms/step - loss: 1.8351 - acc: 0.2005 - auc_roc: 0.9754
Epoch 2/80
1651/1651 [==============================] - 4s 3ms/step - loss: 1.7247 - acc: 0.2901 - auc_roc: 0.9746
Epoch 3/80
1651/1651 [==============================] - 4s 2ms/step - loss: 1.6306 - acc: 0.3913 - auc_roc: 0.9739
Epoch 4/80
1651/1651 [==============================] - 4s 2ms/step - loss: 1.4660 - acc: 0.4476 - auc_roc: 0.9733
Epoch 5/80
1651/1651 [==============================] - 4s 2ms/step - loss: 1.3061 - acc: 0.4852 - auc_roc: 0.9728
Epoch 6/80
1651/1651 [==============================] - 4s 2ms/step - loss: 1.2359 - acc: 0.4985 - auc_roc: 0.9723
Epoch 7/80
1651/1651 [==============================] - 4s 2ms/step - loss: 1.1114 - acc: 0.5488 - auc_roc: 0.9718
Epoch 8/80
1651/1651 [==============================] - 4s 2ms/step - loss: 1.0519 - acc: 0.5584 - auc_roc: 0.9715
Epoch 9/80
1651/1651 [==============================] - 4s 2ms/step - loss: 1.0134 - acc: 0.5887 - auc_roc: 0.9711
Epoch 10/80
1651/1651 [==============================] - 4s 2ms/step - loss: 0.9240 - acc: 0.6214 - auc_roc: 0.9708
Epoch 11/80
1651/1651 [==============================] - 4s 2ms/step - loss: 0.9102 - acc: 0.6160 - auc_roc: 0.9705
Epoch 12/80
1651/1651 [==============================] - 4s 2ms/step - loss: 1.0086 - acc: 0.5875 - auc_roc: 0.9702
Epoch 13/80
1651/1651 [==============================] - 4s 2ms/step - loss: 0.8927 - acc: 0.6220 - auc_roc: 0.9699
Epoch 14/80
1651/1651 [==============================] - 4s 2ms/step - loss: 0.7750 - acc: 0.6560 - auc_roc: 0.9697
Epoch 15/80
1651/1651 [==============================] - 4s 2ms/step - loss: 0.7362 - acc: 0.6638 - auc_roc: 0.9695
Epoch 16/80
1651/1651 [==============================] - 4s 2ms/step - loss: 0.7031 - acc: 0.6753 - auc_roc: 0.9693
Epoch 17/80
1651/1651 [==============================] - 4s 2ms/step - loss: 0.6863 - acc: 0.6808 - auc_roc: 0.9691
Epoch 18/80
1651/1651 [==============================] - 4s 2ms/step - loss: 0.6982 - acc: 0.6729 - auc_roc: 0.9689
Epoch 19/80
1651/1651 [==============================] - 4s 2ms/step - loss: 0.6295 - acc: 0.7020 - auc_roc: 0.9688
Epoch 20/80
1651/1651 [==============================] - 4s 2ms/step - loss: 0.6033 - acc: 0.7099 - auc_roc: 0.9686
Epoch 21/80
1651/1651 [==============================] - 4s 2ms/step - loss: 0.5757 - acc: 0.7050 - auc_roc: 0.9685
Epoch 22/80
1651/1651 [==============================] - 4s 2ms/step - loss: 0.5637 - acc: 0.7414 - auc_roc: 0.9684
Epoch 23/80
1651/1651 [==============================] - 4s 2ms/step - loss: 0.5516 - acc: 0.7299 - auc_roc: 0.9684
Epoch 24/80
1651/1651 [==============================] - 4s 2ms/step - loss: 0.5441 - acc: 0.7177 - auc_roc: 0.9683
Epoch 25/80
1651/1651 [==============================] - 4s 2ms/step - loss: 0.4918 - acc: 0.7456 - auc_roc: 0.9682
Epoch 26/80
1651/1651 [==============================] - 4s 2ms/step - loss: 0.4559 - acc: 0.7789 - auc_roc: 0.9682
Epoch 27/80
1651/1651 [==============================] - 4s 2ms/step - loss: 0.4497 - acc: 0.7820 - auc_roc: 0.9682
Epoch 28/80
1651/1651 [==============================] - 4s 2ms/step - loss: 0.4426 - acc: 0.7832 - auc_roc: 0.9682
Epoch 29/80
1651/1651 [==============================] - 4s 2ms/step - loss: 0.5528 - acc: 0.7196 - auc_roc: 0.9682
Epoch 30/80
1651/1651 [==============================] - 4s 2ms/step - loss: 0.5916 - acc: 0.7129 - auc_roc: 0.9680
Epoch 31/80
1651/1651 [==============================] - 4s 2ms/step - loss: 0.4562 - acc: 0.7638 - auc_roc: 0.9680
Epoch 32/80
1651/1651 [==============================] - 4s 2ms/step - loss: 0.4118 - acc: 0.7922 - auc_roc: 0.9680
Epoch 33/80
1651/1651 [==============================] - 4s 2ms/step - loss: 0.3650 - acc: 0.8213 - auc_roc: 0.9680
Epoch 34/80
1651/1651 [==============================] - 4s 2ms/step - loss: 0.3515 - acc: 0.8298 - auc_roc: 0.9681
Epoch 35/80
1651/1651 [==============================] - 4s 2ms/step - loss: 0.3423 - acc: 0.8304 - auc_roc: 0.9681
Epoch 36/80
1651/1651 [==============================] - 4s 2ms/step - loss: 0.3261 - acc: 0.8425 - auc_roc: 0.9682
Epoch 37/80
1651/1651 [==============================] - 4s 2ms/step - loss: 0.3083 - acc: 0.8552 - auc_roc: 0.9683
Epoch 38/80
1651/1651 [==============================] - 4s 2ms/step - loss: 0.2897 - acc: 0.8528 - auc_roc: 0.9684
Epoch 39/80
1651/1651 [==============================] - 4s 2ms/step - loss: 0.2609 - acc: 0.8716 - auc_roc: 0.9685
Epoch 40/80
1651/1651 [==============================] - 4s 2ms/step - loss: 0.3524 - acc: 0.8401 - auc_roc: 0.9686
Epoch 41/80
1651/1651 [==============================] - 4s 2ms/step - loss: 0.4737 - acc: 0.7783 - auc_roc: 0.9686
Epoch 42/80
1651/1651 [==============================] - 4s 2ms/step - loss: 0.3792 - acc: 0.8280 - auc_roc: 0.9687
Epoch 43/80
1651/1651 [==============================] - 4s 2ms/step - loss: 0.2855 - acc: 0.8710 - auc_roc: 0.9687
Epoch 44/80
1651/1651 [==============================] - 4s 2ms/step - loss: 0.2712 - acc: 0.8601 - auc_roc: 0.9689
Epoch 45/80
1651/1651 [==============================] - 4s 2ms/step - loss: 0.2127 - acc: 0.9049 - auc_roc: 0.9690
Epoch 46/80
1651/1651 [==============================] - 4s 2ms/step - loss: 0.1956 - acc: 0.9146 - auc_roc: 0.9691
Epoch 47/80
1651/1651 [==============================] - 4s 2ms/step - loss: 0.1834 - acc: 0.9200 - auc_roc: 0.9693
Epoch 48/80
1651/1651 [==============================] - 4s 2ms/step - loss: 0.5434 - acc: 0.7256 - auc_roc: 0.9693
Epoch 49/80
1651/1651 [==============================] - 4s 2ms/step - loss: 0.3906 - acc: 0.8407 - auc_roc: 0.9693
Epoch 50/80
1651/1651 [==============================] - 4s 2ms/step - loss: 0.2753 - acc: 0.8789 - auc_roc: 0.9694
Epoch 51/80
1651/1651 [==============================] - 4s 2ms/step - loss: 0.2256 - acc: 0.9013 - auc_roc: 0.9695
Epoch 52/80
1651/1651 [==============================] - 4s 2ms/step - loss: 0.2463 - acc: 0.8855 - auc_roc: 0.9696
Epoch 53/80
1651/1651 [==============================] - 4s 3ms/step - loss: 0.1919 - acc: 0.9116 - auc_roc: 0.9698
Epoch 54/80
1651/1651 [==============================] - 4s 2ms/step - loss: 0.1777 - acc: 0.9194 - auc_roc: 0.9699
Epoch 55/80
1651/1651 [==============================] - 4s 2ms/step - loss: 0.1396 - acc: 0.9425 - auc_roc: 0.9701
Epoch 56/80
1651/1651 [==============================] - 4s 2ms/step - loss: 0.1264 - acc: 0.9449 - auc_roc: 0.9703
Epoch 57/80
1651/1651 [==============================] - 4s 2ms/step - loss: 0.1387 - acc: 0.9449 - auc_roc: 0.9705
Epoch 58/80
1651/1651 [==============================] - 4s 2ms/step - loss: 0.1289 - acc: 0.9503 - auc_roc: 0.9707
Epoch 59/80
1651/1651 [==============================] - 4s 2ms/step - loss: 0.2813 - acc: 0.8752 - auc_roc: 0.9708
Epoch 60/80
1651/1651 [==============================] - 4s 2ms/step - loss: 0.1631 - acc: 0.9346 - auc_roc: 0.9709
Epoch 61/80
1651/1651 [==============================] - 4s 2ms/step - loss: 0.1072 - acc: 0.9600 - auc_roc: 0.9711
Epoch 62/80
1651/1651 [==============================] - 4s 2ms/step - loss: 0.0814 - acc: 0.9691 - auc_roc: 0.9713
Epoch 63/80
1651/1651 [==============================] - 4s 2ms/step - loss: 0.0749 - acc: 0.9685 - auc_roc: 0.9715
Epoch 64/80
1651/1651 [==============================] - 4s 2ms/step - loss: 0.0694 - acc: 0.9764 - auc_roc: 0.9717
Epoch 65/80
1651/1651 [==============================] - 4s 2ms/step - loss: 0.0707 - acc: 0.9715 - auc_roc: 0.9719
Epoch 66/80
1651/1651 [==============================] - 4s 2ms/step - loss: 0.0706 - acc: 0.9703 - auc_roc: 0.9721
Epoch 67/80
1651/1651 [==============================] - 4s 2ms/step - loss: 0.4229 - acc: 0.8740 - auc_roc: 0.9722
Epoch 68/80
1651/1651 [==============================] - 4s 2ms/step - loss: 0.2841 - acc: 0.8849 - auc_roc: 0.9723
Epoch 69/80
1651/1651 [==============================] - 4s 2ms/step - loss: 0.1768 - acc: 0.9303 - auc_roc: 0.9724
Epoch 70/80
1651/1651 [==============================] - 4s 2ms/step - loss: 0.2665 - acc: 0.9134 - auc_roc: 0.9725
Epoch 71/80
1651/1651 [==============================] - 4s 2ms/step - loss: 0.1489 - acc: 0.9394 - auc_roc: 0.9727
Epoch 72/80
1651/1651 [==============================] - 4s 2ms/step - loss: 0.1186 - acc: 0.9558 - auc_roc: 0.9728
Epoch 73/80
1651/1651 [==============================] - 4s 2ms/step - loss: 0.1001 - acc: 0.9667 - auc_roc: 0.9730
Epoch 74/80
1651/1651 [==============================] - 4s 2ms/step - loss: 0.0925 - acc: 0.9624 - auc_roc: 0.9732
Epoch 75/80
1651/1651 [==============================] - 4s 2ms/step - loss: 0.0647 - acc: 0.9782 - auc_roc: 0.9734
Epoch 76/80
1651/1651 [==============================] - 4s 2ms/step - loss: 0.0593 - acc: 0.9830 - auc_roc: 0.9735
Epoch 77/80
1651/1651 [==============================] - 4s 2ms/step - loss: 0.0490 - acc: 0.9830 - auc_roc: 0.9737
Epoch 78/80
1651/1651 [==============================] - 4s 2ms/step - loss: 0.0408 - acc: 0.9873 - auc_roc: 0.9739
Epoch 79/80
1651/1651 [==============================] - 4s 2ms/step - loss: 0.0552 - acc: 0.9830 - auc_roc: 0.9741
Epoch 80/80
1651/1651 [==============================] - 4s 2ms/step - loss: 0.0489 - acc: 0.9843 - auc_roc: 0.9743
... history of metrics comprising: ['acc', 'loss', 'auc_roc']
... model fitting complete > starting model evaluation
modelEvaluate> scores:
[('loss', 2.2920552382852528), ('acc', 0.59238363909620495), ('auc_roc', 0.9742259369750621)]

info> infer classifier name from class name ...
runROCMulticlass> find 6 unique labels:
CKD Stage 1, CKD Stage 2, CKD Stage 3, CKD Stage 4, CKD Stage 5, Others

info> given pre-trained model ...
diagnosis> dim(y_score):(709, 6)
>>> test_auc_cv_metrics >>>
  + dimension test 
  + len(roc_auc):8 =?= n_classes (+{micro, macro}):6+2
  + class name: CKD Stage 1, mean_auc: 0.857106
  + ROC curve of class CKD Stage 1 (area = 0.86)
  + class name: CKD Stage 2, mean_auc: 0.764699
  + ROC curve of class CKD Stage 2 (area = 0.76)
  + class name: CKD Stage 3, mean_auc: 0.706504
  + ROC curve of class CKD Stage 3 (area = 0.71)
  + class name: CKD Stage 4, mean_auc: 0.822097
  + ROC curve of class CKD Stage 4 (area = 0.82)
  + class name: CKD Stage 5, mean_auc: 0.961638
  + ROC curve of class CKD Stage 5 (area = 0.96)
  + class name: Others, mean_auc: 0.820732
  + ROC curve of class Others (area = 0.82)
test_auc_cv_metrics> summary of AUCs vs classes ...
  + min | class=CKD Stage 3, auc=0.706504
  + max | class=CKD Stage 5, auc=0.961638
  + micro auc=0.866200 | macro auc=0.822970
  + Ranked AUC scores: 
    + class=CKD Stage 3, auc=0.706504
    + class=CKD Stage 2, auc=0.764699
    + class=Others, auc=0.820732
    + class=CKD Stage 4, auc=0.822097
    + class=CKD Stage 1, auc=0.857106
    + class=CKD Stage 5, auc=0.961638
  => [('CKD Stage 3', 0.70650404140257028), ('CKD Stage 2', 0.76469890432231902), ('Others', 0.82073197457812841), ('CKD Stage 4', 0.82209660842754373), ('CKD Stage 1', 0.8571064263855831), ('CKD Stage 5', 0.96163785090165455)]
output> saving performance to:
/Users/pleiades/Documents/work/tpheno/seqmaker/data/CKD/plot/roc-multiclass-Sequential-CKD-pv-dm2-regular-smallCKD.tif

runROCMulticlass> test set ratio: 0.300000
modelEvaluate> dim(X_train):(1651, 50, 100), dim(X_test): (709, 50, 100)
  + lookup:
{'Others': 5, 'CKD Stage 5': 4, 'CKD Stage 4': 3, 'CKD Stage 3': 2, 'CKD Stage 2': 1, 'CKD Stage 1': 0}

... class weights:
{0: 6.344086021505376, 1: 0.74494949494949492, 2: 1.1238095238095238, 3: 7.0238095238095237, 4: 0.51890941072999119, 5: 0.64906490649064907}

====================================================================================================
... early stopping>
       + patience: 20, model='max'
... model training>
       + batch_size: 32, epochs: 80, shuffle? True, metric: auc_roc
====================================================================================================
Epoch 1/80
1651/1651 [==============================] - 3s 2ms/step - loss: 1.7547 - acc: 0.2314 - auc_roc: 0.9738
Epoch 2/80
1651/1651 [==============================] - 3s 2ms/step - loss: 1.6463 - acc: 0.3362 - auc_roc: 0.9733
Epoch 3/80
1651/1651 [==============================] - 4s 2ms/step - loss: 1.4999 - acc: 0.4434 - auc_roc: 0.9728
Epoch 4/80
1651/1651 [==============================] - 4s 2ms/step - loss: 1.3378 - acc: 0.4488 - auc_roc: 0.9724
Epoch 5/80
1651/1651 [==============================] - 4s 2ms/step - loss: 1.2027 - acc: 0.5015 - auc_roc: 0.9721
Epoch 6/80
1651/1651 [==============================] - 4s 2ms/step - loss: 1.2800 - acc: 0.4706 - auc_roc: 0.9718
Epoch 7/80
1651/1651 [==============================] - 4s 2ms/step - loss: 1.0607 - acc: 0.5742 - auc_roc: 0.9715
Epoch 8/80
1651/1651 [==============================] - 4s 2ms/step - loss: 1.0320 - acc: 0.5518 - auc_roc: 0.9712
Epoch 9/80
1651/1651 [==============================] - 4s 2ms/step - loss: 0.9699 - acc: 0.5748 - auc_roc: 0.9710
Epoch 10/80
1651/1651 [==============================] - 4s 2ms/step - loss: 0.8867 - acc: 0.6148 - auc_roc: 0.9708
Epoch 11/80
1651/1651 [==============================] - 4s 2ms/step - loss: 0.8495 - acc: 0.6402 - auc_roc: 0.9706
Epoch 12/80
1651/1651 [==============================] - 4s 2ms/step - loss: 0.8437 - acc: 0.6245 - auc_roc: 0.9704
Epoch 13/80
1651/1651 [==============================] - 4s 2ms/step - loss: 0.7812 - acc: 0.6457 - auc_roc: 0.9703
Epoch 14/80
1651/1651 [==============================] - 4s 2ms/step - loss: 0.7995 - acc: 0.6281 - auc_roc: 0.9701
Epoch 15/80
1651/1651 [==============================] - 4s 2ms/step - loss: 0.7499 - acc: 0.6626 - auc_roc: 0.9699
Epoch 16/80
1651/1651 [==============================] - 4s 2ms/step - loss: 0.7116 - acc: 0.6681 - auc_roc: 0.9698
Epoch 17/80
1651/1651 [==============================] - 4s 2ms/step - loss: 0.6464 - acc: 0.7002 - auc_roc: 0.9697
Epoch 18/80
1651/1651 [==============================] - 4s 2ms/step - loss: 0.7141 - acc: 0.6729 - auc_roc: 0.9696
Epoch 19/80
1651/1651 [==============================] - 4s 2ms/step - loss: 0.6577 - acc: 0.6935 - auc_roc: 0.9694
Epoch 20/80
1651/1651 [==============================] - 4s 2ms/step - loss: 0.6094 - acc: 0.7123 - auc_roc: 0.9694
Epoch 21/80
1651/1651 [==============================] - 4s 2ms/step - loss: 0.5729 - acc: 0.7123 - auc_roc: 0.9693
Epoch 22/80
1651/1651 [==============================] - 4s 2ms/step - loss: 0.5272 - acc: 0.7365 - auc_roc: 0.9692
Epoch 23/80
1651/1651 [==============================] - 4s 2ms/step - loss: 0.5110 - acc: 0.7444 - auc_roc: 0.9692
Epoch 24/80
1651/1651 [==============================] - 4s 2ms/step - loss: 0.5255 - acc: 0.7498 - auc_roc: 0.9691
Epoch 25/80
1651/1651 [==============================] - 4s 2ms/step - loss: 0.4607 - acc: 0.7753 - auc_roc: 0.9691
Epoch 26/80
1651/1651 [==============================] - 4s 2ms/step - loss: 0.4310 - acc: 0.7820 - auc_roc: 0.9691
Epoch 27/80
1651/1651 [==============================] - 4s 2ms/step - loss: 0.4166 - acc: 0.7995 - auc_roc: 0.9691
Epoch 28/80
1651/1651 [==============================] - 4s 2ms/step - loss: 0.5768 - acc: 0.7171 - auc_roc: 0.9691
Epoch 29/80
1651/1651 [==============================] - 4s 2ms/step - loss: 0.4900 - acc: 0.7662 - auc_roc: 0.9690
Epoch 30/80
1651/1651 [==============================] - 4s 2ms/step - loss: 0.4264 - acc: 0.7874 - auc_roc: 0.9690
Epoch 31/80
1651/1651 [==============================] - 4s 2ms/step - loss: 0.4052 - acc: 0.7935 - auc_roc: 0.9690
Epoch 32/80
1651/1651 [==============================] - 4s 2ms/step - loss: 0.3525 - acc: 0.8310 - auc_roc: 0.9690
Epoch 33/80
1651/1651 [==============================] - 4s 2ms/step - loss: 0.3286 - acc: 0.8455 - auc_roc: 0.9690
Epoch 34/80
1651/1651 [==============================] - 4s 2ms/step - loss: 0.3092 - acc: 0.8577 - auc_roc: 0.9691
Epoch 35/80
1651/1651 [==============================] - 4s 2ms/step - loss: 0.3857 - acc: 0.8098 - auc_roc: 0.9692
Epoch 36/80
1651/1651 [==============================] - 3s 2ms/step - loss: 0.3333 - acc: 0.8455 - auc_roc: 0.9692
Epoch 37/80
1651/1651 [==============================] - 4s 2ms/step - loss: 0.2864 - acc: 0.8667 - auc_roc: 0.9693
Epoch 38/80
1651/1651 [==============================] - 4s 2ms/step - loss: 0.3431 - acc: 0.8286 - auc_roc: 0.9693
Epoch 39/80
1651/1651 [==============================] - 4s 2ms/step - loss: 0.3026 - acc: 0.8540 - auc_roc: 0.9694
Epoch 40/80
1651/1651 [==============================] - 4s 2ms/step - loss: 0.3532 - acc: 0.8455 - auc_roc: 0.9694
Epoch 41/80
1651/1651 [==============================] - 4s 2ms/step - loss: 0.2662 - acc: 0.8837 - auc_roc: 0.9695
Epoch 42/80
1651/1651 [==============================] - 4s 2ms/step - loss: 0.2163 - acc: 0.9049 - auc_roc: 0.9696
Epoch 43/80
1651/1651 [==============================] - 4s 2ms/step - loss: 0.1883 - acc: 0.9128 - auc_roc: 0.9697
Epoch 44/80
1651/1651 [==============================] - 4s 2ms/step - loss: 0.1691 - acc: 0.9200 - auc_roc: 0.9698
Epoch 45/80
1651/1651 [==============================] - 4s 2ms/step - loss: 0.1601 - acc: 0.9273 - auc_roc: 0.9699
Epoch 46/80
1651/1651 [==============================] - 4s 2ms/step - loss: 0.1744 - acc: 0.9261 - auc_roc: 0.9700
Epoch 47/80
1651/1651 [==============================] - 4s 2ms/step - loss: 0.1360 - acc: 0.9467 - auc_roc: 0.9702
Epoch 48/80
1651/1651 [==============================] - 4s 2ms/step - loss: 0.2942 - acc: 0.8752 - auc_roc: 0.9703
Epoch 49/80
1651/1651 [==============================] - 4s 2ms/step - loss: 0.2273 - acc: 0.9061 - auc_roc: 0.9703
Epoch 50/80
1651/1651 [==============================] - 4s 2ms/step - loss: 0.2553 - acc: 0.8928 - auc_roc: 0.9704
Epoch 51/80
1651/1651 [==============================] - 4s 2ms/step - loss: 0.2338 - acc: 0.9079 - auc_roc: 0.9705
Epoch 52/80
1651/1651 [==============================] - 4s 2ms/step - loss: 0.2048 - acc: 0.9152 - auc_roc: 0.9706
Epoch 53/80
1651/1651 [==============================] - 4s 2ms/step - loss: 0.1563 - acc: 0.9394 - auc_roc: 0.9707
Epoch 54/80
1651/1651 [==============================] - 4s 2ms/step - loss: 0.1233 - acc: 0.9515 - auc_roc: 0.9709
Epoch 55/80
1651/1651 [==============================] - 4s 2ms/step - loss: 0.0958 - acc: 0.9667 - auc_roc: 0.9710
Epoch 56/80
1651/1651 [==============================] - 4s 2ms/step - loss: 0.0978 - acc: 0.9606 - auc_roc: 0.9712
Epoch 57/80
1651/1651 [==============================] - 4s 2ms/step - loss: 0.1022 - acc: 0.9582 - auc_roc: 0.9713
Epoch 58/80
1651/1651 [==============================] - 4s 2ms/step - loss: 0.0968 - acc: 0.9649 - auc_roc: 0.9714
Epoch 59/80
1651/1651 [==============================] - 4s 2ms/step - loss: 0.0724 - acc: 0.9727 - auc_roc: 0.9716
Epoch 60/80
1651/1651 [==============================] - 4s 2ms/step - loss: 0.0725 - acc: 0.9715 - auc_roc: 0.9717
Epoch 61/80
1651/1651 [==============================] - 3s 2ms/step - loss: 0.0560 - acc: 0.9764 - auc_roc: 0.9719
Epoch 62/80
1651/1651 [==============================] - 4s 2ms/step - loss: 0.0552 - acc: 0.9788 - auc_roc: 0.9721
Epoch 63/80
1651/1651 [==============================] - 4s 2ms/step - loss: 0.0524 - acc: 0.9800 - auc_roc: 0.9722
Epoch 64/80
1651/1651 [==============================] - 4s 2ms/step - loss: 0.0841 - acc: 0.9715 - auc_roc: 0.9724
Epoch 65/80
1651/1651 [==============================] - 4s 2ms/step - loss: 0.1346 - acc: 0.9515 - auc_roc: 0.9725
Epoch 66/80
1651/1651 [==============================] - 4s 2ms/step - loss: 0.1956 - acc: 0.9231 - auc_roc: 0.9726
Epoch 67/80
1651/1651 [==============================] - 4s 3ms/step - loss: 0.0988 - acc: 0.9624 - auc_roc: 0.9727
Epoch 68/80
1651/1651 [==============================] - 4s 2ms/step - loss: 0.1397 - acc: 0.9431 - auc_roc: 0.9728
Epoch 69/80
1651/1651 [==============================] - 3s 2ms/step - loss: 0.1528 - acc: 0.9467 - auc_roc: 0.9730
Epoch 70/80
1651/1651 [==============================] - 3s 2ms/step - loss: 0.3139 - acc: 0.8849 - auc_roc: 0.9730
Epoch 71/80
1651/1651 [==============================] - 3s 2ms/step - loss: 0.1478 - acc: 0.9297 - auc_roc: 0.9731
Epoch 72/80
1651/1651 [==============================] - 3s 2ms/step - loss: 0.0932 - acc: 0.9655 - auc_roc: 0.9732
Epoch 73/80
1651/1651 [==============================] - 3s 2ms/step - loss: 0.0710 - acc: 0.9746 - auc_roc: 0.9734
Epoch 74/80
1651/1651 [==============================] - 3s 2ms/step - loss: 0.0600 - acc: 0.9758 - auc_roc: 0.9735
Epoch 75/80
1651/1651 [==============================] - 3s 2ms/step - loss: 0.0449 - acc: 0.9867 - auc_roc: 0.9736
Epoch 76/80
1651/1651 [==============================] - 3s 2ms/step - loss: 0.0365 - acc: 0.9909 - auc_roc: 0.9738
Epoch 77/80
1651/1651 [==============================] - 3s 2ms/step - loss: 0.0372 - acc: 0.9903 - auc_roc: 0.9739
Epoch 78/80
1651/1651 [==============================] - 3s 2ms/step - loss: 0.1096 - acc: 0.9709 - auc_roc: 0.9741
Epoch 79/80
1651/1651 [==============================] - 3s 2ms/step - loss: 0.2212 - acc: 0.9219 - auc_roc: 0.9742
Epoch 80/80
1651/1651 [==============================] - 3s 2ms/step - loss: 0.1003 - acc: 0.9643 - auc_roc: 0.9743
... history of metrics comprising: ['acc', 'loss', 'auc_roc']
... model fitting complete > starting model evaluation
modelEvaluate> scores:
[('loss', 1.9026417594366249), ('acc', 0.55007052202991435), ('auc_roc', 0.97424716724159011)]

info> infer classifier name from class name ...
runROCMulticlass> find 6 unique labels:
CKD Stage 1, CKD Stage 2, CKD Stage 3, CKD Stage 4, CKD Stage 5, Others

info> given pre-trained model ...
diagnosis> dim(y_score):(709, 6)
>>> test_auc_cv_metrics >>>
  + dimension test 
  + len(roc_auc):8 =?= n_classes (+{micro, macro}):6+2
  + class name: CKD Stage 1, mean_auc: 0.847202
  + ROC curve of class CKD Stage 1 (area = 0.85)
  + class name: CKD Stage 2, mean_auc: 0.738646
  + ROC curve of class CKD Stage 2 (area = 0.74)
  + class name: CKD Stage 3, mean_auc: 0.685045
  + ROC curve of class CKD Stage 3 (area = 0.69)
  + class name: CKD Stage 4, mean_auc: 0.767429
  + ROC curve of class CKD Stage 4 (area = 0.77)
  + class name: CKD Stage 5, mean_auc: 0.955051
  + ROC curve of class CKD Stage 5 (area = 0.96)
  + class name: Others, mean_auc: 0.811571
  + ROC curve of class Others (area = 0.81)
test_auc_cv_metrics> summary of AUCs vs classes ...
  + min | class=CKD Stage 3, auc=0.685045
  + max | class=CKD Stage 5, auc=0.955051
  + micro auc=0.857602 | macro auc=0.801729
  + Ranked AUC scores: 
    + class=CKD Stage 3, auc=0.685045
    + class=CKD Stage 2, auc=0.738646
    + class=CKD Stage 4, auc=0.767429
    + class=Others, auc=0.811571
    + class=CKD Stage 1, auc=0.847202
    + class=CKD Stage 5, auc=0.955051
  => [('CKD Stage 3', 0.68504480830132741), ('CKD Stage 2', 0.73864649231505031), ('CKD Stage 4', 0.76742944317315032), ('Others', 0.81157096157404551), ('CKD Stage 1', 0.84720194647201941), ('CKD Stage 5', 0.95505106108348203)]
output> saving performance to:
/Users/pleiades/Documents/work/tpheno/seqmaker/data/CKD/plot/roc-multiclass-Sequential-CKD-pv-dm2-regular-smallCKD.tif

runROCMulticlass> test set ratio: 0.300000
modelEvaluate> dim(X_train):(1651, 50, 100), dim(X_test): (709, 50, 100)
  + lookup:
{'Others': 5, 'CKD Stage 5': 4, 'CKD Stage 4': 3, 'CKD Stage 3': 2, 'CKD Stage 2': 1, 'CKD Stage 1': 0}

... class weights:
{0: 6.344086021505376, 1: 0.74494949494949492, 2: 1.1238095238095238, 3: 7.0238095238095237, 4: 0.51890941072999119, 5: 0.64906490649064907}

====================================================================================================
... early stopping>
       + patience: 20, model='max'
... model training>
       + batch_size: 32, epochs: 80, shuffle? True, metric: auc_roc
====================================================================================================
Epoch 1/80
1651/1651 [==============================] - 3s 2ms/step - loss: 1.8519 - acc: 0.1339 - auc_roc: 0.9739
Epoch 2/80
1651/1651 [==============================] - 3s 2ms/step - loss: 1.7340 - acc: 0.2877 - auc_roc: 0.9735
Epoch 3/80
1651/1651 [==============================] - 3s 2ms/step - loss: 1.5838 - acc: 0.3798 - auc_roc: 0.9731
Epoch 4/80
1651/1651 [==============================] - 3s 2ms/step - loss: 1.3931 - acc: 0.4609 - auc_roc: 0.9728
Epoch 5/80
1651/1651 [==============================] - 3s 2ms/step - loss: 1.2467 - acc: 0.4985 - auc_roc: 0.9726
Epoch 6/80
1651/1651 [==============================] - 3s 2ms/step - loss: 1.1136 - acc: 0.5657 - auc_roc: 0.9724
Epoch 7/80
1651/1651 [==============================] - 3s 2ms/step - loss: 1.0884 - acc: 0.5663 - auc_roc: 0.9722
Epoch 8/80
1651/1651 [==============================] - 3s 2ms/step - loss: 1.0057 - acc: 0.5869 - auc_roc: 0.9720
Epoch 9/80
1651/1651 [==============================] - 3s 2ms/step - loss: 0.9321 - acc: 0.6148 - auc_roc: 0.9718
Epoch 10/80
1651/1651 [==============================] - 3s 2ms/step - loss: 0.9071 - acc: 0.6227 - auc_roc: 0.9716
Epoch 11/80
1651/1651 [==============================] - 3s 2ms/step - loss: 0.8434 - acc: 0.6396 - auc_roc: 0.9715
Epoch 12/80
1651/1651 [==============================] - 3s 2ms/step - loss: 0.7457 - acc: 0.6632 - auc_roc: 0.9714
Epoch 13/80
1651/1651 [==============================] - 3s 2ms/step - loss: 0.7657 - acc: 0.6439 - auc_roc: 0.9713
Epoch 14/80
1651/1651 [==============================] - 3s 2ms/step - loss: 0.7406 - acc: 0.6596 - auc_roc: 0.9712
Epoch 15/80
1651/1651 [==============================] - 3s 2ms/step - loss: 0.6929 - acc: 0.6844 - auc_roc: 0.9711
Epoch 16/80
1651/1651 [==============================] - 3s 2ms/step - loss: 0.7617 - acc: 0.6529 - auc_roc: 0.9710
Epoch 17/80
1651/1651 [==============================] - 3s 2ms/step - loss: 0.6907 - acc: 0.6796 - auc_roc: 0.9709
Epoch 18/80
1651/1651 [==============================] - 3s 2ms/step - loss: 0.6318 - acc: 0.6917 - auc_roc: 0.9708
Epoch 19/80
1651/1651 [==============================] - 3s 2ms/step - loss: 0.6111 - acc: 0.6959 - auc_roc: 0.9707
Epoch 20/80
1651/1651 [==============================] - 3s 2ms/step - loss: 0.5540 - acc: 0.7426 - auc_roc: 0.9706
Epoch 21/80
1651/1651 [==============================] - 3s 2ms/step - loss: 0.5756 - acc: 0.7093 - auc_roc: 0.9706
Epoch 22/80
1651/1651 [==============================] - 3s 2ms/step - loss: 0.6991 - acc: 0.6990 - auc_roc: 0.9705
Epoch 23/80
1651/1651 [==============================] - 3s 2ms/step - loss: 0.5615 - acc: 0.7341 - auc_roc: 0.9704
Epoch 24/80
1651/1651 [==============================] - 3s 2ms/step - loss: 0.5151 - acc: 0.7565 - auc_roc: 0.9704
Epoch 25/80
1651/1651 [==============================] - 3s 2ms/step - loss: 0.4814 - acc: 0.7595 - auc_roc: 0.9704
Epoch 26/80
1651/1651 [==============================] - 3s 2ms/step - loss: 0.6298 - acc: 0.7232 - auc_roc: 0.9704
Epoch 27/80
1651/1651 [==============================] - 3s 2ms/step - loss: 0.6816 - acc: 0.6972 - auc_roc: 0.9703
Epoch 28/80
1651/1651 [==============================] - 3s 2ms/step - loss: 0.5279 - acc: 0.7456 - auc_roc: 0.9702
Epoch 29/80
1651/1651 [==============================] - 3s 2ms/step - loss: 0.4707 - acc: 0.7771 - auc_roc: 0.9702
Epoch 30/80
1651/1651 [==============================] - 3s 2ms/step - loss: 0.4654 - acc: 0.7747 - auc_roc: 0.9702
Epoch 31/80
1651/1651 [==============================] - 3s 2ms/step - loss: 0.4381 - acc: 0.7850 - auc_roc: 0.9702
Epoch 32/80
1651/1651 [==============================] - 3s 2ms/step - loss: 0.3914 - acc: 0.8177 - auc_roc: 0.9702
Epoch 33/80
1651/1651 [==============================] - 3s 2ms/step - loss: 0.3639 - acc: 0.8298 - auc_roc: 0.9702
Epoch 34/80
1651/1651 [==============================] - 3s 2ms/step - loss: 0.3404 - acc: 0.8353 - auc_roc: 0.9702
Epoch 35/80
1651/1651 [==============================] - 3s 2ms/step - loss: 0.3065 - acc: 0.8522 - auc_roc: 0.9702
Epoch 36/80
1651/1651 [==============================] - 3s 2ms/step - loss: 0.3059 - acc: 0.8504 - auc_roc: 0.9703
Epoch 37/80
1651/1651 [==============================] - 3s 2ms/step - loss: 0.2804 - acc: 0.8613 - auc_roc: 0.9703
Epoch 38/80
1651/1651 [==============================] - 3s 2ms/step - loss: 0.2449 - acc: 0.8873 - auc_roc: 0.9704
Epoch 39/80
1651/1651 [==============================] - 3s 2ms/step - loss: 0.3728 - acc: 0.8280 - auc_roc: 0.9705
Epoch 40/80
1651/1651 [==============================] - 3s 2ms/step - loss: 0.3494 - acc: 0.8340 - auc_roc: 0.9705
Epoch 41/80
1651/1651 [==============================] - 3s 2ms/step - loss: 0.3916 - acc: 0.8153 - auc_roc: 0.9705
Epoch 42/80
1651/1651 [==============================] - 3s 2ms/step - loss: 0.2888 - acc: 0.8625 - auc_roc: 0.9705
Epoch 43/80
1651/1651 [==============================] - 3s 2ms/step - loss: 0.2210 - acc: 0.9013 - auc_roc: 0.9706
Epoch 44/80
1651/1651 [==============================] - 3s 2ms/step - loss: 0.3283 - acc: 0.8643 - auc_roc: 0.9706
Epoch 45/80
1651/1651 [==============================] - 3s 2ms/step - loss: 0.2846 - acc: 0.8770 - auc_roc: 0.9707
Epoch 46/80
1651/1651 [==============================] - 3s 2ms/step - loss: 0.2168 - acc: 0.9104 - auc_roc: 0.9708
Epoch 47/80
1651/1651 [==============================] - 3s 2ms/step - loss: 0.1597 - acc: 0.9243 - auc_roc: 0.9708
Epoch 48/80
1651/1651 [==============================] - 3s 2ms/step - loss: 0.1475 - acc: 0.9388 - auc_roc: 0.9709
Epoch 49/80
1651/1651 [==============================] - 3s 2ms/step - loss: 0.1266 - acc: 0.9485 - auc_roc: 0.9710
Epoch 50/80
1651/1651 [==============================] - 3s 2ms/step - loss: 0.1203 - acc: 0.9522 - auc_roc: 0.9712
Epoch 51/80
1651/1651 [==============================] - 3s 2ms/step - loss: 0.1018 - acc: 0.9618 - auc_roc: 0.9713
Epoch 52/80
1651/1651 [==============================] - 3s 2ms/step - loss: 0.1018 - acc: 0.9564 - auc_roc: 0.9714
Epoch 53/80
1651/1651 [==============================] - 3s 2ms/step - loss: 0.0863 - acc: 0.9624 - auc_roc: 0.9715
Epoch 54/80
1651/1651 [==============================] - 3s 2ms/step - loss: 0.0879 - acc: 0.9582 - auc_roc: 0.9716
Epoch 55/80
1651/1651 [==============================] - 3s 2ms/step - loss: 0.0795 - acc: 0.9679 - auc_roc: 0.9717
Epoch 56/80
1651/1651 [==============================] - 3s 2ms/step - loss: 0.1582 - acc: 0.9364 - auc_roc: 0.9718
Epoch 57/80
1651/1651 [==============================] - 3s 2ms/step - loss: 0.1682 - acc: 0.9231 - auc_roc: 0.9719
Epoch 58/80
1651/1651 [==============================] - 3s 2ms/step - loss: 0.2536 - acc: 0.8904 - auc_roc: 0.9720
Epoch 59/80
1651/1651 [==============================] - 3s 2ms/step - loss: 0.1269 - acc: 0.9491 - auc_roc: 0.9721
Epoch 60/80
1651/1651 [==============================] - 3s 2ms/step - loss: 0.0961 - acc: 0.9618 - auc_roc: 0.9722
Epoch 61/80
1651/1651 [==============================] - 3s 2ms/step - loss: 0.0732 - acc: 0.9764 - auc_roc: 0.9723
Epoch 62/80
1651/1651 [==============================] - 3s 2ms/step - loss: 0.0578 - acc: 0.9806 - auc_roc: 0.9724
Epoch 63/80
1651/1651 [==============================] - 3s 2ms/step - loss: 0.0600 - acc: 0.9806 - auc_roc: 0.9725
Epoch 64/80
1651/1651 [==============================] - 3s 2ms/step - loss: 0.0467 - acc: 0.9849 - auc_roc: 0.9727
Epoch 65/80
1651/1651 [==============================] - 3s 2ms/step - loss: 0.0403 - acc: 0.9873 - auc_roc: 0.9728
Epoch 66/80
1651/1651 [==============================] - 3s 2ms/step - loss: 0.0331 - acc: 0.9909 - auc_roc: 0.9729
Epoch 67/80
1651/1651 [==============================] - 3s 2ms/step - loss: 0.1403 - acc: 0.9594 - auc_roc: 0.9730
Epoch 68/80
1651/1651 [==============================] - 3s 2ms/step - loss: 0.3214 - acc: 0.8873 - auc_roc: 0.9731
Epoch 69/80
1651/1651 [==============================] - 3s 2ms/step - loss: 0.1732 - acc: 0.9291 - auc_roc: 0.9731
Epoch 70/80
1651/1651 [==============================] - 3s 2ms/step - loss: 0.1009 - acc: 0.9618 - auc_roc: 0.9732
Epoch 71/80
1651/1651 [==============================] - 3s 2ms/step - loss: 0.0742 - acc: 0.9727 - auc_roc: 0.9733
Epoch 72/80
1651/1651 [==============================] - 3s 2ms/step - loss: 0.0556 - acc: 0.9818 - auc_roc: 0.9735
Epoch 73/80
1651/1651 [==============================] - 3s 2ms/step - loss: 0.0477 - acc: 0.9843 - auc_roc: 0.9736
Epoch 74/80
1651/1651 [==============================] - 3s 2ms/step - loss: 0.0386 - acc: 0.9873 - auc_roc: 0.9737
Epoch 75/80
1651/1651 [==============================] - 3s 2ms/step - loss: 0.0384 - acc: 0.9873 - auc_roc: 0.9738
Epoch 76/80
1651/1651 [==============================] - 3s 2ms/step - loss: 0.0385 - acc: 0.9867 - auc_roc: 0.9739
Epoch 77/80
1651/1651 [==============================] - 3s 2ms/step - loss: 0.0276 - acc: 0.9945 - auc_roc: 0.9740
Epoch 78/80
1651/1651 [==============================] - 3s 2ms/step - loss: 0.0254 - acc: 0.9933 - auc_roc: 0.9742
Epoch 79/80
1651/1651 [==============================] - 3s 2ms/step - loss: 0.0208 - acc: 0.9939 - auc_roc: 0.9743
Epoch 80/80
1651/1651 [==============================] - 3s 2ms/step - loss: 0.0307 - acc: 0.9921 - auc_roc: 0.9744
... history of metrics comprising: ['acc', 'loss', 'auc_roc']
... model fitting complete > starting model evaluation
modelEvaluate> scores:
[('loss', 2.1735123515297228), ('acc', 0.596614950802834), ('auc_roc', 0.97436696257342403)]

info> infer classifier name from class name ...
runROCMulticlass> find 6 unique labels:
CKD Stage 1, CKD Stage 2, CKD Stage 3, CKD Stage 4, CKD Stage 5, Others

info> given pre-trained model ...
diagnosis> dim(y_score):(709, 6)
>>> test_auc_cv_metrics >>>
  + dimension test 
  + len(roc_auc):8 =?= n_classes (+{micro, macro}):6+2
  + class name: CKD Stage 1, mean_auc: 0.794913
  + ROC curve of class CKD Stage 1 (area = 0.79)
  + class name: CKD Stage 2, mean_auc: 0.776189
  + ROC curve of class CKD Stage 2 (area = 0.78)
  + class name: CKD Stage 3, mean_auc: 0.769595
  + ROC curve of class CKD Stage 3 (area = 0.77)
  + class name: CKD Stage 4, mean_auc: 0.716733
  + ROC curve of class CKD Stage 4 (area = 0.72)
  + class name: CKD Stage 5, mean_auc: 0.942322
  + ROC curve of class CKD Stage 5 (area = 0.94)
  + class name: Others, mean_auc: 0.845478
  + ROC curve of class Others (area = 0.85)
test_auc_cv_metrics> summary of AUCs vs classes ...
  + min | class=CKD Stage 4, auc=0.716733
  + max | class=CKD Stage 5, auc=0.942322
  + micro auc=0.877671 | macro auc=0.808518
  + Ranked AUC scores: 
    + class=CKD Stage 4, auc=0.716733
    + class=CKD Stage 3, auc=0.769595
    + class=CKD Stage 2, auc=0.776189
    + class=CKD Stage 1, auc=0.794913
    + class=Others, auc=0.845478
    + class=CKD Stage 5, auc=0.942322
  => [('CKD Stage 4', 0.71673297966401417), ('CKD Stage 3', 0.76959541913076135), ('CKD Stage 2', 0.77618943692710607), ('CKD Stage 1', 0.79491341991341991), ('Others', 0.84547777847036099), ('CKD Stage 5', 0.9423215638186605)]
output> saving performance to:
/Users/pleiades/Documents/work/tpheno/seqmaker/data/CKD/plot/roc-multiclass-Sequential-CKD-pv-dm2-regular-smallCKD.tif

runROCMulticlass> test set ratio: 0.300000
modelEvaluate> dim(X_train):(1651, 50, 100), dim(X_test): (709, 50, 100)
  + lookup:
{'Others': 5, 'CKD Stage 5': 4, 'CKD Stage 4': 3, 'CKD Stage 3': 2, 'CKD Stage 2': 1, 'CKD Stage 1': 0}

... class weights:
{0: 6.344086021505376, 1: 0.74494949494949492, 2: 1.1238095238095238, 3: 7.0238095238095237, 4: 0.51890941072999119, 5: 0.64906490649064907}

====================================================================================================
... early stopping>
       + patience: 20, model='max'
... model training>
       + batch_size: 32, epochs: 80, shuffle? True, metric: auc_roc
====================================================================================================
Epoch 1/80
1651/1651 [==============================] - 3s 2ms/step - loss: 1.7747 - acc: 0.2090 - auc_roc: 0.9741
Epoch 2/80
1651/1651 [==============================] - 3s 2ms/step - loss: 1.6637 - acc: 0.3101 - auc_roc: 0.9738
Epoch 3/80
1651/1651 [==============================] - 3s 2ms/step - loss: 1.4708 - acc: 0.4640 - auc_roc: 0.9735
Epoch 4/80
1651/1651 [==============================] - 3s 2ms/step - loss: 1.3442 - acc: 0.4500 - auc_roc: 0.9733
Epoch 5/80
1651/1651 [==============================] - 3s 2ms/step - loss: 1.2424 - acc: 0.5130 - auc_roc: 0.9731
Epoch 6/80
1651/1651 [==============================] - 3s 2ms/step - loss: 1.1094 - acc: 0.5518 - auc_roc: 0.9729
Epoch 7/80
1651/1651 [==============================] - 3s 2ms/step - loss: 1.0144 - acc: 0.5736 - auc_roc: 0.9728
Epoch 8/80
1651/1651 [==============================] - 3s 2ms/step - loss: 0.9956 - acc: 0.5815 - auc_roc: 0.9726
Epoch 9/80
1651/1651 [==============================] - 3s 2ms/step - loss: 0.8777 - acc: 0.6124 - auc_roc: 0.9725
Epoch 10/80
1651/1651 [==============================] - 3s 2ms/step - loss: 0.8514 - acc: 0.6214 - auc_roc: 0.9724
Epoch 11/80
1651/1651 [==============================] - 3s 2ms/step - loss: 0.8220 - acc: 0.6354 - auc_roc: 0.9723
Epoch 12/80
1651/1651 [==============================] - 3s 2ms/step - loss: 0.7341 - acc: 0.6638 - auc_roc: 0.9722
Epoch 13/80
1651/1651 [==============================] - 3s 2ms/step - loss: 0.6991 - acc: 0.6644 - auc_roc: 0.9721
Epoch 14/80
1651/1651 [==============================] - 3s 2ms/step - loss: 0.6692 - acc: 0.6978 - auc_roc: 0.9721
Epoch 15/80
1651/1651 [==============================] - 3s 2ms/step - loss: 0.6523 - acc: 0.6766 - auc_roc: 0.9720
Epoch 16/80
1651/1651 [==============================] - 3s 2ms/step - loss: 0.8826 - acc: 0.6227 - auc_roc: 0.9719
Epoch 17/80
1651/1651 [==============================] - 3s 2ms/step - loss: 0.6852 - acc: 0.6923 - auc_roc: 0.9718
Epoch 18/80
1651/1651 [==============================] - 3s 2ms/step - loss: 0.6546 - acc: 0.6941 - auc_roc: 0.9717
Epoch 19/80
1651/1651 [==============================] - 3s 2ms/step - loss: 0.6619 - acc: 0.6863 - auc_roc: 0.9717
Epoch 20/80
1651/1651 [==============================] - 3s 2ms/step - loss: 0.6172 - acc: 0.7062 - auc_roc: 0.9716
Epoch 21/80
1651/1651 [==============================] - 3s 2ms/step - loss: 0.5585 - acc: 0.7359 - auc_roc: 0.9716
Epoch 22/80
1651/1651 [==============================] - 3s 2ms/step - loss: 0.5119 - acc: 0.7456 - auc_roc: 0.9715
Epoch 23/80
1651/1651 [==============================] - 3s 2ms/step - loss: 0.5007 - acc: 0.7377 - auc_roc: 0.9715
Epoch 24/80
1651/1651 [==============================] - 3s 2ms/step - loss: 0.5379 - acc: 0.7523 - auc_roc: 0.9715
Epoch 25/80
1651/1651 [==============================] - 3s 2ms/step - loss: 0.4688 - acc: 0.7729 - auc_roc: 0.9714
Epoch 26/80
1651/1651 [==============================] - 3s 2ms/step - loss: 0.4438 - acc: 0.7844 - auc_roc: 0.9714
Epoch 27/80
1651/1651 [==============================] - 3s 2ms/step - loss: 0.4150 - acc: 0.7989 - auc_roc: 0.9714
Epoch 28/80
1651/1651 [==============================] - 3s 2ms/step - loss: 0.3967 - acc: 0.7989 - auc_roc: 0.9714
Epoch 29/80
1651/1651 [==============================] - 3s 2ms/step - loss: 0.3565 - acc: 0.8165 - auc_roc: 0.9715
Epoch 30/80
1651/1651 [==============================] - 3s 2ms/step - loss: 0.3618 - acc: 0.8256 - auc_roc: 0.9715
Epoch 31/80
1651/1651 [==============================] - 3s 2ms/step - loss: 0.3581 - acc: 0.8147 - auc_roc: 0.9715
Epoch 32/80
1651/1651 [==============================] - 3s 2ms/step - loss: 0.3451 - acc: 0.8322 - auc_roc: 0.9715
Epoch 33/80
1651/1651 [==============================] - 3s 2ms/step - loss: 0.3928 - acc: 0.8080 - auc_roc: 0.9715
Epoch 34/80
1651/1651 [==============================] - 3s 2ms/step - loss: 0.3944 - acc: 0.8189 - auc_roc: 0.9715
Epoch 35/80
1651/1651 [==============================] - 3s 2ms/step - loss: 0.3089 - acc: 0.8571 - auc_roc: 0.9716
Epoch 36/80
1651/1651 [==============================] - 3s 2ms/step - loss: 0.3126 - acc: 0.8625 - auc_roc: 0.9716
Epoch 37/80
1651/1651 [==============================] - 3s 2ms/step - loss: 0.2556 - acc: 0.8789 - auc_roc: 0.9716
Epoch 38/80
1651/1651 [==============================] - 3s 2ms/step - loss: 0.2312 - acc: 0.8873 - auc_roc: 0.9717
Epoch 39/80
1651/1651 [==============================] - 3s 2ms/step - loss: 0.2334 - acc: 0.8873 - auc_roc: 0.9717
Epoch 40/80
1651/1651 [==============================] - 3s 2ms/step - loss: 0.2207 - acc: 0.8952 - auc_roc: 0.9718
Epoch 41/80
1651/1651 [==============================] - 3s 2ms/step - loss: 0.1931 - acc: 0.9085 - auc_roc: 0.9719
Epoch 42/80
1651/1651 [==============================] - 3s 2ms/step - loss: 0.3261 - acc: 0.8546 - auc_roc: 0.9719
Epoch 43/80
1651/1651 [==============================] - 3s 2ms/step - loss: 0.2787 - acc: 0.8776 - auc_roc: 0.9719
Epoch 44/80
1651/1651 [==============================] - 3s 2ms/step - loss: 0.1883 - acc: 0.9200 - auc_roc: 0.9720
Epoch 45/80
1651/1651 [==============================] - 3s 2ms/step - loss: 0.2149 - acc: 0.9031 - auc_roc: 0.9721
Epoch 46/80
1651/1651 [==============================] - 3s 2ms/step - loss: 0.1696 - acc: 0.9261 - auc_roc: 0.9721
Epoch 47/80
1651/1651 [==============================] - 3s 2ms/step - loss: 0.1315 - acc: 0.9388 - auc_roc: 0.9722
Epoch 48/80
1651/1651 [==============================] - 3s 2ms/step - loss: 0.1821 - acc: 0.9291 - auc_roc: 0.9723
Epoch 49/80
1651/1651 [==============================] - 3s 2ms/step - loss: 0.1600 - acc: 0.9291 - auc_roc: 0.9724
Epoch 50/80
1651/1651 [==============================] - 3s 2ms/step - loss: 0.1469 - acc: 0.9449 - auc_roc: 0.9724
Epoch 51/80
1651/1651 [==============================] - 3s 2ms/step - loss: 0.1053 - acc: 0.9546 - auc_roc: 0.9725
Epoch 52/80
1651/1651 [==============================] - 3s 2ms/step - loss: 0.0837 - acc: 0.9679 - auc_roc: 0.9726
Epoch 53/80
1651/1651 [==============================] - 3s 2ms/step - loss: 0.0898 - acc: 0.9606 - auc_roc: 0.9727
Epoch 54/80
1651/1651 [==============================] - 3s 2ms/step - loss: 0.0689 - acc: 0.9764 - auc_roc: 0.9728
Epoch 55/80
1651/1651 [==============================] - 3s 2ms/step - loss: 0.0711 - acc: 0.9721 - auc_roc: 0.9729
Epoch 56/80
1651/1651 [==============================] - 3s 2ms/step - loss: 0.0805 - acc: 0.9703 - auc_roc: 0.9730
Epoch 57/80
1651/1651 [==============================] - 3s 2ms/step - loss: 0.0693 - acc: 0.9721 - auc_roc: 0.9731
Epoch 58/80
1651/1651 [==============================] - 3s 2ms/step - loss: 0.0628 - acc: 0.9752 - auc_roc: 0.9732
Epoch 59/80
1651/1651 [==============================] - 3s 2ms/step - loss: 0.0511 - acc: 0.9794 - auc_roc: 0.9733
Epoch 60/80
1651/1651 [==============================] - 3s 2ms/step - loss: 0.0525 - acc: 0.9788 - auc_roc: 0.9734
Epoch 61/80
1651/1651 [==============================] - 3s 2ms/step - loss: 0.0361 - acc: 0.9885 - auc_roc: 0.9735
Epoch 62/80
1651/1651 [==============================] - 3s 2ms/step - loss: 0.2000 - acc: 0.9310 - auc_roc: 0.9736
Epoch 63/80
1651/1651 [==============================] - 3s 2ms/step - loss: 0.2789 - acc: 0.8758 - auc_roc: 0.9736
Epoch 64/80
1651/1651 [==============================] - 3s 2ms/step - loss: 0.1198 - acc: 0.9558 - auc_roc: 0.9737
Epoch 65/80
1651/1651 [==============================] - 3s 2ms/step - loss: 0.0709 - acc: 0.9776 - auc_roc: 0.9737
Epoch 66/80
1651/1651 [==============================] - 3s 2ms/step - loss: 0.1346 - acc: 0.9467 - auc_roc: 0.9738
Epoch 67/80
1651/1651 [==============================] - 3s 2ms/step - loss: 0.2944 - acc: 0.9037 - auc_roc: 0.9739
Epoch 68/80
1651/1651 [==============================] - 3s 2ms/step - loss: 0.1424 - acc: 0.9455 - auc_roc: 0.9739
Epoch 69/80
1651/1651 [==============================] - 3s 2ms/step - loss: 0.0804 - acc: 0.9697 - auc_roc: 0.9740
Epoch 70/80
1651/1651 [==============================] - 3s 2ms/step - loss: 0.0568 - acc: 0.9800 - auc_roc: 0.9741
Epoch 71/80
1651/1651 [==============================] - 3s 2ms/step - loss: 0.0443 - acc: 0.9855 - auc_roc: 0.9742
Epoch 72/80
1651/1651 [==============================] - 3s 2ms/step - loss: 0.0355 - acc: 0.9909 - auc_roc: 0.9743
Epoch 73/80
1651/1651 [==============================] - 3s 2ms/step - loss: 0.0341 - acc: 0.9867 - auc_roc: 0.9744
Epoch 74/80
1651/1651 [==============================] - 3s 2ms/step - loss: 0.0249 - acc: 0.9921 - auc_roc: 0.9745
Epoch 75/80
1651/1651 [==============================] - 3s 2ms/step - loss: 0.0280 - acc: 0.9891 - auc_roc: 0.9746
Epoch 76/80
1651/1651 [==============================] - 3s 2ms/step - loss: 0.0616 - acc: 0.9794 - auc_roc: 0.9747
Epoch 77/80
1651/1651 [==============================] - 3s 2ms/step - loss: 0.0268 - acc: 0.9933 - auc_roc: 0.9748
Epoch 78/80
1651/1651 [==============================] - 3s 2ms/step - loss: 0.0213 - acc: 0.9939 - auc_roc: 0.9749
Epoch 79/80
1651/1651 [==============================] - 3s 2ms/step - loss: 0.0183 - acc: 0.9958 - auc_roc: 0.9750
Epoch 80/80
1651/1651 [==============================] - 3s 2ms/step - loss: 0.0157 - acc: 0.9988 - auc_roc: 0.9751
... history of metrics comprising: ['acc', 'loss', 'auc_roc']
... model fitting complete > starting model evaluation
modelEvaluate> scores:
[('loss', 2.8642688389389406), ('acc', 0.55571227084598351), ('auc_roc', 0.97503701024734757)]

info> infer classifier name from class name ...
runROCMulticlass> find 6 unique labels:
CKD Stage 1, CKD Stage 2, CKD Stage 3, CKD Stage 4, CKD Stage 5, Others

info> given pre-trained model ...
diagnosis> dim(y_score):(709, 6)
>>> test_auc_cv_metrics >>>
  + dimension test 
  + len(roc_auc):8 =?= n_classes (+{micro, macro}):6+2
  + class name: CKD Stage 1, mean_auc: 0.853338
  + ROC curve of class CKD Stage 1 (area = 0.85)
  + class name: CKD Stage 2, mean_auc: 0.745279
  + ROC curve of class CKD Stage 2 (area = 0.75)
  + class name: CKD Stage 3, mean_auc: 0.732844
  + ROC curve of class CKD Stage 3 (area = 0.73)
  + class name: CKD Stage 4, mean_auc: 0.627994
  + ROC curve of class CKD Stage 4 (area = 0.63)
  + class name: CKD Stage 5, mean_auc: 0.949341
  + ROC curve of class CKD Stage 5 (area = 0.95)
  + class name: Others, mean_auc: 0.814524
  + ROC curve of class Others (area = 0.81)
test_auc_cv_metrics> summary of AUCs vs classes ...
  + min | class=CKD Stage 4, auc=0.627994
  + max | class=CKD Stage 5, auc=0.949341
  + micro auc=0.851780 | macro auc=0.788202
  + Ranked AUC scores: 
    + class=CKD Stage 4, auc=0.627994
    + class=CKD Stage 3, auc=0.732844
    + class=CKD Stage 2, auc=0.745279
    + class=Others, auc=0.814524
    + class=CKD Stage 1, auc=0.853338
    + class=CKD Stage 5, auc=0.949341
  => [('CKD Stage 4', 0.62799389778794812), ('CKD Stage 3', 0.73284403669724774), ('CKD Stage 2', 0.74527946038296833), ('Others', 0.81452425960932573), ('CKD Stage 1', 0.85333817126269951), ('CKD Stage 5', 0.94934092834949624)]
output> saving performance to:
/Users/pleiades/Documents/work/tpheno/seqmaker/data/CKD/plot/roc-multiclass-Sequential-CKD-pv-dm2-regular-smallCKD.tif

runROCMulticlass> test set ratio: 0.300000
modelEvaluate> dim(X_train):(1651, 50, 100), dim(X_test): (709, 50, 100)
  + lookup:
{'Others': 5, 'CKD Stage 5': 4, 'CKD Stage 4': 3, 'CKD Stage 3': 2, 'CKD Stage 2': 1, 'CKD Stage 1': 0}

... class weights:
{0: 6.344086021505376, 1: 0.74494949494949492, 2: 1.1238095238095238, 3: 7.0238095238095237, 4: 0.51890941072999119, 5: 0.64906490649064907}

====================================================================================================
... early stopping>
       + patience: 20, model='max'
... model training>
       + batch_size: 32, epochs: 80, shuffle? True, metric: auc_roc
====================================================================================================
Epoch 1/80
1651/1651 [==============================] - 3s 2ms/step - loss: 1.8624 - acc: 0.1605 - auc_roc: 0.9748
Epoch 2/80
1651/1651 [==============================] - 3s 2ms/step - loss: 1.7278 - acc: 0.3192 - auc_roc: 0.9745
Epoch 3/80
1651/1651 [==============================] - 3s 2ms/step - loss: 1.5134 - acc: 0.3882 - auc_roc: 0.9743
Epoch 4/80
1651/1651 [==============================] - 3s 2ms/step - loss: 1.4249 - acc: 0.4306 - auc_roc: 0.9741
Epoch 5/80
1651/1651 [==============================] - 3s 2ms/step - loss: 1.2636 - acc: 0.5003 - auc_roc: 0.9739
Epoch 6/80
1651/1651 [==============================] - 3s 2ms/step - loss: 1.1464 - acc: 0.5239 - auc_roc: 0.9738
Epoch 7/80
1651/1651 [==============================] - 3s 2ms/step - loss: 1.0945 - acc: 0.5397 - auc_roc: 0.9736
Epoch 8/80
1651/1651 [==============================] - 3s 2ms/step - loss: 1.0316 - acc: 0.5657 - auc_roc: 0.9735
Epoch 9/80
1651/1651 [==============================] - 3s 2ms/step - loss: 0.9503 - acc: 0.5851 - auc_roc: 0.9734
Epoch 10/80
1651/1651 [==============================] - 3s 2ms/step - loss: 0.8907 - acc: 0.6081 - auc_roc: 0.9733
Epoch 11/80
1651/1651 [==============================] - 3s 2ms/step - loss: 0.8240 - acc: 0.6269 - auc_roc: 0.9732
Epoch 12/80
1651/1651 [==============================] - 3s 2ms/step - loss: 0.7962 - acc: 0.6414 - auc_roc: 0.9731
Epoch 13/80
1651/1651 [==============================] - 3s 2ms/step - loss: 0.7948 - acc: 0.6354 - auc_roc: 0.9730
Epoch 14/80
1651/1651 [==============================] - 3s 2ms/step - loss: 0.7283 - acc: 0.6578 - auc_roc: 0.9729
Epoch 15/80
1651/1651 [==============================] - 3s 2ms/step - loss: 0.6561 - acc: 0.6953 - auc_roc: 0.9729
Epoch 16/80
1651/1651 [==============================] - 3s 2ms/step - loss: 0.7359 - acc: 0.6784 - auc_roc: 0.9728
Epoch 17/80
1651/1651 [==============================] - 3s 2ms/step - loss: 0.6022 - acc: 0.7105 - auc_roc: 0.9728
Epoch 18/80
1651/1651 [==============================] - 3s 2ms/step - loss: 0.5678 - acc: 0.7214 - auc_roc: 0.9727
Epoch 19/80
1651/1651 [==============================] - 3s 2ms/step - loss: 0.5536 - acc: 0.7317 - auc_roc: 0.9727
Epoch 20/80
1651/1651 [==============================] - 3s 2ms/step - loss: 0.5463 - acc: 0.7268 - auc_roc: 0.9727
Epoch 21/80
1651/1651 [==============================] - 3s 2ms/step - loss: 0.5376 - acc: 0.7474 - auc_roc: 0.9726
Epoch 22/80
1651/1651 [==============================] - 3s 2ms/step - loss: 0.5182 - acc: 0.7517 - auc_roc: 0.9726
Epoch 23/80
1651/1651 [==============================] - 3s 2ms/step - loss: 0.4847 - acc: 0.7765 - auc_roc: 0.9726
Epoch 24/80
1651/1651 [==============================] - 3s 2ms/step - loss: 0.4231 - acc: 0.7953 - auc_roc: 0.9726
Epoch 25/80
1651/1651 [==============================] - 3s 2ms/step - loss: 0.4082 - acc: 0.7977 - auc_roc: 0.9726
Epoch 26/80
1651/1651 [==============================] - 3s 2ms/step - loss: 0.3750 - acc: 0.8171 - auc_roc: 0.9726
Epoch 27/80
1651/1651 [==============================] - 3s 2ms/step - loss: 0.3545 - acc: 0.8286 - auc_roc: 0.9726
Epoch 28/80
1651/1651 [==============================] - 3s 2ms/step - loss: 0.3214 - acc: 0.8383 - auc_roc: 0.9726
Epoch 29/80
1651/1651 [==============================] - 3s 2ms/step - loss: 0.3143 - acc: 0.8383 - auc_roc: 0.9726
Epoch 30/80
1651/1651 [==============================] - 3s 2ms/step - loss: 0.3267 - acc: 0.8413 - auc_roc: 0.9727
Epoch 31/80
1651/1651 [==============================] - 3s 2ms/step - loss: 0.3349 - acc: 0.8449 - auc_roc: 0.9727
Epoch 32/80
1651/1651 [==============================] - 3s 2ms/step - loss: 0.3099 - acc: 0.8589 - auc_roc: 0.9727
Epoch 33/80
1651/1651 [==============================] - 3s 2ms/step - loss: 0.3626 - acc: 0.8498 - auc_roc: 0.9727
Epoch 34/80
1651/1651 [==============================] - 3s 2ms/step - loss: 0.6126 - acc: 0.7553 - auc_roc: 0.9727
Epoch 35/80
1651/1651 [==============================] - 3s 2ms/step - loss: 0.4425 - acc: 0.8195 - auc_roc: 0.9727
Epoch 36/80
1651/1651 [==============================] - 3s 2ms/step - loss: 0.2888 - acc: 0.8789 - auc_roc: 0.9727
Epoch 37/80
1651/1651 [==============================] - 3s 2ms/step - loss: 0.2718 - acc: 0.8843 - auc_roc: 0.9727
Epoch 38/80
1651/1651 [==============================] - 3s 2ms/step - loss: 0.2926 - acc: 0.8583 - auc_roc: 0.9728
Epoch 39/80
1651/1651 [==============================] - 3s 2ms/step - loss: 0.2913 - acc: 0.8504 - auc_roc: 0.9728
Epoch 40/80
1651/1651 [==============================] - 3s 2ms/step - loss: 0.2810 - acc: 0.8667 - auc_roc: 0.9728
Epoch 41/80
1651/1651 [==============================] - 3s 2ms/step - loss: 0.2275 - acc: 0.8892 - auc_roc: 0.9729
Epoch 42/80
1651/1651 [==============================] - 3s 2ms/step - loss: 0.1882 - acc: 0.9164 - auc_roc: 0.9729
Epoch 43/80
1651/1651 [==============================] - 3s 2ms/step - loss: 0.1531 - acc: 0.9340 - auc_roc: 0.9730
Epoch 44/80
1651/1651 [==============================] - 3s 2ms/step - loss: 0.1305 - acc: 0.9455 - auc_roc: 0.9730
Epoch 45/80
1651/1651 [==============================] - 3s 2ms/step - loss: 0.1326 - acc: 0.9364 - auc_roc: 0.9731
Epoch 46/80
1651/1651 [==============================] - 3s 2ms/step - loss: 0.1254 - acc: 0.9479 - auc_roc: 0.9732
Epoch 47/80
1651/1651 [==============================] - 3s 2ms/step - loss: 0.1278 - acc: 0.9473 - auc_roc: 0.9732
Epoch 48/80
1651/1651 [==============================] - 3s 2ms/step - loss: 0.3383 - acc: 0.8686 - auc_roc: 0.9733
Epoch 49/80
1651/1651 [==============================] - 3s 2ms/step - loss: 0.2752 - acc: 0.8867 - auc_roc: 0.9733
Epoch 50/80
1651/1651 [==============================] - 3s 2ms/step - loss: 0.1691 - acc: 0.9328 - auc_roc: 0.9734
Epoch 51/80
1651/1651 [==============================] - 3s 2ms/step - loss: 0.1104 - acc: 0.9582 - auc_roc: 0.9734
Epoch 52/80
1651/1651 [==============================] - 3s 2ms/step - loss: 0.0929 - acc: 0.9606 - auc_roc: 0.9735
Epoch 53/80
1651/1651 [==============================] - 3s 2ms/step - loss: 0.0700 - acc: 0.9715 - auc_roc: 0.9736
Epoch 54/80
1651/1651 [==============================] - 3s 2ms/step - loss: 0.0691 - acc: 0.9758 - auc_roc: 0.9737
Epoch 55/80
1651/1651 [==============================] - 3s 2ms/step - loss: 0.0733 - acc: 0.9691 - auc_roc: 0.9737
Epoch 56/80
1651/1651 [==============================] - 3s 2ms/step - loss: 0.0802 - acc: 0.9661 - auc_roc: 0.9738
Epoch 57/80
1651/1651 [==============================] - 3s 2ms/step - loss: 0.0570 - acc: 0.9782 - auc_roc: 0.9739
Epoch 58/80
1651/1651 [==============================] - 3s 2ms/step - loss: 0.0452 - acc: 0.9861 - auc_roc: 0.9740
Epoch 59/80
1651/1651 [==============================] - 3s 2ms/step - loss: 0.0397 - acc: 0.9867 - auc_roc: 0.9741
Epoch 60/80
1651/1651 [==============================] - 3s 2ms/step - loss: 0.0611 - acc: 0.9776 - auc_roc: 0.9741
Epoch 61/80
1651/1651 [==============================] - 3s 2ms/step - loss: 0.0582 - acc: 0.9788 - auc_roc: 0.9742
Epoch 62/80
1651/1651 [==============================] - 3s 2ms/step - loss: 0.0517 - acc: 0.9812 - auc_roc: 0.9743
Epoch 63/80
1651/1651 [==============================] - 3s 2ms/step - loss: 0.0932 - acc: 0.9661 - auc_roc: 0.9744
Epoch 64/80
1651/1651 [==============================] - 3s 2ms/step - loss: 0.0817 - acc: 0.9727 - auc_roc: 0.9744
Epoch 65/80
1651/1651 [==============================] - 3s 2ms/step - loss: 0.1609 - acc: 0.9297 - auc_roc: 0.9745
Epoch 66/80
1651/1651 [==============================] - 3s 2ms/step - loss: 0.0673 - acc: 0.9740 - auc_roc: 0.9746
Epoch 67/80
1651/1651 [==============================] - 3s 2ms/step - loss: 0.0425 - acc: 0.9879 - auc_roc: 0.9747
Epoch 68/80
1651/1651 [==============================] - 3s 2ms/step - loss: 0.2088 - acc: 0.9437 - auc_roc: 0.9747
Epoch 69/80
1651/1651 [==============================] - 3s 2ms/step - loss: 0.2977 - acc: 0.8995 - auc_roc: 0.9748
Epoch 70/80
1651/1651 [==============================] - 3s 2ms/step - loss: 0.1581 - acc: 0.9400 - auc_roc: 0.9748
Epoch 71/80
1651/1651 [==============================] - 3s 2ms/step - loss: 0.0783 - acc: 0.9733 - auc_roc: 0.9749
Epoch 72/80
1651/1651 [==============================] - 3s 2ms/step - loss: 0.0585 - acc: 0.9830 - auc_roc: 0.9749
Epoch 73/80
1651/1651 [==============================] - 3s 2ms/step - loss: 0.0380 - acc: 0.9879 - auc_roc: 0.9750
Epoch 74/80
1651/1651 [==============================] - 3s 2ms/step - loss: 0.0304 - acc: 0.9933 - auc_roc: 0.9751
Epoch 75/80
1651/1651 [==============================] - 3s 2ms/step - loss: 0.0238 - acc: 0.9952 - auc_roc: 0.9752
Epoch 76/80
1651/1651 [==============================] - 3s 2ms/step - loss: 0.0279 - acc: 0.9903 - auc_roc: 0.9753
Epoch 77/80
1651/1651 [==============================] - 3s 2ms/step - loss: 0.0238 - acc: 0.9927 - auc_roc: 0.9754
Epoch 78/80
1651/1651 [==============================] - 3s 2ms/step - loss: 0.0195 - acc: 0.9976 - auc_roc: 0.9754
Epoch 79/80
1651/1651 [==============================] - 3s 2ms/step - loss: 0.0166 - acc: 0.9970 - auc_roc: 0.9755
Epoch 80/80
1651/1651 [==============================] - 3s 2ms/step - loss: 0.0141 - acc: 0.9964 - auc_roc: 0.9756
... history of metrics comprising: ['acc', 'loss', 'auc_roc']
... model fitting complete > starting model evaluation
modelEvaluate> scores:
[('loss', 2.4019636537023255), ('acc', 0.59097320177659329), ('auc_roc', 0.97556406831203291)]

info> infer classifier name from class name ...
runROCMulticlass> find 6 unique labels:
CKD Stage 1, CKD Stage 2, CKD Stage 3, CKD Stage 4, CKD Stage 5, Others

info> given pre-trained model ...
diagnosis> dim(y_score):(709, 6)
>>> test_auc_cv_metrics >>>
  + dimension test 
  + len(roc_auc):8 =?= n_classes (+{micro, macro}):6+2
  + class name: CKD Stage 1, mean_auc: 0.853996
  + ROC curve of class CKD Stage 1 (area = 0.85)
  + class name: CKD Stage 2, mean_auc: 0.747526
  + ROC curve of class CKD Stage 2 (area = 0.75)
  + class name: CKD Stage 3, mean_auc: 0.773321
  + ROC curve of class CKD Stage 3 (area = 0.77)
  + class name: CKD Stage 4, mean_auc: 0.747143
  + ROC curve of class CKD Stage 4 (area = 0.75)
  + class name: CKD Stage 5, mean_auc: 0.941298
  + ROC curve of class CKD Stage 5 (area = 0.94)
  + class name: Others, mean_auc: 0.843801
  + ROC curve of class Others (area = 0.84)
test_auc_cv_metrics> summary of AUCs vs classes ...
  + min | class=CKD Stage 4, auc=0.747143
  + max | class=CKD Stage 5, auc=0.941298
  + micro auc=0.866783 | macro auc=0.818902
  + Ranked AUC scores: 
    + class=CKD Stage 4, auc=0.747143
    + class=CKD Stage 2, auc=0.747526
    + class=CKD Stage 3, auc=0.773321
    + class=Others, auc=0.843801
    + class=CKD Stage 1, auc=0.853996
    + class=CKD Stage 5, auc=0.941298
  => [('CKD Stage 4', 0.74714285714285711), ('CKD Stage 2', 0.74752587991718422), ('CKD Stage 3', 0.77332076525624915), ('Others', 0.84380061683196872), ('CKD Stage 1', 0.85399581926354728), ('CKD Stage 5', 0.9412979613638387)]
output> saving performance to:
/Users/pleiades/Documents/work/tpheno/seqmaker/data/CKD/plot/roc-multiclass-Sequential-CKD-pv-dm2-regular-smallCKD.tif

runROCMulticlass> test set ratio: 0.300000
modelEvaluate> dim(X_train):(1651, 50, 100), dim(X_test): (709, 50, 100)
  + lookup:
{'Others': 5, 'CKD Stage 5': 4, 'CKD Stage 4': 3, 'CKD Stage 3': 2, 'CKD Stage 2': 1, 'CKD Stage 1': 0}

... class weights:
{0: 6.344086021505376, 1: 0.74494949494949492, 2: 1.1238095238095238, 3: 7.0238095238095237, 4: 0.51890941072999119, 5: 0.64906490649064907}

====================================================================================================
... early stopping>
       + patience: 20, model='max'
... model training>
       + batch_size: 32, epochs: 80, shuffle? True, metric: auc_roc
====================================================================================================
Epoch 1/80
1651/1651 [==============================] - 3s 2ms/step - loss: 1.8108 - acc: 0.1944 - auc_roc: 0.9754
Epoch 2/80
1651/1651 [==============================] - 3s 2ms/step - loss: 1.6732 - acc: 0.3240 - auc_roc: 0.9752
Epoch 3/80
1651/1651 [==============================] - 3s 2ms/step - loss: 1.4910 - acc: 0.4270 - auc_roc: 0.9750
Epoch 4/80
1651/1651 [==============================] - 3s 2ms/step - loss: 1.2941 - acc: 0.4815 - auc_roc: 0.9748
Epoch 5/80
1651/1651 [==============================] - 3s 2ms/step - loss: 1.1888 - acc: 0.5391 - auc_roc: 0.9747
Epoch 6/80
1651/1651 [==============================] - 3s 2ms/step - loss: 1.1377 - acc: 0.5342 - auc_roc: 0.9745
Epoch 7/80
1651/1651 [==============================] - 3s 2ms/step - loss: 1.0177 - acc: 0.5778 - auc_roc: 0.9744
Epoch 8/80
1651/1651 [==============================] - 3s 2ms/step - loss: 0.9658 - acc: 0.6021 - auc_roc: 0.9743
Epoch 9/80
1651/1651 [==============================] - 3s 2ms/step - loss: 0.9175 - acc: 0.5954 - auc_roc: 0.9742
Epoch 10/80
1651/1651 [==============================] - 3s 2ms/step - loss: 0.8267 - acc: 0.6360 - auc_roc: 0.9741
Epoch 11/80
1651/1651 [==============================] - 3s 2ms/step - loss: 0.7994 - acc: 0.6475 - auc_roc: 0.9741
Epoch 12/80
1651/1651 [==============================] - 3s 2ms/step - loss: 0.7449 - acc: 0.6614 - auc_roc: 0.9740
Epoch 13/80
1651/1651 [==============================] - 3s 2ms/step - loss: 0.7056 - acc: 0.6675 - auc_roc: 0.9739
Epoch 14/80
1651/1651 [==============================] - 3s 2ms/step - loss: 0.6655 - acc: 0.6893 - auc_roc: 0.9739
Epoch 15/80
1651/1651 [==============================] - 3s 2ms/step - loss: 0.6539 - acc: 0.6856 - auc_roc: 0.9738
Epoch 16/80
1651/1651 [==============================] - 3s 2ms/step - loss: 0.6065 - acc: 0.7177 - auc_roc: 0.9738
Epoch 17/80
1651/1651 [==============================] - 3s 2ms/step - loss: 0.5772 - acc: 0.7262 - auc_roc: 0.9737
Epoch 18/80
1651/1651 [==============================] - 3s 2ms/step - loss: 0.5783 - acc: 0.7238 - auc_roc: 0.9737
Epoch 19/80
1651/1651 [==============================] - 3s 2ms/step - loss: 0.5769 - acc: 0.7250 - auc_roc: 0.9737
Epoch 20/80
1651/1651 [==============================] - 3s 2ms/step - loss: 0.5243 - acc: 0.7462 - auc_roc: 0.9736
Epoch 21/80
1651/1651 [==============================] - 3s 2ms/step - loss: 0.5027 - acc: 0.7529 - auc_roc: 0.9736
Epoch 22/80
1651/1651 [==============================] - 3s 2ms/step - loss: 0.4821 - acc: 0.7620 - auc_roc: 0.9736
Epoch 23/80
1651/1651 [==============================] - 3s 2ms/step - loss: 0.4522 - acc: 0.7729 - auc_roc: 0.9736
Epoch 24/80
1651/1651 [==============================] - 3s 2ms/step - loss: 0.4147 - acc: 0.7904 - auc_roc: 0.9736
Epoch 25/80
1651/1651 [==============================] - 3s 2ms/step - loss: 0.4494 - acc: 0.7832 - auc_roc: 0.9736
Epoch 26/80
1651/1651 [==============================] - 3s 2ms/step - loss: 0.4980 - acc: 0.7747 - auc_roc: 0.9736
Epoch 27/80
1651/1651 [==============================] - 3s 2ms/step - loss: 0.4582 - acc: 0.7723 - auc_roc: 0.9736
Epoch 28/80
1651/1651 [==============================] - 3s 2ms/step - loss: 0.4737 - acc: 0.7735 - auc_roc: 0.9735
Epoch 29/80
1651/1651 [==============================] - 3s 2ms/step - loss: 0.3534 - acc: 0.8298 - auc_roc: 0.9735
Epoch 30/80
1651/1651 [==============================] - 3s 2ms/step - loss: 0.3357 - acc: 0.8304 - auc_roc: 0.9735
Epoch 31/80
1651/1651 [==============================] - 3s 2ms/step - loss: 0.3044 - acc: 0.8565 - auc_roc: 0.9736
Epoch 32/80
1651/1651 [==============================] - 3s 2ms/step - loss: 0.3279 - acc: 0.8528 - auc_roc: 0.9736
Epoch 33/80
1651/1651 [==============================] - 3s 2ms/step - loss: 0.2843 - acc: 0.8716 - auc_roc: 0.9736
Epoch 34/80
1651/1651 [==============================] - 3s 2ms/step - loss: 0.2356 - acc: 0.8916 - auc_roc: 0.9736
Epoch 35/80
1651/1651 [==============================] - 3s 2ms/step - loss: 0.2192 - acc: 0.9037 - auc_roc: 0.9737
Epoch 36/80
1651/1651 [==============================] - 3s 2ms/step - loss: 0.2209 - acc: 0.9043 - auc_roc: 0.9737
Epoch 37/80
1651/1651 [==============================] - 3s 2ms/step - loss: 0.2921 - acc: 0.8795 - auc_roc: 0.9737
Epoch 38/80
1651/1651 [==============================] - 3s 2ms/step - loss: 0.2093 - acc: 0.8995 - auc_roc: 0.9738
Epoch 39/80
1651/1651 [==============================] - 3s 2ms/step - loss: 0.2017 - acc: 0.9055 - auc_roc: 0.9738
Epoch 40/80
1651/1651 [==============================] - 3s 2ms/step - loss: 0.1810 - acc: 0.9164 - auc_roc: 0.9739
Epoch 41/80
1651/1651 [==============================] - 3s 2ms/step - loss: 0.1358 - acc: 0.9376 - auc_roc: 0.9739
Epoch 42/80
1651/1651 [==============================] - 3s 2ms/step - loss: 0.1408 - acc: 0.9461 - auc_roc: 0.9740
Epoch 43/80
1651/1651 [==============================] - 3s 2ms/step - loss: 0.2656 - acc: 0.8922 - auc_roc: 0.9740
Epoch 44/80
1651/1651 [==============================] - 3s 2ms/step - loss: 0.2373 - acc: 0.8928 - auc_roc: 0.9740
Epoch 45/80
1651/1651 [==============================] - 3s 2ms/step - loss: 0.1782 - acc: 0.9237 - auc_roc: 0.9741
Epoch 46/80
1651/1651 [==============================] - 3s 2ms/step - loss: 0.1324 - acc: 0.9400 - auc_roc: 0.9741
Epoch 47/80
1651/1651 [==============================] - 3s 2ms/step - loss: 0.1307 - acc: 0.9485 - auc_roc: 0.9742
Epoch 48/80
1651/1651 [==============================] - 3s 2ms/step - loss: 0.0998 - acc: 0.9570 - auc_roc: 0.9742
Epoch 49/80
1651/1651 [==============================] - 3s 2ms/step - loss: 0.0890 - acc: 0.9631 - auc_roc: 0.9743
Epoch 50/80
1651/1651 [==============================] - 3s 2ms/step - loss: 0.0799 - acc: 0.9721 - auc_roc: 0.9744
Epoch 51/80
1651/1651 [==============================] - 3s 2ms/step - loss: 0.0631 - acc: 0.9764 - auc_roc: 0.9744
Epoch 52/80
1651/1651 [==============================] - 3s 2ms/step - loss: 0.0631 - acc: 0.9752 - auc_roc: 0.9745
Epoch 53/80
1651/1651 [==============================] - 3s 2ms/step - loss: 0.0548 - acc: 0.9794 - auc_roc: 0.9746
Epoch 54/80
1651/1651 [==============================] - 3s 2ms/step - loss: 0.0806 - acc: 0.9697 - auc_roc: 0.9746
Epoch 55/80
1651/1651 [==============================] - 3s 2ms/step - loss: 0.2657 - acc: 0.9013 - auc_roc: 0.9747
Epoch 56/80
1651/1651 [==============================] - 3s 2ms/step - loss: 0.2355 - acc: 0.9170 - auc_roc: 0.9747
Epoch 57/80
1651/1651 [==============================] - 3s 2ms/step - loss: 0.2678 - acc: 0.9025 - auc_roc: 0.9747
Epoch 58/80
1651/1651 [==============================] - 3s 2ms/step - loss: 0.1433 - acc: 0.9400 - auc_roc: 0.9748
Epoch 59/80
1651/1651 [==============================] - 3s 2ms/step - loss: 0.0878 - acc: 0.9691 - auc_roc: 0.9748
Epoch 60/80
1651/1651 [==============================] - 3s 2ms/step - loss: 0.0588 - acc: 0.9812 - auc_roc: 0.9749
Epoch 61/80
1651/1651 [==============================] - 3s 2ms/step - loss: 0.0544 - acc: 0.9824 - auc_roc: 0.9750
Epoch 62/80
1651/1651 [==============================] - 3s 2ms/step - loss: 0.0522 - acc: 0.9806 - auc_roc: 0.9750
Epoch 63/80
1651/1651 [==============================] - 3s 2ms/step - loss: 0.1444 - acc: 0.9382 - auc_roc: 0.9751
Epoch 64/80
1651/1651 [==============================] - 3s 2ms/step - loss: 0.0680 - acc: 0.9746 - auc_roc: 0.9752
Epoch 65/80
1651/1651 [==============================] - 3s 2ms/step - loss: 0.0437 - acc: 0.9873 - auc_roc: 0.9752
Epoch 66/80
1651/1651 [==============================] - 3s 2ms/step - loss: 0.0374 - acc: 0.9867 - auc_roc: 0.9753
Epoch 67/80
1651/1651 [==============================] - 3s 2ms/step - loss: 0.0304 - acc: 0.9909 - auc_roc: 0.9754
Epoch 68/80
1651/1651 [==============================] - 3s 2ms/step - loss: 0.0251 - acc: 0.9927 - auc_roc: 0.9754
Epoch 69/80
1651/1651 [==============================] - 3s 2ms/step - loss: 0.0220 - acc: 0.9939 - auc_roc: 0.9755
Epoch 70/80
1651/1651 [==============================] - 3s 2ms/step - loss: 0.0219 - acc: 0.9939 - auc_roc: 0.9756
Epoch 71/80
1651/1651 [==============================] - 3s 2ms/step - loss: 0.0210 - acc: 0.9915 - auc_roc: 0.9757
Epoch 72/80
1651/1651 [==============================] - 3s 2ms/step - loss: 0.0230 - acc: 0.9933 - auc_roc: 0.9757
Epoch 73/80
1651/1651 [==============================] - 3s 2ms/step - loss: 0.0313 - acc: 0.9879 - auc_roc: 0.9758
Epoch 74/80
1651/1651 [==============================] - 3s 2ms/step - loss: 0.0413 - acc: 0.9867 - auc_roc: 0.9759
Epoch 75/80
1651/1651 [==============================] - 3s 2ms/step - loss: 0.0523 - acc: 0.9843 - auc_roc: 0.9759
Epoch 76/80
1651/1651 [==============================] - 3s 2ms/step - loss: 0.0246 - acc: 0.9945 - auc_roc: 0.9760
Epoch 77/80
1651/1651 [==============================] - 3s 2ms/step - loss: 0.0154 - acc: 0.9970 - auc_roc: 0.9761
Epoch 78/80
1651/1651 [==============================] - 3s 2ms/step - loss: 0.0205 - acc: 0.9964 - auc_roc: 0.9761
Epoch 79/80
1651/1651 [==============================] - 3s 2ms/step - loss: 0.1040 - acc: 0.9576 - auc_roc: 0.9762
Epoch 80/80
1651/1651 [==============================] - 3s 2ms/step - loss: 0.0444 - acc: 0.9861 - auc_roc: 0.9763
... history of metrics comprising: ['acc', 'loss', 'auc_roc']
... model fitting complete > starting model evaluation
modelEvaluate> scores:
[('loss', 2.2331960917527987), ('acc', 0.56981664320141368), ('auc_roc', 0.97622064878305026)]

info> infer classifier name from class name ...
runROCMulticlass> find 6 unique labels:
CKD Stage 1, CKD Stage 2, CKD Stage 3, CKD Stage 4, CKD Stage 5, Others

info> given pre-trained model ...
diagnosis> dim(y_score):(709, 6)
>>> test_auc_cv_metrics >>>
  + dimension test 
  + len(roc_auc):8 =?= n_classes (+{micro, macro}):6+2
  + class name: CKD Stage 1, mean_auc: 0.915789
  + ROC curve of class CKD Stage 1 (area = 0.92)
  + class name: CKD Stage 2, mean_auc: 0.757651
  + ROC curve of class CKD Stage 2 (area = 0.76)
  + class name: CKD Stage 3, mean_auc: 0.728472
  + ROC curve of class CKD Stage 3 (area = 0.73)
  + class name: CKD Stage 4, mean_auc: 0.743324
  + ROC curve of class CKD Stage 4 (area = 0.74)
  + class name: CKD Stage 5, mean_auc: 0.960361
  + ROC curve of class CKD Stage 5 (area = 0.96)
  + class name: Others, mean_auc: 0.819548
  + ROC curve of class Others (area = 0.82)
test_auc_cv_metrics> summary of AUCs vs classes ...
  + min | class=CKD Stage 3, auc=0.728472
  + max | class=CKD Stage 5, auc=0.960361
  + micro auc=0.867727 | macro auc=0.821802
  + Ranked AUC scores: 
    + class=CKD Stage 3, auc=0.728472
    + class=CKD Stage 4, auc=0.743324
    + class=CKD Stage 2, auc=0.757651
    + class=Others, auc=0.819548
    + class=CKD Stage 1, auc=0.915789
    + class=CKD Stage 5, auc=0.960361
  => [('CKD Stage 3', 0.72847169524965849), ('CKD Stage 4', 0.74332372718539863), ('CKD Stage 2', 0.75765056648777585), ('Others', 0.81954817412832681), ('CKD Stage 1', 0.91578947368421049), ('CKD Stage 5', 0.96036125987110843)]
output> saving performance to:
/Users/pleiades/Documents/work/tpheno/seqmaker/data/CKD/plot/roc-multiclass-Sequential-CKD-pv-dm2-regular-smallCKD.tif

runROCMulticlass> test set ratio: 0.300000
modelEvaluate> dim(X_train):(1651, 50, 100), dim(X_test): (709, 50, 100)
  + lookup:
{'Others': 5, 'CKD Stage 5': 4, 'CKD Stage 4': 3, 'CKD Stage 3': 2, 'CKD Stage 2': 1, 'CKD Stage 1': 0}

... class weights:
{0: 6.344086021505376, 1: 0.74494949494949492, 2: 1.1238095238095238, 3: 7.0238095238095237, 4: 0.51890941072999119, 5: 0.64906490649064907}

====================================================================================================
... early stopping>
       + patience: 20, model='max'
... model training>
       + batch_size: 32, epochs: 80, shuffle? True, metric: auc_roc
====================================================================================================
Epoch 1/80
1651/1651 [==============================] - 3s 2ms/step - loss: 1.7463 - acc: 0.2392 - auc_roc: 0.9761
Epoch 2/80
1651/1651 [==============================] - 3s 2ms/step - loss: 1.6315 - acc: 0.3640 - auc_roc: 0.9759
Epoch 3/80
1651/1651 [==============================] - 3s 2ms/step - loss: 1.4392 - acc: 0.4700 - auc_roc: 0.9757
Epoch 4/80
1651/1651 [==============================] - 3s 2ms/step - loss: 1.2872 - acc: 0.4894 - auc_roc: 0.9756
Epoch 5/80
1651/1651 [==============================] - 3s 2ms/step - loss: 1.1670 - acc: 0.5300 - auc_roc: 0.9755
Epoch 6/80
1651/1651 [==============================] - 3s 2ms/step - loss: 1.1263 - acc: 0.5294 - auc_roc: 0.9754
Epoch 7/80
1651/1651 [==============================] - 3s 2ms/step - loss: 1.0236 - acc: 0.5766 - auc_roc: 0.9753
Epoch 8/80
1651/1651 [==============================] - 3s 2ms/step - loss: 0.9463 - acc: 0.6069 - auc_roc: 0.9752
Epoch 9/80
1651/1651 [==============================] - 3s 2ms/step - loss: 0.9099 - acc: 0.5966 - auc_roc: 0.9751
Epoch 10/80
1651/1651 [==============================] - 3s 2ms/step - loss: 0.8911 - acc: 0.6039 - auc_roc: 0.9750
Epoch 11/80
1651/1651 [==============================] - 3s 2ms/step - loss: 0.8340 - acc: 0.6342 - auc_roc: 0.9750
Epoch 12/80
1651/1651 [==============================] - 3s 2ms/step - loss: 0.7421 - acc: 0.6657 - auc_roc: 0.9749
Epoch 13/80
1651/1651 [==============================] - 3s 2ms/step - loss: 0.7571 - acc: 0.6499 - auc_roc: 0.9749
Epoch 14/80
1651/1651 [==============================] - 3s 2ms/step - loss: 0.6985 - acc: 0.6687 - auc_roc: 0.9748
Epoch 15/80
1651/1651 [==============================] - 3s 2ms/step - loss: 0.6432 - acc: 0.6893 - auc_roc: 0.9748
Epoch 16/80
1651/1651 [==============================] - 3s 2ms/step - loss: 0.6223 - acc: 0.7044 - auc_roc: 0.9747
Epoch 17/80
1651/1651 [==============================] - 3s 2ms/step - loss: 0.5893 - acc: 0.7068 - auc_roc: 0.9747
Epoch 18/80
1651/1651 [==============================] - 3s 2ms/step - loss: 0.5737 - acc: 0.7286 - auc_roc: 0.9747
Epoch 19/80
1651/1651 [==============================] - 3s 2ms/step - loss: 0.5507 - acc: 0.7353 - auc_roc: 0.9746
Epoch 20/80
1651/1651 [==============================] - 3s 2ms/step - loss: 0.5028 - acc: 0.7547 - auc_roc: 0.9746
Epoch 21/80
1651/1651 [==============================] - 3s 2ms/step - loss: 0.5099 - acc: 0.7547 - auc_roc: 0.9746
Epoch 22/80
1651/1651 [==============================] - 3s 2ms/step - loss: 0.5835 - acc: 0.6972 - auc_roc: 0.9746
Epoch 23/80
1651/1651 [==============================] - 3s 2ms/step - loss: 0.4529 - acc: 0.7589 - auc_roc: 0.9745
Epoch 24/80
1651/1651 [==============================] - 3s 2ms/step - loss: 0.4221 - acc: 0.7904 - auc_roc: 0.9745
Epoch 25/80
1651/1651 [==============================] - 3s 2ms/step - loss: 0.4003 - acc: 0.7977 - auc_roc: 0.9745
Epoch 26/80
1651/1651 [==============================] - 3s 2ms/step - loss: 0.4099 - acc: 0.8038 - auc_roc: 0.9745
Epoch 27/80
1651/1651 [==============================] - 3s 2ms/step - loss: 0.3836 - acc: 0.8007 - auc_roc: 0.9745
Epoch 28/80
1651/1651 [==============================] - 3s 2ms/step - loss: 0.4884 - acc: 0.8038 - auc_roc: 0.9745
Epoch 29/80
1651/1651 [==============================] - 3s 2ms/step - loss: 0.4863 - acc: 0.7886 - auc_roc: 0.9745
Epoch 30/80
1651/1651 [==============================] - 3s 2ms/step - loss: 0.4096 - acc: 0.8141 - auc_roc: 0.9745
Epoch 31/80
1651/1651 [==============================] - 3s 2ms/step - loss: 0.3263 - acc: 0.8498 - auc_roc: 0.9745
Epoch 32/80
1651/1651 [==============================] - 3s 2ms/step - loss: 0.2873 - acc: 0.8637 - auc_roc: 0.9745
Epoch 33/80
1651/1651 [==============================] - 3s 2ms/step - loss: 0.2911 - acc: 0.8601 - auc_roc: 0.9746
Epoch 34/80
1651/1651 [==============================] - 3s 2ms/step - loss: 0.2565 - acc: 0.8879 - auc_roc: 0.9746
Epoch 35/80
1651/1651 [==============================] - 3s 2ms/step - loss: 0.2151 - acc: 0.8988 - auc_roc: 0.9746
Epoch 36/80
1651/1651 [==============================] - 3s 2ms/step - loss: 0.2005 - acc: 0.9079 - auc_roc: 0.9746
Epoch 37/80
1651/1651 [==============================] - 3s 2ms/step - loss: 0.1674 - acc: 0.9213 - auc_roc: 0.9747
Epoch 38/80
1651/1651 [==============================] - 3s 2ms/step - loss: 0.1526 - acc: 0.9340 - auc_roc: 0.9747
Epoch 39/80
1651/1651 [==============================] - 3s 2ms/step - loss: 0.1473 - acc: 0.9328 - auc_roc: 0.9748
Epoch 40/80
1651/1651 [==============================] - 3s 2ms/step - loss: 0.1486 - acc: 0.9328 - auc_roc: 0.9748
Epoch 41/80
1651/1651 [==============================] - 3s 2ms/step - loss: 0.1563 - acc: 0.9340 - auc_roc: 0.9749
Epoch 42/80
1651/1651 [==============================] - 3s 2ms/step - loss: 0.2300 - acc: 0.9055 - auc_roc: 0.9749
Epoch 43/80
1651/1651 [==============================] - 3s 2ms/step - loss: 0.2080 - acc: 0.9122 - auc_roc: 0.9749
Epoch 44/80
1651/1651 [==============================] - 3s 2ms/step - loss: 0.1993 - acc: 0.9213 - auc_roc: 0.9750
Epoch 45/80
1651/1651 [==============================] - 3s 2ms/step - loss: 0.1098 - acc: 0.9540 - auc_roc: 0.9750
Epoch 46/80
1651/1651 [==============================] - 3s 2ms/step - loss: 0.0907 - acc: 0.9649 - auc_roc: 0.9751
Epoch 47/80
1651/1651 [==============================] - 3s 2ms/step - loss: 0.1788 - acc: 0.9394 - auc_roc: 0.9751
Epoch 48/80
1651/1651 [==============================] - 3s 2ms/step - loss: 0.1265 - acc: 0.9552 - auc_roc: 0.9751
Epoch 49/80
1651/1651 [==============================] - 3s 2ms/step - loss: 0.1847 - acc: 0.9219 - auc_roc: 0.9752
Epoch 50/80
1651/1651 [==============================] - 3s 2ms/step - loss: 0.1345 - acc: 0.9485 - auc_roc: 0.9752
Epoch 51/80
1651/1651 [==============================] - 3s 2ms/step - loss: 0.0863 - acc: 0.9697 - auc_roc: 0.9753
Epoch 52/80
1651/1651 [==============================] - 3s 2ms/step - loss: 0.0715 - acc: 0.9733 - auc_roc: 0.9753
Epoch 53/80
1651/1651 [==============================] - 3s 2ms/step - loss: 0.0706 - acc: 0.9782 - auc_roc: 0.9754
Epoch 54/80
1651/1651 [==============================] - 3s 2ms/step - loss: 0.0591 - acc: 0.9800 - auc_roc: 0.9755
Epoch 55/80
1651/1651 [==============================] - 3s 2ms/step - loss: 0.0501 - acc: 0.9849 - auc_roc: 0.9755
Epoch 56/80
1651/1651 [==============================] - 3s 2ms/step - loss: 0.0390 - acc: 0.9909 - auc_roc: 0.9756
Epoch 57/80
1651/1651 [==============================] - 3s 2ms/step - loss: 0.0397 - acc: 0.9897 - auc_roc: 0.9756
Epoch 58/80
1651/1651 [==============================] - 3s 2ms/step - loss: 0.0397 - acc: 0.9867 - auc_roc: 0.9757
Epoch 59/80
1651/1651 [==============================] - 3s 2ms/step - loss: 0.0693 - acc: 0.9776 - auc_roc: 0.9758
Epoch 60/80
1651/1651 [==============================] - 3s 2ms/step - loss: 0.1461 - acc: 0.9485 - auc_roc: 0.9758
Epoch 61/80
1651/1651 [==============================] - 3s 2ms/step - loss: 0.2386 - acc: 0.9001 - auc_roc: 0.9758
Epoch 62/80
1651/1651 [==============================] - 3s 2ms/step - loss: 0.1094 - acc: 0.9552 - auc_roc: 0.9759
Epoch 63/80
1651/1651 [==============================] - 3s 2ms/step - loss: 0.1346 - acc: 0.9479 - auc_roc: 0.9759
Epoch 64/80
1651/1651 [==============================] - 3s 2ms/step - loss: 0.1303 - acc: 0.9455 - auc_roc: 0.9760
Epoch 65/80
1651/1651 [==============================] - 3s 2ms/step - loss: 0.0880 - acc: 0.9697 - auc_roc: 0.9760
Epoch 66/80
1651/1651 [==============================] - 3s 2ms/step - loss: 0.0751 - acc: 0.9733 - auc_roc: 0.9761
Epoch 67/80
1651/1651 [==============================] - 3s 2ms/step - loss: 0.0618 - acc: 0.9746 - auc_roc: 0.9761
Epoch 68/80
1651/1651 [==============================] - 3s 2ms/step - loss: 0.0659 - acc: 0.9721 - auc_roc: 0.9762
Epoch 69/80
1651/1651 [==============================] - 3s 2ms/step - loss: 0.0291 - acc: 0.9915 - auc_roc: 0.9762
Epoch 70/80
1651/1651 [==============================] - 3s 2ms/step - loss: 0.0255 - acc: 0.9945 - auc_roc: 0.9763
Epoch 71/80
1651/1651 [==============================] - 3s 2ms/step - loss: 0.0199 - acc: 0.9958 - auc_roc: 0.9764
Epoch 72/80
1651/1651 [==============================] - 3s 2ms/step - loss: 0.0347 - acc: 0.9885 - auc_roc: 0.9764
Epoch 73/80
1651/1651 [==============================] - 3s 2ms/step - loss: 0.0228 - acc: 0.9945 - auc_roc: 0.9765
Epoch 74/80
1651/1651 [==============================] - 3s 2ms/step - loss: 0.0207 - acc: 0.9952 - auc_roc: 0.9765
Epoch 75/80
1651/1651 [==============================] - 3s 2ms/step - loss: 0.0179 - acc: 0.9976 - auc_roc: 0.9766
Epoch 76/80
1651/1651 [==============================] - 3s 2ms/step - loss: 0.0155 - acc: 0.9970 - auc_roc: 0.9767
Epoch 77/80
1651/1651 [==============================] - 3s 2ms/step - loss: 0.0167 - acc: 0.9976 - auc_roc: 0.9767
Epoch 78/80
1651/1651 [==============================] - 3s 2ms/step - loss: 0.0157 - acc: 0.9952 - auc_roc: 0.9768
Epoch 79/80
1651/1651 [==============================] - 3s 2ms/step - loss: 0.0104 - acc: 0.9988 - auc_roc: 0.9768
Epoch 80/80
1651/1651 [==============================] - 3s 2ms/step - loss: 0.0127 - acc: 0.9988 - auc_roc: 0.9769
... history of metrics comprising: ['acc', 'loss', 'auc_roc']
... model fitting complete > starting model evaluation
modelEvaluate> scores:
[('loss', 2.7678330225856222), ('acc', 0.58956276445698164), ('auc_roc', 0.97687193654656246)]

info> infer classifier name from class name ...
runROCMulticlass> find 6 unique labels:
CKD Stage 1, CKD Stage 2, CKD Stage 3, CKD Stage 4, CKD Stage 5, Others

info> given pre-trained model ...
diagnosis> dim(y_score):(709, 6)
>>> test_auc_cv_metrics >>>
  + dimension test 
  + len(roc_auc):8 =?= n_classes (+{micro, macro}):6+2
  + class name: CKD Stage 1, mean_auc: 0.844746
  + ROC curve of class CKD Stage 1 (area = 0.84)
  + class name: CKD Stage 2, mean_auc: 0.767000
  + ROC curve of class CKD Stage 2 (area = 0.77)
  + class name: CKD Stage 3, mean_auc: 0.722381
  + ROC curve of class CKD Stage 3 (area = 0.72)
  + class name: CKD Stage 4, mean_auc: 0.676641
  + ROC curve of class CKD Stage 4 (area = 0.68)
  + class name: CKD Stage 5, mean_auc: 0.945396
  + ROC curve of class CKD Stage 5 (area = 0.95)
  + class name: Others, mean_auc: 0.809577
  + ROC curve of class Others (area = 0.81)
test_auc_cv_metrics> summary of AUCs vs classes ...
  + min | class=CKD Stage 4, auc=0.676641
  + max | class=CKD Stage 5, auc=0.945396
  + micro auc=0.857500 | macro auc=0.795697
  + Ranked AUC scores: 
    + class=CKD Stage 4, auc=0.676641
    + class=CKD Stage 3, auc=0.722381
    + class=CKD Stage 2, auc=0.767000
    + class=Others, auc=0.809577
    + class=CKD Stage 1, auc=0.844746
    + class=CKD Stage 5, auc=0.945396
  => [('CKD Stage 4', 0.67664059843590607), ('CKD Stage 3', 0.72238129757158387), ('CKD Stage 2', 0.76699967773122779), ('Others', 0.80957690837262652), ('CKD Stage 1', 0.8447460299583287), ('CKD Stage 5', 0.94539566499935879)]
output> saving performance to:
/Users/pleiades/Documents/work/tpheno/seqmaker/data/CKD/plot/roc-multiclass-Sequential-CKD-pv-dm2-regular-smallCKD.tif

runROCMulticlass> test set ratio: 0.300000
modelEvaluate> dim(X_train):(1651, 50, 100), dim(X_test): (709, 50, 100)
  + lookup:
{'Others': 5, 'CKD Stage 5': 4, 'CKD Stage 4': 3, 'CKD Stage 3': 2, 'CKD Stage 2': 1, 'CKD Stage 1': 0}

... class weights:
{0: 6.344086021505376, 1: 0.74494949494949492, 2: 1.1238095238095238, 3: 7.0238095238095237, 4: 0.51890941072999119, 5: 0.64906490649064907}

====================================================================================================
... early stopping>
       + patience: 20, model='max'
... model training>
       + batch_size: 32, epochs: 80, shuffle? True, metric: auc_roc
====================================================================================================
Epoch 1/80
1651/1651 [==============================] - 3s 2ms/step - loss: 1.7725 - acc: 0.1853 - auc_roc: 0.9767
Epoch 2/80
1651/1651 [==============================] - 3s 2ms/step - loss: 1.6439 - acc: 0.3773 - auc_roc: 0.9765
Epoch 3/80
1651/1651 [==============================] - 3s 2ms/step - loss: 1.4557 - acc: 0.4512 - auc_roc: 0.9764
Epoch 4/80
1651/1651 [==============================] - 3s 2ms/step - loss: 1.2815 - acc: 0.4779 - auc_roc: 0.9763
Epoch 5/80
1651/1651 [==============================] - 3s 2ms/step - loss: 1.2244 - acc: 0.5233 - auc_roc: 0.9762
Epoch 6/80
1651/1651 [==============================] - 3s 2ms/step - loss: 1.0629 - acc: 0.5857 - auc_roc: 0.9761
Epoch 7/80
1651/1651 [==============================] - 3s 2ms/step - loss: 0.9702 - acc: 0.5899 - auc_roc: 0.9760
Epoch 8/80
1651/1651 [==============================] - 3s 2ms/step - loss: 0.9539 - acc: 0.6008 - auc_roc: 0.9759
Epoch 9/80
1651/1651 [==============================] - 3s 2ms/step - loss: 0.9103 - acc: 0.5936 - auc_roc: 0.9759
Epoch 10/80
1651/1651 [==============================] - 3s 2ms/step - loss: 0.8679 - acc: 0.6081 - auc_roc: 0.9758
Epoch 11/80
1651/1651 [==============================] - 3s 2ms/step - loss: 0.7439 - acc: 0.6548 - auc_roc: 0.9757
Epoch 12/80
1651/1651 [==============================] - 3s 2ms/step - loss: 0.7406 - acc: 0.6766 - auc_roc: 0.9757
Epoch 13/80
1651/1651 [==============================] - 3s 2ms/step - loss: 0.7096 - acc: 0.6747 - auc_roc: 0.9756
Epoch 14/80
1651/1651 [==============================] - 3s 2ms/step - loss: 0.6989 - acc: 0.6875 - auc_roc: 0.9756
Epoch 15/80
1651/1651 [==============================] - 3s 2ms/step - loss: 0.6255 - acc: 0.6941 - auc_roc: 0.9755
Epoch 16/80
1651/1651 [==============================] - 3s 2ms/step - loss: 0.5723 - acc: 0.7196 - auc_roc: 0.9755
Epoch 17/80
1651/1651 [==============================] - 3s 2ms/step - loss: 0.5560 - acc: 0.7305 - auc_roc: 0.9755
Epoch 18/80
1651/1651 [==============================] - 3s 2ms/step - loss: 0.5516 - acc: 0.7408 - auc_roc: 0.9755
Epoch 19/80
1651/1651 [==============================] - 3s 2ms/step - loss: 0.5029 - acc: 0.7420 - auc_roc: 0.9754
Epoch 20/80
1651/1651 [==============================] - 3s 2ms/step - loss: 0.4725 - acc: 0.7559 - auc_roc: 0.9754
Epoch 21/80
1651/1651 [==============================] - 3s 2ms/step - loss: 0.4526 - acc: 0.7723 - auc_roc: 0.9754
Epoch 22/80
1651/1651 [==============================] - 3s 2ms/step - loss: 0.4588 - acc: 0.7741 - auc_roc: 0.9754
Epoch 23/80
1651/1651 [==============================] - 3s 2ms/step - loss: 0.5852 - acc: 0.7359 - auc_roc: 0.9754
Epoch 24/80
1651/1651 [==============================] - 3s 2ms/step - loss: 0.5268 - acc: 0.7498 - auc_roc: 0.9754
Epoch 25/80
1651/1651 [==============================] - 3s 2ms/step - loss: 0.4593 - acc: 0.7838 - auc_roc: 0.9754
Epoch 26/80
1651/1651 [==============================] - 3s 2ms/step - loss: 0.4387 - acc: 0.7710 - auc_roc: 0.9753
Epoch 27/80
1651/1651 [==============================] - 3s 2ms/step - loss: 0.3690 - acc: 0.8177 - auc_roc: 0.9753
Epoch 28/80
1651/1651 [==============================] - 3s 2ms/step - loss: 0.3493 - acc: 0.8262 - auc_roc: 0.9753
Epoch 29/80
1651/1651 [==============================] - 3s 2ms/step - loss: 0.3234 - acc: 0.8413 - auc_roc: 0.9753
Epoch 30/80
1651/1651 [==============================] - 3s 2ms/step - loss: 0.3681 - acc: 0.8304 - auc_roc: 0.9754
Epoch 31/80
1651/1651 [==============================] - 3s 2ms/step - loss: 0.5802 - acc: 0.7414 - auc_roc: 0.9754
Epoch 32/80
1651/1651 [==============================] - 3s 2ms/step - loss: 0.5429 - acc: 0.7498 - auc_roc: 0.9753
Epoch 33/80
1651/1651 [==============================] - 3s 2ms/step - loss: 0.4642 - acc: 0.7929 - auc_roc: 0.9753
Epoch 34/80
1651/1651 [==============================] - 3s 2ms/step - loss: 0.3626 - acc: 0.8201 - auc_roc: 0.9753
Epoch 35/80
1651/1651 [==============================] - 3s 2ms/step - loss: 0.2958 - acc: 0.8540 - auc_roc: 0.9753
Epoch 36/80
1651/1651 [==============================] - 3s 2ms/step - loss: 0.2694 - acc: 0.8667 - auc_roc: 0.9753
Epoch 37/80
1651/1651 [==============================] - 3s 2ms/step - loss: 0.2766 - acc: 0.8710 - auc_roc: 0.9754
Epoch 38/80
1651/1651 [==============================] - 3s 2ms/step - loss: 0.2597 - acc: 0.8764 - auc_roc: 0.9754
Epoch 39/80
1651/1651 [==============================] - 3s 2ms/step - loss: 0.2103 - acc: 0.9019 - auc_roc: 0.9754
Epoch 40/80
1651/1651 [==============================] - 3s 2ms/step - loss: 0.2042 - acc: 0.9019 - auc_roc: 0.9754
Epoch 41/80
1651/1651 [==============================] - 3s 2ms/step - loss: 0.1863 - acc: 0.9128 - auc_roc: 0.9755
Epoch 42/80
1651/1651 [==============================] - 3s 2ms/step - loss: 0.1953 - acc: 0.9152 - auc_roc: 0.9755
Epoch 43/80
1651/1651 [==============================] - 3s 2ms/step - loss: 0.1522 - acc: 0.9297 - auc_roc: 0.9755
Epoch 44/80
1651/1651 [==============================] - 3s 2ms/step - loss: 0.1399 - acc: 0.9340 - auc_roc: 0.9756
Epoch 45/80
1651/1651 [==============================] - 3s 2ms/step - loss: 0.1285 - acc: 0.9443 - auc_roc: 0.9756
Epoch 46/80
1651/1651 [==============================] - 3s 2ms/step - loss: 0.1202 - acc: 0.9461 - auc_roc: 0.9756
Epoch 47/80
1651/1651 [==============================] - 3s 2ms/step - loss: 0.2574 - acc: 0.8740 - auc_roc: 0.9757
Epoch 48/80
1651/1651 [==============================] - 3s 2ms/step - loss: 0.1566 - acc: 0.9316 - auc_roc: 0.9757
Epoch 49/80
1651/1651 [==============================] - 3s 2ms/step - loss: 0.1102 - acc: 0.9485 - auc_roc: 0.9757
Epoch 50/80
1651/1651 [==============================] - 3s 2ms/step - loss: 0.0993 - acc: 0.9552 - auc_roc: 0.9758
Epoch 51/80
1651/1651 [==============================] - 3s 2ms/step - loss: 0.0784 - acc: 0.9649 - auc_roc: 0.9758
Epoch 52/80
1651/1651 [==============================] - 3s 2ms/step - loss: 0.2787 - acc: 0.8861 - auc_roc: 0.9759
Epoch 53/80
1651/1651 [==============================] - 3s 2ms/step - loss: 0.3805 - acc: 0.8516 - auc_roc: 0.9759
Epoch 54/80
1651/1651 [==============================] - 3s 2ms/step - loss: 0.1847 - acc: 0.9243 - auc_roc: 0.9759
Epoch 55/80
1651/1651 [==============================] - 3s 2ms/step - loss: 0.1284 - acc: 0.9431 - auc_roc: 0.9759
Epoch 56/80
1651/1651 [==============================] - 3s 2ms/step - loss: 0.0894 - acc: 0.9631 - auc_roc: 0.9760
Epoch 57/80
1651/1651 [==============================] - 3s 2ms/step - loss: 0.0763 - acc: 0.9697 - auc_roc: 0.9760
Epoch 58/80
1651/1651 [==============================] - 3s 2ms/step - loss: 0.0849 - acc: 0.9679 - auc_roc: 0.9761
Epoch 59/80
1651/1651 [==============================] - 3s 2ms/step - loss: 0.0731 - acc: 0.9746 - auc_roc: 0.9761
Epoch 60/80
1651/1651 [==============================] - 3s 2ms/step - loss: 0.0577 - acc: 0.9752 - auc_roc: 0.9762
Epoch 61/80
1651/1651 [==============================] - 3s 2ms/step - loss: 0.0493 - acc: 0.9867 - auc_roc: 0.9762
Epoch 62/80
1651/1651 [==============================] - 3s 2ms/step - loss: 0.0503 - acc: 0.9843 - auc_roc: 0.9763
Epoch 63/80
1651/1651 [==============================] - 3s 2ms/step - loss: 0.0713 - acc: 0.9727 - auc_roc: 0.9763
Epoch 64/80
1651/1651 [==============================] - 3s 2ms/step - loss: 0.0531 - acc: 0.9824 - auc_roc: 0.9764
Epoch 65/80
1651/1651 [==============================] - 3s 2ms/step - loss: 0.0393 - acc: 0.9885 - auc_roc: 0.9764
Epoch 66/80
1651/1651 [==============================] - 3s 2ms/step - loss: 0.0549 - acc: 0.9836 - auc_roc: 0.9765
Epoch 67/80
1651/1651 [==============================] - 3s 2ms/step - loss: 0.0344 - acc: 0.9891 - auc_roc: 0.9765
Epoch 68/80
1651/1651 [==============================] - 3s 2ms/step - loss: 0.0188 - acc: 0.9982 - auc_roc: 0.9766
Epoch 69/80
1651/1651 [==============================] - 3s 2ms/step - loss: 0.0208 - acc: 0.9933 - auc_roc: 0.9766
Epoch 70/80
1651/1651 [==============================] - 3s 2ms/step - loss: 0.1471 - acc: 0.9455 - auc_roc: 0.9767
Epoch 71/80
1651/1651 [==============================] - 3s 2ms/step - loss: 0.0903 - acc: 0.9576 - auc_roc: 0.9767
Epoch 72/80
1651/1651 [==============================] - 3s 2ms/step - loss: 0.0457 - acc: 0.9855 - auc_roc: 0.9768
Epoch 73/80
1651/1651 [==============================] - 3s 2ms/step - loss: 0.0270 - acc: 0.9964 - auc_roc: 0.9768
Epoch 74/80
1651/1651 [==============================] - 3s 2ms/step - loss: 0.0202 - acc: 0.9958 - auc_roc: 0.9769
Epoch 75/80
1651/1651 [==============================] - 3s 2ms/step - loss: 0.0222 - acc: 0.9933 - auc_roc: 0.9769
Epoch 76/80
1651/1651 [==============================] - 3s 2ms/step - loss: 0.0206 - acc: 0.9939 - auc_roc: 0.9770
Epoch 77/80
1651/1651 [==============================] - 3s 2ms/step - loss: 0.0159 - acc: 0.9964 - auc_roc: 0.9770
Epoch 78/80
1651/1651 [==============================] - 3s 2ms/step - loss: 0.0132 - acc: 0.9988 - auc_roc: 0.9771
Epoch 79/80
1651/1651 [==============================] - 3s 2ms/step - loss: 0.0127 - acc: 0.9970 - auc_roc: 0.9771
Epoch 80/80
1651/1651 [==============================] - 3s 2ms/step - loss: 0.0128 - acc: 0.9982 - auc_roc: 0.9772
... history of metrics comprising: ['acc', 'loss', 'auc_roc']
... model fitting complete > starting model evaluation
modelEvaluate> scores:
[('loss', 2.7673042792359261), ('acc', 0.57968970389224916), ('auc_roc', 0.977156751330716)]

info> infer classifier name from class name ...
runROCMulticlass> find 6 unique labels:
CKD Stage 1, CKD Stage 2, CKD Stage 3, CKD Stage 4, CKD Stage 5, Others

info> given pre-trained model ...
diagnosis> dim(y_score):(709, 6)
>>> test_auc_cv_metrics >>>
  + dimension test 
  + len(roc_auc):8 =?= n_classes (+{micro, macro}):6+2
  + class name: CKD Stage 1, mean_auc: 0.854462
  + ROC curve of class CKD Stage 1 (area = 0.85)
  + class name: CKD Stage 2, mean_auc: 0.740793
  + ROC curve of class CKD Stage 2 (area = 0.74)
  + class name: CKD Stage 3, mean_auc: 0.761361
  + ROC curve of class CKD Stage 3 (area = 0.76)
  + class name: CKD Stage 4, mean_auc: 0.743326
  + ROC curve of class CKD Stage 4 (area = 0.74)
  + class name: CKD Stage 5, mean_auc: 0.952343
  + ROC curve of class CKD Stage 5 (area = 0.95)
  + class name: Others, mean_auc: 0.836037
  + ROC curve of class Others (area = 0.84)
test_auc_cv_metrics> summary of AUCs vs classes ...
  + min | class=CKD Stage 2, auc=0.740793
  + max | class=CKD Stage 5, auc=0.952343
  + micro auc=0.864011 | macro auc=0.815634
  + Ranked AUC scores: 
    + class=CKD Stage 2, auc=0.740793
    + class=CKD Stage 4, auc=0.743326
    + class=CKD Stage 3, auc=0.761361
    + class=Others, auc=0.836037
    + class=CKD Stage 1, auc=0.854462
    + class=CKD Stage 5, auc=0.952343
  => [('CKD Stage 2', 0.74079327811474172), ('CKD Stage 4', 0.74332611832611839), ('CKD Stage 3', 0.76136106395019798), ('Others', 0.83603703272388497), ('CKD Stage 1', 0.85446224256292902), ('CKD Stage 5', 0.95234252471094571)]
output> saving performance to:
/Users/pleiades/Documents/work/tpheno/seqmaker/data/CKD/plot/roc-multiclass-Sequential-CKD-pv-dm2-regular-smallCKD.tif

analyze_perf> min => 
Counter({'CKD Stage 4': 6, 'CKD Stage 3': 3, 'CKD Stage 2': 1})

analyze_perf> max => 
Counter({'CKD Stage 5': 10})

result> min(label: CKD Stage 4, score: 0.695957), err: (0.62799389778794812, 0.74714285714285711)
        max(label: CKD Stage 5, score: 0.951754), err: (0.9412979613638387, 0.96163785090165455)
result> other performance metrics ...
    + metric=micro => 0.864231 (err: (0.85177955800995053, 0.87767132634812139))
    + metric=macro => 0.808338 (err: (0.78820236319878934, 0.82296970213688814))
    + metric=loss => 2.368048 (err: (1.9026417594366249, 2.8642688389389406))
    + metric=acc => 0.582623 (err: (0.55007052202991435, 0.60225669966093742))
    + metric=auc_roc => 0.976080 (err: (0.9742259369750621, 0.98063528705887459))
pleiades@~/Documents/work/tpheno/seqmaker\:) 
